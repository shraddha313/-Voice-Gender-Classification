{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np \n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch # import PyTorch\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'F:\\dataset_sri' # Replace with the directory path containing the .m4a files\n",
    "\n",
    "# Identify the missing file number\n",
    "missing_file_number = 163\n",
    "\n",
    "# Get a sorted list of all .m4a files in the directory\n",
    "all_files = sorted(os.listdir(directory), key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "for file in all_files:\n",
    "    # Extract the file number from the file name\n",
    "    file_number = int(file.split('.')[0])\n",
    "    # If the file number is greater than the missing file number, decrement the file number\n",
    "    if file_number > missing_file_number:\n",
    "        new_file_number = file_number - 1\n",
    "        new_file_name = f'{new_file_number}.m4a'\n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(directory, file), os.path.join(directory, new_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spafe.features.gfcc import gfcc\n",
    "from spafe.utils import vis\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np \n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch # import PyTorch\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'F:\\dataset_sri'\n",
    "output_directory= r'F:\\dains'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "def extract_mfcc(file_name):\n",
    "    # Convert m4a file to wav            \n",
    "    audio = AudioSegment.from_file(file_name)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "    data, samplerate = sf.read(\"temp.wav\")\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=samplerate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    \n",
    "    return mfccs_processed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # replace with your output directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "\n",
    "\n",
    "for file in wav_files:\n",
    "    mfccs = extract_mfcc(file)\n",
    "    \n",
    "    # Convert array to torch tensor\n",
    "    mfccs = torch.tensor(mfccs)\n",
    "\n",
    "    # Construct output file name by replacing .wav with .pt and changing the directory\n",
    "    output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "    \n",
    "    # Save to a PyTorch file (.pt)\n",
    "    torch.save(mfccs, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'F:\\dains' # Replace with the directory path containing the .m4a files\n",
    "\n",
    "# Identify the missing file number\n",
    "missing_file_number = 163\n",
    "\n",
    "# Get a sorted list of all .m4a files in the directory\n",
    "all_files = sorted(os.listdir(directory), key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "for file in all_files:\n",
    "    # Extract the file number from the file name\n",
    "    file_number = int(file.split('.')[0])\n",
    "    # If the file number is greater than the missing file number, decrement the file number\n",
    "    if file_number > missing_file_number:\n",
    "        new_file_number = file_number - 1\n",
    "        new_file_name = f'{new_file_number}.pt'\n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(directory, file), os.path.join(directory, new_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'F:\\data' # Replace with the directory path containing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'F:\\dataset_sri'\n",
    "output_directory= r'F:\\dataset_feature'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "def extract_mfcc(file_name):\n",
    "    # Convert m4a file to wav            \n",
    "    audio = AudioSegment.from_file(file_name)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "    data, samplerate = sf.read(\"temp.wav\")\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=samplerate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    \n",
    "    return mfccs_processed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # replace with your output directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "\n",
    "\n",
    "for file in wav_files:\n",
    "    mfccs = extract_mfcc(file)\n",
    "    \n",
    "    # Convert array to torch tensor\n",
    "    mfccs = torch.tensor(mfccs)\n",
    "\n",
    "    # Construct output file name by replacing .wav with .pt and changing the directory\n",
    "    output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "    \n",
    "    # Save to a PyTorch file (.pt)\n",
    "    torch.save(mfccs, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import fnmatch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(file_path, output_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "def extract_melscale_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "    return mels_db.flatten() # Flatten the feature array\n",
    "\n",
    "def extract_melspectrogram(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    return spectrogram.flatten() # Flatten the spectrogram\n",
    "\n",
    "def extract_audio_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    # Change here: Find max pitch for each frame and then take their mean as overall pitch\n",
    "    pitch = np.mean([pitch[magnitude.argmax()] for pitch, magnitude in zip(pitches, magnitudes)])\n",
    "    fft = np.abs(np.fft.fft(y))[:len(y)//2]\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.hstack([mfccs.mean(axis=1), spectral_centroids.mean(), spectral_rolloff.mean(), zero_crossing_rate.mean(), pitch, fft.mean()])\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\dataset_sri\\0.m4a\n",
      "F:\\dataset_sri\\1.m4a\n",
      "F:\\dataset_sri\\10.m4a\n",
      "F:\\dataset_sri\\100.m4a\n",
      "F:\\dataset_sri\\1000.m4a\n",
      "F:\\dataset_sri\\1001.m4a\n",
      "F:\\dataset_sri\\1002.m4a\n",
      "F:\\dataset_sri\\1003.m4a\n",
      "F:\\dataset_sri\\1004.m4a\n",
      "F:\\dataset_sri\\1005.m4a\n",
      "F:\\dataset_sri\\1006.m4a\n",
      "F:\\dataset_sri\\1007.m4a\n",
      "F:\\dataset_sri\\1008.m4a\n",
      "F:\\dataset_sri\\1009.m4a\n",
      "F:\\dataset_sri\\101.m4a\n",
      "F:\\dataset_sri\\1010.m4a\n",
      "F:\\dataset_sri\\1011.m4a\n",
      "F:\\dataset_sri\\1012.m4a\n",
      "F:\\dataset_sri\\1013.m4a\n",
      "F:\\dataset_sri\\1014.m4a\n",
      "F:\\dataset_sri\\1015.m4a\n",
      "F:\\dataset_sri\\1016.m4a\n",
      "F:\\dataset_sri\\1017.m4a\n",
      "F:\\dataset_sri\\1018.m4a\n",
      "F:\\dataset_sri\\1019.m4a\n",
      "F:\\dataset_sri\\102.m4a\n",
      "F:\\dataset_sri\\1020.m4a\n",
      "F:\\dataset_sri\\1021.m4a\n",
      "F:\\dataset_sri\\1022.m4a\n",
      "F:\\dataset_sri\\1023.m4a\n",
      "F:\\dataset_sri\\1024.m4a\n",
      "F:\\dataset_sri\\1025.m4a\n",
      "F:\\dataset_sri\\1026.m4a\n",
      "F:\\dataset_sri\\1027.m4a\n",
      "F:\\dataset_sri\\1028.m4a\n",
      "F:\\dataset_sri\\1029.m4a\n",
      "F:\\dataset_sri\\103.m4a\n",
      "F:\\dataset_sri\\1030.m4a\n",
      "F:\\dataset_sri\\1031.m4a\n",
      "F:\\dataset_sri\\1032.m4a\n",
      "F:\\dataset_sri\\1033.m4a\n",
      "F:\\dataset_sri\\1034.m4a\n",
      "F:\\dataset_sri\\1035.m4a\n",
      "F:\\dataset_sri\\1036.m4a\n",
      "F:\\dataset_sri\\1037.m4a\n",
      "F:\\dataset_sri\\1038.m4a\n",
      "F:\\dataset_sri\\1039.m4a\n",
      "F:\\dataset_sri\\104.m4a\n",
      "F:\\dataset_sri\\1040.m4a\n",
      "F:\\dataset_sri\\1041.m4a\n",
      "F:\\dataset_sri\\1042.m4a\n",
      "F:\\dataset_sri\\1043.m4a\n",
      "F:\\dataset_sri\\1044.m4a\n",
      "F:\\dataset_sri\\1045.m4a\n",
      "F:\\dataset_sri\\1046.m4a\n",
      "F:\\dataset_sri\\1047.m4a\n",
      "F:\\dataset_sri\\1048.m4a\n",
      "F:\\dataset_sri\\1049.m4a\n",
      "F:\\dataset_sri\\105.m4a\n",
      "F:\\dataset_sri\\1050.m4a\n",
      "F:\\dataset_sri\\1051.m4a\n",
      "F:\\dataset_sri\\1052.m4a\n",
      "F:\\dataset_sri\\1053.m4a\n",
      "F:\\dataset_sri\\1054.m4a\n",
      "F:\\dataset_sri\\1055.m4a\n",
      "F:\\dataset_sri\\1056.m4a\n",
      "F:\\dataset_sri\\1057.m4a\n",
      "F:\\dataset_sri\\1058.m4a\n",
      "F:\\dataset_sri\\1059.m4a\n",
      "F:\\dataset_sri\\106.m4a\n",
      "F:\\dataset_sri\\1060.m4a\n",
      "F:\\dataset_sri\\1061.m4a\n",
      "F:\\dataset_sri\\1062.m4a\n",
      "F:\\dataset_sri\\1063.m4a\n",
      "F:\\dataset_sri\\1064.m4a\n",
      "F:\\dataset_sri\\1065.m4a\n",
      "F:\\dataset_sri\\1066.m4a\n",
      "F:\\dataset_sri\\1067.m4a\n",
      "F:\\dataset_sri\\1068.m4a\n",
      "F:\\dataset_sri\\1069.m4a\n",
      "F:\\dataset_sri\\107.m4a\n",
      "F:\\dataset_sri\\1070.m4a\n",
      "F:\\dataset_sri\\1071.m4a\n",
      "F:\\dataset_sri\\1072.m4a\n",
      "F:\\dataset_sri\\1073.m4a\n",
      "F:\\dataset_sri\\1074.m4a\n",
      "F:\\dataset_sri\\1075.m4a\n",
      "F:\\dataset_sri\\1076.m4a\n",
      "F:\\dataset_sri\\1077.m4a\n",
      "F:\\dataset_sri\\1078.m4a\n",
      "F:\\dataset_sri\\1079.m4a\n",
      "F:\\dataset_sri\\108.m4a\n",
      "F:\\dataset_sri\\1080.m4a\n",
      "F:\\dataset_sri\\1081.m4a\n",
      "F:\\dataset_sri\\1082.m4a\n",
      "F:\\dataset_sri\\1083.m4a\n",
      "F:\\dataset_sri\\1084.m4a\n",
      "F:\\dataset_sri\\1085.m4a\n",
      "F:\\dataset_sri\\1086.m4a\n",
      "F:\\dataset_sri\\1087.m4a\n",
      "F:\\dataset_sri\\1088.m4a\n",
      "F:\\dataset_sri\\1089.m4a\n",
      "F:\\dataset_sri\\109.m4a\n",
      "F:\\dataset_sri\\1090.m4a\n",
      "F:\\dataset_sri\\1091.m4a\n",
      "F:\\dataset_sri\\1092.m4a\n",
      "F:\\dataset_sri\\1093.m4a\n",
      "F:\\dataset_sri\\1094.m4a\n",
      "F:\\dataset_sri\\1095.m4a\n",
      "F:\\dataset_sri\\1096.m4a\n",
      "F:\\dataset_sri\\1097.m4a\n",
      "F:\\dataset_sri\\1098.m4a\n",
      "F:\\dataset_sri\\1099.m4a\n",
      "F:\\dataset_sri\\11.m4a\n",
      "F:\\dataset_sri\\110.m4a\n",
      "F:\\dataset_sri\\1100.m4a\n",
      "F:\\dataset_sri\\1101.m4a\n",
      "F:\\dataset_sri\\1102.m4a\n",
      "F:\\dataset_sri\\1103.m4a\n",
      "F:\\dataset_sri\\1104.m4a\n",
      "F:\\dataset_sri\\1105.m4a\n",
      "F:\\dataset_sri\\1106.m4a\n",
      "F:\\dataset_sri\\1107.m4a\n",
      "F:\\dataset_sri\\1108.m4a\n",
      "F:\\dataset_sri\\1109.m4a\n",
      "F:\\dataset_sri\\111.m4a\n",
      "F:\\dataset_sri\\1110.m4a\n",
      "F:\\dataset_sri\\1111.m4a\n",
      "F:\\dataset_sri\\1112.m4a\n",
      "F:\\dataset_sri\\1113.m4a\n",
      "F:\\dataset_sri\\1114.m4a\n",
      "F:\\dataset_sri\\1115.m4a\n",
      "F:\\dataset_sri\\1116.m4a\n",
      "F:\\dataset_sri\\1117.m4a\n",
      "F:\\dataset_sri\\1118.m4a\n",
      "F:\\dataset_sri\\1119.m4a\n",
      "F:\\dataset_sri\\112.m4a\n",
      "F:\\dataset_sri\\1120.m4a\n",
      "F:\\dataset_sri\\1121.m4a\n",
      "F:\\dataset_sri\\1122.m4a\n",
      "F:\\dataset_sri\\1123.m4a\n",
      "F:\\dataset_sri\\1124.m4a\n",
      "F:\\dataset_sri\\1125.m4a\n",
      "F:\\dataset_sri\\1126.m4a\n",
      "F:\\dataset_sri\\1127.m4a\n",
      "F:\\dataset_sri\\1128.m4a\n",
      "F:\\dataset_sri\\1129.m4a\n",
      "F:\\dataset_sri\\113.m4a\n",
      "F:\\dataset_sri\\1130.m4a\n",
      "F:\\dataset_sri\\1131.m4a\n",
      "F:\\dataset_sri\\1132.m4a\n",
      "F:\\dataset_sri\\1133.m4a\n",
      "F:\\dataset_sri\\1134.m4a\n",
      "F:\\dataset_sri\\1135.m4a\n",
      "F:\\dataset_sri\\1136.m4a\n",
      "F:\\dataset_sri\\1137.m4a\n",
      "F:\\dataset_sri\\1138.m4a\n",
      "F:\\dataset_sri\\1139.m4a\n",
      "F:\\dataset_sri\\114.m4a\n",
      "F:\\dataset_sri\\1140.m4a\n",
      "F:\\dataset_sri\\1141.m4a\n",
      "F:\\dataset_sri\\1142.m4a\n",
      "F:\\dataset_sri\\1143.m4a\n",
      "F:\\dataset_sri\\1144.m4a\n",
      "F:\\dataset_sri\\1145.m4a\n",
      "F:\\dataset_sri\\1146.m4a\n",
      "F:\\dataset_sri\\1147.m4a\n",
      "F:\\dataset_sri\\1148.m4a\n",
      "F:\\dataset_sri\\1149.m4a\n",
      "F:\\dataset_sri\\115.m4a\n",
      "F:\\dataset_sri\\1150.m4a\n",
      "F:\\dataset_sri\\1151.m4a\n",
      "F:\\dataset_sri\\1152.m4a\n",
      "F:\\dataset_sri\\1153.m4a\n",
      "F:\\dataset_sri\\1154.m4a\n",
      "F:\\dataset_sri\\1155.m4a\n",
      "F:\\dataset_sri\\1156.m4a\n",
      "F:\\dataset_sri\\1157.m4a\n",
      "F:\\dataset_sri\\1158.m4a\n",
      "F:\\dataset_sri\\1159.m4a\n",
      "F:\\dataset_sri\\116.m4a\n",
      "F:\\dataset_sri\\1160.m4a\n",
      "F:\\dataset_sri\\1161.m4a\n",
      "F:\\dataset_sri\\1162.m4a\n",
      "F:\\dataset_sri\\1163.m4a\n",
      "F:\\dataset_sri\\1164.m4a\n",
      "F:\\dataset_sri\\1165.m4a\n",
      "F:\\dataset_sri\\1166.m4a\n",
      "F:\\dataset_sri\\1167.m4a\n",
      "F:\\dataset_sri\\1168.m4a\n",
      "F:\\dataset_sri\\1169.m4a\n",
      "F:\\dataset_sri\\117.m4a\n",
      "F:\\dataset_sri\\1170.m4a\n",
      "F:\\dataset_sri\\1171.m4a\n",
      "F:\\dataset_sri\\1172.m4a\n",
      "F:\\dataset_sri\\1173.m4a\n",
      "F:\\dataset_sri\\1174.m4a\n",
      "F:\\dataset_sri\\1175.m4a\n",
      "F:\\dataset_sri\\1176.m4a\n",
      "F:\\dataset_sri\\1177.m4a\n",
      "F:\\dataset_sri\\1178.m4a\n",
      "F:\\dataset_sri\\1179.m4a\n",
      "F:\\dataset_sri\\118.m4a\n",
      "F:\\dataset_sri\\1180.m4a\n",
      "F:\\dataset_sri\\1181.m4a\n",
      "F:\\dataset_sri\\1182.m4a\n",
      "F:\\dataset_sri\\1183.m4a\n",
      "F:\\dataset_sri\\1184.m4a\n",
      "F:\\dataset_sri\\1185.m4a\n",
      "F:\\dataset_sri\\1186.m4a\n",
      "F:\\dataset_sri\\1187.m4a\n",
      "F:\\dataset_sri\\1188.m4a\n",
      "F:\\dataset_sri\\1189.m4a\n",
      "F:\\dataset_sri\\119.m4a\n",
      "F:\\dataset_sri\\1190.m4a\n",
      "F:\\dataset_sri\\1191.m4a\n",
      "F:\\dataset_sri\\1192.m4a\n",
      "F:\\dataset_sri\\1193.m4a\n",
      "F:\\dataset_sri\\1194.m4a\n",
      "F:\\dataset_sri\\1195.m4a\n",
      "F:\\dataset_sri\\1196.m4a\n",
      "F:\\dataset_sri\\1197.m4a\n",
      "F:\\dataset_sri\\1198.m4a\n",
      "F:\\dataset_sri\\1199.m4a\n",
      "F:\\dataset_sri\\12.m4a\n",
      "F:\\dataset_sri\\120.m4a\n",
      "F:\\dataset_sri\\1200.m4a\n",
      "F:\\dataset_sri\\1201.m4a\n",
      "F:\\dataset_sri\\1202.m4a\n",
      "F:\\dataset_sri\\1203.m4a\n",
      "F:\\dataset_sri\\1204.m4a\n",
      "F:\\dataset_sri\\1205.m4a\n",
      "F:\\dataset_sri\\1206.m4a\n",
      "F:\\dataset_sri\\1207.m4a\n",
      "F:\\dataset_sri\\1208.m4a\n",
      "F:\\dataset_sri\\1209.m4a\n",
      "F:\\dataset_sri\\121.m4a\n",
      "F:\\dataset_sri\\1210.m4a\n",
      "F:\\dataset_sri\\1211.m4a\n",
      "F:\\dataset_sri\\1212.m4a\n",
      "F:\\dataset_sri\\1213.m4a\n",
      "F:\\dataset_sri\\1214.m4a\n",
      "F:\\dataset_sri\\1215.m4a\n",
      "F:\\dataset_sri\\1216.m4a\n",
      "F:\\dataset_sri\\1217.m4a\n",
      "F:\\dataset_sri\\1218.m4a\n",
      "F:\\dataset_sri\\1219.m4a\n",
      "F:\\dataset_sri\\122.m4a\n",
      "F:\\dataset_sri\\1220.m4a\n",
      "F:\\dataset_sri\\1221.m4a\n",
      "F:\\dataset_sri\\1222.m4a\n",
      "F:\\dataset_sri\\1223.m4a\n",
      "F:\\dataset_sri\\1224.m4a\n",
      "F:\\dataset_sri\\1225.m4a\n",
      "F:\\dataset_sri\\1226.m4a\n",
      "F:\\dataset_sri\\1227.m4a\n",
      "F:\\dataset_sri\\1228.m4a\n",
      "F:\\dataset_sri\\1229.m4a\n",
      "F:\\dataset_sri\\123.m4a\n",
      "F:\\dataset_sri\\1230.m4a\n",
      "F:\\dataset_sri\\1231.m4a\n",
      "F:\\dataset_sri\\1232.m4a\n",
      "F:\\dataset_sri\\1233.m4a\n",
      "F:\\dataset_sri\\1234.m4a\n",
      "F:\\dataset_sri\\1235.m4a\n",
      "F:\\dataset_sri\\1236.m4a\n",
      "F:\\dataset_sri\\1237.m4a\n",
      "F:\\dataset_sri\\1238.m4a\n",
      "F:\\dataset_sri\\1239.m4a\n",
      "F:\\dataset_sri\\124.m4a\n",
      "F:\\dataset_sri\\1240.m4a\n",
      "F:\\dataset_sri\\1241.m4a\n",
      "F:\\dataset_sri\\1242.m4a\n",
      "F:\\dataset_sri\\1243.m4a\n",
      "F:\\dataset_sri\\1244.m4a\n",
      "F:\\dataset_sri\\1245.m4a\n",
      "F:\\dataset_sri\\1246.m4a\n",
      "F:\\dataset_sri\\1247.m4a\n",
      "F:\\dataset_sri\\1248.m4a\n",
      "F:\\dataset_sri\\1249.m4a\n",
      "F:\\dataset_sri\\125.m4a\n",
      "F:\\dataset_sri\\1250.m4a\n",
      "F:\\dataset_sri\\1251.m4a\n",
      "F:\\dataset_sri\\1252.m4a\n",
      "F:\\dataset_sri\\1253.m4a\n",
      "F:\\dataset_sri\\1254.m4a\n",
      "F:\\dataset_sri\\1255.m4a\n",
      "F:\\dataset_sri\\1256.m4a\n",
      "F:\\dataset_sri\\1257.m4a\n",
      "F:\\dataset_sri\\1258.m4a\n",
      "F:\\dataset_sri\\1259.m4a\n",
      "F:\\dataset_sri\\126.m4a\n",
      "F:\\dataset_sri\\1260.m4a\n",
      "F:\\dataset_sri\\1261.m4a\n",
      "F:\\dataset_sri\\1262.m4a\n",
      "F:\\dataset_sri\\1263.m4a\n",
      "F:\\dataset_sri\\1264.m4a\n",
      "F:\\dataset_sri\\1265.m4a\n",
      "F:\\dataset_sri\\1266.m4a\n",
      "F:\\dataset_sri\\1267.m4a\n",
      "F:\\dataset_sri\\1268.m4a\n",
      "F:\\dataset_sri\\1269.m4a\n",
      "F:\\dataset_sri\\127.m4a\n",
      "F:\\dataset_sri\\1270.m4a\n",
      "F:\\dataset_sri\\1271.m4a\n",
      "F:\\dataset_sri\\1272.m4a\n",
      "F:\\dataset_sri\\1273.m4a\n",
      "F:\\dataset_sri\\1274.m4a\n",
      "F:\\dataset_sri\\1275.m4a\n",
      "F:\\dataset_sri\\1276.m4a\n",
      "F:\\dataset_sri\\1277.m4a\n",
      "F:\\dataset_sri\\1278.m4a\n",
      "F:\\dataset_sri\\1279.m4a\n",
      "F:\\dataset_sri\\128.m4a\n",
      "F:\\dataset_sri\\1280.m4a\n",
      "F:\\dataset_sri\\1281.m4a\n",
      "F:\\dataset_sri\\1282.m4a\n",
      "F:\\dataset_sri\\1283.m4a\n",
      "F:\\dataset_sri\\1284.m4a\n",
      "F:\\dataset_sri\\1285.m4a\n",
      "F:\\dataset_sri\\1286.m4a\n",
      "F:\\dataset_sri\\1287.m4a\n",
      "F:\\dataset_sri\\1288.m4a\n",
      "F:\\dataset_sri\\1289.m4a\n",
      "F:\\dataset_sri\\129.m4a\n",
      "F:\\dataset_sri\\1290.m4a\n",
      "F:\\dataset_sri\\1291.m4a\n",
      "F:\\dataset_sri\\1292.m4a\n",
      "F:\\dataset_sri\\1293.m4a\n",
      "F:\\dataset_sri\\1294.m4a\n",
      "F:\\dataset_sri\\1295.m4a\n",
      "F:\\dataset_sri\\1296.m4a\n",
      "F:\\dataset_sri\\1297.m4a\n",
      "F:\\dataset_sri\\1298.m4a\n",
      "F:\\dataset_sri\\1299.m4a\n",
      "F:\\dataset_sri\\13.m4a\n",
      "F:\\dataset_sri\\130.m4a\n",
      "F:\\dataset_sri\\1300.m4a\n",
      "F:\\dataset_sri\\1301.m4a\n",
      "F:\\dataset_sri\\1302.m4a\n",
      "F:\\dataset_sri\\1303.m4a\n",
      "F:\\dataset_sri\\1304.m4a\n",
      "F:\\dataset_sri\\1305.m4a\n",
      "F:\\dataset_sri\\1306.m4a\n",
      "F:\\dataset_sri\\1307.m4a\n",
      "F:\\dataset_sri\\1308.m4a\n",
      "F:\\dataset_sri\\1309.m4a\n",
      "F:\\dataset_sri\\131.m4a\n",
      "F:\\dataset_sri\\1310.m4a\n",
      "F:\\dataset_sri\\1311.m4a\n",
      "F:\\dataset_sri\\1312.m4a\n",
      "F:\\dataset_sri\\1313.m4a\n",
      "F:\\dataset_sri\\1314.m4a\n",
      "F:\\dataset_sri\\1315.m4a\n",
      "F:\\dataset_sri\\1316.m4a\n",
      "F:\\dataset_sri\\1317.m4a\n",
      "F:\\dataset_sri\\1318.m4a\n",
      "F:\\dataset_sri\\1319.m4a\n",
      "F:\\dataset_sri\\132.m4a\n",
      "F:\\dataset_sri\\1320.m4a\n",
      "F:\\dataset_sri\\1321.m4a\n",
      "F:\\dataset_sri\\1322.m4a\n",
      "F:\\dataset_sri\\1323.m4a\n",
      "F:\\dataset_sri\\1324.m4a\n",
      "F:\\dataset_sri\\1325.m4a\n",
      "F:\\dataset_sri\\1326.m4a\n",
      "F:\\dataset_sri\\1327.m4a\n",
      "F:\\dataset_sri\\1328.m4a\n",
      "F:\\dataset_sri\\1329.m4a\n",
      "F:\\dataset_sri\\133.m4a\n",
      "F:\\dataset_sri\\1330.m4a\n",
      "F:\\dataset_sri\\1331.m4a\n",
      "F:\\dataset_sri\\1332.m4a\n",
      "F:\\dataset_sri\\1333.m4a\n",
      "F:\\dataset_sri\\1334.m4a\n",
      "F:\\dataset_sri\\1335.m4a\n",
      "F:\\dataset_sri\\1336.m4a\n",
      "F:\\dataset_sri\\1337.m4a\n",
      "F:\\dataset_sri\\1338.m4a\n",
      "F:\\dataset_sri\\1339.m4a\n",
      "F:\\dataset_sri\\134.m4a\n",
      "F:\\dataset_sri\\1340.m4a\n",
      "F:\\dataset_sri\\1341.m4a\n",
      "F:\\dataset_sri\\1342.m4a\n",
      "F:\\dataset_sri\\1343.m4a\n",
      "F:\\dataset_sri\\1344.m4a\n",
      "F:\\dataset_sri\\1345.m4a\n",
      "F:\\dataset_sri\\1346.m4a\n",
      "F:\\dataset_sri\\1347.m4a\n",
      "F:\\dataset_sri\\1348.m4a\n",
      "F:\\dataset_sri\\1349.m4a\n",
      "F:\\dataset_sri\\135.m4a\n",
      "F:\\dataset_sri\\1350.m4a\n",
      "F:\\dataset_sri\\1351.m4a\n",
      "F:\\dataset_sri\\1352.m4a\n",
      "F:\\dataset_sri\\1353.m4a\n",
      "F:\\dataset_sri\\1354.m4a\n",
      "F:\\dataset_sri\\1355.m4a\n",
      "F:\\dataset_sri\\1356.m4a\n",
      "F:\\dataset_sri\\1357.m4a\n",
      "F:\\dataset_sri\\1358.m4a\n",
      "F:\\dataset_sri\\1359.m4a\n",
      "F:\\dataset_sri\\136.m4a\n",
      "F:\\dataset_sri\\1360.m4a\n",
      "F:\\dataset_sri\\1361.m4a\n",
      "F:\\dataset_sri\\1362.m4a\n",
      "F:\\dataset_sri\\1363.m4a\n",
      "F:\\dataset_sri\\1364.m4a\n",
      "F:\\dataset_sri\\1365.m4a\n",
      "F:\\dataset_sri\\1366.m4a\n",
      "F:\\dataset_sri\\1367.m4a\n",
      "F:\\dataset_sri\\1368.m4a\n",
      "F:\\dataset_sri\\1369.m4a\n",
      "F:\\dataset_sri\\137.m4a\n",
      "F:\\dataset_sri\\1370.m4a\n",
      "F:\\dataset_sri\\1371.m4a\n",
      "F:\\dataset_sri\\1372.m4a\n",
      "F:\\dataset_sri\\1373.m4a\n",
      "F:\\dataset_sri\\1374.m4a\n",
      "F:\\dataset_sri\\1375.m4a\n",
      "F:\\dataset_sri\\1376.m4a\n",
      "F:\\dataset_sri\\1377.m4a\n",
      "F:\\dataset_sri\\1378.m4a\n",
      "F:\\dataset_sri\\1379.m4a\n",
      "F:\\dataset_sri\\138.m4a\n",
      "F:\\dataset_sri\\1380.m4a\n",
      "F:\\dataset_sri\\1381.m4a\n",
      "F:\\dataset_sri\\1382.m4a\n",
      "F:\\dataset_sri\\1383.m4a\n",
      "F:\\dataset_sri\\1384.m4a\n",
      "F:\\dataset_sri\\1385.m4a\n",
      "F:\\dataset_sri\\1386.m4a\n",
      "F:\\dataset_sri\\1387.m4a\n",
      "F:\\dataset_sri\\1388.m4a\n",
      "F:\\dataset_sri\\1389.m4a\n",
      "F:\\dataset_sri\\139.m4a\n",
      "F:\\dataset_sri\\1390.m4a\n",
      "F:\\dataset_sri\\1391.m4a\n",
      "F:\\dataset_sri\\1392.m4a\n",
      "F:\\dataset_sri\\1393.m4a\n",
      "F:\\dataset_sri\\1394.m4a\n",
      "F:\\dataset_sri\\1395.m4a\n",
      "F:\\dataset_sri\\1396.m4a\n",
      "F:\\dataset_sri\\1397.m4a\n",
      "F:\\dataset_sri\\1398.m4a\n",
      "F:\\dataset_sri\\1399.m4a\n",
      "F:\\dataset_sri\\14.m4a\n",
      "F:\\dataset_sri\\140.m4a\n",
      "F:\\dataset_sri\\1400.m4a\n",
      "F:\\dataset_sri\\1401.m4a\n",
      "F:\\dataset_sri\\1402.m4a\n",
      "F:\\dataset_sri\\1403.m4a\n",
      "F:\\dataset_sri\\1404.m4a\n",
      "F:\\dataset_sri\\1405.m4a\n",
      "F:\\dataset_sri\\1406.m4a\n",
      "F:\\dataset_sri\\1407.m4a\n",
      "F:\\dataset_sri\\1408.m4a\n",
      "F:\\dataset_sri\\1409.m4a\n",
      "F:\\dataset_sri\\141.m4a\n",
      "F:\\dataset_sri\\1410.m4a\n",
      "F:\\dataset_sri\\1411.m4a\n",
      "F:\\dataset_sri\\1412.m4a\n",
      "F:\\dataset_sri\\1413.m4a\n",
      "F:\\dataset_sri\\1414.m4a\n",
      "F:\\dataset_sri\\1415.m4a\n",
      "F:\\dataset_sri\\1416.m4a\n",
      "F:\\dataset_sri\\1417.m4a\n",
      "F:\\dataset_sri\\1418.m4a\n",
      "F:\\dataset_sri\\1419.m4a\n",
      "F:\\dataset_sri\\142.m4a\n",
      "F:\\dataset_sri\\1420.m4a\n",
      "F:\\dataset_sri\\1421.m4a\n",
      "F:\\dataset_sri\\1422.m4a\n",
      "F:\\dataset_sri\\1423.m4a\n",
      "F:\\dataset_sri\\1424.m4a\n",
      "F:\\dataset_sri\\1425.m4a\n",
      "F:\\dataset_sri\\1426.m4a\n",
      "F:\\dataset_sri\\1427.m4a\n",
      "F:\\dataset_sri\\1428.m4a\n",
      "F:\\dataset_sri\\1429.m4a\n",
      "F:\\dataset_sri\\143.m4a\n",
      "F:\\dataset_sri\\1430.m4a\n",
      "F:\\dataset_sri\\1431.m4a\n",
      "F:\\dataset_sri\\1432.m4a\n",
      "F:\\dataset_sri\\1433.m4a\n",
      "F:\\dataset_sri\\1434.m4a\n",
      "F:\\dataset_sri\\1435.m4a\n",
      "F:\\dataset_sri\\1436.m4a\n",
      "F:\\dataset_sri\\1437.m4a\n",
      "F:\\dataset_sri\\1438.m4a\n",
      "F:\\dataset_sri\\1439.m4a\n",
      "F:\\dataset_sri\\144.m4a\n",
      "F:\\dataset_sri\\1440.m4a\n",
      "F:\\dataset_sri\\1441.m4a\n",
      "F:\\dataset_sri\\1442.m4a\n",
      "F:\\dataset_sri\\1443.m4a\n",
      "F:\\dataset_sri\\1444.m4a\n",
      "F:\\dataset_sri\\1445.m4a\n",
      "F:\\dataset_sri\\1446.m4a\n",
      "F:\\dataset_sri\\1447.m4a\n",
      "F:\\dataset_sri\\1448.m4a\n",
      "F:\\dataset_sri\\1449.m4a\n",
      "F:\\dataset_sri\\145.m4a\n",
      "F:\\dataset_sri\\1450.m4a\n",
      "F:\\dataset_sri\\1451.m4a\n",
      "F:\\dataset_sri\\1452.m4a\n",
      "F:\\dataset_sri\\1453.m4a\n",
      "F:\\dataset_sri\\1454.m4a\n",
      "F:\\dataset_sri\\1455.m4a\n",
      "F:\\dataset_sri\\1456.m4a\n",
      "F:\\dataset_sri\\1457.m4a\n",
      "F:\\dataset_sri\\1458.m4a\n",
      "F:\\dataset_sri\\1459.m4a\n",
      "F:\\dataset_sri\\146.m4a\n",
      "F:\\dataset_sri\\1460.m4a\n",
      "F:\\dataset_sri\\1461.m4a\n",
      "F:\\dataset_sri\\1462.m4a\n",
      "F:\\dataset_sri\\1463.m4a\n",
      "F:\\dataset_sri\\1464.m4a\n",
      "F:\\dataset_sri\\1465.m4a\n",
      "F:\\dataset_sri\\1466.m4a\n",
      "F:\\dataset_sri\\1467.m4a\n",
      "F:\\dataset_sri\\1468.m4a\n",
      "F:\\dataset_sri\\1469.m4a\n",
      "F:\\dataset_sri\\147.m4a\n",
      "F:\\dataset_sri\\1470.m4a\n",
      "F:\\dataset_sri\\1471.m4a\n",
      "F:\\dataset_sri\\1472.m4a\n",
      "F:\\dataset_sri\\1473.m4a\n",
      "F:\\dataset_sri\\1474.m4a\n",
      "F:\\dataset_sri\\1475.m4a\n",
      "F:\\dataset_sri\\1476.m4a\n",
      "F:\\dataset_sri\\1477.m4a\n",
      "F:\\dataset_sri\\1478.m4a\n",
      "F:\\dataset_sri\\1479.m4a\n",
      "F:\\dataset_sri\\148.m4a\n",
      "F:\\dataset_sri\\1480.m4a\n",
      "F:\\dataset_sri\\1481.m4a\n",
      "F:\\dataset_sri\\1482.m4a\n",
      "F:\\dataset_sri\\1483.m4a\n",
      "F:\\dataset_sri\\1484.m4a\n",
      "F:\\dataset_sri\\1485.m4a\n",
      "F:\\dataset_sri\\1486.m4a\n",
      "F:\\dataset_sri\\1487.m4a\n",
      "F:\\dataset_sri\\1488.m4a\n",
      "F:\\dataset_sri\\1489.m4a\n",
      "F:\\dataset_sri\\149.m4a\n",
      "F:\\dataset_sri\\1490.m4a\n",
      "F:\\dataset_sri\\1491.m4a\n",
      "F:\\dataset_sri\\1492.m4a\n",
      "F:\\dataset_sri\\1493.m4a\n",
      "F:\\dataset_sri\\1494.m4a\n",
      "F:\\dataset_sri\\1495.m4a\n",
      "F:\\dataset_sri\\1496.m4a\n",
      "F:\\dataset_sri\\1497.m4a\n",
      "F:\\dataset_sri\\1498.m4a\n",
      "F:\\dataset_sri\\1499.m4a\n",
      "F:\\dataset_sri\\15.m4a\n",
      "F:\\dataset_sri\\150.m4a\n",
      "F:\\dataset_sri\\1500.m4a\n",
      "F:\\dataset_sri\\1501.m4a\n",
      "F:\\dataset_sri\\1502.m4a\n",
      "F:\\dataset_sri\\1503.m4a\n",
      "F:\\dataset_sri\\1504.m4a\n",
      "F:\\dataset_sri\\1505.m4a\n",
      "F:\\dataset_sri\\1506.m4a\n",
      "F:\\dataset_sri\\1507.m4a\n",
      "F:\\dataset_sri\\1508.m4a\n",
      "F:\\dataset_sri\\1509.m4a\n",
      "F:\\dataset_sri\\151.m4a\n",
      "F:\\dataset_sri\\1510.m4a\n",
      "F:\\dataset_sri\\1511.m4a\n",
      "F:\\dataset_sri\\1512.m4a\n",
      "F:\\dataset_sri\\1513.m4a\n",
      "F:\\dataset_sri\\1514.m4a\n",
      "F:\\dataset_sri\\1515.m4a\n",
      "F:\\dataset_sri\\1516.m4a\n",
      "F:\\dataset_sri\\1517.m4a\n",
      "F:\\dataset_sri\\1518.m4a\n",
      "F:\\dataset_sri\\1519.m4a\n",
      "F:\\dataset_sri\\152.m4a\n",
      "F:\\dataset_sri\\1520.m4a\n",
      "F:\\dataset_sri\\1521.m4a\n",
      "F:\\dataset_sri\\1522.m4a\n",
      "F:\\dataset_sri\\1523.m4a\n",
      "F:\\dataset_sri\\1524.m4a\n",
      "F:\\dataset_sri\\1525.m4a\n",
      "F:\\dataset_sri\\1526.m4a\n",
      "F:\\dataset_sri\\1527.m4a\n",
      "F:\\dataset_sri\\1528.m4a\n",
      "F:\\dataset_sri\\1529.m4a\n",
      "F:\\dataset_sri\\153.m4a\n",
      "F:\\dataset_sri\\1530.m4a\n",
      "F:\\dataset_sri\\1531.m4a\n",
      "F:\\dataset_sri\\1532.m4a\n",
      "F:\\dataset_sri\\1533.m4a\n",
      "F:\\dataset_sri\\1534.m4a\n",
      "F:\\dataset_sri\\1535.m4a\n",
      "F:\\dataset_sri\\1536.m4a\n",
      "F:\\dataset_sri\\1537.m4a\n",
      "F:\\dataset_sri\\1538.m4a\n",
      "F:\\dataset_sri\\1539.m4a\n",
      "F:\\dataset_sri\\154.m4a\n",
      "F:\\dataset_sri\\1540.m4a\n",
      "F:\\dataset_sri\\1541.m4a\n",
      "F:\\dataset_sri\\1542.m4a\n",
      "F:\\dataset_sri\\1543.m4a\n",
      "F:\\dataset_sri\\1544.m4a\n",
      "F:\\dataset_sri\\1545.m4a\n",
      "F:\\dataset_sri\\1546.m4a\n",
      "F:\\dataset_sri\\1547.m4a\n",
      "F:\\dataset_sri\\1548.m4a\n",
      "F:\\dataset_sri\\1549.m4a\n",
      "F:\\dataset_sri\\155.m4a\n",
      "F:\\dataset_sri\\1550.m4a\n",
      "F:\\dataset_sri\\1551.m4a\n",
      "F:\\dataset_sri\\1552.m4a\n",
      "F:\\dataset_sri\\1553.m4a\n",
      "F:\\dataset_sri\\1554.m4a\n",
      "F:\\dataset_sri\\1555.m4a\n",
      "F:\\dataset_sri\\1556.m4a\n",
      "F:\\dataset_sri\\1557.m4a\n",
      "F:\\dataset_sri\\1558.m4a\n",
      "F:\\dataset_sri\\1559.m4a\n",
      "F:\\dataset_sri\\156.m4a\n",
      "F:\\dataset_sri\\1560.m4a\n",
      "F:\\dataset_sri\\1561.m4a\n",
      "F:\\dataset_sri\\1562.m4a\n",
      "F:\\dataset_sri\\1563.m4a\n",
      "F:\\dataset_sri\\1564.m4a\n",
      "F:\\dataset_sri\\1565.m4a\n",
      "F:\\dataset_sri\\1566.m4a\n",
      "F:\\dataset_sri\\1567.m4a\n",
      "F:\\dataset_sri\\1568.m4a\n",
      "F:\\dataset_sri\\1569.m4a\n",
      "F:\\dataset_sri\\157.m4a\n",
      "F:\\dataset_sri\\1570.m4a\n",
      "F:\\dataset_sri\\1571.m4a\n",
      "F:\\dataset_sri\\1572.m4a\n",
      "F:\\dataset_sri\\1573.m4a\n",
      "F:\\dataset_sri\\1574.m4a\n",
      "F:\\dataset_sri\\1575.m4a\n",
      "F:\\dataset_sri\\1576.m4a\n",
      "F:\\dataset_sri\\1577.m4a\n",
      "F:\\dataset_sri\\1578.m4a\n",
      "F:\\dataset_sri\\1579.m4a\n",
      "F:\\dataset_sri\\158.m4a\n",
      "F:\\dataset_sri\\1580.m4a\n",
      "F:\\dataset_sri\\1581.m4a\n",
      "F:\\dataset_sri\\1582.m4a\n",
      "F:\\dataset_sri\\1583.m4a\n",
      "F:\\dataset_sri\\1584.m4a\n",
      "F:\\dataset_sri\\1585.m4a\n",
      "F:\\dataset_sri\\1586.m4a\n",
      "F:\\dataset_sri\\1587.m4a\n",
      "F:\\dataset_sri\\1588.m4a\n",
      "F:\\dataset_sri\\1589.m4a\n",
      "F:\\dataset_sri\\159.m4a\n",
      "F:\\dataset_sri\\1590.m4a\n",
      "F:\\dataset_sri\\1591.m4a\n",
      "F:\\dataset_sri\\1592.m4a\n",
      "F:\\dataset_sri\\1593.m4a\n",
      "F:\\dataset_sri\\1594.m4a\n",
      "F:\\dataset_sri\\1595.m4a\n",
      "F:\\dataset_sri\\1596.m4a\n",
      "F:\\dataset_sri\\1597.m4a\n",
      "F:\\dataset_sri\\1598.m4a\n",
      "F:\\dataset_sri\\1599.m4a\n",
      "F:\\dataset_sri\\16.m4a\n",
      "F:\\dataset_sri\\160.m4a\n",
      "F:\\dataset_sri\\1600.m4a\n",
      "F:\\dataset_sri\\1601.m4a\n",
      "F:\\dataset_sri\\1602.m4a\n",
      "F:\\dataset_sri\\1603.m4a\n",
      "F:\\dataset_sri\\1604.m4a\n",
      "F:\\dataset_sri\\1605.m4a\n",
      "F:\\dataset_sri\\1606.m4a\n",
      "F:\\dataset_sri\\1607.m4a\n",
      "F:\\dataset_sri\\1608.m4a\n",
      "F:\\dataset_sri\\1609.m4a\n",
      "F:\\dataset_sri\\161.m4a\n",
      "F:\\dataset_sri\\1610.m4a\n",
      "F:\\dataset_sri\\1611.m4a\n",
      "F:\\dataset_sri\\1612.m4a\n",
      "F:\\dataset_sri\\1613.m4a\n",
      "F:\\dataset_sri\\1614.m4a\n",
      "F:\\dataset_sri\\1615.m4a\n",
      "F:\\dataset_sri\\1616.m4a\n",
      "F:\\dataset_sri\\1617.m4a\n",
      "F:\\dataset_sri\\1618.m4a\n",
      "F:\\dataset_sri\\1619.m4a\n",
      "F:\\dataset_sri\\162.m4a\n",
      "F:\\dataset_sri\\1620.m4a\n",
      "F:\\dataset_sri\\1621.m4a\n",
      "F:\\dataset_sri\\1622.m4a\n",
      "F:\\dataset_sri\\1623.m4a\n",
      "F:\\dataset_sri\\1624.m4a\n",
      "F:\\dataset_sri\\1625.m4a\n",
      "F:\\dataset_sri\\1626.m4a\n",
      "F:\\dataset_sri\\1627.m4a\n",
      "F:\\dataset_sri\\1628.m4a\n",
      "F:\\dataset_sri\\1629.m4a\n",
      "F:\\dataset_sri\\163.m4a\n",
      "F:\\dataset_sri\\1630.m4a\n",
      "F:\\dataset_sri\\1631.m4a\n",
      "F:\\dataset_sri\\1632.m4a\n",
      "F:\\dataset_sri\\1633.m4a\n",
      "F:\\dataset_sri\\1634.m4a\n",
      "F:\\dataset_sri\\1635.m4a\n",
      "F:\\dataset_sri\\1636.m4a\n",
      "F:\\dataset_sri\\1637.m4a\n",
      "F:\\dataset_sri\\1638.m4a\n",
      "F:\\dataset_sri\\1639.m4a\n",
      "F:\\dataset_sri\\164.m4a\n",
      "F:\\dataset_sri\\1640.m4a\n",
      "F:\\dataset_sri\\1641.m4a\n",
      "F:\\dataset_sri\\1642.m4a\n",
      "F:\\dataset_sri\\1643.m4a\n",
      "F:\\dataset_sri\\1644.m4a\n",
      "F:\\dataset_sri\\1645.m4a\n",
      "F:\\dataset_sri\\1646.m4a\n",
      "F:\\dataset_sri\\1647.m4a\n",
      "F:\\dataset_sri\\1648.m4a\n",
      "F:\\dataset_sri\\1649.m4a\n",
      "F:\\dataset_sri\\165.m4a\n",
      "F:\\dataset_sri\\1650.m4a\n",
      "F:\\dataset_sri\\1651.m4a\n",
      "F:\\dataset_sri\\1652.m4a\n",
      "F:\\dataset_sri\\1653.m4a\n",
      "F:\\dataset_sri\\1654.m4a\n",
      "F:\\dataset_sri\\1655.m4a\n",
      "F:\\dataset_sri\\1656.m4a\n",
      "F:\\dataset_sri\\1657.m4a\n",
      "F:\\dataset_sri\\1658.m4a\n",
      "F:\\dataset_sri\\1659.m4a\n",
      "F:\\dataset_sri\\166.m4a\n",
      "F:\\dataset_sri\\1660.m4a\n",
      "F:\\dataset_sri\\1661.m4a\n",
      "F:\\dataset_sri\\1662.m4a\n",
      "F:\\dataset_sri\\1663.m4a\n",
      "F:\\dataset_sri\\1664.m4a\n",
      "F:\\dataset_sri\\1665.m4a\n",
      "F:\\dataset_sri\\1666.m4a\n",
      "F:\\dataset_sri\\1667.m4a\n",
      "F:\\dataset_sri\\1668.m4a\n",
      "F:\\dataset_sri\\1669.m4a\n",
      "F:\\dataset_sri\\167.m4a\n",
      "F:\\dataset_sri\\1670.m4a\n",
      "F:\\dataset_sri\\1671.m4a\n",
      "F:\\dataset_sri\\1672.m4a\n",
      "F:\\dataset_sri\\1673.m4a\n",
      "F:\\dataset_sri\\1674.m4a\n",
      "F:\\dataset_sri\\1675.m4a\n",
      "F:\\dataset_sri\\1676.m4a\n",
      "F:\\dataset_sri\\1677.m4a\n",
      "F:\\dataset_sri\\1678.m4a\n",
      "F:\\dataset_sri\\1679.m4a\n",
      "F:\\dataset_sri\\168.m4a\n",
      "F:\\dataset_sri\\1680.m4a\n",
      "F:\\dataset_sri\\1681.m4a\n",
      "F:\\dataset_sri\\1682.m4a\n",
      "F:\\dataset_sri\\1683.m4a\n",
      "F:\\dataset_sri\\1684.m4a\n",
      "F:\\dataset_sri\\1685.m4a\n",
      "F:\\dataset_sri\\1686.m4a\n",
      "F:\\dataset_sri\\1687.m4a\n",
      "F:\\dataset_sri\\1688.m4a\n",
      "F:\\dataset_sri\\1689.m4a\n",
      "F:\\dataset_sri\\169.m4a\n",
      "F:\\dataset_sri\\1690.m4a\n",
      "F:\\dataset_sri\\1691.m4a\n",
      "F:\\dataset_sri\\1692.m4a\n",
      "F:\\dataset_sri\\1693.m4a\n",
      "F:\\dataset_sri\\1694.m4a\n",
      "F:\\dataset_sri\\1695.m4a\n",
      "F:\\dataset_sri\\1696.m4a\n",
      "F:\\dataset_sri\\1697.m4a\n",
      "F:\\dataset_sri\\1698.m4a\n",
      "F:\\dataset_sri\\1699.m4a\n",
      "F:\\dataset_sri\\17.m4a\n",
      "F:\\dataset_sri\\170.m4a\n",
      "F:\\dataset_sri\\1700.m4a\n",
      "F:\\dataset_sri\\1701.m4a\n",
      "F:\\dataset_sri\\1702.m4a\n",
      "F:\\dataset_sri\\1703.m4a\n",
      "F:\\dataset_sri\\1704.m4a\n",
      "F:\\dataset_sri\\1705.m4a\n",
      "F:\\dataset_sri\\1706.m4a\n",
      "F:\\dataset_sri\\1707.m4a\n",
      "F:\\dataset_sri\\1708.m4a\n",
      "F:\\dataset_sri\\1709.m4a\n",
      "F:\\dataset_sri\\171.m4a\n",
      "F:\\dataset_sri\\1710.m4a\n",
      "F:\\dataset_sri\\1711.m4a\n",
      "F:\\dataset_sri\\1712.m4a\n",
      "F:\\dataset_sri\\1713.m4a\n",
      "F:\\dataset_sri\\1714.m4a\n",
      "F:\\dataset_sri\\1715.m4a\n",
      "F:\\dataset_sri\\1716.m4a\n",
      "F:\\dataset_sri\\1717.m4a\n",
      "F:\\dataset_sri\\1718.m4a\n",
      "F:\\dataset_sri\\1719.m4a\n",
      "F:\\dataset_sri\\172.m4a\n",
      "F:\\dataset_sri\\1720.m4a\n",
      "F:\\dataset_sri\\1721.m4a\n",
      "F:\\dataset_sri\\1722.m4a\n",
      "F:\\dataset_sri\\1723.m4a\n",
      "F:\\dataset_sri\\1724.m4a\n",
      "F:\\dataset_sri\\1725.m4a\n",
      "F:\\dataset_sri\\1726.m4a\n",
      "F:\\dataset_sri\\1727.m4a\n",
      "F:\\dataset_sri\\1728.m4a\n",
      "F:\\dataset_sri\\1729.m4a\n",
      "F:\\dataset_sri\\173.m4a\n",
      "F:\\dataset_sri\\1730.m4a\n",
      "F:\\dataset_sri\\1731.m4a\n",
      "F:\\dataset_sri\\1732.m4a\n",
      "F:\\dataset_sri\\1733.m4a\n",
      "F:\\dataset_sri\\1734.m4a\n",
      "F:\\dataset_sri\\1735.m4a\n",
      "F:\\dataset_sri\\1736.m4a\n",
      "F:\\dataset_sri\\1737.m4a\n",
      "F:\\dataset_sri\\1738.m4a\n",
      "F:\\dataset_sri\\1739.m4a\n",
      "F:\\dataset_sri\\174.m4a\n",
      "F:\\dataset_sri\\1740.m4a\n",
      "F:\\dataset_sri\\1741.m4a\n",
      "F:\\dataset_sri\\1742.m4a\n",
      "F:\\dataset_sri\\1743.m4a\n",
      "F:\\dataset_sri\\1744.m4a\n",
      "F:\\dataset_sri\\1745.m4a\n",
      "F:\\dataset_sri\\1746.m4a\n",
      "F:\\dataset_sri\\1747.m4a\n",
      "F:\\dataset_sri\\1748.m4a\n",
      "F:\\dataset_sri\\1749.m4a\n",
      "F:\\dataset_sri\\175.m4a\n",
      "F:\\dataset_sri\\1750.m4a\n",
      "F:\\dataset_sri\\1751.m4a\n",
      "F:\\dataset_sri\\1752.m4a\n",
      "F:\\dataset_sri\\1753.m4a\n",
      "F:\\dataset_sri\\1754.m4a\n",
      "F:\\dataset_sri\\1755.m4a\n",
      "F:\\dataset_sri\\1756.m4a\n",
      "F:\\dataset_sri\\1757.m4a\n",
      "F:\\dataset_sri\\1758.m4a\n",
      "F:\\dataset_sri\\1759.m4a\n",
      "F:\\dataset_sri\\176.m4a\n",
      "F:\\dataset_sri\\1760.m4a\n",
      "F:\\dataset_sri\\1761.m4a\n",
      "F:\\dataset_sri\\1762.m4a\n",
      "F:\\dataset_sri\\1763.m4a\n",
      "F:\\dataset_sri\\1764.m4a\n",
      "F:\\dataset_sri\\1765.m4a\n",
      "F:\\dataset_sri\\1766.m4a\n",
      "F:\\dataset_sri\\1767.m4a\n",
      "F:\\dataset_sri\\1768.m4a\n",
      "F:\\dataset_sri\\1769.m4a\n",
      "F:\\dataset_sri\\177.m4a\n",
      "F:\\dataset_sri\\1770.m4a\n",
      "F:\\dataset_sri\\1771.m4a\n",
      "F:\\dataset_sri\\1772.m4a\n",
      "F:\\dataset_sri\\1773.m4a\n",
      "F:\\dataset_sri\\1774.m4a\n",
      "F:\\dataset_sri\\1775.m4a\n",
      "F:\\dataset_sri\\1776.m4a\n",
      "F:\\dataset_sri\\1777.m4a\n",
      "F:\\dataset_sri\\1778.m4a\n",
      "F:\\dataset_sri\\1779.m4a\n",
      "F:\\dataset_sri\\178.m4a\n",
      "F:\\dataset_sri\\1780.m4a\n",
      "F:\\dataset_sri\\1781.m4a\n",
      "F:\\dataset_sri\\1782.m4a\n",
      "F:\\dataset_sri\\1783.m4a\n",
      "F:\\dataset_sri\\1784.m4a\n",
      "F:\\dataset_sri\\1785.m4a\n",
      "F:\\dataset_sri\\1786.m4a\n",
      "F:\\dataset_sri\\1787.m4a\n",
      "F:\\dataset_sri\\1788.m4a\n",
      "F:\\dataset_sri\\1789.m4a\n",
      "F:\\dataset_sri\\179.m4a\n",
      "F:\\dataset_sri\\1790.m4a\n",
      "F:\\dataset_sri\\1791.m4a\n",
      "F:\\dataset_sri\\1792.m4a\n",
      "F:\\dataset_sri\\1793.m4a\n",
      "F:\\dataset_sri\\1794.m4a\n",
      "F:\\dataset_sri\\1795.m4a\n",
      "F:\\dataset_sri\\1796.m4a\n",
      "F:\\dataset_sri\\1797.m4a\n",
      "F:\\dataset_sri\\1798.m4a\n",
      "F:\\dataset_sri\\1799.m4a\n",
      "F:\\dataset_sri\\18.m4a\n",
      "F:\\dataset_sri\\180.m4a\n",
      "F:\\dataset_sri\\1800.m4a\n",
      "F:\\dataset_sri\\1801.m4a\n",
      "F:\\dataset_sri\\1802.m4a\n",
      "F:\\dataset_sri\\1803.m4a\n",
      "F:\\dataset_sri\\1804.m4a\n",
      "F:\\dataset_sri\\1805.m4a\n",
      "F:\\dataset_sri\\1806.m4a\n",
      "F:\\dataset_sri\\1807.m4a\n",
      "F:\\dataset_sri\\1808.m4a\n",
      "F:\\dataset_sri\\1809.m4a\n",
      "F:\\dataset_sri\\181.m4a\n",
      "F:\\dataset_sri\\1810.m4a\n",
      "F:\\dataset_sri\\1811.m4a\n",
      "F:\\dataset_sri\\1812.m4a\n",
      "F:\\dataset_sri\\1813.m4a\n",
      "F:\\dataset_sri\\1814.m4a\n",
      "F:\\dataset_sri\\1815.m4a\n",
      "F:\\dataset_sri\\1816.m4a\n",
      "F:\\dataset_sri\\1817.m4a\n",
      "F:\\dataset_sri\\1818.m4a\n",
      "F:\\dataset_sri\\1819.m4a\n",
      "F:\\dataset_sri\\182.m4a\n",
      "F:\\dataset_sri\\1820.m4a\n",
      "F:\\dataset_sri\\1821.m4a\n",
      "F:\\dataset_sri\\1822.m4a\n",
      "F:\\dataset_sri\\1823.m4a\n",
      "F:\\dataset_sri\\1824.m4a\n",
      "F:\\dataset_sri\\1825.m4a\n",
      "F:\\dataset_sri\\1826.m4a\n",
      "F:\\dataset_sri\\1827.m4a\n",
      "F:\\dataset_sri\\1828.m4a\n",
      "F:\\dataset_sri\\1829.m4a\n",
      "F:\\dataset_sri\\183.m4a\n",
      "F:\\dataset_sri\\1830.m4a\n",
      "F:\\dataset_sri\\1831.m4a\n",
      "F:\\dataset_sri\\1832.m4a\n",
      "F:\\dataset_sri\\1833.m4a\n",
      "F:\\dataset_sri\\1834.m4a\n",
      "F:\\dataset_sri\\1835.m4a\n",
      "F:\\dataset_sri\\1836.m4a\n",
      "F:\\dataset_sri\\1837.m4a\n",
      "F:\\dataset_sri\\1838.m4a\n",
      "F:\\dataset_sri\\1839.m4a\n",
      "F:\\dataset_sri\\184.m4a\n",
      "F:\\dataset_sri\\1840.m4a\n",
      "F:\\dataset_sri\\1841.m4a\n",
      "F:\\dataset_sri\\1842.m4a\n",
      "F:\\dataset_sri\\1843.m4a\n",
      "F:\\dataset_sri\\1844.m4a\n",
      "F:\\dataset_sri\\1845.m4a\n",
      "F:\\dataset_sri\\1846.m4a\n",
      "F:\\dataset_sri\\1847.m4a\n",
      "F:\\dataset_sri\\1848.m4a\n",
      "F:\\dataset_sri\\1849.m4a\n",
      "F:\\dataset_sri\\185.m4a\n",
      "F:\\dataset_sri\\1850.m4a\n",
      "F:\\dataset_sri\\1851.m4a\n",
      "F:\\dataset_sri\\1852.m4a\n",
      "F:\\dataset_sri\\1853.m4a\n",
      "F:\\dataset_sri\\1854.m4a\n",
      "F:\\dataset_sri\\1855.m4a\n",
      "F:\\dataset_sri\\1856.m4a\n",
      "F:\\dataset_sri\\1857.m4a\n",
      "F:\\dataset_sri\\1858.m4a\n",
      "F:\\dataset_sri\\1859.m4a\n",
      "F:\\dataset_sri\\186.m4a\n",
      "F:\\dataset_sri\\1860.m4a\n",
      "F:\\dataset_sri\\1861.m4a\n",
      "F:\\dataset_sri\\1862.m4a\n",
      "F:\\dataset_sri\\1863.m4a\n",
      "F:\\dataset_sri\\1864.m4a\n",
      "F:\\dataset_sri\\1865.m4a\n",
      "F:\\dataset_sri\\1866.m4a\n",
      "F:\\dataset_sri\\1867.m4a\n",
      "F:\\dataset_sri\\1868.m4a\n",
      "F:\\dataset_sri\\1869.m4a\n",
      "F:\\dataset_sri\\187.m4a\n",
      "F:\\dataset_sri\\1870.m4a\n",
      "F:\\dataset_sri\\1871.m4a\n",
      "F:\\dataset_sri\\1872.m4a\n",
      "F:\\dataset_sri\\1873.m4a\n",
      "F:\\dataset_sri\\1874.m4a\n",
      "F:\\dataset_sri\\1875.m4a\n",
      "F:\\dataset_sri\\1876.m4a\n",
      "F:\\dataset_sri\\1877.m4a\n",
      "F:\\dataset_sri\\1878.m4a\n",
      "F:\\dataset_sri\\1879.m4a\n",
      "F:\\dataset_sri\\188.m4a\n",
      "F:\\dataset_sri\\1880.m4a\n",
      "F:\\dataset_sri\\1881.m4a\n",
      "F:\\dataset_sri\\1882.m4a\n",
      "F:\\dataset_sri\\1883.m4a\n",
      "F:\\dataset_sri\\1884.m4a\n",
      "F:\\dataset_sri\\1885.m4a\n",
      "F:\\dataset_sri\\1886.m4a\n",
      "F:\\dataset_sri\\1887.m4a\n",
      "F:\\dataset_sri\\1888.m4a\n",
      "F:\\dataset_sri\\1889.m4a\n",
      "F:\\dataset_sri\\189.m4a\n",
      "F:\\dataset_sri\\1890.m4a\n",
      "F:\\dataset_sri\\1891.m4a\n",
      "F:\\dataset_sri\\1892.m4a\n",
      "F:\\dataset_sri\\1893.m4a\n",
      "F:\\dataset_sri\\1894.m4a\n",
      "F:\\dataset_sri\\1895.m4a\n",
      "F:\\dataset_sri\\1896.m4a\n",
      "F:\\dataset_sri\\1897.m4a\n",
      "F:\\dataset_sri\\1898.m4a\n",
      "F:\\dataset_sri\\1899.m4a\n",
      "F:\\dataset_sri\\19.m4a\n",
      "F:\\dataset_sri\\190.m4a\n",
      "F:\\dataset_sri\\1900.m4a\n",
      "F:\\dataset_sri\\1901.m4a\n",
      "F:\\dataset_sri\\1902.m4a\n",
      "F:\\dataset_sri\\1903.m4a\n",
      "F:\\dataset_sri\\1904.m4a\n",
      "F:\\dataset_sri\\1905.m4a\n",
      "F:\\dataset_sri\\1906.m4a\n",
      "F:\\dataset_sri\\1907.m4a\n",
      "F:\\dataset_sri\\1908.m4a\n",
      "F:\\dataset_sri\\1909.m4a\n",
      "F:\\dataset_sri\\191.m4a\n",
      "F:\\dataset_sri\\1910.m4a\n",
      "F:\\dataset_sri\\1911.m4a\n",
      "F:\\dataset_sri\\1912.m4a\n",
      "F:\\dataset_sri\\1913.m4a\n",
      "F:\\dataset_sri\\1914.m4a\n",
      "F:\\dataset_sri\\1915.m4a\n",
      "F:\\dataset_sri\\1916.m4a\n",
      "F:\\dataset_sri\\1917.m4a\n",
      "F:\\dataset_sri\\1918.m4a\n",
      "F:\\dataset_sri\\1919.m4a\n",
      "F:\\dataset_sri\\192.m4a\n",
      "F:\\dataset_sri\\1920.m4a\n",
      "F:\\dataset_sri\\1921.m4a\n",
      "F:\\dataset_sri\\1922.m4a\n",
      "F:\\dataset_sri\\1923.m4a\n",
      "F:\\dataset_sri\\1924.m4a\n",
      "F:\\dataset_sri\\1925.m4a\n",
      "F:\\dataset_sri\\1926.m4a\n",
      "F:\\dataset_sri\\1927.m4a\n",
      "F:\\dataset_sri\\1928.m4a\n",
      "F:\\dataset_sri\\1929.m4a\n",
      "F:\\dataset_sri\\193.m4a\n",
      "F:\\dataset_sri\\1930.m4a\n",
      "F:\\dataset_sri\\1931.m4a\n",
      "F:\\dataset_sri\\1932.m4a\n",
      "F:\\dataset_sri\\1933.m4a\n",
      "F:\\dataset_sri\\1934.m4a\n",
      "F:\\dataset_sri\\1935.m4a\n",
      "F:\\dataset_sri\\1936.m4a\n",
      "F:\\dataset_sri\\1937.m4a\n",
      "F:\\dataset_sri\\1938.m4a\n",
      "F:\\dataset_sri\\1939.m4a\n",
      "F:\\dataset_sri\\194.m4a\n",
      "F:\\dataset_sri\\1940.m4a\n",
      "F:\\dataset_sri\\1941.m4a\n",
      "F:\\dataset_sri\\1942.m4a\n",
      "F:\\dataset_sri\\1943.m4a\n",
      "F:\\dataset_sri\\1944.m4a\n",
      "F:\\dataset_sri\\1945.m4a\n",
      "F:\\dataset_sri\\1946.m4a\n",
      "F:\\dataset_sri\\1947.m4a\n",
      "F:\\dataset_sri\\1948.m4a\n",
      "F:\\dataset_sri\\1949.m4a\n",
      "F:\\dataset_sri\\195.m4a\n",
      "F:\\dataset_sri\\1950.m4a\n",
      "F:\\dataset_sri\\1951.m4a\n",
      "F:\\dataset_sri\\1952.m4a\n",
      "F:\\dataset_sri\\1953.m4a\n",
      "F:\\dataset_sri\\1954.m4a\n",
      "F:\\dataset_sri\\1955.m4a\n",
      "F:\\dataset_sri\\1956.m4a\n",
      "F:\\dataset_sri\\1957.m4a\n",
      "F:\\dataset_sri\\1958.m4a\n",
      "F:\\dataset_sri\\1959.m4a\n",
      "F:\\dataset_sri\\196.m4a\n",
      "F:\\dataset_sri\\1960.m4a\n",
      "F:\\dataset_sri\\1961.m4a\n",
      "F:\\dataset_sri\\1962.m4a\n",
      "F:\\dataset_sri\\1963.m4a\n",
      "F:\\dataset_sri\\1964.m4a\n",
      "F:\\dataset_sri\\1965.m4a\n",
      "F:\\dataset_sri\\1966.m4a\n",
      "F:\\dataset_sri\\1967.m4a\n",
      "F:\\dataset_sri\\1968.m4a\n",
      "F:\\dataset_sri\\1969.m4a\n",
      "F:\\dataset_sri\\197.m4a\n",
      "F:\\dataset_sri\\1970.m4a\n",
      "F:\\dataset_sri\\1971.m4a\n",
      "F:\\dataset_sri\\1972.m4a\n",
      "F:\\dataset_sri\\1973.m4a\n",
      "F:\\dataset_sri\\1974.m4a\n",
      "F:\\dataset_sri\\1975.m4a\n",
      "F:\\dataset_sri\\1976.m4a\n",
      "F:\\dataset_sri\\1977.m4a\n",
      "F:\\dataset_sri\\1978.m4a\n",
      "F:\\dataset_sri\\1979.m4a\n",
      "F:\\dataset_sri\\198.m4a\n",
      "F:\\dataset_sri\\1980.m4a\n",
      "F:\\dataset_sri\\1981.m4a\n",
      "F:\\dataset_sri\\1982.m4a\n",
      "F:\\dataset_sri\\1983.m4a\n",
      "F:\\dataset_sri\\1984.m4a\n",
      "F:\\dataset_sri\\1985.m4a\n",
      "F:\\dataset_sri\\1986.m4a\n",
      "F:\\dataset_sri\\1987.m4a\n",
      "F:\\dataset_sri\\1988.m4a\n",
      "F:\\dataset_sri\\1989.m4a\n",
      "F:\\dataset_sri\\199.m4a\n",
      "F:\\dataset_sri\\1990.m4a\n",
      "F:\\dataset_sri\\1991.m4a\n",
      "F:\\dataset_sri\\1992.m4a\n",
      "F:\\dataset_sri\\1993.m4a\n",
      "F:\\dataset_sri\\1994.m4a\n",
      "F:\\dataset_sri\\1995.m4a\n",
      "F:\\dataset_sri\\1996.m4a\n",
      "F:\\dataset_sri\\1997.m4a\n",
      "F:\\dataset_sri\\1998.m4a\n",
      "F:\\dataset_sri\\1999.m4a\n",
      "F:\\dataset_sri\\2.m4a\n",
      "F:\\dataset_sri\\20.m4a\n",
      "F:\\dataset_sri\\200.m4a\n",
      "F:\\dataset_sri\\2000.m4a\n",
      "F:\\dataset_sri\\2001.m4a\n",
      "F:\\dataset_sri\\2002.m4a\n",
      "F:\\dataset_sri\\2003.m4a\n",
      "F:\\dataset_sri\\2004.m4a\n",
      "F:\\dataset_sri\\2005.m4a\n",
      "F:\\dataset_sri\\2006.m4a\n",
      "F:\\dataset_sri\\2007.m4a\n",
      "F:\\dataset_sri\\2008.m4a\n",
      "F:\\dataset_sri\\2009.m4a\n",
      "F:\\dataset_sri\\201.m4a\n",
      "F:\\dataset_sri\\2010.m4a\n",
      "F:\\dataset_sri\\2011.m4a\n",
      "F:\\dataset_sri\\2012.m4a\n",
      "F:\\dataset_sri\\2013.m4a\n",
      "F:\\dataset_sri\\2014.m4a\n",
      "F:\\dataset_sri\\2015.m4a\n",
      "F:\\dataset_sri\\2016.m4a\n",
      "F:\\dataset_sri\\2017.m4a\n",
      "F:\\dataset_sri\\2018.m4a\n",
      "F:\\dataset_sri\\2019.m4a\n",
      "F:\\dataset_sri\\202.m4a\n",
      "F:\\dataset_sri\\2020.m4a\n",
      "F:\\dataset_sri\\2021.m4a\n",
      "F:\\dataset_sri\\2022.m4a\n",
      "F:\\dataset_sri\\2023.m4a\n",
      "F:\\dataset_sri\\2024.m4a\n",
      "F:\\dataset_sri\\2025.m4a\n",
      "F:\\dataset_sri\\2026.m4a\n",
      "F:\\dataset_sri\\2027.m4a\n",
      "F:\\dataset_sri\\2028.m4a\n",
      "F:\\dataset_sri\\2029.m4a\n",
      "F:\\dataset_sri\\203.m4a\n",
      "F:\\dataset_sri\\2030.m4a\n",
      "F:\\dataset_sri\\2031.m4a\n",
      "F:\\dataset_sri\\2032.m4a\n",
      "F:\\dataset_sri\\2033.m4a\n",
      "F:\\dataset_sri\\2034.m4a\n",
      "F:\\dataset_sri\\2035.m4a\n",
      "F:\\dataset_sri\\2036.m4a\n",
      "F:\\dataset_sri\\2037.m4a\n",
      "F:\\dataset_sri\\2038.m4a\n",
      "F:\\dataset_sri\\2039.m4a\n",
      "F:\\dataset_sri\\204.m4a\n",
      "F:\\dataset_sri\\2040.m4a\n",
      "F:\\dataset_sri\\2041.m4a\n",
      "F:\\dataset_sri\\2042.m4a\n",
      "F:\\dataset_sri\\2043.m4a\n",
      "F:\\dataset_sri\\2044.m4a\n",
      "F:\\dataset_sri\\2045.m4a\n",
      "F:\\dataset_sri\\2046.m4a\n",
      "F:\\dataset_sri\\2047.m4a\n",
      "F:\\dataset_sri\\2048.m4a\n",
      "F:\\dataset_sri\\2049.m4a\n",
      "F:\\dataset_sri\\205.m4a\n",
      "F:\\dataset_sri\\2050.m4a\n",
      "F:\\dataset_sri\\2051.m4a\n",
      "F:\\dataset_sri\\2052.m4a\n",
      "F:\\dataset_sri\\2053.m4a\n",
      "F:\\dataset_sri\\2054.m4a\n",
      "F:\\dataset_sri\\2055.m4a\n",
      "F:\\dataset_sri\\2056.m4a\n",
      "F:\\dataset_sri\\2057.m4a\n",
      "F:\\dataset_sri\\2058.m4a\n",
      "F:\\dataset_sri\\2059.m4a\n",
      "F:\\dataset_sri\\206.m4a\n",
      "F:\\dataset_sri\\2060.m4a\n",
      "F:\\dataset_sri\\2061.m4a\n",
      "F:\\dataset_sri\\2062.m4a\n",
      "F:\\dataset_sri\\2063.m4a\n",
      "F:\\dataset_sri\\2064.m4a\n",
      "F:\\dataset_sri\\2065.m4a\n",
      "F:\\dataset_sri\\2066.m4a\n",
      "F:\\dataset_sri\\2067.m4a\n",
      "F:\\dataset_sri\\2068.m4a\n",
      "F:\\dataset_sri\\2069.m4a\n",
      "F:\\dataset_sri\\207.m4a\n",
      "F:\\dataset_sri\\2070.m4a\n",
      "F:\\dataset_sri\\2071.m4a\n",
      "F:\\dataset_sri\\2072.m4a\n",
      "F:\\dataset_sri\\2073.m4a\n",
      "F:\\dataset_sri\\2074.m4a\n",
      "F:\\dataset_sri\\2075.m4a\n",
      "F:\\dataset_sri\\2076.m4a\n",
      "F:\\dataset_sri\\2077.m4a\n",
      "F:\\dataset_sri\\2078.m4a\n",
      "F:\\dataset_sri\\2079.m4a\n",
      "F:\\dataset_sri\\208.m4a\n",
      "F:\\dataset_sri\\2080.m4a\n",
      "F:\\dataset_sri\\2081.m4a\n",
      "F:\\dataset_sri\\2082.m4a\n",
      "F:\\dataset_sri\\2083.m4a\n",
      "F:\\dataset_sri\\2084.m4a\n",
      "F:\\dataset_sri\\2085.m4a\n",
      "F:\\dataset_sri\\2086.m4a\n",
      "F:\\dataset_sri\\2087.m4a\n",
      "F:\\dataset_sri\\2088.m4a\n",
      "F:\\dataset_sri\\2089.m4a\n",
      "F:\\dataset_sri\\209.m4a\n",
      "F:\\dataset_sri\\2090.m4a\n",
      "F:\\dataset_sri\\2091.m4a\n",
      "F:\\dataset_sri\\2092.m4a\n",
      "F:\\dataset_sri\\2093.m4a\n",
      "F:\\dataset_sri\\2094.m4a\n",
      "F:\\dataset_sri\\2095.m4a\n",
      "F:\\dataset_sri\\2096.m4a\n",
      "F:\\dataset_sri\\2097.m4a\n",
      "F:\\dataset_sri\\2098.m4a\n",
      "F:\\dataset_sri\\2099.m4a\n",
      "F:\\dataset_sri\\21.m4a\n",
      "F:\\dataset_sri\\210.m4a\n",
      "F:\\dataset_sri\\2100.m4a\n",
      "F:\\dataset_sri\\2101.m4a\n",
      "F:\\dataset_sri\\2102.m4a\n",
      "F:\\dataset_sri\\2103.m4a\n",
      "F:\\dataset_sri\\2104.m4a\n",
      "F:\\dataset_sri\\2105.m4a\n",
      "F:\\dataset_sri\\2106.m4a\n",
      "F:\\dataset_sri\\2107.m4a\n",
      "F:\\dataset_sri\\2108.m4a\n",
      "F:\\dataset_sri\\2109.m4a\n",
      "F:\\dataset_sri\\211.m4a\n",
      "F:\\dataset_sri\\2110.m4a\n",
      "F:\\dataset_sri\\2111.m4a\n",
      "F:\\dataset_sri\\2112.m4a\n",
      "F:\\dataset_sri\\2113.m4a\n",
      "F:\\dataset_sri\\2114.m4a\n",
      "F:\\dataset_sri\\2115.m4a\n",
      "F:\\dataset_sri\\2116.m4a\n",
      "F:\\dataset_sri\\2117.m4a\n",
      "F:\\dataset_sri\\2118.m4a\n",
      "F:\\dataset_sri\\2119.m4a\n",
      "F:\\dataset_sri\\212.m4a\n",
      "F:\\dataset_sri\\2120.m4a\n",
      "F:\\dataset_sri\\2121.m4a\n",
      "F:\\dataset_sri\\2122.m4a\n",
      "F:\\dataset_sri\\2123.m4a\n",
      "F:\\dataset_sri\\2124.m4a\n",
      "F:\\dataset_sri\\2125.m4a\n",
      "F:\\dataset_sri\\2126.m4a\n",
      "F:\\dataset_sri\\2127.m4a\n",
      "F:\\dataset_sri\\2128.m4a\n",
      "F:\\dataset_sri\\2129.m4a\n",
      "F:\\dataset_sri\\213.m4a\n",
      "F:\\dataset_sri\\2130.m4a\n",
      "F:\\dataset_sri\\2131.m4a\n",
      "F:\\dataset_sri\\2132.m4a\n",
      "F:\\dataset_sri\\2133.m4a\n",
      "F:\\dataset_sri\\2134.m4a\n",
      "F:\\dataset_sri\\2135.m4a\n",
      "F:\\dataset_sri\\2136.m4a\n",
      "F:\\dataset_sri\\2137.m4a\n",
      "F:\\dataset_sri\\2138.m4a\n",
      "F:\\dataset_sri\\2139.m4a\n",
      "F:\\dataset_sri\\214.m4a\n",
      "F:\\dataset_sri\\2140.m4a\n",
      "F:\\dataset_sri\\2141.m4a\n",
      "F:\\dataset_sri\\2142.m4a\n",
      "F:\\dataset_sri\\2143.m4a\n",
      "F:\\dataset_sri\\2144.m4a\n",
      "F:\\dataset_sri\\2145.m4a\n",
      "F:\\dataset_sri\\2146.m4a\n",
      "F:\\dataset_sri\\2147.m4a\n",
      "F:\\dataset_sri\\2148.m4a\n",
      "F:\\dataset_sri\\2149.m4a\n",
      "F:\\dataset_sri\\215.m4a\n",
      "F:\\dataset_sri\\2150.m4a\n",
      "F:\\dataset_sri\\2151.m4a\n",
      "F:\\dataset_sri\\2152.m4a\n",
      "F:\\dataset_sri\\2153.m4a\n",
      "F:\\dataset_sri\\2154.m4a\n",
      "F:\\dataset_sri\\2155.m4a\n",
      "F:\\dataset_sri\\2156.m4a\n",
      "F:\\dataset_sri\\2157.m4a\n",
      "F:\\dataset_sri\\2158.m4a\n",
      "F:\\dataset_sri\\2159.m4a\n",
      "F:\\dataset_sri\\216.m4a\n",
      "F:\\dataset_sri\\2160.m4a\n",
      "F:\\dataset_sri\\2161.m4a\n",
      "F:\\dataset_sri\\2162.m4a\n",
      "F:\\dataset_sri\\2163.m4a\n",
      "F:\\dataset_sri\\2164.m4a\n",
      "F:\\dataset_sri\\2165.m4a\n",
      "F:\\dataset_sri\\2166.m4a\n",
      "F:\\dataset_sri\\2167.m4a\n",
      "F:\\dataset_sri\\2168.m4a\n",
      "F:\\dataset_sri\\2169.m4a\n",
      "F:\\dataset_sri\\217.m4a\n",
      "F:\\dataset_sri\\2170.m4a\n",
      "F:\\dataset_sri\\2171.m4a\n",
      "F:\\dataset_sri\\2172.m4a\n",
      "F:\\dataset_sri\\2173.m4a\n",
      "F:\\dataset_sri\\2174.m4a\n",
      "F:\\dataset_sri\\2175.m4a\n",
      "F:\\dataset_sri\\2176.m4a\n",
      "F:\\dataset_sri\\2177.m4a\n",
      "F:\\dataset_sri\\2178.m4a\n",
      "F:\\dataset_sri\\2179.m4a\n",
      "F:\\dataset_sri\\218.m4a\n",
      "F:\\dataset_sri\\2180.m4a\n",
      "F:\\dataset_sri\\2181.m4a\n",
      "F:\\dataset_sri\\2182.m4a\n",
      "F:\\dataset_sri\\2183.m4a\n",
      "F:\\dataset_sri\\2184.m4a\n",
      "F:\\dataset_sri\\2185.m4a\n",
      "F:\\dataset_sri\\2186.m4a\n",
      "F:\\dataset_sri\\2187.m4a\n",
      "F:\\dataset_sri\\2188.m4a\n",
      "F:\\dataset_sri\\2189.m4a\n",
      "F:\\dataset_sri\\219.m4a\n",
      "F:\\dataset_sri\\2190.m4a\n",
      "F:\\dataset_sri\\2191.m4a\n",
      "F:\\dataset_sri\\2192.m4a\n",
      "F:\\dataset_sri\\2193.m4a\n",
      "F:\\dataset_sri\\2194.m4a\n",
      "F:\\dataset_sri\\2195.m4a\n",
      "F:\\dataset_sri\\2196.m4a\n",
      "F:\\dataset_sri\\2197.m4a\n",
      "F:\\dataset_sri\\2198.m4a\n",
      "F:\\dataset_sri\\2199.m4a\n",
      "F:\\dataset_sri\\22.m4a\n",
      "F:\\dataset_sri\\220.m4a\n",
      "F:\\dataset_sri\\2200.m4a\n",
      "F:\\dataset_sri\\2201.m4a\n",
      "F:\\dataset_sri\\2202.m4a\n",
      "F:\\dataset_sri\\2203.m4a\n",
      "F:\\dataset_sri\\2204.m4a\n",
      "F:\\dataset_sri\\2205.m4a\n",
      "F:\\dataset_sri\\2206.m4a\n",
      "F:\\dataset_sri\\2207.m4a\n",
      "F:\\dataset_sri\\2208.m4a\n",
      "F:\\dataset_sri\\2209.m4a\n",
      "F:\\dataset_sri\\221.m4a\n",
      "F:\\dataset_sri\\2210.m4a\n",
      "F:\\dataset_sri\\2211.m4a\n",
      "F:\\dataset_sri\\2212.m4a\n",
      "F:\\dataset_sri\\2213.m4a\n",
      "F:\\dataset_sri\\2214.m4a\n",
      "F:\\dataset_sri\\2215.m4a\n",
      "F:\\dataset_sri\\2216.m4a\n",
      "F:\\dataset_sri\\2217.m4a\n",
      "F:\\dataset_sri\\2218.m4a\n",
      "F:\\dataset_sri\\2219.m4a\n",
      "F:\\dataset_sri\\222.m4a\n",
      "F:\\dataset_sri\\2220.m4a\n",
      "F:\\dataset_sri\\2221.m4a\n",
      "F:\\dataset_sri\\2222.m4a\n",
      "F:\\dataset_sri\\2223.m4a\n",
      "F:\\dataset_sri\\2224.m4a\n",
      "F:\\dataset_sri\\2225.m4a\n",
      "F:\\dataset_sri\\2226.m4a\n",
      "F:\\dataset_sri\\2227.m4a\n",
      "F:\\dataset_sri\\2228.m4a\n",
      "F:\\dataset_sri\\2229.m4a\n",
      "F:\\dataset_sri\\223.m4a\n",
      "F:\\dataset_sri\\2230.m4a\n",
      "F:\\dataset_sri\\2231.m4a\n",
      "F:\\dataset_sri\\2232.m4a\n",
      "F:\\dataset_sri\\2233.m4a\n",
      "F:\\dataset_sri\\2234.m4a\n",
      "F:\\dataset_sri\\2235.m4a\n",
      "F:\\dataset_sri\\2236.m4a\n",
      "F:\\dataset_sri\\2237.m4a\n",
      "F:\\dataset_sri\\2238.m4a\n",
      "F:\\dataset_sri\\2239.m4a\n",
      "F:\\dataset_sri\\224.m4a\n",
      "F:\\dataset_sri\\2240.m4a\n",
      "F:\\dataset_sri\\2241.m4a\n",
      "F:\\dataset_sri\\2242.m4a\n",
      "F:\\dataset_sri\\2243.m4a\n",
      "F:\\dataset_sri\\2244.m4a\n",
      "F:\\dataset_sri\\2245.m4a\n",
      "F:\\dataset_sri\\2246.m4a\n",
      "F:\\dataset_sri\\2247.m4a\n",
      "F:\\dataset_sri\\2248.m4a\n",
      "F:\\dataset_sri\\2249.m4a\n",
      "F:\\dataset_sri\\225.m4a\n",
      "F:\\dataset_sri\\2250.m4a\n",
      "F:\\dataset_sri\\2251.m4a\n",
      "F:\\dataset_sri\\2252.m4a\n",
      "F:\\dataset_sri\\2253.m4a\n",
      "F:\\dataset_sri\\2254.m4a\n",
      "F:\\dataset_sri\\2255.m4a\n",
      "F:\\dataset_sri\\2256.m4a\n",
      "F:\\dataset_sri\\2257.m4a\n",
      "F:\\dataset_sri\\2258.m4a\n",
      "F:\\dataset_sri\\2259.m4a\n",
      "F:\\dataset_sri\\226.m4a\n",
      "F:\\dataset_sri\\2260.m4a\n",
      "F:\\dataset_sri\\2261.m4a\n",
      "F:\\dataset_sri\\2262.m4a\n",
      "F:\\dataset_sri\\2263.m4a\n",
      "F:\\dataset_sri\\2264.m4a\n",
      "F:\\dataset_sri\\2265.m4a\n",
      "F:\\dataset_sri\\2266.m4a\n",
      "F:\\dataset_sri\\2267.m4a\n",
      "F:\\dataset_sri\\2268.m4a\n",
      "F:\\dataset_sri\\2269.m4a\n",
      "F:\\dataset_sri\\227.m4a\n",
      "F:\\dataset_sri\\2270.m4a\n",
      "F:\\dataset_sri\\2271.m4a\n",
      "F:\\dataset_sri\\2272.m4a\n",
      "F:\\dataset_sri\\2273.m4a\n",
      "F:\\dataset_sri\\2274.m4a\n",
      "F:\\dataset_sri\\2275.m4a\n",
      "F:\\dataset_sri\\2276.m4a\n",
      "F:\\dataset_sri\\2277.m4a\n",
      "F:\\dataset_sri\\2278.m4a\n",
      "F:\\dataset_sri\\2279.m4a\n",
      "F:\\dataset_sri\\228.m4a\n",
      "F:\\dataset_sri\\2280.m4a\n",
      "F:\\dataset_sri\\2281.m4a\n",
      "F:\\dataset_sri\\2282.m4a\n",
      "F:\\dataset_sri\\2283.m4a\n",
      "F:\\dataset_sri\\2284.m4a\n",
      "F:\\dataset_sri\\2285.m4a\n",
      "F:\\dataset_sri\\2286.m4a\n",
      "F:\\dataset_sri\\2287.m4a\n",
      "F:\\dataset_sri\\2288.m4a\n",
      "F:\\dataset_sri\\2289.m4a\n",
      "F:\\dataset_sri\\229.m4a\n",
      "F:\\dataset_sri\\2290.m4a\n",
      "F:\\dataset_sri\\2291.m4a\n",
      "F:\\dataset_sri\\2292.m4a\n",
      "F:\\dataset_sri\\2293.m4a\n",
      "F:\\dataset_sri\\2294.m4a\n",
      "F:\\dataset_sri\\2295.m4a\n",
      "F:\\dataset_sri\\2296.m4a\n",
      "F:\\dataset_sri\\2297.m4a\n",
      "F:\\dataset_sri\\2298.m4a\n",
      "F:\\dataset_sri\\2299.m4a\n",
      "F:\\dataset_sri\\23.m4a\n",
      "F:\\dataset_sri\\230.m4a\n",
      "F:\\dataset_sri\\2300.m4a\n",
      "F:\\dataset_sri\\2301.m4a\n",
      "F:\\dataset_sri\\2302.m4a\n",
      "F:\\dataset_sri\\2303.m4a\n",
      "F:\\dataset_sri\\2304.m4a\n",
      "F:\\dataset_sri\\2305.m4a\n",
      "F:\\dataset_sri\\2306.m4a\n",
      "F:\\dataset_sri\\2307.m4a\n",
      "F:\\dataset_sri\\2308.m4a\n",
      "F:\\dataset_sri\\2309.m4a\n",
      "F:\\dataset_sri\\231.m4a\n",
      "F:\\dataset_sri\\2310.m4a\n",
      "F:\\dataset_sri\\2311.m4a\n",
      "F:\\dataset_sri\\2312.m4a\n",
      "F:\\dataset_sri\\2313.m4a\n",
      "F:\\dataset_sri\\2314.m4a\n",
      "F:\\dataset_sri\\2315.m4a\n",
      "F:\\dataset_sri\\2316.m4a\n",
      "F:\\dataset_sri\\2317.m4a\n",
      "F:\\dataset_sri\\2318.m4a\n",
      "F:\\dataset_sri\\2319.m4a\n",
      "F:\\dataset_sri\\232.m4a\n",
      "F:\\dataset_sri\\2320.m4a\n",
      "F:\\dataset_sri\\2321.m4a\n",
      "F:\\dataset_sri\\2322.m4a\n",
      "F:\\dataset_sri\\2323.m4a\n",
      "F:\\dataset_sri\\2324.m4a\n",
      "F:\\dataset_sri\\2325.m4a\n",
      "F:\\dataset_sri\\2326.m4a\n",
      "F:\\dataset_sri\\2327.m4a\n",
      "F:\\dataset_sri\\2328.m4a\n",
      "F:\\dataset_sri\\2329.m4a\n",
      "F:\\dataset_sri\\233.m4a\n",
      "F:\\dataset_sri\\2330.m4a\n",
      "F:\\dataset_sri\\2331.m4a\n",
      "F:\\dataset_sri\\2332.m4a\n",
      "F:\\dataset_sri\\2333.m4a\n",
      "F:\\dataset_sri\\2334.m4a\n",
      "F:\\dataset_sri\\2335.m4a\n",
      "F:\\dataset_sri\\2336.m4a\n",
      "F:\\dataset_sri\\2337.m4a\n",
      "F:\\dataset_sri\\2338.m4a\n",
      "F:\\dataset_sri\\2339.m4a\n",
      "F:\\dataset_sri\\234.m4a\n",
      "F:\\dataset_sri\\2340.m4a\n",
      "F:\\dataset_sri\\2341.m4a\n",
      "F:\\dataset_sri\\2342.m4a\n",
      "F:\\dataset_sri\\2343.m4a\n",
      "F:\\dataset_sri\\2344.m4a\n",
      "F:\\dataset_sri\\2345.m4a\n",
      "F:\\dataset_sri\\2346.m4a\n",
      "F:\\dataset_sri\\2347.m4a\n",
      "F:\\dataset_sri\\2348.m4a\n",
      "F:\\dataset_sri\\2349.m4a\n",
      "F:\\dataset_sri\\235.m4a\n",
      "F:\\dataset_sri\\2350.m4a\n",
      "F:\\dataset_sri\\2351.m4a\n",
      "F:\\dataset_sri\\2352.m4a\n",
      "F:\\dataset_sri\\2353.m4a\n",
      "F:\\dataset_sri\\2354.m4a\n",
      "F:\\dataset_sri\\2355.m4a\n",
      "F:\\dataset_sri\\2356.m4a\n",
      "F:\\dataset_sri\\2357.m4a\n",
      "F:\\dataset_sri\\2358.m4a\n",
      "F:\\dataset_sri\\2359.m4a\n",
      "F:\\dataset_sri\\236.m4a\n",
      "F:\\dataset_sri\\2360.m4a\n",
      "F:\\dataset_sri\\2361.m4a\n",
      "F:\\dataset_sri\\2362.m4a\n",
      "F:\\dataset_sri\\2363.m4a\n",
      "F:\\dataset_sri\\2364.m4a\n",
      "F:\\dataset_sri\\2365.m4a\n",
      "F:\\dataset_sri\\2366.m4a\n",
      "F:\\dataset_sri\\2367.m4a\n",
      "F:\\dataset_sri\\2368.m4a\n",
      "F:\\dataset_sri\\2369.m4a\n",
      "F:\\dataset_sri\\237.m4a\n",
      "F:\\dataset_sri\\2370.m4a\n",
      "F:\\dataset_sri\\2371.m4a\n",
      "F:\\dataset_sri\\2372.m4a\n",
      "F:\\dataset_sri\\2373.m4a\n",
      "F:\\dataset_sri\\2374.m4a\n",
      "F:\\dataset_sri\\2375.m4a\n",
      "F:\\dataset_sri\\2376.m4a\n",
      "F:\\dataset_sri\\2377.m4a\n",
      "F:\\dataset_sri\\2378.m4a\n",
      "F:\\dataset_sri\\2379.m4a\n",
      "F:\\dataset_sri\\238.m4a\n",
      "F:\\dataset_sri\\2380.m4a\n",
      "F:\\dataset_sri\\2381.m4a\n",
      "F:\\dataset_sri\\2382.m4a\n",
      "F:\\dataset_sri\\2383.m4a\n",
      "F:\\dataset_sri\\2384.m4a\n",
      "F:\\dataset_sri\\2385.m4a\n",
      "F:\\dataset_sri\\2386.m4a\n",
      "F:\\dataset_sri\\2387.m4a\n",
      "F:\\dataset_sri\\2388.m4a\n",
      "F:\\dataset_sri\\2389.m4a\n",
      "F:\\dataset_sri\\239.m4a\n",
      "F:\\dataset_sri\\2390.m4a\n",
      "F:\\dataset_sri\\2391.m4a\n",
      "F:\\dataset_sri\\2392.m4a\n",
      "F:\\dataset_sri\\2393.m4a\n",
      "F:\\dataset_sri\\2394.m4a\n",
      "F:\\dataset_sri\\2395.m4a\n",
      "F:\\dataset_sri\\2396.m4a\n",
      "F:\\dataset_sri\\2397.m4a\n",
      "F:\\dataset_sri\\2398.m4a\n",
      "F:\\dataset_sri\\2399.m4a\n",
      "F:\\dataset_sri\\24.m4a\n",
      "F:\\dataset_sri\\240.m4a\n",
      "F:\\dataset_sri\\2400.m4a\n",
      "F:\\dataset_sri\\2401.m4a\n",
      "F:\\dataset_sri\\2402.m4a\n",
      "F:\\dataset_sri\\2403.m4a\n",
      "F:\\dataset_sri\\2404.m4a\n",
      "F:\\dataset_sri\\2405.m4a\n",
      "F:\\dataset_sri\\2406.m4a\n",
      "F:\\dataset_sri\\2407.m4a\n",
      "F:\\dataset_sri\\2408.m4a\n",
      "F:\\dataset_sri\\2409.m4a\n",
      "F:\\dataset_sri\\241.m4a\n",
      "F:\\dataset_sri\\2410.m4a\n",
      "F:\\dataset_sri\\2411.m4a\n",
      "F:\\dataset_sri\\2412.m4a\n",
      "F:\\dataset_sri\\2413.m4a\n",
      "F:\\dataset_sri\\2414.m4a\n",
      "F:\\dataset_sri\\2415.m4a\n",
      "F:\\dataset_sri\\2416.m4a\n",
      "F:\\dataset_sri\\2417.m4a\n",
      "F:\\dataset_sri\\2418.m4a\n",
      "F:\\dataset_sri\\2419.m4a\n",
      "F:\\dataset_sri\\242.m4a\n",
      "F:\\dataset_sri\\2420.m4a\n",
      "F:\\dataset_sri\\2421.m4a\n",
      "F:\\dataset_sri\\2422.m4a\n",
      "F:\\dataset_sri\\2423.m4a\n",
      "F:\\dataset_sri\\2424.m4a\n",
      "F:\\dataset_sri\\2425.m4a\n",
      "F:\\dataset_sri\\2426.m4a\n",
      "F:\\dataset_sri\\2427.m4a\n",
      "F:\\dataset_sri\\2428.m4a\n",
      "F:\\dataset_sri\\2429.m4a\n",
      "F:\\dataset_sri\\243.m4a\n",
      "F:\\dataset_sri\\2430.m4a\n",
      "F:\\dataset_sri\\2431.m4a\n",
      "F:\\dataset_sri\\2432.m4a\n",
      "F:\\dataset_sri\\2433.m4a\n",
      "F:\\dataset_sri\\2434.m4a\n",
      "F:\\dataset_sri\\2435.m4a\n",
      "F:\\dataset_sri\\2436.m4a\n",
      "F:\\dataset_sri\\2437.m4a\n",
      "F:\\dataset_sri\\2438.m4a\n",
      "F:\\dataset_sri\\2439.m4a\n",
      "F:\\dataset_sri\\244.m4a\n",
      "F:\\dataset_sri\\2440.m4a\n",
      "F:\\dataset_sri\\2441.m4a\n",
      "F:\\dataset_sri\\2442.m4a\n",
      "F:\\dataset_sri\\2443.m4a\n",
      "F:\\dataset_sri\\2444.m4a\n",
      "F:\\dataset_sri\\2445.m4a\n",
      "F:\\dataset_sri\\2446.m4a\n",
      "F:\\dataset_sri\\2447.m4a\n",
      "F:\\dataset_sri\\2448.m4a\n",
      "F:\\dataset_sri\\2449.m4a\n",
      "F:\\dataset_sri\\245.m4a\n",
      "F:\\dataset_sri\\2450.m4a\n",
      "F:\\dataset_sri\\2451.m4a\n",
      "F:\\dataset_sri\\2452.m4a\n",
      "F:\\dataset_sri\\2453.m4a\n",
      "F:\\dataset_sri\\2454.m4a\n",
      "F:\\dataset_sri\\2455.m4a\n",
      "F:\\dataset_sri\\2456.m4a\n",
      "F:\\dataset_sri\\2457.m4a\n",
      "F:\\dataset_sri\\2458.m4a\n",
      "F:\\dataset_sri\\2459.m4a\n",
      "F:\\dataset_sri\\246.m4a\n",
      "F:\\dataset_sri\\2460.m4a\n",
      "F:\\dataset_sri\\2461.m4a\n",
      "F:\\dataset_sri\\2462.m4a\n",
      "F:\\dataset_sri\\2463.m4a\n",
      "F:\\dataset_sri\\2464.m4a\n",
      "F:\\dataset_sri\\2465.m4a\n",
      "F:\\dataset_sri\\2466.m4a\n",
      "F:\\dataset_sri\\2467.m4a\n",
      "F:\\dataset_sri\\2468.m4a\n",
      "F:\\dataset_sri\\2469.m4a\n",
      "F:\\dataset_sri\\247.m4a\n",
      "F:\\dataset_sri\\2470.m4a\n",
      "F:\\dataset_sri\\2471.m4a\n",
      "F:\\dataset_sri\\2472.m4a\n",
      "F:\\dataset_sri\\2473.m4a\n",
      "F:\\dataset_sri\\2474.m4a\n",
      "F:\\dataset_sri\\2475.m4a\n",
      "F:\\dataset_sri\\2476.m4a\n",
      "F:\\dataset_sri\\2477.m4a\n",
      "F:\\dataset_sri\\2478.m4a\n",
      "F:\\dataset_sri\\2479.m4a\n",
      "F:\\dataset_sri\\248.m4a\n",
      "F:\\dataset_sri\\2480.m4a\n",
      "F:\\dataset_sri\\2481.m4a\n",
      "F:\\dataset_sri\\2482.m4a\n",
      "F:\\dataset_sri\\2483.m4a\n",
      "F:\\dataset_sri\\2484.m4a\n",
      "F:\\dataset_sri\\2485.m4a\n",
      "F:\\dataset_sri\\2486.m4a\n",
      "F:\\dataset_sri\\2487.m4a\n",
      "F:\\dataset_sri\\2488.m4a\n",
      "F:\\dataset_sri\\2489.m4a\n",
      "F:\\dataset_sri\\249.m4a\n",
      "F:\\dataset_sri\\2490.m4a\n",
      "F:\\dataset_sri\\2491.m4a\n",
      "F:\\dataset_sri\\2492.m4a\n",
      "F:\\dataset_sri\\2493.m4a\n",
      "F:\\dataset_sri\\2494.m4a\n",
      "F:\\dataset_sri\\2495.m4a\n",
      "F:\\dataset_sri\\2496.m4a\n",
      "F:\\dataset_sri\\2497.m4a\n",
      "F:\\dataset_sri\\2498.m4a\n",
      "F:\\dataset_sri\\2499.m4a\n",
      "F:\\dataset_sri\\25.m4a\n",
      "F:\\dataset_sri\\250.m4a\n",
      "F:\\dataset_sri\\2500.m4a\n",
      "F:\\dataset_sri\\2501.m4a\n",
      "F:\\dataset_sri\\2502.m4a\n",
      "F:\\dataset_sri\\2503.m4a\n",
      "F:\\dataset_sri\\2504.m4a\n",
      "F:\\dataset_sri\\2505.m4a\n",
      "F:\\dataset_sri\\2506.m4a\n",
      "F:\\dataset_sri\\2507.m4a\n",
      "F:\\dataset_sri\\2508.m4a\n",
      "F:\\dataset_sri\\2509.m4a\n",
      "F:\\dataset_sri\\251.m4a\n",
      "F:\\dataset_sri\\2510.m4a\n",
      "F:\\dataset_sri\\2511.m4a\n",
      "F:\\dataset_sri\\2512.m4a\n",
      "F:\\dataset_sri\\2513.m4a\n",
      "F:\\dataset_sri\\2514.m4a\n",
      "F:\\dataset_sri\\2515.m4a\n",
      "F:\\dataset_sri\\2516.m4a\n",
      "F:\\dataset_sri\\2517.m4a\n",
      "F:\\dataset_sri\\2518.m4a\n",
      "F:\\dataset_sri\\2519.m4a\n",
      "F:\\dataset_sri\\252.m4a\n",
      "F:\\dataset_sri\\2520.m4a\n",
      "F:\\dataset_sri\\2521.m4a\n",
      "F:\\dataset_sri\\2522.m4a\n",
      "F:\\dataset_sri\\2523.m4a\n",
      "F:\\dataset_sri\\2524.m4a\n",
      "F:\\dataset_sri\\2525.m4a\n",
      "F:\\dataset_sri\\2526.m4a\n",
      "F:\\dataset_sri\\2527.m4a\n",
      "F:\\dataset_sri\\2528.m4a\n",
      "F:\\dataset_sri\\2529.m4a\n",
      "F:\\dataset_sri\\253.m4a\n",
      "F:\\dataset_sri\\2530.m4a\n",
      "F:\\dataset_sri\\2531.m4a\n",
      "F:\\dataset_sri\\2532.m4a\n",
      "F:\\dataset_sri\\2533.m4a\n",
      "F:\\dataset_sri\\2534.m4a\n",
      "F:\\dataset_sri\\2535.m4a\n",
      "F:\\dataset_sri\\2536.m4a\n",
      "F:\\dataset_sri\\2537.m4a\n",
      "F:\\dataset_sri\\2538.m4a\n",
      "F:\\dataset_sri\\2539.m4a\n",
      "F:\\dataset_sri\\254.m4a\n",
      "F:\\dataset_sri\\2540.m4a\n",
      "F:\\dataset_sri\\2541.m4a\n",
      "F:\\dataset_sri\\2542.m4a\n",
      "F:\\dataset_sri\\2543.m4a\n",
      "F:\\dataset_sri\\2544.m4a\n",
      "F:\\dataset_sri\\2545.m4a\n",
      "F:\\dataset_sri\\2546.m4a\n",
      "F:\\dataset_sri\\2547.m4a\n",
      "F:\\dataset_sri\\2548.m4a\n",
      "F:\\dataset_sri\\2549.m4a\n",
      "F:\\dataset_sri\\255.m4a\n",
      "F:\\dataset_sri\\2550.m4a\n",
      "F:\\dataset_sri\\2551.m4a\n",
      "F:\\dataset_sri\\2552.m4a\n",
      "F:\\dataset_sri\\2553.m4a\n",
      "F:\\dataset_sri\\2554.m4a\n",
      "F:\\dataset_sri\\2555.m4a\n",
      "F:\\dataset_sri\\2556.m4a\n",
      "F:\\dataset_sri\\2557.m4a\n",
      "F:\\dataset_sri\\2558.m4a\n",
      "F:\\dataset_sri\\2559.m4a\n",
      "F:\\dataset_sri\\256.m4a\n",
      "F:\\dataset_sri\\2560.m4a\n",
      "F:\\dataset_sri\\2561.m4a\n",
      "F:\\dataset_sri\\2562.m4a\n",
      "F:\\dataset_sri\\2563.m4a\n",
      "F:\\dataset_sri\\2564.m4a\n",
      "F:\\dataset_sri\\2565.m4a\n",
      "F:\\dataset_sri\\2566.m4a\n",
      "F:\\dataset_sri\\2567.m4a\n",
      "F:\\dataset_sri\\2568.m4a\n",
      "F:\\dataset_sri\\2569.m4a\n",
      "F:\\dataset_sri\\257.m4a\n",
      "F:\\dataset_sri\\2570.m4a\n",
      "F:\\dataset_sri\\2571.m4a\n",
      "F:\\dataset_sri\\2572.m4a\n",
      "F:\\dataset_sri\\2573.m4a\n",
      "F:\\dataset_sri\\2574.m4a\n",
      "F:\\dataset_sri\\2575.m4a\n",
      "F:\\dataset_sri\\2576.m4a\n",
      "F:\\dataset_sri\\2577.m4a\n",
      "F:\\dataset_sri\\2578.m4a\n",
      "F:\\dataset_sri\\2579.m4a\n",
      "F:\\dataset_sri\\258.m4a\n",
      "F:\\dataset_sri\\2580.m4a\n",
      "F:\\dataset_sri\\2581.m4a\n",
      "F:\\dataset_sri\\2582.m4a\n",
      "F:\\dataset_sri\\2583.m4a\n",
      "F:\\dataset_sri\\2584.m4a\n",
      "F:\\dataset_sri\\2585.m4a\n",
      "F:\\dataset_sri\\2586.m4a\n",
      "F:\\dataset_sri\\2587.m4a\n",
      "F:\\dataset_sri\\2588.m4a\n",
      "F:\\dataset_sri\\2589.m4a\n",
      "F:\\dataset_sri\\259.m4a\n",
      "F:\\dataset_sri\\2590.m4a\n",
      "F:\\dataset_sri\\2591.m4a\n",
      "F:\\dataset_sri\\2592.m4a\n",
      "F:\\dataset_sri\\2593.m4a\n",
      "F:\\dataset_sri\\2594.m4a\n",
      "F:\\dataset_sri\\2595.m4a\n",
      "F:\\dataset_sri\\2596.m4a\n",
      "F:\\dataset_sri\\2597.m4a\n",
      "F:\\dataset_sri\\2598.m4a\n",
      "F:\\dataset_sri\\2599.m4a\n",
      "F:\\dataset_sri\\26.m4a\n",
      "F:\\dataset_sri\\260.m4a\n",
      "F:\\dataset_sri\\2600.m4a\n",
      "F:\\dataset_sri\\2601.m4a\n",
      "F:\\dataset_sri\\2602.m4a\n",
      "F:\\dataset_sri\\2603.m4a\n",
      "F:\\dataset_sri\\2604.m4a\n",
      "F:\\dataset_sri\\2605.m4a\n",
      "F:\\dataset_sri\\2606.m4a\n",
      "F:\\dataset_sri\\2607.m4a\n",
      "F:\\dataset_sri\\2608.m4a\n",
      "F:\\dataset_sri\\2609.m4a\n",
      "F:\\dataset_sri\\261.m4a\n",
      "F:\\dataset_sri\\2610.m4a\n",
      "F:\\dataset_sri\\2611.m4a\n",
      "F:\\dataset_sri\\2612.m4a\n",
      "F:\\dataset_sri\\2613.m4a\n",
      "F:\\dataset_sri\\2614.m4a\n",
      "F:\\dataset_sri\\2615.m4a\n",
      "F:\\dataset_sri\\2616.m4a\n",
      "F:\\dataset_sri\\2617.m4a\n",
      "F:\\dataset_sri\\2618.m4a\n",
      "F:\\dataset_sri\\2619.m4a\n",
      "F:\\dataset_sri\\262.m4a\n",
      "F:\\dataset_sri\\2620.m4a\n",
      "F:\\dataset_sri\\2621.m4a\n",
      "F:\\dataset_sri\\2622.m4a\n",
      "F:\\dataset_sri\\2623.m4a\n",
      "F:\\dataset_sri\\2624.m4a\n",
      "F:\\dataset_sri\\2625.m4a\n",
      "F:\\dataset_sri\\2626.m4a\n",
      "F:\\dataset_sri\\2627.m4a\n",
      "F:\\dataset_sri\\2628.m4a\n",
      "F:\\dataset_sri\\2629.m4a\n",
      "F:\\dataset_sri\\263.m4a\n",
      "F:\\dataset_sri\\2630.m4a\n",
      "F:\\dataset_sri\\2631.m4a\n",
      "F:\\dataset_sri\\2632.m4a\n",
      "F:\\dataset_sri\\2633.m4a\n",
      "F:\\dataset_sri\\2634.m4a\n",
      "F:\\dataset_sri\\2635.m4a\n",
      "F:\\dataset_sri\\2636.m4a\n",
      "F:\\dataset_sri\\2637.m4a\n",
      "F:\\dataset_sri\\2638.m4a\n",
      "F:\\dataset_sri\\2639.m4a\n",
      "F:\\dataset_sri\\264.m4a\n",
      "F:\\dataset_sri\\2640.m4a\n",
      "F:\\dataset_sri\\2641.m4a\n",
      "F:\\dataset_sri\\2642.m4a\n",
      "F:\\dataset_sri\\2643.m4a\n",
      "F:\\dataset_sri\\2644.m4a\n",
      "F:\\dataset_sri\\2645.m4a\n",
      "F:\\dataset_sri\\2646.m4a\n",
      "F:\\dataset_sri\\2647.m4a\n",
      "F:\\dataset_sri\\2648.m4a\n",
      "F:\\dataset_sri\\2649.m4a\n",
      "F:\\dataset_sri\\265.m4a\n",
      "F:\\dataset_sri\\2650.m4a\n",
      "F:\\dataset_sri\\2651.m4a\n",
      "F:\\dataset_sri\\2652.m4a\n",
      "F:\\dataset_sri\\2653.m4a\n",
      "F:\\dataset_sri\\2654.m4a\n",
      "F:\\dataset_sri\\2655.m4a\n",
      "F:\\dataset_sri\\2656.m4a\n",
      "F:\\dataset_sri\\2657.m4a\n",
      "F:\\dataset_sri\\2658.m4a\n",
      "F:\\dataset_sri\\2659.m4a\n",
      "F:\\dataset_sri\\266.m4a\n",
      "F:\\dataset_sri\\2660.m4a\n",
      "F:\\dataset_sri\\2661.m4a\n",
      "F:\\dataset_sri\\2662.m4a\n",
      "F:\\dataset_sri\\2663.m4a\n",
      "F:\\dataset_sri\\2664.m4a\n",
      "F:\\dataset_sri\\2665.m4a\n",
      "F:\\dataset_sri\\2666.m4a\n",
      "F:\\dataset_sri\\2667.m4a\n",
      "F:\\dataset_sri\\2668.m4a\n",
      "F:\\dataset_sri\\2669.m4a\n",
      "F:\\dataset_sri\\267.m4a\n",
      "F:\\dataset_sri\\2670.m4a\n",
      "F:\\dataset_sri\\2671.m4a\n",
      "F:\\dataset_sri\\2672.m4a\n",
      "F:\\dataset_sri\\2673.m4a\n",
      "F:\\dataset_sri\\2674.m4a\n",
      "F:\\dataset_sri\\2675.m4a\n",
      "F:\\dataset_sri\\2676.m4a\n",
      "F:\\dataset_sri\\2677.m4a\n",
      "F:\\dataset_sri\\2678.m4a\n",
      "F:\\dataset_sri\\2679.m4a\n",
      "F:\\dataset_sri\\268.m4a\n",
      "F:\\dataset_sri\\2680.m4a\n",
      "F:\\dataset_sri\\2681.m4a\n",
      "F:\\dataset_sri\\2682.m4a\n",
      "F:\\dataset_sri\\2683.m4a\n",
      "F:\\dataset_sri\\2684.m4a\n",
      "F:\\dataset_sri\\2685.m4a\n",
      "F:\\dataset_sri\\2686.m4a\n",
      "F:\\dataset_sri\\2687.m4a\n",
      "F:\\dataset_sri\\2688.m4a\n",
      "F:\\dataset_sri\\2689.m4a\n",
      "F:\\dataset_sri\\269.m4a\n",
      "F:\\dataset_sri\\2690.m4a\n",
      "F:\\dataset_sri\\2691.m4a\n",
      "F:\\dataset_sri\\2692.m4a\n",
      "F:\\dataset_sri\\2693.m4a\n",
      "F:\\dataset_sri\\2694.m4a\n",
      "F:\\dataset_sri\\2695.m4a\n",
      "F:\\dataset_sri\\2696.m4a\n",
      "F:\\dataset_sri\\2697.m4a\n",
      "F:\\dataset_sri\\2698.m4a\n",
      "F:\\dataset_sri\\2699.m4a\n",
      "F:\\dataset_sri\\27.m4a\n",
      "F:\\dataset_sri\\270.m4a\n",
      "F:\\dataset_sri\\2700.m4a\n",
      "F:\\dataset_sri\\2701.m4a\n",
      "F:\\dataset_sri\\2702.m4a\n",
      "F:\\dataset_sri\\2703.m4a\n",
      "F:\\dataset_sri\\2704.m4a\n",
      "F:\\dataset_sri\\2705.m4a\n",
      "F:\\dataset_sri\\2706.m4a\n",
      "F:\\dataset_sri\\2707.m4a\n",
      "F:\\dataset_sri\\2708.m4a\n",
      "F:\\dataset_sri\\2709.m4a\n",
      "F:\\dataset_sri\\271.m4a\n",
      "F:\\dataset_sri\\2710.m4a\n",
      "F:\\dataset_sri\\2711.m4a\n",
      "F:\\dataset_sri\\2712.m4a\n",
      "F:\\dataset_sri\\2713.m4a\n",
      "F:\\dataset_sri\\2714.m4a\n",
      "F:\\dataset_sri\\2715.m4a\n",
      "F:\\dataset_sri\\2716.m4a\n",
      "F:\\dataset_sri\\2717.m4a\n",
      "F:\\dataset_sri\\2718.m4a\n",
      "F:\\dataset_sri\\2719.m4a\n",
      "F:\\dataset_sri\\272.m4a\n",
      "F:\\dataset_sri\\2720.m4a\n",
      "F:\\dataset_sri\\2721.m4a\n",
      "F:\\dataset_sri\\2722.m4a\n",
      "F:\\dataset_sri\\2723.m4a\n",
      "F:\\dataset_sri\\2724.m4a\n",
      "F:\\dataset_sri\\2725.m4a\n",
      "F:\\dataset_sri\\2726.m4a\n",
      "F:\\dataset_sri\\2727.m4a\n",
      "F:\\dataset_sri\\2728.m4a\n",
      "F:\\dataset_sri\\2729.m4a\n",
      "F:\\dataset_sri\\273.m4a\n",
      "F:\\dataset_sri\\2730.m4a\n",
      "F:\\dataset_sri\\2731.m4a\n",
      "F:\\dataset_sri\\2732.m4a\n",
      "F:\\dataset_sri\\2733.m4a\n",
      "F:\\dataset_sri\\2734.m4a\n",
      "F:\\dataset_sri\\2735.m4a\n",
      "F:\\dataset_sri\\2736.m4a\n",
      "F:\\dataset_sri\\2737.m4a\n",
      "F:\\dataset_sri\\2738.m4a\n",
      "F:\\dataset_sri\\2739.m4a\n",
      "F:\\dataset_sri\\274.m4a\n",
      "F:\\dataset_sri\\2740.m4a\n",
      "F:\\dataset_sri\\2741.m4a\n",
      "F:\\dataset_sri\\2742.m4a\n",
      "F:\\dataset_sri\\2743.m4a\n",
      "F:\\dataset_sri\\2744.m4a\n",
      "F:\\dataset_sri\\2745.m4a\n",
      "F:\\dataset_sri\\2746.m4a\n",
      "F:\\dataset_sri\\2747.m4a\n",
      "F:\\dataset_sri\\2748.m4a\n",
      "F:\\dataset_sri\\2749.m4a\n",
      "F:\\dataset_sri\\275.m4a\n",
      "F:\\dataset_sri\\2750.m4a\n",
      "F:\\dataset_sri\\2751.m4a\n",
      "F:\\dataset_sri\\2752.m4a\n",
      "F:\\dataset_sri\\2753.m4a\n",
      "F:\\dataset_sri\\2754.m4a\n",
      "F:\\dataset_sri\\2755.m4a\n",
      "F:\\dataset_sri\\2756.m4a\n",
      "F:\\dataset_sri\\2757.m4a\n",
      "F:\\dataset_sri\\2758.m4a\n",
      "F:\\dataset_sri\\2759.m4a\n",
      "F:\\dataset_sri\\276.m4a\n",
      "F:\\dataset_sri\\2760.m4a\n",
      "F:\\dataset_sri\\2761.m4a\n",
      "F:\\dataset_sri\\2762.m4a\n",
      "F:\\dataset_sri\\2763.m4a\n",
      "F:\\dataset_sri\\2764.m4a\n",
      "F:\\dataset_sri\\2765.m4a\n",
      "F:\\dataset_sri\\2766.m4a\n",
      "F:\\dataset_sri\\2767.m4a\n",
      "F:\\dataset_sri\\2768.m4a\n",
      "F:\\dataset_sri\\2769.m4a\n",
      "F:\\dataset_sri\\277.m4a\n",
      "F:\\dataset_sri\\2770.m4a\n",
      "F:\\dataset_sri\\2771.m4a\n",
      "F:\\dataset_sri\\2772.m4a\n",
      "F:\\dataset_sri\\2773.m4a\n",
      "F:\\dataset_sri\\2774.m4a\n",
      "F:\\dataset_sri\\2775.m4a\n",
      "F:\\dataset_sri\\2776.m4a\n",
      "F:\\dataset_sri\\2777.m4a\n",
      "F:\\dataset_sri\\2778.m4a\n",
      "F:\\dataset_sri\\2779.m4a\n",
      "F:\\dataset_sri\\278.m4a\n",
      "F:\\dataset_sri\\2780.m4a\n",
      "F:\\dataset_sri\\2781.m4a\n",
      "F:\\dataset_sri\\2782.m4a\n",
      "F:\\dataset_sri\\2783.m4a\n",
      "F:\\dataset_sri\\2784.m4a\n",
      "F:\\dataset_sri\\2785.m4a\n",
      "F:\\dataset_sri\\2786.m4a\n",
      "F:\\dataset_sri\\2787.m4a\n",
      "F:\\dataset_sri\\2788.m4a\n",
      "F:\\dataset_sri\\2789.m4a\n",
      "F:\\dataset_sri\\279.m4a\n",
      "F:\\dataset_sri\\2790.m4a\n",
      "F:\\dataset_sri\\2791.m4a\n",
      "F:\\dataset_sri\\2792.m4a\n",
      "F:\\dataset_sri\\2793.m4a\n",
      "F:\\dataset_sri\\2794.m4a\n",
      "F:\\dataset_sri\\2795.m4a\n",
      "F:\\dataset_sri\\2796.m4a\n",
      "F:\\dataset_sri\\2797.m4a\n",
      "F:\\dataset_sri\\2798.m4a\n",
      "F:\\dataset_sri\\2799.m4a\n",
      "F:\\dataset_sri\\28.m4a\n",
      "F:\\dataset_sri\\280.m4a\n",
      "F:\\dataset_sri\\2800.m4a\n",
      "F:\\dataset_sri\\2801.m4a\n",
      "F:\\dataset_sri\\2802.m4a\n",
      "F:\\dataset_sri\\2803.m4a\n",
      "F:\\dataset_sri\\2804.m4a\n",
      "F:\\dataset_sri\\2805.m4a\n",
      "F:\\dataset_sri\\2806.m4a\n",
      "F:\\dataset_sri\\2807.m4a\n",
      "F:\\dataset_sri\\2808.m4a\n",
      "F:\\dataset_sri\\2809.m4a\n",
      "F:\\dataset_sri\\281.m4a\n",
      "F:\\dataset_sri\\2810.m4a\n",
      "F:\\dataset_sri\\2811.m4a\n",
      "F:\\dataset_sri\\2812.m4a\n",
      "F:\\dataset_sri\\2813.m4a\n",
      "F:\\dataset_sri\\2814.m4a\n",
      "F:\\dataset_sri\\2815.m4a\n",
      "F:\\dataset_sri\\2816.m4a\n",
      "F:\\dataset_sri\\2817.m4a\n",
      "F:\\dataset_sri\\2818.m4a\n",
      "F:\\dataset_sri\\2819.m4a\n",
      "F:\\dataset_sri\\282.m4a\n",
      "F:\\dataset_sri\\2820.m4a\n",
      "F:\\dataset_sri\\2821.m4a\n",
      "F:\\dataset_sri\\2822.m4a\n",
      "F:\\dataset_sri\\2823.m4a\n",
      "F:\\dataset_sri\\2824.m4a\n",
      "F:\\dataset_sri\\2825.m4a\n",
      "F:\\dataset_sri\\2826.m4a\n",
      "F:\\dataset_sri\\2827.m4a\n",
      "F:\\dataset_sri\\2828.m4a\n",
      "F:\\dataset_sri\\2829.m4a\n",
      "F:\\dataset_sri\\283.m4a\n",
      "F:\\dataset_sri\\2830.m4a\n",
      "F:\\dataset_sri\\2831.m4a\n",
      "F:\\dataset_sri\\2832.m4a\n",
      "F:\\dataset_sri\\2833.m4a\n",
      "F:\\dataset_sri\\2834.m4a\n",
      "F:\\dataset_sri\\2835.m4a\n",
      "F:\\dataset_sri\\2836.m4a\n",
      "F:\\dataset_sri\\2837.m4a\n",
      "F:\\dataset_sri\\2838.m4a\n",
      "F:\\dataset_sri\\2839.m4a\n",
      "F:\\dataset_sri\\284.m4a\n",
      "F:\\dataset_sri\\2840.m4a\n",
      "F:\\dataset_sri\\2841.m4a\n",
      "F:\\dataset_sri\\2842.m4a\n",
      "F:\\dataset_sri\\2843.m4a\n",
      "F:\\dataset_sri\\2844.m4a\n",
      "F:\\dataset_sri\\2845.m4a\n",
      "F:\\dataset_sri\\2846.m4a\n",
      "F:\\dataset_sri\\2847.m4a\n",
      "F:\\dataset_sri\\2848.m4a\n",
      "F:\\dataset_sri\\2849.m4a\n",
      "F:\\dataset_sri\\285.m4a\n",
      "F:\\dataset_sri\\2850.m4a\n",
      "F:\\dataset_sri\\2851.m4a\n",
      "F:\\dataset_sri\\2852.m4a\n",
      "F:\\dataset_sri\\2853.m4a\n",
      "F:\\dataset_sri\\2854.m4a\n",
      "F:\\dataset_sri\\2855.m4a\n",
      "F:\\dataset_sri\\2856.m4a\n",
      "F:\\dataset_sri\\2857.m4a\n",
      "F:\\dataset_sri\\2858.m4a\n",
      "F:\\dataset_sri\\2859.m4a\n",
      "F:\\dataset_sri\\286.m4a\n",
      "F:\\dataset_sri\\2860.m4a\n",
      "F:\\dataset_sri\\2861.m4a\n",
      "F:\\dataset_sri\\2862.m4a\n",
      "F:\\dataset_sri\\2863.m4a\n",
      "F:\\dataset_sri\\2864.m4a\n",
      "F:\\dataset_sri\\2865.m4a\n",
      "F:\\dataset_sri\\2866.m4a\n",
      "F:\\dataset_sri\\2867.m4a\n",
      "F:\\dataset_sri\\2868.m4a\n",
      "F:\\dataset_sri\\2869.m4a\n",
      "F:\\dataset_sri\\287.m4a\n",
      "F:\\dataset_sri\\2870.m4a\n",
      "F:\\dataset_sri\\2871.m4a\n",
      "F:\\dataset_sri\\2872.m4a\n",
      "F:\\dataset_sri\\2873.m4a\n",
      "F:\\dataset_sri\\2874.m4a\n",
      "F:\\dataset_sri\\2875.m4a\n",
      "F:\\dataset_sri\\2876.m4a\n",
      "F:\\dataset_sri\\2877.m4a\n",
      "F:\\dataset_sri\\2878.m4a\n",
      "F:\\dataset_sri\\2879.m4a\n",
      "F:\\dataset_sri\\288.m4a\n",
      "F:\\dataset_sri\\2880.m4a\n",
      "F:\\dataset_sri\\2881.m4a\n",
      "F:\\dataset_sri\\2882.m4a\n",
      "F:\\dataset_sri\\2883.m4a\n",
      "F:\\dataset_sri\\2884.m4a\n",
      "F:\\dataset_sri\\2885.m4a\n",
      "F:\\dataset_sri\\2886.m4a\n",
      "F:\\dataset_sri\\2887.m4a\n",
      "F:\\dataset_sri\\2888.m4a\n",
      "F:\\dataset_sri\\2889.m4a\n",
      "F:\\dataset_sri\\289.m4a\n",
      "F:\\dataset_sri\\2890.m4a\n",
      "F:\\dataset_sri\\2891.m4a\n",
      "F:\\dataset_sri\\2892.m4a\n",
      "F:\\dataset_sri\\2893.m4a\n",
      "F:\\dataset_sri\\2894.m4a\n",
      "F:\\dataset_sri\\2895.m4a\n",
      "F:\\dataset_sri\\2896.m4a\n",
      "F:\\dataset_sri\\2897.m4a\n",
      "F:\\dataset_sri\\2898.m4a\n",
      "F:\\dataset_sri\\2899.m4a\n",
      "F:\\dataset_sri\\29.m4a\n",
      "F:\\dataset_sri\\290.m4a\n",
      "F:\\dataset_sri\\2900.m4a\n",
      "F:\\dataset_sri\\2901.m4a\n",
      "F:\\dataset_sri\\2902.m4a\n",
      "F:\\dataset_sri\\2903.m4a\n",
      "F:\\dataset_sri\\2904.m4a\n",
      "F:\\dataset_sri\\2905.m4a\n",
      "F:\\dataset_sri\\2906.m4a\n",
      "F:\\dataset_sri\\2907.m4a\n",
      "F:\\dataset_sri\\2908.m4a\n",
      "F:\\dataset_sri\\2909.m4a\n",
      "F:\\dataset_sri\\291.m4a\n",
      "F:\\dataset_sri\\2910.m4a\n",
      "F:\\dataset_sri\\2911.m4a\n",
      "F:\\dataset_sri\\2912.m4a\n",
      "F:\\dataset_sri\\2913.m4a\n",
      "F:\\dataset_sri\\2914.m4a\n",
      "F:\\dataset_sri\\2915.m4a\n",
      "F:\\dataset_sri\\2916.m4a\n",
      "F:\\dataset_sri\\2917.m4a\n",
      "F:\\dataset_sri\\2918.m4a\n",
      "F:\\dataset_sri\\2919.m4a\n",
      "F:\\dataset_sri\\292.m4a\n",
      "F:\\dataset_sri\\2920.m4a\n",
      "F:\\dataset_sri\\2921.m4a\n",
      "F:\\dataset_sri\\2922.m4a\n",
      "F:\\dataset_sri\\2923.m4a\n",
      "F:\\dataset_sri\\2924.m4a\n",
      "F:\\dataset_sri\\2925.m4a\n",
      "F:\\dataset_sri\\2926.m4a\n",
      "F:\\dataset_sri\\2927.m4a\n",
      "F:\\dataset_sri\\2928.m4a\n",
      "F:\\dataset_sri\\2929.m4a\n",
      "F:\\dataset_sri\\293.m4a\n",
      "F:\\dataset_sri\\2930.m4a\n",
      "F:\\dataset_sri\\2931.m4a\n",
      "F:\\dataset_sri\\2932.m4a\n",
      "F:\\dataset_sri\\2933.m4a\n",
      "F:\\dataset_sri\\2934.m4a\n",
      "F:\\dataset_sri\\2935.m4a\n",
      "F:\\dataset_sri\\2936.m4a\n",
      "F:\\dataset_sri\\2937.m4a\n",
      "F:\\dataset_sri\\2938.m4a\n",
      "F:\\dataset_sri\\2939.m4a\n",
      "F:\\dataset_sri\\294.m4a\n",
      "F:\\dataset_sri\\2940.m4a\n",
      "F:\\dataset_sri\\2941.m4a\n",
      "F:\\dataset_sri\\2942.m4a\n",
      "F:\\dataset_sri\\2943.m4a\n",
      "F:\\dataset_sri\\2944.m4a\n",
      "F:\\dataset_sri\\2945.m4a\n",
      "F:\\dataset_sri\\2946.m4a\n",
      "F:\\dataset_sri\\2947.m4a\n",
      "F:\\dataset_sri\\2948.m4a\n",
      "F:\\dataset_sri\\2949.m4a\n",
      "F:\\dataset_sri\\295.m4a\n",
      "F:\\dataset_sri\\2950.m4a\n",
      "F:\\dataset_sri\\2951.m4a\n",
      "F:\\dataset_sri\\2952.m4a\n",
      "F:\\dataset_sri\\2953.m4a\n",
      "F:\\dataset_sri\\2954.m4a\n",
      "F:\\dataset_sri\\2955.m4a\n",
      "F:\\dataset_sri\\2956.m4a\n",
      "F:\\dataset_sri\\2957.m4a\n",
      "F:\\dataset_sri\\2958.m4a\n",
      "F:\\dataset_sri\\2959.m4a\n",
      "F:\\dataset_sri\\296.m4a\n",
      "F:\\dataset_sri\\2960.m4a\n",
      "F:\\dataset_sri\\2961.m4a\n",
      "F:\\dataset_sri\\2962.m4a\n",
      "F:\\dataset_sri\\2963.m4a\n",
      "F:\\dataset_sri\\2964.m4a\n",
      "F:\\dataset_sri\\2965.m4a\n",
      "F:\\dataset_sri\\2966.m4a\n",
      "F:\\dataset_sri\\2967.m4a\n",
      "F:\\dataset_sri\\2968.m4a\n",
      "F:\\dataset_sri\\2969.m4a\n",
      "F:\\dataset_sri\\297.m4a\n",
      "F:\\dataset_sri\\2970.m4a\n",
      "F:\\dataset_sri\\2971.m4a\n",
      "F:\\dataset_sri\\2972.m4a\n",
      "F:\\dataset_sri\\2973.m4a\n",
      "F:\\dataset_sri\\2974.m4a\n",
      "F:\\dataset_sri\\2975.m4a\n",
      "F:\\dataset_sri\\2976.m4a\n",
      "F:\\dataset_sri\\2977.m4a\n",
      "F:\\dataset_sri\\2978.m4a\n",
      "F:\\dataset_sri\\2979.m4a\n",
      "F:\\dataset_sri\\298.m4a\n",
      "F:\\dataset_sri\\2980.m4a\n",
      "F:\\dataset_sri\\2981.m4a\n",
      "F:\\dataset_sri\\2982.m4a\n",
      "F:\\dataset_sri\\2983.m4a\n",
      "F:\\dataset_sri\\2984.m4a\n",
      "F:\\dataset_sri\\2985.m4a\n",
      "F:\\dataset_sri\\2986.m4a\n",
      "F:\\dataset_sri\\2987.m4a\n",
      "F:\\dataset_sri\\2988.m4a\n",
      "F:\\dataset_sri\\2989.m4a\n",
      "F:\\dataset_sri\\299.m4a\n",
      "F:\\dataset_sri\\2990.m4a\n",
      "F:\\dataset_sri\\2991.m4a\n",
      "F:\\dataset_sri\\2992.m4a\n",
      "F:\\dataset_sri\\2993.m4a\n",
      "F:\\dataset_sri\\2994.m4a\n",
      "F:\\dataset_sri\\2995.m4a\n",
      "F:\\dataset_sri\\2996.m4a\n",
      "F:\\dataset_sri\\2997.m4a\n",
      "F:\\dataset_sri\\2998.m4a\n",
      "F:\\dataset_sri\\2999.m4a\n",
      "F:\\dataset_sri\\3.m4a\n",
      "F:\\dataset_sri\\30.m4a\n",
      "F:\\dataset_sri\\300.m4a\n",
      "F:\\dataset_sri\\3000.m4a\n",
      "F:\\dataset_sri\\3001.m4a\n",
      "F:\\dataset_sri\\3002.m4a\n",
      "F:\\dataset_sri\\3003.m4a\n",
      "F:\\dataset_sri\\3004.m4a\n",
      "F:\\dataset_sri\\3005.m4a\n",
      "F:\\dataset_sri\\3006.m4a\n",
      "F:\\dataset_sri\\3007.m4a\n",
      "F:\\dataset_sri\\3008.m4a\n",
      "F:\\dataset_sri\\3009.m4a\n",
      "F:\\dataset_sri\\301.m4a\n",
      "F:\\dataset_sri\\3010.m4a\n",
      "F:\\dataset_sri\\3011.m4a\n",
      "F:\\dataset_sri\\3012.m4a\n",
      "F:\\dataset_sri\\3013.m4a\n",
      "F:\\dataset_sri\\3014.m4a\n",
      "F:\\dataset_sri\\3015.m4a\n",
      "F:\\dataset_sri\\3016.m4a\n",
      "F:\\dataset_sri\\3017.m4a\n",
      "F:\\dataset_sri\\3018.m4a\n",
      "F:\\dataset_sri\\3019.m4a\n",
      "F:\\dataset_sri\\302.m4a\n",
      "F:\\dataset_sri\\3020.m4a\n",
      "F:\\dataset_sri\\3021.m4a\n",
      "F:\\dataset_sri\\3022.m4a\n",
      "F:\\dataset_sri\\3023.m4a\n",
      "F:\\dataset_sri\\3024.m4a\n",
      "F:\\dataset_sri\\3025.m4a\n",
      "F:\\dataset_sri\\3026.m4a\n",
      "F:\\dataset_sri\\3027.m4a\n",
      "F:\\dataset_sri\\3028.m4a\n",
      "F:\\dataset_sri\\3029.m4a\n",
      "F:\\dataset_sri\\303.m4a\n",
      "F:\\dataset_sri\\3030.m4a\n",
      "F:\\dataset_sri\\3031.m4a\n",
      "F:\\dataset_sri\\3032.m4a\n",
      "F:\\dataset_sri\\3033.m4a\n",
      "F:\\dataset_sri\\3034.m4a\n",
      "F:\\dataset_sri\\3035.m4a\n",
      "F:\\dataset_sri\\3036.m4a\n",
      "F:\\dataset_sri\\3037.m4a\n",
      "F:\\dataset_sri\\3038.m4a\n",
      "F:\\dataset_sri\\3039.m4a\n",
      "F:\\dataset_sri\\304.m4a\n",
      "F:\\dataset_sri\\3040.m4a\n",
      "F:\\dataset_sri\\3041.m4a\n",
      "F:\\dataset_sri\\3042.m4a\n",
      "F:\\dataset_sri\\3043.m4a\n",
      "F:\\dataset_sri\\3044.m4a\n",
      "F:\\dataset_sri\\3045.m4a\n",
      "F:\\dataset_sri\\3046.m4a\n",
      "F:\\dataset_sri\\3047.m4a\n",
      "F:\\dataset_sri\\3048.m4a\n",
      "F:\\dataset_sri\\3049.m4a\n",
      "F:\\dataset_sri\\305.m4a\n",
      "F:\\dataset_sri\\3050.m4a\n",
      "F:\\dataset_sri\\3051.m4a\n",
      "F:\\dataset_sri\\3052.m4a\n",
      "F:\\dataset_sri\\3053.m4a\n",
      "F:\\dataset_sri\\3054.m4a\n",
      "F:\\dataset_sri\\3055.m4a\n",
      "F:\\dataset_sri\\3056.m4a\n",
      "F:\\dataset_sri\\3057.m4a\n",
      "F:\\dataset_sri\\3058.m4a\n",
      "F:\\dataset_sri\\3059.m4a\n",
      "F:\\dataset_sri\\306.m4a\n",
      "F:\\dataset_sri\\3060.m4a\n",
      "F:\\dataset_sri\\3061.m4a\n",
      "F:\\dataset_sri\\3062.m4a\n",
      "F:\\dataset_sri\\3063.m4a\n",
      "F:\\dataset_sri\\3064.m4a\n",
      "F:\\dataset_sri\\3065.m4a\n",
      "F:\\dataset_sri\\3066.m4a\n",
      "F:\\dataset_sri\\3067.m4a\n",
      "F:\\dataset_sri\\3068.m4a\n",
      "F:\\dataset_sri\\3069.m4a\n",
      "F:\\dataset_sri\\307.m4a\n",
      "F:\\dataset_sri\\3070.m4a\n",
      "F:\\dataset_sri\\3071.m4a\n",
      "F:\\dataset_sri\\3072.m4a\n",
      "F:\\dataset_sri\\3073.m4a\n",
      "F:\\dataset_sri\\3074.m4a\n",
      "F:\\dataset_sri\\3075.m4a\n",
      "F:\\dataset_sri\\3076.m4a\n",
      "F:\\dataset_sri\\3077.m4a\n",
      "F:\\dataset_sri\\3078.m4a\n",
      "F:\\dataset_sri\\3079.m4a\n",
      "F:\\dataset_sri\\308.m4a\n",
      "F:\\dataset_sri\\3080.m4a\n",
      "F:\\dataset_sri\\3081.m4a\n",
      "F:\\dataset_sri\\3082.m4a\n",
      "F:\\dataset_sri\\3083.m4a\n",
      "F:\\dataset_sri\\3084.m4a\n",
      "F:\\dataset_sri\\3085.m4a\n",
      "F:\\dataset_sri\\3086.m4a\n",
      "F:\\dataset_sri\\3087.m4a\n",
      "F:\\dataset_sri\\3088.m4a\n",
      "F:\\dataset_sri\\3089.m4a\n",
      "F:\\dataset_sri\\309.m4a\n",
      "F:\\dataset_sri\\3090.m4a\n",
      "F:\\dataset_sri\\3091.m4a\n",
      "F:\\dataset_sri\\3092.m4a\n",
      "F:\\dataset_sri\\3093.m4a\n",
      "F:\\dataset_sri\\3094.m4a\n",
      "F:\\dataset_sri\\3095.m4a\n",
      "F:\\dataset_sri\\3096.m4a\n",
      "F:\\dataset_sri\\3097.m4a\n",
      "F:\\dataset_sri\\3098.m4a\n",
      "F:\\dataset_sri\\3099.m4a\n",
      "F:\\dataset_sri\\31.m4a\n",
      "F:\\dataset_sri\\310.m4a\n",
      "F:\\dataset_sri\\3100.m4a\n",
      "F:\\dataset_sri\\3101.m4a\n",
      "F:\\dataset_sri\\3102.m4a\n",
      "F:\\dataset_sri\\3103.m4a\n",
      "F:\\dataset_sri\\3104.m4a\n",
      "F:\\dataset_sri\\3105.m4a\n",
      "F:\\dataset_sri\\3106.m4a\n",
      "F:\\dataset_sri\\3107.m4a\n",
      "F:\\dataset_sri\\3108.m4a\n",
      "F:\\dataset_sri\\3109.m4a\n",
      "F:\\dataset_sri\\311.m4a\n",
      "F:\\dataset_sri\\3110.m4a\n",
      "F:\\dataset_sri\\3111.m4a\n",
      "F:\\dataset_sri\\3112.m4a\n",
      "F:\\dataset_sri\\3113.m4a\n",
      "F:\\dataset_sri\\3114.m4a\n",
      "F:\\dataset_sri\\3115.m4a\n",
      "F:\\dataset_sri\\3116.m4a\n",
      "F:\\dataset_sri\\3117.m4a\n",
      "F:\\dataset_sri\\3118.m4a\n",
      "F:\\dataset_sri\\3119.m4a\n",
      "F:\\dataset_sri\\312.m4a\n",
      "F:\\dataset_sri\\3120.m4a\n",
      "F:\\dataset_sri\\3121.m4a\n",
      "F:\\dataset_sri\\3122.m4a\n",
      "F:\\dataset_sri\\3123.m4a\n",
      "F:\\dataset_sri\\3124.m4a\n",
      "F:\\dataset_sri\\3125.m4a\n",
      "F:\\dataset_sri\\3126.m4a\n",
      "F:\\dataset_sri\\3127.m4a\n",
      "F:\\dataset_sri\\3128.m4a\n",
      "F:\\dataset_sri\\3129.m4a\n",
      "F:\\dataset_sri\\313.m4a\n",
      "F:\\dataset_sri\\3130.m4a\n",
      "F:\\dataset_sri\\3131.m4a\n",
      "F:\\dataset_sri\\3132.m4a\n",
      "F:\\dataset_sri\\3133.m4a\n",
      "F:\\dataset_sri\\3134.m4a\n",
      "F:\\dataset_sri\\3135.m4a\n",
      "F:\\dataset_sri\\3136.m4a\n",
      "F:\\dataset_sri\\3137.m4a\n",
      "F:\\dataset_sri\\3138.m4a\n",
      "F:\\dataset_sri\\3139.m4a\n",
      "F:\\dataset_sri\\314.m4a\n",
      "F:\\dataset_sri\\3140.m4a\n",
      "F:\\dataset_sri\\3141.m4a\n",
      "F:\\dataset_sri\\3142.m4a\n",
      "F:\\dataset_sri\\3143.m4a\n",
      "F:\\dataset_sri\\3144.m4a\n",
      "F:\\dataset_sri\\3145.m4a\n",
      "F:\\dataset_sri\\3146.m4a\n",
      "F:\\dataset_sri\\3147.m4a\n",
      "F:\\dataset_sri\\3148.m4a\n",
      "F:\\dataset_sri\\3149.m4a\n",
      "F:\\dataset_sri\\315.m4a\n",
      "F:\\dataset_sri\\3150.m4a\n",
      "F:\\dataset_sri\\3151.m4a\n",
      "F:\\dataset_sri\\3152.m4a\n",
      "F:\\dataset_sri\\3153.m4a\n",
      "F:\\dataset_sri\\3154.m4a\n",
      "F:\\dataset_sri\\3155.m4a\n",
      "F:\\dataset_sri\\3156.m4a\n",
      "F:\\dataset_sri\\3157.m4a\n",
      "F:\\dataset_sri\\3158.m4a\n",
      "F:\\dataset_sri\\3159.m4a\n",
      "F:\\dataset_sri\\316.m4a\n",
      "F:\\dataset_sri\\3160.m4a\n",
      "F:\\dataset_sri\\3161.m4a\n",
      "F:\\dataset_sri\\3162.m4a\n",
      "F:\\dataset_sri\\3163.m4a\n",
      "F:\\dataset_sri\\3164.m4a\n",
      "F:\\dataset_sri\\3165.m4a\n",
      "F:\\dataset_sri\\3166.m4a\n",
      "F:\\dataset_sri\\3167.m4a\n",
      "F:\\dataset_sri\\3168.m4a\n",
      "F:\\dataset_sri\\3169.m4a\n",
      "F:\\dataset_sri\\317.m4a\n",
      "F:\\dataset_sri\\3170.m4a\n",
      "F:\\dataset_sri\\3171.m4a\n",
      "F:\\dataset_sri\\3172.m4a\n",
      "F:\\dataset_sri\\3173.m4a\n",
      "F:\\dataset_sri\\3174.m4a\n",
      "F:\\dataset_sri\\3175.m4a\n",
      "F:\\dataset_sri\\3176.m4a\n",
      "F:\\dataset_sri\\3177.m4a\n",
      "F:\\dataset_sri\\3178.m4a\n",
      "F:\\dataset_sri\\3179.m4a\n",
      "F:\\dataset_sri\\318.m4a\n",
      "F:\\dataset_sri\\3180.m4a\n",
      "F:\\dataset_sri\\3181.m4a\n",
      "F:\\dataset_sri\\3182.m4a\n",
      "F:\\dataset_sri\\3183.m4a\n",
      "F:\\dataset_sri\\3184.m4a\n",
      "F:\\dataset_sri\\3185.m4a\n",
      "F:\\dataset_sri\\3186.m4a\n",
      "F:\\dataset_sri\\3187.m4a\n",
      "F:\\dataset_sri\\3188.m4a\n",
      "F:\\dataset_sri\\3189.m4a\n",
      "F:\\dataset_sri\\319.m4a\n",
      "F:\\dataset_sri\\3190.m4a\n",
      "F:\\dataset_sri\\3191.m4a\n",
      "F:\\dataset_sri\\3192.m4a\n",
      "F:\\dataset_sri\\3193.m4a\n",
      "F:\\dataset_sri\\3194.m4a\n",
      "F:\\dataset_sri\\3195.m4a\n",
      "F:\\dataset_sri\\3196.m4a\n",
      "F:\\dataset_sri\\3197.m4a\n",
      "F:\\dataset_sri\\3198.m4a\n",
      "F:\\dataset_sri\\3199.m4a\n",
      "F:\\dataset_sri\\32.m4a\n",
      "F:\\dataset_sri\\320.m4a\n",
      "F:\\dataset_sri\\3200.m4a\n",
      "F:\\dataset_sri\\3201.m4a\n",
      "F:\\dataset_sri\\3202.m4a\n",
      "F:\\dataset_sri\\3203.m4a\n",
      "F:\\dataset_sri\\3204.m4a\n",
      "F:\\dataset_sri\\3205.m4a\n",
      "F:\\dataset_sri\\3206.m4a\n",
      "F:\\dataset_sri\\3207.m4a\n",
      "F:\\dataset_sri\\3208.m4a\n",
      "F:\\dataset_sri\\3209.m4a\n",
      "F:\\dataset_sri\\321.m4a\n",
      "F:\\dataset_sri\\3210.m4a\n",
      "F:\\dataset_sri\\3211.m4a\n",
      "F:\\dataset_sri\\3212.m4a\n",
      "F:\\dataset_sri\\3213.m4a\n",
      "F:\\dataset_sri\\3214.m4a\n",
      "F:\\dataset_sri\\3215.m4a\n",
      "F:\\dataset_sri\\3216.m4a\n",
      "F:\\dataset_sri\\3217.m4a\n",
      "F:\\dataset_sri\\3218.m4a\n",
      "F:\\dataset_sri\\3219.m4a\n",
      "F:\\dataset_sri\\322.m4a\n",
      "F:\\dataset_sri\\3220.m4a\n",
      "F:\\dataset_sri\\3221.m4a\n",
      "F:\\dataset_sri\\3222.m4a\n",
      "F:\\dataset_sri\\3223.m4a\n",
      "F:\\dataset_sri\\3224.m4a\n",
      "F:\\dataset_sri\\3225.m4a\n",
      "F:\\dataset_sri\\3226.m4a\n",
      "F:\\dataset_sri\\3227.m4a\n",
      "F:\\dataset_sri\\3228.m4a\n",
      "F:\\dataset_sri\\3229.m4a\n",
      "F:\\dataset_sri\\323.m4a\n",
      "F:\\dataset_sri\\3230.m4a\n",
      "F:\\dataset_sri\\3231.m4a\n",
      "F:\\dataset_sri\\3232.m4a\n",
      "F:\\dataset_sri\\3233.m4a\n",
      "F:\\dataset_sri\\3234.m4a\n",
      "F:\\dataset_sri\\3235.m4a\n",
      "F:\\dataset_sri\\3236.m4a\n",
      "F:\\dataset_sri\\3237.m4a\n",
      "F:\\dataset_sri\\3238.m4a\n",
      "F:\\dataset_sri\\3239.m4a\n",
      "F:\\dataset_sri\\324.m4a\n",
      "F:\\dataset_sri\\3240.m4a\n",
      "F:\\dataset_sri\\3241.m4a\n",
      "F:\\dataset_sri\\3242.m4a\n",
      "F:\\dataset_sri\\3243.m4a\n",
      "F:\\dataset_sri\\3244.m4a\n",
      "F:\\dataset_sri\\3245.m4a\n",
      "F:\\dataset_sri\\3246.m4a\n",
      "F:\\dataset_sri\\3247.m4a\n",
      "F:\\dataset_sri\\3248.m4a\n",
      "F:\\dataset_sri\\3249.m4a\n",
      "F:\\dataset_sri\\325.m4a\n",
      "F:\\dataset_sri\\3250.m4a\n",
      "F:\\dataset_sri\\3251.m4a\n",
      "F:\\dataset_sri\\3252.m4a\n",
      "F:\\dataset_sri\\3253.m4a\n",
      "F:\\dataset_sri\\3254.m4a\n",
      "F:\\dataset_sri\\3255.m4a\n",
      "F:\\dataset_sri\\3256.m4a\n",
      "F:\\dataset_sri\\3257.m4a\n",
      "F:\\dataset_sri\\3258.m4a\n",
      "F:\\dataset_sri\\3259.m4a\n",
      "F:\\dataset_sri\\326.m4a\n",
      "F:\\dataset_sri\\3260.m4a\n",
      "F:\\dataset_sri\\3261.m4a\n",
      "F:\\dataset_sri\\3262.m4a\n",
      "F:\\dataset_sri\\3263.m4a\n",
      "F:\\dataset_sri\\3264.m4a\n",
      "F:\\dataset_sri\\3265.m4a\n",
      "F:\\dataset_sri\\3266.m4a\n",
      "F:\\dataset_sri\\3267.m4a\n",
      "F:\\dataset_sri\\3268.m4a\n",
      "F:\\dataset_sri\\3269.m4a\n",
      "F:\\dataset_sri\\327.m4a\n",
      "F:\\dataset_sri\\3270.m4a\n",
      "F:\\dataset_sri\\3271.m4a\n",
      "F:\\dataset_sri\\3272.m4a\n",
      "F:\\dataset_sri\\3273.m4a\n",
      "F:\\dataset_sri\\3274.m4a\n",
      "F:\\dataset_sri\\3275.m4a\n",
      "F:\\dataset_sri\\3276.m4a\n",
      "F:\\dataset_sri\\3277.m4a\n",
      "F:\\dataset_sri\\3278.m4a\n",
      "F:\\dataset_sri\\3279.m4a\n",
      "F:\\dataset_sri\\328.m4a\n",
      "F:\\dataset_sri\\3280.m4a\n",
      "F:\\dataset_sri\\3281.m4a\n",
      "F:\\dataset_sri\\3282.m4a\n",
      "F:\\dataset_sri\\3283.m4a\n",
      "F:\\dataset_sri\\3284.m4a\n",
      "F:\\dataset_sri\\3285.m4a\n",
      "F:\\dataset_sri\\3286.m4a\n",
      "F:\\dataset_sri\\3287.m4a\n",
      "F:\\dataset_sri\\3288.m4a\n",
      "F:\\dataset_sri\\3289.m4a\n",
      "F:\\dataset_sri\\329.m4a\n",
      "F:\\dataset_sri\\3290.m4a\n",
      "F:\\dataset_sri\\3291.m4a\n",
      "F:\\dataset_sri\\3292.m4a\n",
      "F:\\dataset_sri\\3293.m4a\n",
      "F:\\dataset_sri\\3294.m4a\n",
      "F:\\dataset_sri\\3295.m4a\n",
      "F:\\dataset_sri\\3296.m4a\n",
      "F:\\dataset_sri\\3297.m4a\n",
      "F:\\dataset_sri\\3298.m4a\n",
      "F:\\dataset_sri\\3299.m4a\n",
      "F:\\dataset_sri\\33.m4a\n",
      "F:\\dataset_sri\\330.m4a\n",
      "F:\\dataset_sri\\3300.m4a\n",
      "F:\\dataset_sri\\3301.m4a\n",
      "F:\\dataset_sri\\3302.m4a\n",
      "F:\\dataset_sri\\3303.m4a\n",
      "F:\\dataset_sri\\3304.m4a\n",
      "F:\\dataset_sri\\3305.m4a\n",
      "F:\\dataset_sri\\3306.m4a\n",
      "F:\\dataset_sri\\3307.m4a\n",
      "F:\\dataset_sri\\3308.m4a\n",
      "F:\\dataset_sri\\3309.m4a\n",
      "F:\\dataset_sri\\331.m4a\n",
      "F:\\dataset_sri\\3310.m4a\n",
      "F:\\dataset_sri\\3311.m4a\n",
      "F:\\dataset_sri\\3312.m4a\n",
      "F:\\dataset_sri\\3313.m4a\n",
      "F:\\dataset_sri\\3314.m4a\n",
      "F:\\dataset_sri\\3315.m4a\n",
      "F:\\dataset_sri\\3316.m4a\n",
      "F:\\dataset_sri\\3317.m4a\n",
      "F:\\dataset_sri\\3318.m4a\n",
      "F:\\dataset_sri\\3319.m4a\n",
      "F:\\dataset_sri\\332.m4a\n",
      "F:\\dataset_sri\\3320.m4a\n",
      "F:\\dataset_sri\\3321.m4a\n",
      "F:\\dataset_sri\\3322.m4a\n",
      "F:\\dataset_sri\\3323.m4a\n",
      "F:\\dataset_sri\\3324.m4a\n",
      "F:\\dataset_sri\\3325.m4a\n",
      "F:\\dataset_sri\\3326.m4a\n",
      "F:\\dataset_sri\\3327.m4a\n",
      "F:\\dataset_sri\\3328.m4a\n",
      "F:\\dataset_sri\\3329.m4a\n",
      "F:\\dataset_sri\\333.m4a\n",
      "F:\\dataset_sri\\3330.m4a\n",
      "F:\\dataset_sri\\3331.m4a\n",
      "F:\\dataset_sri\\3332.m4a\n",
      "F:\\dataset_sri\\3333.m4a\n",
      "F:\\dataset_sri\\3334.m4a\n",
      "F:\\dataset_sri\\3335.m4a\n",
      "F:\\dataset_sri\\3336.m4a\n",
      "F:\\dataset_sri\\3337.m4a\n",
      "F:\\dataset_sri\\3338.m4a\n",
      "F:\\dataset_sri\\3339.m4a\n",
      "F:\\dataset_sri\\334.m4a\n",
      "F:\\dataset_sri\\3340.m4a\n",
      "F:\\dataset_sri\\3341.m4a\n",
      "F:\\dataset_sri\\3342.m4a\n",
      "F:\\dataset_sri\\3343.m4a\n",
      "F:\\dataset_sri\\3344.m4a\n",
      "F:\\dataset_sri\\3345.m4a\n",
      "F:\\dataset_sri\\3346.m4a\n",
      "F:\\dataset_sri\\3347.m4a\n",
      "F:\\dataset_sri\\3348.m4a\n",
      "F:\\dataset_sri\\3349.m4a\n",
      "F:\\dataset_sri\\335.m4a\n",
      "F:\\dataset_sri\\3350.m4a\n",
      "F:\\dataset_sri\\3351.m4a\n",
      "F:\\dataset_sri\\3352.m4a\n",
      "F:\\dataset_sri\\3353.m4a\n",
      "F:\\dataset_sri\\3354.m4a\n",
      "F:\\dataset_sri\\3355.m4a\n",
      "F:\\dataset_sri\\3356.m4a\n",
      "F:\\dataset_sri\\3357.m4a\n",
      "F:\\dataset_sri\\3358.m4a\n",
      "F:\\dataset_sri\\3359.m4a\n",
      "F:\\dataset_sri\\336.m4a\n",
      "F:\\dataset_sri\\3360.m4a\n",
      "F:\\dataset_sri\\3361.m4a\n",
      "F:\\dataset_sri\\3362.m4a\n",
      "F:\\dataset_sri\\3363.m4a\n",
      "F:\\dataset_sri\\3364.m4a\n",
      "F:\\dataset_sri\\3365.m4a\n",
      "F:\\dataset_sri\\3366.m4a\n",
      "F:\\dataset_sri\\3367.m4a\n",
      "F:\\dataset_sri\\3368.m4a\n",
      "F:\\dataset_sri\\3369.m4a\n",
      "F:\\dataset_sri\\337.m4a\n",
      "F:\\dataset_sri\\3370.m4a\n",
      "F:\\dataset_sri\\3371.m4a\n",
      "F:\\dataset_sri\\3372.m4a\n",
      "F:\\dataset_sri\\3373.m4a\n",
      "F:\\dataset_sri\\3374.m4a\n",
      "F:\\dataset_sri\\3375.m4a\n",
      "F:\\dataset_sri\\3376.m4a\n",
      "F:\\dataset_sri\\3377.m4a\n",
      "F:\\dataset_sri\\3378.m4a\n",
      "F:\\dataset_sri\\3379.m4a\n",
      "F:\\dataset_sri\\338.m4a\n",
      "F:\\dataset_sri\\3380.m4a\n",
      "F:\\dataset_sri\\3381.m4a\n",
      "F:\\dataset_sri\\3382.m4a\n",
      "F:\\dataset_sri\\3383.m4a\n",
      "F:\\dataset_sri\\3384.m4a\n",
      "F:\\dataset_sri\\3385.m4a\n",
      "F:\\dataset_sri\\3386.m4a\n",
      "F:\\dataset_sri\\3387.m4a\n",
      "F:\\dataset_sri\\3388.m4a\n",
      "F:\\dataset_sri\\3389.m4a\n",
      "F:\\dataset_sri\\339.m4a\n",
      "F:\\dataset_sri\\3390.m4a\n",
      "F:\\dataset_sri\\3391.m4a\n",
      "F:\\dataset_sri\\3392.m4a\n",
      "F:\\dataset_sri\\3393.m4a\n",
      "F:\\dataset_sri\\3394.m4a\n",
      "F:\\dataset_sri\\3395.m4a\n",
      "F:\\dataset_sri\\3396.m4a\n",
      "F:\\dataset_sri\\3397.m4a\n",
      "F:\\dataset_sri\\3398.m4a\n",
      "F:\\dataset_sri\\3399.m4a\n",
      "F:\\dataset_sri\\34.m4a\n",
      "F:\\dataset_sri\\340.m4a\n",
      "F:\\dataset_sri\\3400.m4a\n",
      "F:\\dataset_sri\\3401.m4a\n",
      "F:\\dataset_sri\\3402.m4a\n",
      "F:\\dataset_sri\\3403.m4a\n",
      "F:\\dataset_sri\\3404.m4a\n",
      "F:\\dataset_sri\\3405.m4a\n",
      "F:\\dataset_sri\\3406.m4a\n",
      "F:\\dataset_sri\\3407.m4a\n",
      "F:\\dataset_sri\\3408.m4a\n",
      "F:\\dataset_sri\\3409.m4a\n",
      "F:\\dataset_sri\\341.m4a\n",
      "F:\\dataset_sri\\3410.m4a\n",
      "F:\\dataset_sri\\3411.m4a\n",
      "F:\\dataset_sri\\3412.m4a\n",
      "F:\\dataset_sri\\3413.m4a\n",
      "F:\\dataset_sri\\3414.m4a\n",
      "F:\\dataset_sri\\3415.m4a\n",
      "F:\\dataset_sri\\3416.m4a\n",
      "F:\\dataset_sri\\3417.m4a\n",
      "F:\\dataset_sri\\3418.m4a\n",
      "F:\\dataset_sri\\3419.m4a\n",
      "F:\\dataset_sri\\342.m4a\n",
      "F:\\dataset_sri\\3420.m4a\n",
      "F:\\dataset_sri\\3421.m4a\n",
      "F:\\dataset_sri\\3422.m4a\n",
      "F:\\dataset_sri\\3423.m4a\n",
      "F:\\dataset_sri\\3424.m4a\n",
      "F:\\dataset_sri\\3425.m4a\n",
      "F:\\dataset_sri\\3426.m4a\n",
      "F:\\dataset_sri\\3427.m4a\n",
      "F:\\dataset_sri\\3428.m4a\n",
      "F:\\dataset_sri\\3429.m4a\n",
      "F:\\dataset_sri\\343.m4a\n",
      "F:\\dataset_sri\\3430.m4a\n",
      "F:\\dataset_sri\\3431.m4a\n",
      "F:\\dataset_sri\\3432.m4a\n",
      "F:\\dataset_sri\\3433.m4a\n",
      "F:\\dataset_sri\\3434.m4a\n",
      "F:\\dataset_sri\\3435.m4a\n",
      "F:\\dataset_sri\\3436.m4a\n",
      "F:\\dataset_sri\\3437.m4a\n",
      "F:\\dataset_sri\\3438.m4a\n",
      "F:\\dataset_sri\\3439.m4a\n",
      "F:\\dataset_sri\\344.m4a\n",
      "F:\\dataset_sri\\3440.m4a\n",
      "F:\\dataset_sri\\3441.m4a\n",
      "F:\\dataset_sri\\3442.m4a\n",
      "F:\\dataset_sri\\3443.m4a\n",
      "F:\\dataset_sri\\3444.m4a\n",
      "F:\\dataset_sri\\3445.m4a\n",
      "F:\\dataset_sri\\3446.m4a\n",
      "F:\\dataset_sri\\3447.m4a\n",
      "F:\\dataset_sri\\3448.m4a\n",
      "F:\\dataset_sri\\3449.m4a\n",
      "F:\\dataset_sri\\345.m4a\n",
      "F:\\dataset_sri\\3450.m4a\n",
      "F:\\dataset_sri\\3451.m4a\n",
      "F:\\dataset_sri\\3452.m4a\n",
      "F:\\dataset_sri\\3453.m4a\n",
      "F:\\dataset_sri\\3454.m4a\n",
      "F:\\dataset_sri\\3455.m4a\n",
      "F:\\dataset_sri\\3456.m4a\n",
      "F:\\dataset_sri\\3457.m4a\n",
      "F:\\dataset_sri\\3458.m4a\n",
      "F:\\dataset_sri\\3459.m4a\n",
      "F:\\dataset_sri\\346.m4a\n",
      "F:\\dataset_sri\\3460.m4a\n",
      "F:\\dataset_sri\\3461.m4a\n",
      "F:\\dataset_sri\\3462.m4a\n",
      "F:\\dataset_sri\\3463.m4a\n",
      "F:\\dataset_sri\\3464.m4a\n",
      "F:\\dataset_sri\\3465.m4a\n",
      "F:\\dataset_sri\\3466.m4a\n",
      "F:\\dataset_sri\\3467.m4a\n",
      "F:\\dataset_sri\\3468.m4a\n",
      "F:\\dataset_sri\\3469.m4a\n",
      "F:\\dataset_sri\\347.m4a\n",
      "F:\\dataset_sri\\3470.m4a\n",
      "F:\\dataset_sri\\3471.m4a\n",
      "F:\\dataset_sri\\3472.m4a\n",
      "F:\\dataset_sri\\3473.m4a\n",
      "F:\\dataset_sri\\3474.m4a\n",
      "F:\\dataset_sri\\3475.m4a\n",
      "F:\\dataset_sri\\3476.m4a\n",
      "F:\\dataset_sri\\3477.m4a\n",
      "F:\\dataset_sri\\3478.m4a\n",
      "F:\\dataset_sri\\3479.m4a\n",
      "F:\\dataset_sri\\348.m4a\n",
      "F:\\dataset_sri\\3480.m4a\n",
      "F:\\dataset_sri\\3481.m4a\n",
      "F:\\dataset_sri\\3482.m4a\n",
      "F:\\dataset_sri\\3483.m4a\n",
      "F:\\dataset_sri\\3484.m4a\n",
      "F:\\dataset_sri\\3485.m4a\n",
      "F:\\dataset_sri\\3486.m4a\n",
      "F:\\dataset_sri\\3487.m4a\n",
      "F:\\dataset_sri\\3488.m4a\n",
      "F:\\dataset_sri\\3489.m4a\n",
      "F:\\dataset_sri\\349.m4a\n",
      "F:\\dataset_sri\\3490.m4a\n",
      "F:\\dataset_sri\\3491.m4a\n",
      "F:\\dataset_sri\\3492.m4a\n",
      "F:\\dataset_sri\\3493.m4a\n",
      "F:\\dataset_sri\\3494.m4a\n",
      "F:\\dataset_sri\\3495.m4a\n",
      "F:\\dataset_sri\\3496.m4a\n",
      "F:\\dataset_sri\\3497.m4a\n",
      "F:\\dataset_sri\\3498.m4a\n",
      "F:\\dataset_sri\\3499.m4a\n",
      "F:\\dataset_sri\\35.m4a\n",
      "F:\\dataset_sri\\350.m4a\n",
      "F:\\dataset_sri\\3500.m4a\n",
      "F:\\dataset_sri\\3501.m4a\n",
      "F:\\dataset_sri\\3502.m4a\n",
      "F:\\dataset_sri\\3503.m4a\n",
      "F:\\dataset_sri\\3504.m4a\n",
      "F:\\dataset_sri\\3505.m4a\n",
      "F:\\dataset_sri\\3506.m4a\n",
      "F:\\dataset_sri\\3507.m4a\n",
      "F:\\dataset_sri\\3508.m4a\n",
      "F:\\dataset_sri\\3509.m4a\n",
      "F:\\dataset_sri\\351.m4a\n",
      "F:\\dataset_sri\\3510.m4a\n",
      "F:\\dataset_sri\\3511.m4a\n",
      "F:\\dataset_sri\\3512.m4a\n",
      "F:\\dataset_sri\\3513.m4a\n",
      "F:\\dataset_sri\\3514.m4a\n",
      "F:\\dataset_sri\\3515.m4a\n",
      "F:\\dataset_sri\\3516.m4a\n",
      "F:\\dataset_sri\\3517.m4a\n",
      "F:\\dataset_sri\\3518.m4a\n",
      "F:\\dataset_sri\\3519.m4a\n",
      "F:\\dataset_sri\\352.m4a\n",
      "F:\\dataset_sri\\3520.m4a\n",
      "F:\\dataset_sri\\3521.m4a\n",
      "F:\\dataset_sri\\3522.m4a\n",
      "F:\\dataset_sri\\3523.m4a\n",
      "F:\\dataset_sri\\3524.m4a\n",
      "F:\\dataset_sri\\3525.m4a\n",
      "F:\\dataset_sri\\3526.m4a\n",
      "F:\\dataset_sri\\3527.m4a\n",
      "F:\\dataset_sri\\3528.m4a\n",
      "F:\\dataset_sri\\3529.m4a\n",
      "F:\\dataset_sri\\353.m4a\n",
      "F:\\dataset_sri\\3530.m4a\n",
      "F:\\dataset_sri\\3531.m4a\n",
      "F:\\dataset_sri\\3532.m4a\n",
      "F:\\dataset_sri\\3533.m4a\n",
      "F:\\dataset_sri\\3534.m4a\n",
      "F:\\dataset_sri\\3535.m4a\n",
      "F:\\dataset_sri\\3536.m4a\n",
      "F:\\dataset_sri\\3537.m4a\n",
      "F:\\dataset_sri\\3538.m4a\n",
      "F:\\dataset_sri\\3539.m4a\n",
      "F:\\dataset_sri\\354.m4a\n",
      "F:\\dataset_sri\\3540.m4a\n",
      "F:\\dataset_sri\\3541.m4a\n",
      "F:\\dataset_sri\\3542.m4a\n",
      "F:\\dataset_sri\\3543.m4a\n",
      "F:\\dataset_sri\\3544.m4a\n",
      "F:\\dataset_sri\\3545.m4a\n",
      "F:\\dataset_sri\\3546.m4a\n",
      "F:\\dataset_sri\\3547.m4a\n",
      "F:\\dataset_sri\\3548.m4a\n",
      "F:\\dataset_sri\\3549.m4a\n",
      "F:\\dataset_sri\\355.m4a\n",
      "F:\\dataset_sri\\3550.m4a\n",
      "F:\\dataset_sri\\3551.m4a\n",
      "F:\\dataset_sri\\3552.m4a\n",
      "F:\\dataset_sri\\3553.m4a\n",
      "F:\\dataset_sri\\3554.m4a\n",
      "F:\\dataset_sri\\3555.m4a\n",
      "F:\\dataset_sri\\3556.m4a\n",
      "F:\\dataset_sri\\3557.m4a\n",
      "F:\\dataset_sri\\3558.m4a\n",
      "F:\\dataset_sri\\3559.m4a\n",
      "F:\\dataset_sri\\356.m4a\n",
      "F:\\dataset_sri\\3560.m4a\n",
      "F:\\dataset_sri\\3561.m4a\n",
      "F:\\dataset_sri\\3562.m4a\n",
      "F:\\dataset_sri\\3563.m4a\n",
      "F:\\dataset_sri\\3564.m4a\n",
      "F:\\dataset_sri\\3565.m4a\n",
      "F:\\dataset_sri\\3566.m4a\n",
      "F:\\dataset_sri\\3567.m4a\n",
      "F:\\dataset_sri\\3568.m4a\n",
      "F:\\dataset_sri\\3569.m4a\n",
      "F:\\dataset_sri\\357.m4a\n",
      "F:\\dataset_sri\\3570.m4a\n",
      "F:\\dataset_sri\\3571.m4a\n",
      "F:\\dataset_sri\\3572.m4a\n",
      "F:\\dataset_sri\\3573.m4a\n",
      "F:\\dataset_sri\\3574.m4a\n",
      "F:\\dataset_sri\\3575.m4a\n",
      "F:\\dataset_sri\\3576.m4a\n",
      "F:\\dataset_sri\\3577.m4a\n",
      "F:\\dataset_sri\\3578.m4a\n",
      "F:\\dataset_sri\\3579.m4a\n",
      "F:\\dataset_sri\\358.m4a\n",
      "F:\\dataset_sri\\3580.m4a\n",
      "F:\\dataset_sri\\3581.m4a\n",
      "F:\\dataset_sri\\3582.m4a\n",
      "F:\\dataset_sri\\3583.m4a\n",
      "F:\\dataset_sri\\3584.m4a\n",
      "F:\\dataset_sri\\3585.m4a\n",
      "F:\\dataset_sri\\3586.m4a\n",
      "F:\\dataset_sri\\3587.m4a\n",
      "F:\\dataset_sri\\3588.m4a\n",
      "F:\\dataset_sri\\3589.m4a\n",
      "F:\\dataset_sri\\359.m4a\n",
      "F:\\dataset_sri\\3590.m4a\n",
      "F:\\dataset_sri\\3591.m4a\n",
      "F:\\dataset_sri\\3592.m4a\n",
      "F:\\dataset_sri\\3593.m4a\n",
      "F:\\dataset_sri\\3594.m4a\n",
      "F:\\dataset_sri\\3595.m4a\n",
      "F:\\dataset_sri\\3596.m4a\n",
      "F:\\dataset_sri\\3597.m4a\n",
      "F:\\dataset_sri\\3598.m4a\n",
      "F:\\dataset_sri\\3599.m4a\n",
      "F:\\dataset_sri\\36.m4a\n",
      "F:\\dataset_sri\\360.m4a\n",
      "F:\\dataset_sri\\3600.m4a\n",
      "F:\\dataset_sri\\3601.m4a\n",
      "F:\\dataset_sri\\3602.m4a\n",
      "F:\\dataset_sri\\3603.m4a\n",
      "F:\\dataset_sri\\3604.m4a\n",
      "F:\\dataset_sri\\3605.m4a\n",
      "F:\\dataset_sri\\3606.m4a\n",
      "F:\\dataset_sri\\3607.m4a\n",
      "F:\\dataset_sri\\3608.m4a\n",
      "F:\\dataset_sri\\3609.m4a\n",
      "F:\\dataset_sri\\361.m4a\n",
      "F:\\dataset_sri\\3610.m4a\n",
      "F:\\dataset_sri\\3611.m4a\n",
      "F:\\dataset_sri\\3612.m4a\n",
      "F:\\dataset_sri\\3613.m4a\n",
      "F:\\dataset_sri\\3614.m4a\n",
      "F:\\dataset_sri\\3615.m4a\n",
      "F:\\dataset_sri\\3616.m4a\n",
      "F:\\dataset_sri\\3617.m4a\n",
      "F:\\dataset_sri\\3618.m4a\n",
      "F:\\dataset_sri\\3619.m4a\n",
      "F:\\dataset_sri\\362.m4a\n",
      "F:\\dataset_sri\\3620.m4a\n",
      "F:\\dataset_sri\\3621.m4a\n",
      "F:\\dataset_sri\\3622.m4a\n",
      "F:\\dataset_sri\\3623.m4a\n",
      "F:\\dataset_sri\\3624.m4a\n",
      "F:\\dataset_sri\\3625.m4a\n",
      "F:\\dataset_sri\\3626.m4a\n",
      "F:\\dataset_sri\\3627.m4a\n",
      "F:\\dataset_sri\\3628.m4a\n",
      "F:\\dataset_sri\\3629.m4a\n",
      "F:\\dataset_sri\\363.m4a\n",
      "F:\\dataset_sri\\3630.m4a\n",
      "F:\\dataset_sri\\3631.m4a\n",
      "F:\\dataset_sri\\3632.m4a\n",
      "F:\\dataset_sri\\3633.m4a\n",
      "F:\\dataset_sri\\3634.m4a\n",
      "F:\\dataset_sri\\3635.m4a\n",
      "F:\\dataset_sri\\3636.m4a\n",
      "F:\\dataset_sri\\3637.m4a\n",
      "F:\\dataset_sri\\3638.m4a\n",
      "F:\\dataset_sri\\3639.m4a\n",
      "F:\\dataset_sri\\364.m4a\n",
      "F:\\dataset_sri\\3640.m4a\n",
      "F:\\dataset_sri\\3641.m4a\n",
      "F:\\dataset_sri\\3642.m4a\n",
      "F:\\dataset_sri\\3643.m4a\n",
      "F:\\dataset_sri\\3644.m4a\n",
      "F:\\dataset_sri\\3645.m4a\n",
      "F:\\dataset_sri\\3646.m4a\n",
      "F:\\dataset_sri\\3647.m4a\n",
      "F:\\dataset_sri\\3648.m4a\n",
      "F:\\dataset_sri\\3649.m4a\n",
      "F:\\dataset_sri\\365.m4a\n",
      "F:\\dataset_sri\\3650.m4a\n",
      "F:\\dataset_sri\\3651.m4a\n",
      "F:\\dataset_sri\\3652.m4a\n",
      "F:\\dataset_sri\\3653.m4a\n",
      "F:\\dataset_sri\\3654.m4a\n",
      "F:\\dataset_sri\\3655.m4a\n",
      "F:\\dataset_sri\\3656.m4a\n",
      "F:\\dataset_sri\\3657.m4a\n",
      "F:\\dataset_sri\\3658.m4a\n",
      "F:\\dataset_sri\\3659.m4a\n",
      "F:\\dataset_sri\\366.m4a\n",
      "F:\\dataset_sri\\3660.m4a\n",
      "F:\\dataset_sri\\3661.m4a\n",
      "F:\\dataset_sri\\3662.m4a\n",
      "F:\\dataset_sri\\3663.m4a\n",
      "F:\\dataset_sri\\3664.m4a\n",
      "F:\\dataset_sri\\3665.m4a\n",
      "F:\\dataset_sri\\3666.m4a\n",
      "F:\\dataset_sri\\3667.m4a\n",
      "F:\\dataset_sri\\3668.m4a\n",
      "F:\\dataset_sri\\3669.m4a\n",
      "F:\\dataset_sri\\367.m4a\n",
      "F:\\dataset_sri\\3670.m4a\n",
      "F:\\dataset_sri\\3671.m4a\n",
      "F:\\dataset_sri\\3672.m4a\n",
      "F:\\dataset_sri\\3673.m4a\n",
      "F:\\dataset_sri\\3674.m4a\n",
      "F:\\dataset_sri\\3675.m4a\n",
      "F:\\dataset_sri\\3676.m4a\n",
      "F:\\dataset_sri\\3677.m4a\n",
      "F:\\dataset_sri\\3678.m4a\n",
      "F:\\dataset_sri\\3679.m4a\n",
      "F:\\dataset_sri\\368.m4a\n",
      "F:\\dataset_sri\\3680.m4a\n",
      "F:\\dataset_sri\\3681.m4a\n",
      "F:\\dataset_sri\\3682.m4a\n",
      "F:\\dataset_sri\\3683.m4a\n",
      "F:\\dataset_sri\\3684.m4a\n",
      "F:\\dataset_sri\\3685.m4a\n",
      "F:\\dataset_sri\\3686.m4a\n",
      "F:\\dataset_sri\\3687.m4a\n",
      "F:\\dataset_sri\\3688.m4a\n",
      "F:\\dataset_sri\\3689.m4a\n",
      "F:\\dataset_sri\\369.m4a\n",
      "F:\\dataset_sri\\3690.m4a\n",
      "F:\\dataset_sri\\3691.m4a\n",
      "F:\\dataset_sri\\3692.m4a\n",
      "F:\\dataset_sri\\3693.m4a\n",
      "F:\\dataset_sri\\3694.m4a\n",
      "F:\\dataset_sri\\3695.m4a\n",
      "F:\\dataset_sri\\3696.m4a\n",
      "F:\\dataset_sri\\3697.m4a\n",
      "F:\\dataset_sri\\3698.m4a\n",
      "F:\\dataset_sri\\3699.m4a\n",
      "F:\\dataset_sri\\37.m4a\n",
      "F:\\dataset_sri\\370.m4a\n",
      "F:\\dataset_sri\\3700.m4a\n",
      "F:\\dataset_sri\\3701.m4a\n",
      "F:\\dataset_sri\\3702.m4a\n",
      "F:\\dataset_sri\\3703.m4a\n",
      "F:\\dataset_sri\\3704.m4a\n",
      "F:\\dataset_sri\\3705.m4a\n",
      "F:\\dataset_sri\\3706.m4a\n",
      "F:\\dataset_sri\\3707.m4a\n",
      "F:\\dataset_sri\\3708.m4a\n",
      "F:\\dataset_sri\\3709.m4a\n",
      "F:\\dataset_sri\\371.m4a\n",
      "F:\\dataset_sri\\3710.m4a\n",
      "F:\\dataset_sri\\3711.m4a\n",
      "F:\\dataset_sri\\3712.m4a\n",
      "F:\\dataset_sri\\3713.m4a\n",
      "F:\\dataset_sri\\3714.m4a\n",
      "F:\\dataset_sri\\3715.m4a\n",
      "F:\\dataset_sri\\3716.m4a\n",
      "F:\\dataset_sri\\3717.m4a\n",
      "F:\\dataset_sri\\3718.m4a\n",
      "F:\\dataset_sri\\3719.m4a\n",
      "F:\\dataset_sri\\372.m4a\n",
      "F:\\dataset_sri\\3720.m4a\n",
      "F:\\dataset_sri\\3721.m4a\n",
      "F:\\dataset_sri\\3722.m4a\n",
      "F:\\dataset_sri\\3723.m4a\n",
      "F:\\dataset_sri\\3724.m4a\n",
      "F:\\dataset_sri\\3725.m4a\n",
      "F:\\dataset_sri\\3726.m4a\n",
      "F:\\dataset_sri\\3727.m4a\n",
      "F:\\dataset_sri\\3728.m4a\n",
      "F:\\dataset_sri\\3729.m4a\n",
      "F:\\dataset_sri\\373.m4a\n",
      "F:\\dataset_sri\\3730.m4a\n",
      "F:\\dataset_sri\\3731.m4a\n",
      "F:\\dataset_sri\\3732.m4a\n",
      "F:\\dataset_sri\\3733.m4a\n",
      "F:\\dataset_sri\\3734.m4a\n",
      "F:\\dataset_sri\\3735.m4a\n",
      "F:\\dataset_sri\\3736.m4a\n",
      "F:\\dataset_sri\\3737.m4a\n",
      "F:\\dataset_sri\\3738.m4a\n",
      "F:\\dataset_sri\\3739.m4a\n",
      "F:\\dataset_sri\\374.m4a\n",
      "F:\\dataset_sri\\3740.m4a\n",
      "F:\\dataset_sri\\3741.m4a\n",
      "F:\\dataset_sri\\3742.m4a\n",
      "F:\\dataset_sri\\3743.m4a\n",
      "F:\\dataset_sri\\3744.m4a\n",
      "F:\\dataset_sri\\3745.m4a\n",
      "F:\\dataset_sri\\3746.m4a\n",
      "F:\\dataset_sri\\3747.m4a\n",
      "F:\\dataset_sri\\3748.m4a\n",
      "F:\\dataset_sri\\3749.m4a\n",
      "F:\\dataset_sri\\375.m4a\n",
      "F:\\dataset_sri\\3750.m4a\n",
      "F:\\dataset_sri\\3751.m4a\n",
      "F:\\dataset_sri\\3752.m4a\n",
      "F:\\dataset_sri\\3753.m4a\n",
      "F:\\dataset_sri\\3754.m4a\n",
      "F:\\dataset_sri\\3755.m4a\n",
      "F:\\dataset_sri\\3756.m4a\n",
      "F:\\dataset_sri\\3757.m4a\n",
      "F:\\dataset_sri\\3758.m4a\n",
      "F:\\dataset_sri\\3759.m4a\n",
      "F:\\dataset_sri\\376.m4a\n",
      "F:\\dataset_sri\\3760.m4a\n",
      "F:\\dataset_sri\\3761.m4a\n",
      "F:\\dataset_sri\\3762.m4a\n",
      "F:\\dataset_sri\\3763.m4a\n",
      "F:\\dataset_sri\\3764.m4a\n",
      "F:\\dataset_sri\\3765.m4a\n",
      "F:\\dataset_sri\\3766.m4a\n",
      "F:\\dataset_sri\\3767.m4a\n",
      "F:\\dataset_sri\\3768.m4a\n",
      "F:\\dataset_sri\\3769.m4a\n",
      "F:\\dataset_sri\\377.m4a\n",
      "F:\\dataset_sri\\3770.m4a\n",
      "F:\\dataset_sri\\3771.m4a\n",
      "F:\\dataset_sri\\3772.m4a\n",
      "F:\\dataset_sri\\3773.m4a\n",
      "F:\\dataset_sri\\3774.m4a\n",
      "F:\\dataset_sri\\3775.m4a\n",
      "F:\\dataset_sri\\3776.m4a\n",
      "F:\\dataset_sri\\3777.m4a\n",
      "F:\\dataset_sri\\3778.m4a\n",
      "F:\\dataset_sri\\3779.m4a\n",
      "F:\\dataset_sri\\378.m4a\n",
      "F:\\dataset_sri\\3780.m4a\n",
      "F:\\dataset_sri\\3781.m4a\n",
      "F:\\dataset_sri\\3782.m4a\n",
      "F:\\dataset_sri\\3783.m4a\n",
      "F:\\dataset_sri\\3784.m4a\n",
      "F:\\dataset_sri\\3785.m4a\n",
      "F:\\dataset_sri\\3786.m4a\n",
      "F:\\dataset_sri\\3787.m4a\n",
      "F:\\dataset_sri\\3788.m4a\n",
      "F:\\dataset_sri\\3789.m4a\n",
      "F:\\dataset_sri\\379.m4a\n",
      "F:\\dataset_sri\\3790.m4a\n",
      "F:\\dataset_sri\\3791.m4a\n",
      "F:\\dataset_sri\\3792.m4a\n",
      "F:\\dataset_sri\\3793.m4a\n",
      "F:\\dataset_sri\\3794.m4a\n",
      "F:\\dataset_sri\\3795.m4a\n",
      "F:\\dataset_sri\\3796.m4a\n",
      "F:\\dataset_sri\\3797.m4a\n",
      "F:\\dataset_sri\\3798.m4a\n",
      "F:\\dataset_sri\\3799.m4a\n",
      "F:\\dataset_sri\\38.m4a\n",
      "F:\\dataset_sri\\380.m4a\n",
      "F:\\dataset_sri\\3800.m4a\n",
      "F:\\dataset_sri\\3801.m4a\n",
      "F:\\dataset_sri\\3802.m4a\n",
      "F:\\dataset_sri\\3803.m4a\n",
      "F:\\dataset_sri\\3804.m4a\n",
      "F:\\dataset_sri\\3805.m4a\n",
      "F:\\dataset_sri\\3806.m4a\n",
      "F:\\dataset_sri\\3807.m4a\n",
      "F:\\dataset_sri\\3808.m4a\n",
      "F:\\dataset_sri\\3809.m4a\n",
      "F:\\dataset_sri\\381.m4a\n",
      "F:\\dataset_sri\\3810.m4a\n",
      "F:\\dataset_sri\\3811.m4a\n",
      "F:\\dataset_sri\\3812.m4a\n",
      "F:\\dataset_sri\\3813.m4a\n",
      "F:\\dataset_sri\\3814.m4a\n",
      "F:\\dataset_sri\\3815.m4a\n",
      "F:\\dataset_sri\\3816.m4a\n",
      "F:\\dataset_sri\\3817.m4a\n",
      "F:\\dataset_sri\\3818.m4a\n",
      "F:\\dataset_sri\\3819.m4a\n",
      "F:\\dataset_sri\\382.m4a\n",
      "F:\\dataset_sri\\3820.m4a\n",
      "F:\\dataset_sri\\3821.m4a\n",
      "F:\\dataset_sri\\3822.m4a\n",
      "F:\\dataset_sri\\3823.m4a\n",
      "F:\\dataset_sri\\3824.m4a\n",
      "F:\\dataset_sri\\3825.m4a\n",
      "F:\\dataset_sri\\3826.m4a\n",
      "F:\\dataset_sri\\3827.m4a\n",
      "F:\\dataset_sri\\3828.m4a\n",
      "F:\\dataset_sri\\3829.m4a\n",
      "F:\\dataset_sri\\383.m4a\n",
      "F:\\dataset_sri\\3830.m4a\n",
      "F:\\dataset_sri\\3831.m4a\n",
      "F:\\dataset_sri\\3832.m4a\n",
      "F:\\dataset_sri\\3833.m4a\n",
      "F:\\dataset_sri\\3834.m4a\n",
      "F:\\dataset_sri\\3835.m4a\n",
      "F:\\dataset_sri\\3836.m4a\n",
      "F:\\dataset_sri\\3837.m4a\n",
      "F:\\dataset_sri\\3838.m4a\n",
      "F:\\dataset_sri\\3839.m4a\n",
      "F:\\dataset_sri\\384.m4a\n",
      "F:\\dataset_sri\\3840.m4a\n",
      "F:\\dataset_sri\\3841.m4a\n",
      "F:\\dataset_sri\\3842.m4a\n",
      "F:\\dataset_sri\\3843.m4a\n",
      "F:\\dataset_sri\\3844.m4a\n",
      "F:\\dataset_sri\\3845.m4a\n",
      "F:\\dataset_sri\\3846.m4a\n",
      "F:\\dataset_sri\\3847.m4a\n",
      "F:\\dataset_sri\\3848.m4a\n",
      "F:\\dataset_sri\\3849.m4a\n",
      "F:\\dataset_sri\\385.m4a\n",
      "F:\\dataset_sri\\3850.m4a\n",
      "F:\\dataset_sri\\3851.m4a\n",
      "F:\\dataset_sri\\3852.m4a\n",
      "F:\\dataset_sri\\3853.m4a\n",
      "F:\\dataset_sri\\3854.m4a\n",
      "F:\\dataset_sri\\3855.m4a\n",
      "F:\\dataset_sri\\3856.m4a\n",
      "F:\\dataset_sri\\3857.m4a\n",
      "F:\\dataset_sri\\3858.m4a\n",
      "F:\\dataset_sri\\3859.m4a\n",
      "F:\\dataset_sri\\386.m4a\n",
      "F:\\dataset_sri\\3860.m4a\n",
      "F:\\dataset_sri\\3861.m4a\n",
      "F:\\dataset_sri\\3862.m4a\n",
      "F:\\dataset_sri\\3863.m4a\n",
      "F:\\dataset_sri\\3864.m4a\n",
      "F:\\dataset_sri\\3865.m4a\n",
      "F:\\dataset_sri\\3866.m4a\n",
      "F:\\dataset_sri\\3867.m4a\n",
      "F:\\dataset_sri\\3868.m4a\n",
      "F:\\dataset_sri\\3869.m4a\n",
      "F:\\dataset_sri\\387.m4a\n",
      "F:\\dataset_sri\\3870.m4a\n",
      "F:\\dataset_sri\\3871.m4a\n",
      "F:\\dataset_sri\\3872.m4a\n",
      "F:\\dataset_sri\\3873.m4a\n",
      "F:\\dataset_sri\\3874.m4a\n",
      "F:\\dataset_sri\\3875.m4a\n",
      "F:\\dataset_sri\\3876.m4a\n",
      "F:\\dataset_sri\\3877.m4a\n",
      "F:\\dataset_sri\\3878.m4a\n",
      "F:\\dataset_sri\\3879.m4a\n",
      "F:\\dataset_sri\\388.m4a\n",
      "F:\\dataset_sri\\3880.m4a\n",
      "F:\\dataset_sri\\3881.m4a\n",
      "F:\\dataset_sri\\3882.m4a\n",
      "F:\\dataset_sri\\3883.m4a\n",
      "F:\\dataset_sri\\3884.m4a\n",
      "F:\\dataset_sri\\3885.m4a\n",
      "F:\\dataset_sri\\3886.m4a\n",
      "F:\\dataset_sri\\3887.m4a\n",
      "F:\\dataset_sri\\3888.m4a\n",
      "F:\\dataset_sri\\3889.m4a\n",
      "F:\\dataset_sri\\389.m4a\n",
      "F:\\dataset_sri\\3890.m4a\n",
      "F:\\dataset_sri\\3891.m4a\n",
      "F:\\dataset_sri\\3892.m4a\n",
      "F:\\dataset_sri\\3893.m4a\n",
      "F:\\dataset_sri\\3894.m4a\n",
      "F:\\dataset_sri\\3895.m4a\n",
      "F:\\dataset_sri\\3896.m4a\n",
      "F:\\dataset_sri\\3897.m4a\n",
      "F:\\dataset_sri\\3898.m4a\n",
      "F:\\dataset_sri\\3899.m4a\n",
      "F:\\dataset_sri\\39.m4a\n",
      "F:\\dataset_sri\\390.m4a\n",
      "F:\\dataset_sri\\3900.m4a\n",
      "F:\\dataset_sri\\3901.m4a\n",
      "F:\\dataset_sri\\3902.m4a\n",
      "F:\\dataset_sri\\3903.m4a\n",
      "F:\\dataset_sri\\3904.m4a\n",
      "F:\\dataset_sri\\3905.m4a\n",
      "F:\\dataset_sri\\3906.m4a\n",
      "F:\\dataset_sri\\3907.m4a\n",
      "F:\\dataset_sri\\3908.m4a\n",
      "F:\\dataset_sri\\3909.m4a\n",
      "F:\\dataset_sri\\391.m4a\n",
      "F:\\dataset_sri\\3910.m4a\n",
      "F:\\dataset_sri\\3911.m4a\n",
      "F:\\dataset_sri\\3912.m4a\n",
      "F:\\dataset_sri\\3913.m4a\n",
      "F:\\dataset_sri\\3914.m4a\n",
      "F:\\dataset_sri\\3915.m4a\n",
      "F:\\dataset_sri\\3916.m4a\n",
      "F:\\dataset_sri\\3917.m4a\n",
      "F:\\dataset_sri\\3918.m4a\n",
      "F:\\dataset_sri\\3919.m4a\n",
      "F:\\dataset_sri\\392.m4a\n",
      "F:\\dataset_sri\\3920.m4a\n",
      "F:\\dataset_sri\\3921.m4a\n",
      "F:\\dataset_sri\\3922.m4a\n",
      "F:\\dataset_sri\\3923.m4a\n",
      "F:\\dataset_sri\\3924.m4a\n",
      "F:\\dataset_sri\\3925.m4a\n",
      "F:\\dataset_sri\\3926.m4a\n",
      "F:\\dataset_sri\\3927.m4a\n",
      "F:\\dataset_sri\\3928.m4a\n",
      "F:\\dataset_sri\\3929.m4a\n",
      "F:\\dataset_sri\\393.m4a\n",
      "F:\\dataset_sri\\3930.m4a\n",
      "F:\\dataset_sri\\3931.m4a\n",
      "F:\\dataset_sri\\3932.m4a\n",
      "F:\\dataset_sri\\3933.m4a\n",
      "F:\\dataset_sri\\3934.m4a\n",
      "F:\\dataset_sri\\3935.m4a\n",
      "F:\\dataset_sri\\3936.m4a\n",
      "F:\\dataset_sri\\3937.m4a\n",
      "F:\\dataset_sri\\3938.m4a\n",
      "F:\\dataset_sri\\3939.m4a\n",
      "F:\\dataset_sri\\394.m4a\n",
      "F:\\dataset_sri\\3940.m4a\n",
      "F:\\dataset_sri\\3941.m4a\n",
      "F:\\dataset_sri\\3942.m4a\n",
      "F:\\dataset_sri\\3943.m4a\n",
      "F:\\dataset_sri\\3944.m4a\n",
      "F:\\dataset_sri\\3945.m4a\n",
      "F:\\dataset_sri\\3946.m4a\n",
      "F:\\dataset_sri\\3947.m4a\n",
      "F:\\dataset_sri\\3948.m4a\n",
      "F:\\dataset_sri\\3949.m4a\n",
      "F:\\dataset_sri\\395.m4a\n",
      "F:\\dataset_sri\\3950.m4a\n",
      "F:\\dataset_sri\\3951.m4a\n",
      "F:\\dataset_sri\\3952.m4a\n",
      "F:\\dataset_sri\\3953.m4a\n",
      "F:\\dataset_sri\\3954.m4a\n",
      "F:\\dataset_sri\\3955.m4a\n",
      "F:\\dataset_sri\\3956.m4a\n",
      "F:\\dataset_sri\\3957.m4a\n",
      "F:\\dataset_sri\\3958.m4a\n",
      "F:\\dataset_sri\\3959.m4a\n",
      "F:\\dataset_sri\\396.m4a\n",
      "F:\\dataset_sri\\3960.m4a\n",
      "F:\\dataset_sri\\3961.m4a\n",
      "F:\\dataset_sri\\3962.m4a\n",
      "F:\\dataset_sri\\3963.m4a\n",
      "F:\\dataset_sri\\3964.m4a\n",
      "F:\\dataset_sri\\3965.m4a\n",
      "F:\\dataset_sri\\3966.m4a\n",
      "F:\\dataset_sri\\3967.m4a\n",
      "F:\\dataset_sri\\3968.m4a\n",
      "F:\\dataset_sri\\3969.m4a\n",
      "F:\\dataset_sri\\397.m4a\n",
      "F:\\dataset_sri\\3970.m4a\n",
      "F:\\dataset_sri\\3971.m4a\n",
      "F:\\dataset_sri\\3972.m4a\n",
      "F:\\dataset_sri\\3973.m4a\n",
      "F:\\dataset_sri\\3974.m4a\n",
      "F:\\dataset_sri\\3975.m4a\n",
      "F:\\dataset_sri\\3976.m4a\n",
      "F:\\dataset_sri\\3977.m4a\n",
      "F:\\dataset_sri\\3978.m4a\n",
      "F:\\dataset_sri\\3979.m4a\n",
      "F:\\dataset_sri\\398.m4a\n",
      "F:\\dataset_sri\\3980.m4a\n",
      "F:\\dataset_sri\\3981.m4a\n",
      "F:\\dataset_sri\\3982.m4a\n",
      "F:\\dataset_sri\\3983.m4a\n",
      "F:\\dataset_sri\\3984.m4a\n",
      "F:\\dataset_sri\\3985.m4a\n",
      "F:\\dataset_sri\\3986.m4a\n",
      "F:\\dataset_sri\\3987.m4a\n",
      "F:\\dataset_sri\\3988.m4a\n",
      "F:\\dataset_sri\\3989.m4a\n",
      "F:\\dataset_sri\\399.m4a\n",
      "F:\\dataset_sri\\3990.m4a\n",
      "F:\\dataset_sri\\3991.m4a\n",
      "F:\\dataset_sri\\3992.m4a\n",
      "F:\\dataset_sri\\3993.m4a\n",
      "F:\\dataset_sri\\3994.m4a\n",
      "F:\\dataset_sri\\3995.m4a\n",
      "F:\\dataset_sri\\3996.m4a\n",
      "F:\\dataset_sri\\3997.m4a\n",
      "F:\\dataset_sri\\3998.m4a\n",
      "F:\\dataset_sri\\3999.m4a\n",
      "F:\\dataset_sri\\4.m4a\n",
      "F:\\dataset_sri\\40.m4a\n",
      "F:\\dataset_sri\\400.m4a\n",
      "F:\\dataset_sri\\4000.m4a\n",
      "F:\\dataset_sri\\4001.m4a\n",
      "F:\\dataset_sri\\4002.m4a\n",
      "F:\\dataset_sri\\4003.m4a\n",
      "F:\\dataset_sri\\4004.m4a\n",
      "F:\\dataset_sri\\4005.m4a\n",
      "F:\\dataset_sri\\4006.m4a\n",
      "F:\\dataset_sri\\4007.m4a\n",
      "F:\\dataset_sri\\4008.m4a\n",
      "F:\\dataset_sri\\4009.m4a\n",
      "F:\\dataset_sri\\401.m4a\n",
      "F:\\dataset_sri\\4010.m4a\n",
      "F:\\dataset_sri\\4011.m4a\n",
      "F:\\dataset_sri\\4012.m4a\n",
      "F:\\dataset_sri\\4013.m4a\n",
      "F:\\dataset_sri\\4014.m4a\n",
      "F:\\dataset_sri\\4015.m4a\n",
      "F:\\dataset_sri\\4016.m4a\n",
      "F:\\dataset_sri\\4017.m4a\n",
      "F:\\dataset_sri\\4018.m4a\n",
      "F:\\dataset_sri\\4019.m4a\n",
      "F:\\dataset_sri\\402.m4a\n",
      "F:\\dataset_sri\\4020.m4a\n",
      "F:\\dataset_sri\\4021.m4a\n",
      "F:\\dataset_sri\\4022.m4a\n",
      "F:\\dataset_sri\\4023.m4a\n",
      "F:\\dataset_sri\\4024.m4a\n",
      "F:\\dataset_sri\\4025.m4a\n",
      "F:\\dataset_sri\\4026.m4a\n",
      "F:\\dataset_sri\\4027.m4a\n",
      "F:\\dataset_sri\\4028.m4a\n",
      "F:\\dataset_sri\\4029.m4a\n",
      "F:\\dataset_sri\\403.m4a\n",
      "F:\\dataset_sri\\4030.m4a\n",
      "F:\\dataset_sri\\4031.m4a\n",
      "F:\\dataset_sri\\4032.m4a\n",
      "F:\\dataset_sri\\4033.m4a\n",
      "F:\\dataset_sri\\4034.m4a\n",
      "F:\\dataset_sri\\4035.m4a\n",
      "F:\\dataset_sri\\4036.m4a\n",
      "F:\\dataset_sri\\4037.m4a\n",
      "F:\\dataset_sri\\4038.m4a\n",
      "F:\\dataset_sri\\4039.m4a\n",
      "F:\\dataset_sri\\404.m4a\n",
      "F:\\dataset_sri\\4040.m4a\n",
      "F:\\dataset_sri\\4041.m4a\n",
      "F:\\dataset_sri\\4042.m4a\n",
      "F:\\dataset_sri\\4043.m4a\n",
      "F:\\dataset_sri\\4044.m4a\n",
      "F:\\dataset_sri\\4045.m4a\n",
      "F:\\dataset_sri\\4046.m4a\n",
      "F:\\dataset_sri\\4047.m4a\n",
      "F:\\dataset_sri\\4048.m4a\n",
      "F:\\dataset_sri\\4049.m4a\n",
      "F:\\dataset_sri\\405.m4a\n",
      "F:\\dataset_sri\\4050.m4a\n",
      "F:\\dataset_sri\\4051.m4a\n",
      "F:\\dataset_sri\\4052.m4a\n",
      "F:\\dataset_sri\\4053.m4a\n",
      "F:\\dataset_sri\\4054.m4a\n",
      "F:\\dataset_sri\\4055.m4a\n",
      "F:\\dataset_sri\\4056.m4a\n",
      "F:\\dataset_sri\\4057.m4a\n",
      "F:\\dataset_sri\\4058.m4a\n",
      "F:\\dataset_sri\\4059.m4a\n",
      "F:\\dataset_sri\\406.m4a\n",
      "F:\\dataset_sri\\4060.m4a\n",
      "F:\\dataset_sri\\4061.m4a\n",
      "F:\\dataset_sri\\4062.m4a\n",
      "F:\\dataset_sri\\4063.m4a\n",
      "F:\\dataset_sri\\4064.m4a\n",
      "F:\\dataset_sri\\4065.m4a\n",
      "F:\\dataset_sri\\4066.m4a\n",
      "F:\\dataset_sri\\4067.m4a\n",
      "F:\\dataset_sri\\4068.m4a\n",
      "F:\\dataset_sri\\4069.m4a\n",
      "F:\\dataset_sri\\407.m4a\n",
      "F:\\dataset_sri\\4070.m4a\n",
      "F:\\dataset_sri\\4071.m4a\n",
      "F:\\dataset_sri\\4072.m4a\n",
      "F:\\dataset_sri\\4073.m4a\n",
      "F:\\dataset_sri\\4074.m4a\n",
      "F:\\dataset_sri\\4075.m4a\n",
      "F:\\dataset_sri\\4076.m4a\n",
      "F:\\dataset_sri\\4077.m4a\n",
      "F:\\dataset_sri\\4078.m4a\n",
      "F:\\dataset_sri\\4079.m4a\n",
      "F:\\dataset_sri\\408.m4a\n",
      "F:\\dataset_sri\\4080.m4a\n",
      "F:\\dataset_sri\\4081.m4a\n",
      "F:\\dataset_sri\\4082.m4a\n",
      "F:\\dataset_sri\\4083.m4a\n",
      "F:\\dataset_sri\\4084.m4a\n",
      "F:\\dataset_sri\\4085.m4a\n",
      "F:\\dataset_sri\\4086.m4a\n",
      "F:\\dataset_sri\\4087.m4a\n",
      "F:\\dataset_sri\\4088.m4a\n",
      "F:\\dataset_sri\\4089.m4a\n",
      "F:\\dataset_sri\\409.m4a\n",
      "F:\\dataset_sri\\4090.m4a\n",
      "F:\\dataset_sri\\4091.m4a\n",
      "F:\\dataset_sri\\4092.m4a\n",
      "F:\\dataset_sri\\4093.m4a\n",
      "F:\\dataset_sri\\4094.m4a\n",
      "F:\\dataset_sri\\4095.m4a\n",
      "F:\\dataset_sri\\4096.m4a\n",
      "F:\\dataset_sri\\4097.m4a\n",
      "F:\\dataset_sri\\4098.m4a\n",
      "F:\\dataset_sri\\4099.m4a\n",
      "F:\\dataset_sri\\41.m4a\n",
      "F:\\dataset_sri\\410.m4a\n",
      "F:\\dataset_sri\\4100.m4a\n",
      "F:\\dataset_sri\\4101.m4a\n",
      "F:\\dataset_sri\\4102.m4a\n",
      "F:\\dataset_sri\\4103.m4a\n",
      "F:\\dataset_sri\\4104.m4a\n",
      "F:\\dataset_sri\\4105.m4a\n",
      "F:\\dataset_sri\\4106.m4a\n",
      "F:\\dataset_sri\\4107.m4a\n",
      "F:\\dataset_sri\\4108.m4a\n",
      "F:\\dataset_sri\\4109.m4a\n",
      "F:\\dataset_sri\\411.m4a\n",
      "F:\\dataset_sri\\4110.m4a\n",
      "F:\\dataset_sri\\4111.m4a\n",
      "F:\\dataset_sri\\4112.m4a\n",
      "F:\\dataset_sri\\4113.m4a\n",
      "F:\\dataset_sri\\4114.m4a\n",
      "F:\\dataset_sri\\4115.m4a\n",
      "F:\\dataset_sri\\4116.m4a\n",
      "F:\\dataset_sri\\4117.m4a\n",
      "F:\\dataset_sri\\4118.m4a\n",
      "F:\\dataset_sri\\4119.m4a\n",
      "F:\\dataset_sri\\412.m4a\n",
      "F:\\dataset_sri\\4120.m4a\n",
      "F:\\dataset_sri\\4121.m4a\n",
      "F:\\dataset_sri\\4122.m4a\n",
      "F:\\dataset_sri\\4123.m4a\n",
      "F:\\dataset_sri\\4124.m4a\n",
      "F:\\dataset_sri\\4125.m4a\n",
      "F:\\dataset_sri\\4126.m4a\n",
      "F:\\dataset_sri\\4127.m4a\n",
      "F:\\dataset_sri\\4128.m4a\n",
      "F:\\dataset_sri\\4129.m4a\n",
      "F:\\dataset_sri\\413.m4a\n",
      "F:\\dataset_sri\\4130.m4a\n",
      "F:\\dataset_sri\\4131.m4a\n",
      "F:\\dataset_sri\\4132.m4a\n",
      "F:\\dataset_sri\\4133.m4a\n",
      "F:\\dataset_sri\\4134.m4a\n",
      "F:\\dataset_sri\\4135.m4a\n",
      "F:\\dataset_sri\\4136.m4a\n",
      "F:\\dataset_sri\\4137.m4a\n",
      "F:\\dataset_sri\\4138.m4a\n",
      "F:\\dataset_sri\\4139.m4a\n",
      "F:\\dataset_sri\\414.m4a\n",
      "F:\\dataset_sri\\4140.m4a\n",
      "F:\\dataset_sri\\4141.m4a\n",
      "F:\\dataset_sri\\4142.m4a\n",
      "F:\\dataset_sri\\4143.m4a\n",
      "F:\\dataset_sri\\4144.m4a\n",
      "F:\\dataset_sri\\4145.m4a\n",
      "F:\\dataset_sri\\4146.m4a\n",
      "F:\\dataset_sri\\4147.m4a\n",
      "F:\\dataset_sri\\4148.m4a\n",
      "F:\\dataset_sri\\4149.m4a\n",
      "F:\\dataset_sri\\415.m4a\n",
      "F:\\dataset_sri\\4150.m4a\n",
      "F:\\dataset_sri\\4151.m4a\n",
      "F:\\dataset_sri\\4152.m4a\n",
      "F:\\dataset_sri\\4153.m4a\n",
      "F:\\dataset_sri\\4154.m4a\n",
      "F:\\dataset_sri\\4155.m4a\n",
      "F:\\dataset_sri\\4156.m4a\n",
      "F:\\dataset_sri\\4157.m4a\n",
      "F:\\dataset_sri\\4158.m4a\n",
      "F:\\dataset_sri\\4159.m4a\n",
      "F:\\dataset_sri\\416.m4a\n",
      "F:\\dataset_sri\\4160.m4a\n",
      "F:\\dataset_sri\\4161.m4a\n",
      "F:\\dataset_sri\\4162.m4a\n",
      "F:\\dataset_sri\\4163.m4a\n",
      "F:\\dataset_sri\\4164.m4a\n",
      "F:\\dataset_sri\\4165.m4a\n",
      "F:\\dataset_sri\\4166.m4a\n",
      "F:\\dataset_sri\\4167.m4a\n",
      "F:\\dataset_sri\\4168.m4a\n",
      "F:\\dataset_sri\\4169.m4a\n",
      "F:\\dataset_sri\\417.m4a\n",
      "F:\\dataset_sri\\4170.m4a\n",
      "F:\\dataset_sri\\4171.m4a\n",
      "F:\\dataset_sri\\4172.m4a\n",
      "F:\\dataset_sri\\4173.m4a\n",
      "F:\\dataset_sri\\4174.m4a\n",
      "F:\\dataset_sri\\4175.m4a\n",
      "F:\\dataset_sri\\4176.m4a\n",
      "F:\\dataset_sri\\4177.m4a\n",
      "F:\\dataset_sri\\4178.m4a\n",
      "F:\\dataset_sri\\4179.m4a\n",
      "F:\\dataset_sri\\418.m4a\n",
      "F:\\dataset_sri\\4180.m4a\n",
      "F:\\dataset_sri\\4181.m4a\n",
      "F:\\dataset_sri\\4182.m4a\n",
      "F:\\dataset_sri\\4183.m4a\n",
      "F:\\dataset_sri\\4184.m4a\n",
      "F:\\dataset_sri\\4185.m4a\n",
      "F:\\dataset_sri\\4186.m4a\n",
      "F:\\dataset_sri\\4187.m4a\n",
      "F:\\dataset_sri\\4188.m4a\n",
      "F:\\dataset_sri\\4189.m4a\n",
      "F:\\dataset_sri\\419.m4a\n",
      "F:\\dataset_sri\\4190.m4a\n",
      "F:\\dataset_sri\\4191.m4a\n",
      "F:\\dataset_sri\\4192.m4a\n",
      "F:\\dataset_sri\\4193.m4a\n",
      "F:\\dataset_sri\\4194.m4a\n",
      "F:\\dataset_sri\\4195.m4a\n",
      "F:\\dataset_sri\\4196.m4a\n",
      "F:\\dataset_sri\\4197.m4a\n",
      "F:\\dataset_sri\\4198.m4a\n",
      "F:\\dataset_sri\\4199.m4a\n",
      "F:\\dataset_sri\\42.m4a\n",
      "F:\\dataset_sri\\420.m4a\n",
      "F:\\dataset_sri\\4200.m4a\n",
      "F:\\dataset_sri\\4201.m4a\n",
      "F:\\dataset_sri\\4202.m4a\n",
      "F:\\dataset_sri\\4203.m4a\n",
      "F:\\dataset_sri\\4204.m4a\n",
      "F:\\dataset_sri\\4205.m4a\n",
      "F:\\dataset_sri\\4206.m4a\n",
      "F:\\dataset_sri\\4207.m4a\n",
      "F:\\dataset_sri\\4208.m4a\n",
      "F:\\dataset_sri\\4209.m4a\n",
      "F:\\dataset_sri\\421.m4a\n",
      "F:\\dataset_sri\\4210.m4a\n",
      "F:\\dataset_sri\\4211.m4a\n",
      "F:\\dataset_sri\\4212.m4a\n",
      "F:\\dataset_sri\\4213.m4a\n",
      "F:\\dataset_sri\\4214.m4a\n",
      "F:\\dataset_sri\\4215.m4a\n",
      "F:\\dataset_sri\\4216.m4a\n",
      "F:\\dataset_sri\\4217.m4a\n",
      "F:\\dataset_sri\\4218.m4a\n",
      "F:\\dataset_sri\\4219.m4a\n",
      "F:\\dataset_sri\\422.m4a\n",
      "F:\\dataset_sri\\4220.m4a\n",
      "F:\\dataset_sri\\4221.m4a\n",
      "F:\\dataset_sri\\4222.m4a\n",
      "F:\\dataset_sri\\4223.m4a\n",
      "F:\\dataset_sri\\4224.m4a\n",
      "F:\\dataset_sri\\4225.m4a\n",
      "F:\\dataset_sri\\4226.m4a\n",
      "F:\\dataset_sri\\4227.m4a\n",
      "F:\\dataset_sri\\4228.m4a\n",
      "F:\\dataset_sri\\4229.m4a\n",
      "F:\\dataset_sri\\423.m4a\n",
      "F:\\dataset_sri\\4230.m4a\n",
      "F:\\dataset_sri\\4231.m4a\n",
      "F:\\dataset_sri\\4232.m4a\n",
      "F:\\dataset_sri\\4233.m4a\n",
      "F:\\dataset_sri\\4234.m4a\n",
      "F:\\dataset_sri\\4235.m4a\n",
      "F:\\dataset_sri\\4236.m4a\n",
      "F:\\dataset_sri\\4237.m4a\n",
      "F:\\dataset_sri\\4238.m4a\n",
      "F:\\dataset_sri\\4239.m4a\n",
      "F:\\dataset_sri\\424.m4a\n",
      "F:\\dataset_sri\\4240.m4a\n",
      "F:\\dataset_sri\\4241.m4a\n",
      "F:\\dataset_sri\\4242.m4a\n",
      "F:\\dataset_sri\\4243.m4a\n",
      "F:\\dataset_sri\\4244.m4a\n",
      "F:\\dataset_sri\\4245.m4a\n",
      "F:\\dataset_sri\\4246.m4a\n",
      "F:\\dataset_sri\\4247.m4a\n",
      "F:\\dataset_sri\\4248.m4a\n",
      "F:\\dataset_sri\\4249.m4a\n",
      "F:\\dataset_sri\\425.m4a\n",
      "F:\\dataset_sri\\4250.m4a\n",
      "F:\\dataset_sri\\4251.m4a\n",
      "F:\\dataset_sri\\4252.m4a\n",
      "F:\\dataset_sri\\4253.m4a\n",
      "F:\\dataset_sri\\4254.m4a\n",
      "F:\\dataset_sri\\4255.m4a\n",
      "F:\\dataset_sri\\4256.m4a\n",
      "F:\\dataset_sri\\4257.m4a\n",
      "F:\\dataset_sri\\4258.m4a\n",
      "F:\\dataset_sri\\4259.m4a\n",
      "F:\\dataset_sri\\426.m4a\n",
      "F:\\dataset_sri\\4260.m4a\n",
      "F:\\dataset_sri\\4261.m4a\n",
      "F:\\dataset_sri\\4262.m4a\n",
      "F:\\dataset_sri\\4263.m4a\n",
      "F:\\dataset_sri\\4264.m4a\n",
      "F:\\dataset_sri\\4265.m4a\n",
      "F:\\dataset_sri\\4266.m4a\n",
      "F:\\dataset_sri\\4267.m4a\n",
      "F:\\dataset_sri\\4268.m4a\n",
      "F:\\dataset_sri\\4269.m4a\n",
      "F:\\dataset_sri\\427.m4a\n",
      "F:\\dataset_sri\\4270.m4a\n",
      "F:\\dataset_sri\\4271.m4a\n",
      "F:\\dataset_sri\\4272.m4a\n",
      "F:\\dataset_sri\\4273.m4a\n",
      "F:\\dataset_sri\\4274.m4a\n",
      "F:\\dataset_sri\\4275.m4a\n",
      "F:\\dataset_sri\\4276.m4a\n",
      "F:\\dataset_sri\\4277.m4a\n",
      "F:\\dataset_sri\\4278.m4a\n",
      "F:\\dataset_sri\\4279.m4a\n",
      "F:\\dataset_sri\\428.m4a\n",
      "F:\\dataset_sri\\4280.m4a\n",
      "F:\\dataset_sri\\4281.m4a\n",
      "F:\\dataset_sri\\4282.m4a\n",
      "F:\\dataset_sri\\4283.m4a\n",
      "F:\\dataset_sri\\4284.m4a\n",
      "F:\\dataset_sri\\4285.m4a\n",
      "F:\\dataset_sri\\4286.m4a\n",
      "F:\\dataset_sri\\4287.m4a\n",
      "F:\\dataset_sri\\4288.m4a\n",
      "F:\\dataset_sri\\4289.m4a\n",
      "F:\\dataset_sri\\429.m4a\n",
      "F:\\dataset_sri\\4290.m4a\n",
      "F:\\dataset_sri\\4291.m4a\n",
      "F:\\dataset_sri\\4292.m4a\n",
      "F:\\dataset_sri\\4293.m4a\n",
      "F:\\dataset_sri\\4294.m4a\n",
      "F:\\dataset_sri\\4295.m4a\n",
      "F:\\dataset_sri\\4296.m4a\n",
      "F:\\dataset_sri\\4297.m4a\n",
      "F:\\dataset_sri\\4298.m4a\n",
      "F:\\dataset_sri\\4299.m4a\n",
      "F:\\dataset_sri\\43.m4a\n",
      "F:\\dataset_sri\\430.m4a\n",
      "F:\\dataset_sri\\4300.m4a\n",
      "F:\\dataset_sri\\4301.m4a\n",
      "F:\\dataset_sri\\4302.m4a\n",
      "F:\\dataset_sri\\4303.m4a\n",
      "F:\\dataset_sri\\4304.m4a\n",
      "F:\\dataset_sri\\4305.m4a\n",
      "F:\\dataset_sri\\4306.m4a\n",
      "F:\\dataset_sri\\4307.m4a\n",
      "F:\\dataset_sri\\4308.m4a\n",
      "F:\\dataset_sri\\4309.m4a\n",
      "F:\\dataset_sri\\431.m4a\n",
      "F:\\dataset_sri\\4310.m4a\n",
      "F:\\dataset_sri\\4311.m4a\n",
      "F:\\dataset_sri\\4312.m4a\n",
      "F:\\dataset_sri\\4313.m4a\n",
      "F:\\dataset_sri\\4314.m4a\n",
      "F:\\dataset_sri\\4315.m4a\n",
      "F:\\dataset_sri\\4316.m4a\n",
      "F:\\dataset_sri\\4317.m4a\n",
      "F:\\dataset_sri\\4318.m4a\n",
      "F:\\dataset_sri\\4319.m4a\n",
      "F:\\dataset_sri\\432.m4a\n",
      "F:\\dataset_sri\\4320.m4a\n",
      "F:\\dataset_sri\\4321.m4a\n",
      "F:\\dataset_sri\\4322.m4a\n",
      "F:\\dataset_sri\\4323.m4a\n",
      "F:\\dataset_sri\\4324.m4a\n",
      "F:\\dataset_sri\\4325.m4a\n",
      "F:\\dataset_sri\\4326.m4a\n",
      "F:\\dataset_sri\\4327.m4a\n",
      "F:\\dataset_sri\\4328.m4a\n",
      "F:\\dataset_sri\\4329.m4a\n",
      "F:\\dataset_sri\\433.m4a\n",
      "F:\\dataset_sri\\4330.m4a\n",
      "F:\\dataset_sri\\4331.m4a\n",
      "F:\\dataset_sri\\4332.m4a\n",
      "F:\\dataset_sri\\4333.m4a\n",
      "F:\\dataset_sri\\4334.m4a\n",
      "F:\\dataset_sri\\4335.m4a\n",
      "F:\\dataset_sri\\4336.m4a\n",
      "F:\\dataset_sri\\4337.m4a\n",
      "F:\\dataset_sri\\4338.m4a\n",
      "F:\\dataset_sri\\4339.m4a\n",
      "F:\\dataset_sri\\434.m4a\n",
      "F:\\dataset_sri\\4340.m4a\n",
      "F:\\dataset_sri\\4341.m4a\n",
      "F:\\dataset_sri\\4342.m4a\n",
      "F:\\dataset_sri\\4343.m4a\n",
      "F:\\dataset_sri\\4344.m4a\n",
      "F:\\dataset_sri\\4345.m4a\n",
      "F:\\dataset_sri\\4346.m4a\n",
      "F:\\dataset_sri\\4347.m4a\n",
      "F:\\dataset_sri\\4348.m4a\n",
      "F:\\dataset_sri\\4349.m4a\n",
      "F:\\dataset_sri\\435.m4a\n",
      "F:\\dataset_sri\\4350.m4a\n",
      "F:\\dataset_sri\\4351.m4a\n",
      "F:\\dataset_sri\\4352.m4a\n",
      "F:\\dataset_sri\\4353.m4a\n",
      "F:\\dataset_sri\\4354.m4a\n",
      "F:\\dataset_sri\\4355.m4a\n",
      "F:\\dataset_sri\\4356.m4a\n",
      "F:\\dataset_sri\\4357.m4a\n",
      "F:\\dataset_sri\\4358.m4a\n",
      "F:\\dataset_sri\\4359.m4a\n",
      "F:\\dataset_sri\\436.m4a\n",
      "F:\\dataset_sri\\4360.m4a\n",
      "F:\\dataset_sri\\4361.m4a\n",
      "F:\\dataset_sri\\4362.m4a\n",
      "F:\\dataset_sri\\4363.m4a\n",
      "F:\\dataset_sri\\4364.m4a\n",
      "F:\\dataset_sri\\4365.m4a\n",
      "F:\\dataset_sri\\4366.m4a\n",
      "F:\\dataset_sri\\4367.m4a\n",
      "F:\\dataset_sri\\4368.m4a\n",
      "F:\\dataset_sri\\4369.m4a\n",
      "F:\\dataset_sri\\437.m4a\n",
      "F:\\dataset_sri\\4370.m4a\n",
      "F:\\dataset_sri\\4371.m4a\n",
      "F:\\dataset_sri\\4372.m4a\n",
      "F:\\dataset_sri\\4373.m4a\n",
      "F:\\dataset_sri\\4374.m4a\n",
      "F:\\dataset_sri\\4375.m4a\n",
      "F:\\dataset_sri\\4376.m4a\n",
      "F:\\dataset_sri\\4377.m4a\n",
      "F:\\dataset_sri\\4378.m4a\n",
      "F:\\dataset_sri\\4379.m4a\n",
      "F:\\dataset_sri\\438.m4a\n",
      "F:\\dataset_sri\\4380.m4a\n",
      "F:\\dataset_sri\\4381.m4a\n",
      "F:\\dataset_sri\\4382.m4a\n",
      "F:\\dataset_sri\\4383.m4a\n",
      "F:\\dataset_sri\\4384.m4a\n",
      "F:\\dataset_sri\\4385.m4a\n",
      "F:\\dataset_sri\\4386.m4a\n",
      "F:\\dataset_sri\\4387.m4a\n",
      "F:\\dataset_sri\\4388.m4a\n",
      "F:\\dataset_sri\\4389.m4a\n",
      "F:\\dataset_sri\\439.m4a\n",
      "F:\\dataset_sri\\4390.m4a\n",
      "F:\\dataset_sri\\4391.m4a\n",
      "F:\\dataset_sri\\4392.m4a\n",
      "F:\\dataset_sri\\4393.m4a\n",
      "F:\\dataset_sri\\4394.m4a\n",
      "F:\\dataset_sri\\4395.m4a\n",
      "F:\\dataset_sri\\4396.m4a\n",
      "F:\\dataset_sri\\4397.m4a\n",
      "F:\\dataset_sri\\4398.m4a\n",
      "F:\\dataset_sri\\4399.m4a\n",
      "F:\\dataset_sri\\44.m4a\n",
      "F:\\dataset_sri\\440.m4a\n",
      "F:\\dataset_sri\\4400.m4a\n",
      "F:\\dataset_sri\\4401.m4a\n",
      "F:\\dataset_sri\\4402.m4a\n",
      "F:\\dataset_sri\\4403.m4a\n",
      "F:\\dataset_sri\\4404.m4a\n",
      "F:\\dataset_sri\\4405.m4a\n",
      "F:\\dataset_sri\\4406.m4a\n",
      "F:\\dataset_sri\\4407.m4a\n",
      "F:\\dataset_sri\\4408.m4a\n",
      "F:\\dataset_sri\\4409.m4a\n",
      "F:\\dataset_sri\\441.m4a\n",
      "F:\\dataset_sri\\4410.m4a\n",
      "F:\\dataset_sri\\4411.m4a\n",
      "F:\\dataset_sri\\4412.m4a\n",
      "F:\\dataset_sri\\4413.m4a\n",
      "F:\\dataset_sri\\4414.m4a\n",
      "F:\\dataset_sri\\4415.m4a\n",
      "F:\\dataset_sri\\4416.m4a\n",
      "F:\\dataset_sri\\4417.m4a\n",
      "F:\\dataset_sri\\4418.m4a\n",
      "F:\\dataset_sri\\4419.m4a\n",
      "F:\\dataset_sri\\442.m4a\n",
      "F:\\dataset_sri\\4420.m4a\n",
      "F:\\dataset_sri\\4421.m4a\n",
      "F:\\dataset_sri\\4422.m4a\n",
      "F:\\dataset_sri\\4423.m4a\n",
      "F:\\dataset_sri\\4424.m4a\n",
      "F:\\dataset_sri\\4425.m4a\n",
      "F:\\dataset_sri\\4426.m4a\n",
      "F:\\dataset_sri\\4427.m4a\n",
      "F:\\dataset_sri\\4428.m4a\n",
      "F:\\dataset_sri\\4429.m4a\n",
      "F:\\dataset_sri\\443.m4a\n",
      "F:\\dataset_sri\\4430.m4a\n",
      "F:\\dataset_sri\\4431.m4a\n",
      "F:\\dataset_sri\\4432.m4a\n",
      "F:\\dataset_sri\\4433.m4a\n",
      "F:\\dataset_sri\\4434.m4a\n",
      "F:\\dataset_sri\\4435.m4a\n",
      "F:\\dataset_sri\\4436.m4a\n",
      "F:\\dataset_sri\\4437.m4a\n",
      "F:\\dataset_sri\\4438.m4a\n",
      "F:\\dataset_sri\\4439.m4a\n",
      "F:\\dataset_sri\\444.m4a\n",
      "F:\\dataset_sri\\4440.m4a\n",
      "F:\\dataset_sri\\4441.m4a\n",
      "F:\\dataset_sri\\4442.m4a\n",
      "F:\\dataset_sri\\4443.m4a\n",
      "F:\\dataset_sri\\4444.m4a\n",
      "F:\\dataset_sri\\4445.m4a\n",
      "F:\\dataset_sri\\4446.m4a\n",
      "F:\\dataset_sri\\4447.m4a\n",
      "F:\\dataset_sri\\4448.m4a\n",
      "F:\\dataset_sri\\4449.m4a\n",
      "F:\\dataset_sri\\445.m4a\n",
      "F:\\dataset_sri\\4450.m4a\n",
      "F:\\dataset_sri\\4451.m4a\n",
      "F:\\dataset_sri\\4452.m4a\n",
      "F:\\dataset_sri\\4453.m4a\n",
      "F:\\dataset_sri\\4454.m4a\n",
      "F:\\dataset_sri\\4455.m4a\n",
      "F:\\dataset_sri\\4456.m4a\n",
      "F:\\dataset_sri\\4457.m4a\n",
      "F:\\dataset_sri\\4458.m4a\n",
      "F:\\dataset_sri\\4459.m4a\n",
      "F:\\dataset_sri\\446.m4a\n",
      "F:\\dataset_sri\\4460.m4a\n",
      "F:\\dataset_sri\\4461.m4a\n",
      "F:\\dataset_sri\\4462.m4a\n",
      "F:\\dataset_sri\\4463.m4a\n",
      "F:\\dataset_sri\\4464.m4a\n",
      "F:\\dataset_sri\\4465.m4a\n",
      "F:\\dataset_sri\\4466.m4a\n",
      "F:\\dataset_sri\\4467.m4a\n",
      "F:\\dataset_sri\\4468.m4a\n",
      "F:\\dataset_sri\\4469.m4a\n",
      "F:\\dataset_sri\\447.m4a\n",
      "F:\\dataset_sri\\4470.m4a\n",
      "F:\\dataset_sri\\4471.m4a\n",
      "F:\\dataset_sri\\4472.m4a\n",
      "F:\\dataset_sri\\4473.m4a\n",
      "F:\\dataset_sri\\4474.m4a\n",
      "F:\\dataset_sri\\4475.m4a\n",
      "F:\\dataset_sri\\4476.m4a\n",
      "F:\\dataset_sri\\4477.m4a\n",
      "F:\\dataset_sri\\4478.m4a\n",
      "F:\\dataset_sri\\4479.m4a\n",
      "F:\\dataset_sri\\448.m4a\n",
      "F:\\dataset_sri\\4480.m4a\n",
      "F:\\dataset_sri\\4481.m4a\n",
      "F:\\dataset_sri\\4482.m4a\n",
      "F:\\dataset_sri\\4483.m4a\n",
      "F:\\dataset_sri\\4484.m4a\n",
      "F:\\dataset_sri\\4485.m4a\n",
      "F:\\dataset_sri\\4486.m4a\n",
      "F:\\dataset_sri\\4487.m4a\n",
      "F:\\dataset_sri\\4488.m4a\n",
      "F:\\dataset_sri\\4489.m4a\n",
      "F:\\dataset_sri\\449.m4a\n",
      "F:\\dataset_sri\\4490.m4a\n",
      "F:\\dataset_sri\\4491.m4a\n",
      "F:\\dataset_sri\\4492.m4a\n",
      "F:\\dataset_sri\\4493.m4a\n",
      "F:\\dataset_sri\\4494.m4a\n",
      "F:\\dataset_sri\\4495.m4a\n",
      "F:\\dataset_sri\\4496.m4a\n",
      "F:\\dataset_sri\\4497.m4a\n",
      "F:\\dataset_sri\\4498.m4a\n",
      "F:\\dataset_sri\\4499.m4a\n",
      "F:\\dataset_sri\\45.m4a\n",
      "F:\\dataset_sri\\450.m4a\n",
      "F:\\dataset_sri\\4500.m4a\n",
      "F:\\dataset_sri\\4501.m4a\n",
      "F:\\dataset_sri\\4502.m4a\n",
      "F:\\dataset_sri\\4503.m4a\n",
      "F:\\dataset_sri\\4504.m4a\n",
      "F:\\dataset_sri\\4505.m4a\n",
      "F:\\dataset_sri\\4506.m4a\n",
      "F:\\dataset_sri\\4507.m4a\n",
      "F:\\dataset_sri\\4508.m4a\n",
      "F:\\dataset_sri\\4509.m4a\n",
      "F:\\dataset_sri\\451.m4a\n",
      "F:\\dataset_sri\\4510.m4a\n",
      "F:\\dataset_sri\\4511.m4a\n",
      "F:\\dataset_sri\\4512.m4a\n",
      "F:\\dataset_sri\\4513.m4a\n",
      "F:\\dataset_sri\\4514.m4a\n",
      "F:\\dataset_sri\\4515.m4a\n",
      "F:\\dataset_sri\\4516.m4a\n",
      "F:\\dataset_sri\\4517.m4a\n",
      "F:\\dataset_sri\\4518.m4a\n",
      "F:\\dataset_sri\\4519.m4a\n",
      "F:\\dataset_sri\\452.m4a\n",
      "F:\\dataset_sri\\4520.m4a\n",
      "F:\\dataset_sri\\4521.m4a\n",
      "F:\\dataset_sri\\4522.m4a\n",
      "F:\\dataset_sri\\4523.m4a\n",
      "F:\\dataset_sri\\4524.m4a\n",
      "F:\\dataset_sri\\4525.m4a\n",
      "F:\\dataset_sri\\4526.m4a\n",
      "F:\\dataset_sri\\4527.m4a\n",
      "F:\\dataset_sri\\4528.m4a\n",
      "F:\\dataset_sri\\4529.m4a\n",
      "F:\\dataset_sri\\453.m4a\n",
      "F:\\dataset_sri\\4530.m4a\n",
      "F:\\dataset_sri\\4531.m4a\n",
      "F:\\dataset_sri\\4532.m4a\n",
      "F:\\dataset_sri\\4533.m4a\n",
      "F:\\dataset_sri\\4534.m4a\n",
      "F:\\dataset_sri\\4535.m4a\n",
      "F:\\dataset_sri\\4536.m4a\n",
      "F:\\dataset_sri\\4537.m4a\n",
      "F:\\dataset_sri\\4538.m4a\n",
      "F:\\dataset_sri\\4539.m4a\n",
      "F:\\dataset_sri\\454.m4a\n",
      "F:\\dataset_sri\\4540.m4a\n",
      "F:\\dataset_sri\\4541.m4a\n",
      "F:\\dataset_sri\\4542.m4a\n",
      "F:\\dataset_sri\\4543.m4a\n",
      "F:\\dataset_sri\\4544.m4a\n",
      "F:\\dataset_sri\\4545.m4a\n",
      "F:\\dataset_sri\\4546.m4a\n",
      "F:\\dataset_sri\\4547.m4a\n",
      "F:\\dataset_sri\\4548.m4a\n",
      "F:\\dataset_sri\\4549.m4a\n",
      "F:\\dataset_sri\\455.m4a\n",
      "F:\\dataset_sri\\4550.m4a\n",
      "F:\\dataset_sri\\4551.m4a\n",
      "F:\\dataset_sri\\4552.m4a\n",
      "F:\\dataset_sri\\4553.m4a\n",
      "F:\\dataset_sri\\4554.m4a\n",
      "F:\\dataset_sri\\4555.m4a\n",
      "F:\\dataset_sri\\4556.m4a\n",
      "F:\\dataset_sri\\4557.m4a\n",
      "F:\\dataset_sri\\4558.m4a\n",
      "F:\\dataset_sri\\4559.m4a\n",
      "F:\\dataset_sri\\456.m4a\n",
      "F:\\dataset_sri\\4560.m4a\n",
      "F:\\dataset_sri\\4561.m4a\n",
      "F:\\dataset_sri\\4562.m4a\n",
      "F:\\dataset_sri\\4563.m4a\n",
      "F:\\dataset_sri\\4564.m4a\n",
      "F:\\dataset_sri\\4565.m4a\n",
      "F:\\dataset_sri\\4566.m4a\n",
      "F:\\dataset_sri\\4567.m4a\n",
      "F:\\dataset_sri\\4568.m4a\n",
      "F:\\dataset_sri\\4569.m4a\n",
      "F:\\dataset_sri\\457.m4a\n",
      "F:\\dataset_sri\\4570.m4a\n",
      "F:\\dataset_sri\\4571.m4a\n",
      "F:\\dataset_sri\\4572.m4a\n",
      "F:\\dataset_sri\\4573.m4a\n",
      "F:\\dataset_sri\\4574.m4a\n",
      "F:\\dataset_sri\\4575.m4a\n",
      "F:\\dataset_sri\\4576.m4a\n",
      "F:\\dataset_sri\\4577.m4a\n",
      "F:\\dataset_sri\\4578.m4a\n",
      "F:\\dataset_sri\\4579.m4a\n",
      "F:\\dataset_sri\\458.m4a\n",
      "F:\\dataset_sri\\4580.m4a\n",
      "F:\\dataset_sri\\4581.m4a\n",
      "F:\\dataset_sri\\4582.m4a\n",
      "F:\\dataset_sri\\4583.m4a\n",
      "F:\\dataset_sri\\4584.m4a\n",
      "F:\\dataset_sri\\4585.m4a\n",
      "F:\\dataset_sri\\4586.m4a\n",
      "F:\\dataset_sri\\4587.m4a\n",
      "F:\\dataset_sri\\4588.m4a\n",
      "F:\\dataset_sri\\4589.m4a\n",
      "F:\\dataset_sri\\459.m4a\n",
      "F:\\dataset_sri\\4590.m4a\n",
      "F:\\dataset_sri\\4591.m4a\n",
      "F:\\dataset_sri\\4592.m4a\n",
      "F:\\dataset_sri\\4593.m4a\n",
      "F:\\dataset_sri\\4594.m4a\n",
      "F:\\dataset_sri\\4595.m4a\n",
      "F:\\dataset_sri\\4596.m4a\n",
      "F:\\dataset_sri\\4597.m4a\n",
      "F:\\dataset_sri\\4598.m4a\n",
      "F:\\dataset_sri\\4599.m4a\n",
      "F:\\dataset_sri\\46.m4a\n",
      "F:\\dataset_sri\\460.m4a\n",
      "F:\\dataset_sri\\4600.m4a\n",
      "F:\\dataset_sri\\4601.m4a\n",
      "F:\\dataset_sri\\4602.m4a\n",
      "F:\\dataset_sri\\4603.m4a\n",
      "F:\\dataset_sri\\4604.m4a\n",
      "F:\\dataset_sri\\4605.m4a\n",
      "F:\\dataset_sri\\4606.m4a\n",
      "F:\\dataset_sri\\4607.m4a\n",
      "F:\\dataset_sri\\4608.m4a\n",
      "F:\\dataset_sri\\4609.m4a\n",
      "F:\\dataset_sri\\461.m4a\n",
      "F:\\dataset_sri\\4610.m4a\n",
      "F:\\dataset_sri\\4611.m4a\n",
      "F:\\dataset_sri\\4612.m4a\n",
      "F:\\dataset_sri\\4613.m4a\n",
      "F:\\dataset_sri\\4614.m4a\n",
      "F:\\dataset_sri\\4615.m4a\n",
      "F:\\dataset_sri\\4616.m4a\n",
      "F:\\dataset_sri\\4617.m4a\n",
      "F:\\dataset_sri\\4618.m4a\n",
      "F:\\dataset_sri\\4619.m4a\n",
      "F:\\dataset_sri\\462.m4a\n",
      "F:\\dataset_sri\\4620.m4a\n",
      "F:\\dataset_sri\\4621.m4a\n",
      "F:\\dataset_sri\\4622.m4a\n",
      "F:\\dataset_sri\\4623.m4a\n",
      "F:\\dataset_sri\\4624.m4a\n",
      "F:\\dataset_sri\\4625.m4a\n",
      "F:\\dataset_sri\\4626.m4a\n",
      "F:\\dataset_sri\\4627.m4a\n",
      "F:\\dataset_sri\\4628.m4a\n",
      "F:\\dataset_sri\\4629.m4a\n",
      "F:\\dataset_sri\\463.m4a\n",
      "F:\\dataset_sri\\4630.m4a\n",
      "F:\\dataset_sri\\4631.m4a\n",
      "F:\\dataset_sri\\4632.m4a\n",
      "F:\\dataset_sri\\4633.m4a\n",
      "F:\\dataset_sri\\4634.m4a\n",
      "F:\\dataset_sri\\4635.m4a\n",
      "F:\\dataset_sri\\4636.m4a\n",
      "F:\\dataset_sri\\4637.m4a\n",
      "F:\\dataset_sri\\4638.m4a\n",
      "F:\\dataset_sri\\4639.m4a\n",
      "F:\\dataset_sri\\464.m4a\n",
      "F:\\dataset_sri\\4640.m4a\n",
      "F:\\dataset_sri\\4641.m4a\n",
      "F:\\dataset_sri\\4642.m4a\n",
      "F:\\dataset_sri\\4643.m4a\n",
      "F:\\dataset_sri\\4644.m4a\n",
      "F:\\dataset_sri\\4645.m4a\n",
      "F:\\dataset_sri\\4646.m4a\n",
      "F:\\dataset_sri\\4647.m4a\n",
      "F:\\dataset_sri\\4648.m4a\n",
      "F:\\dataset_sri\\4649.m4a\n",
      "F:\\dataset_sri\\465.m4a\n",
      "F:\\dataset_sri\\4650.m4a\n",
      "F:\\dataset_sri\\4651.m4a\n",
      "F:\\dataset_sri\\4652.m4a\n",
      "F:\\dataset_sri\\4653.m4a\n",
      "F:\\dataset_sri\\4654.m4a\n",
      "F:\\dataset_sri\\4655.m4a\n",
      "F:\\dataset_sri\\4656.m4a\n",
      "F:\\dataset_sri\\4657.m4a\n",
      "F:\\dataset_sri\\4658.m4a\n",
      "F:\\dataset_sri\\4659.m4a\n",
      "F:\\dataset_sri\\466.m4a\n",
      "F:\\dataset_sri\\4660.m4a\n",
      "F:\\dataset_sri\\4661.m4a\n",
      "F:\\dataset_sri\\4662.m4a\n",
      "F:\\dataset_sri\\4663.m4a\n",
      "F:\\dataset_sri\\4664.m4a\n",
      "F:\\dataset_sri\\4665.m4a\n",
      "F:\\dataset_sri\\4666.m4a\n",
      "F:\\dataset_sri\\4667.m4a\n",
      "F:\\dataset_sri\\4668.m4a\n",
      "F:\\dataset_sri\\4669.m4a\n",
      "F:\\dataset_sri\\467.m4a\n",
      "F:\\dataset_sri\\4670.m4a\n",
      "F:\\dataset_sri\\4671.m4a\n",
      "F:\\dataset_sri\\4672.m4a\n",
      "F:\\dataset_sri\\4673.m4a\n",
      "F:\\dataset_sri\\4674.m4a\n",
      "F:\\dataset_sri\\4675.m4a\n",
      "F:\\dataset_sri\\4676.m4a\n",
      "F:\\dataset_sri\\4677.m4a\n",
      "F:\\dataset_sri\\4678.m4a\n",
      "F:\\dataset_sri\\4679.m4a\n",
      "F:\\dataset_sri\\468.m4a\n",
      "F:\\dataset_sri\\4680.m4a\n",
      "F:\\dataset_sri\\4681.m4a\n",
      "F:\\dataset_sri\\4682.m4a\n",
      "F:\\dataset_sri\\4683.m4a\n",
      "F:\\dataset_sri\\4684.m4a\n",
      "F:\\dataset_sri\\4685.m4a\n",
      "F:\\dataset_sri\\4686.m4a\n",
      "F:\\dataset_sri\\4687.m4a\n",
      "F:\\dataset_sri\\4688.m4a\n",
      "F:\\dataset_sri\\4689.m4a\n",
      "F:\\dataset_sri\\469.m4a\n",
      "F:\\dataset_sri\\4690.m4a\n",
      "F:\\dataset_sri\\4691.m4a\n",
      "F:\\dataset_sri\\4692.m4a\n",
      "F:\\dataset_sri\\4693.m4a\n",
      "F:\\dataset_sri\\4694.m4a\n",
      "F:\\dataset_sri\\4695.m4a\n",
      "F:\\dataset_sri\\4696.m4a\n",
      "F:\\dataset_sri\\4697.m4a\n",
      "F:\\dataset_sri\\4698.m4a\n",
      "F:\\dataset_sri\\4699.m4a\n",
      "F:\\dataset_sri\\47.m4a\n",
      "F:\\dataset_sri\\470.m4a\n",
      "F:\\dataset_sri\\4700.m4a\n",
      "F:\\dataset_sri\\4701.m4a\n",
      "F:\\dataset_sri\\4702.m4a\n",
      "F:\\dataset_sri\\4703.m4a\n",
      "F:\\dataset_sri\\4704.m4a\n",
      "F:\\dataset_sri\\4705.m4a\n",
      "F:\\dataset_sri\\4706.m4a\n",
      "F:\\dataset_sri\\4707.m4a\n",
      "F:\\dataset_sri\\4708.m4a\n",
      "F:\\dataset_sri\\4709.m4a\n",
      "F:\\dataset_sri\\471.m4a\n",
      "F:\\dataset_sri\\4710.m4a\n",
      "F:\\dataset_sri\\4711.m4a\n",
      "F:\\dataset_sri\\4712.m4a\n",
      "F:\\dataset_sri\\4713.m4a\n",
      "F:\\dataset_sri\\4714.m4a\n",
      "F:\\dataset_sri\\4715.m4a\n",
      "F:\\dataset_sri\\4716.m4a\n",
      "F:\\dataset_sri\\4717.m4a\n",
      "F:\\dataset_sri\\4718.m4a\n",
      "F:\\dataset_sri\\4719.m4a\n",
      "F:\\dataset_sri\\472.m4a\n",
      "F:\\dataset_sri\\4720.m4a\n",
      "F:\\dataset_sri\\4721.m4a\n",
      "F:\\dataset_sri\\4722.m4a\n",
      "F:\\dataset_sri\\4723.m4a\n",
      "F:\\dataset_sri\\4724.m4a\n",
      "F:\\dataset_sri\\4725.m4a\n",
      "F:\\dataset_sri\\4726.m4a\n",
      "F:\\dataset_sri\\4727.m4a\n",
      "F:\\dataset_sri\\4728.m4a\n",
      "F:\\dataset_sri\\4729.m4a\n",
      "F:\\dataset_sri\\473.m4a\n",
      "F:\\dataset_sri\\4730.m4a\n",
      "F:\\dataset_sri\\4731.m4a\n",
      "F:\\dataset_sri\\4732.m4a\n",
      "F:\\dataset_sri\\4733.m4a\n",
      "F:\\dataset_sri\\4734.m4a\n",
      "F:\\dataset_sri\\4735.m4a\n",
      "F:\\dataset_sri\\4736.m4a\n",
      "F:\\dataset_sri\\4737.m4a\n",
      "F:\\dataset_sri\\4738.m4a\n",
      "F:\\dataset_sri\\4739.m4a\n",
      "F:\\dataset_sri\\474.m4a\n",
      "F:\\dataset_sri\\4740.m4a\n",
      "F:\\dataset_sri\\4741.m4a\n",
      "F:\\dataset_sri\\4742.m4a\n",
      "F:\\dataset_sri\\4743.m4a\n",
      "F:\\dataset_sri\\4744.m4a\n",
      "F:\\dataset_sri\\4745.m4a\n",
      "F:\\dataset_sri\\4746.m4a\n",
      "F:\\dataset_sri\\4747.m4a\n",
      "F:\\dataset_sri\\4748.m4a\n",
      "F:\\dataset_sri\\4749.m4a\n",
      "F:\\dataset_sri\\475.m4a\n",
      "F:\\dataset_sri\\4750.m4a\n",
      "F:\\dataset_sri\\4751.m4a\n",
      "F:\\dataset_sri\\4752.m4a\n",
      "F:\\dataset_sri\\4753.m4a\n",
      "F:\\dataset_sri\\4754.m4a\n",
      "F:\\dataset_sri\\4755.m4a\n",
      "F:\\dataset_sri\\4756.m4a\n",
      "F:\\dataset_sri\\4757.m4a\n",
      "F:\\dataset_sri\\4758.m4a\n",
      "F:\\dataset_sri\\4759.m4a\n",
      "F:\\dataset_sri\\476.m4a\n",
      "F:\\dataset_sri\\4760.m4a\n",
      "F:\\dataset_sri\\4761.m4a\n",
      "F:\\dataset_sri\\4762.m4a\n",
      "F:\\dataset_sri\\4763.m4a\n",
      "F:\\dataset_sri\\4764.m4a\n",
      "F:\\dataset_sri\\4765.m4a\n",
      "F:\\dataset_sri\\4766.m4a\n",
      "F:\\dataset_sri\\4767.m4a\n",
      "F:\\dataset_sri\\4768.m4a\n",
      "F:\\dataset_sri\\4769.m4a\n",
      "F:\\dataset_sri\\477.m4a\n",
      "F:\\dataset_sri\\4770.m4a\n",
      "F:\\dataset_sri\\4771.m4a\n",
      "F:\\dataset_sri\\4772.m4a\n",
      "F:\\dataset_sri\\4773.m4a\n",
      "F:\\dataset_sri\\4774.m4a\n",
      "F:\\dataset_sri\\4775.m4a\n",
      "F:\\dataset_sri\\4776.m4a\n",
      "F:\\dataset_sri\\4777.m4a\n",
      "F:\\dataset_sri\\4778.m4a\n",
      "F:\\dataset_sri\\4779.m4a\n",
      "F:\\dataset_sri\\478.m4a\n",
      "F:\\dataset_sri\\4780.m4a\n",
      "F:\\dataset_sri\\4781.m4a\n",
      "F:\\dataset_sri\\4782.m4a\n",
      "F:\\dataset_sri\\4783.m4a\n",
      "F:\\dataset_sri\\4784.m4a\n",
      "F:\\dataset_sri\\4785.m4a\n",
      "F:\\dataset_sri\\4786.m4a\n",
      "F:\\dataset_sri\\4787.m4a\n",
      "F:\\dataset_sri\\4788.m4a\n",
      "F:\\dataset_sri\\4789.m4a\n",
      "F:\\dataset_sri\\479.m4a\n",
      "F:\\dataset_sri\\4790.m4a\n",
      "F:\\dataset_sri\\4791.m4a\n",
      "F:\\dataset_sri\\4792.m4a\n",
      "F:\\dataset_sri\\4793.m4a\n",
      "F:\\dataset_sri\\4794.m4a\n",
      "F:\\dataset_sri\\4795.m4a\n",
      "F:\\dataset_sri\\4796.m4a\n",
      "F:\\dataset_sri\\4797.m4a\n",
      "F:\\dataset_sri\\4798.m4a\n",
      "F:\\dataset_sri\\4799.m4a\n",
      "F:\\dataset_sri\\48.m4a\n",
      "F:\\dataset_sri\\480.m4a\n",
      "F:\\dataset_sri\\4800.m4a\n",
      "F:\\dataset_sri\\4801.m4a\n",
      "F:\\dataset_sri\\4802.m4a\n",
      "F:\\dataset_sri\\4803.m4a\n",
      "F:\\dataset_sri\\4804.m4a\n",
      "F:\\dataset_sri\\4805.m4a\n",
      "F:\\dataset_sri\\4806.m4a\n",
      "F:\\dataset_sri\\4807.m4a\n",
      "F:\\dataset_sri\\4808.m4a\n",
      "F:\\dataset_sri\\4809.m4a\n",
      "F:\\dataset_sri\\481.m4a\n",
      "F:\\dataset_sri\\4810.m4a\n",
      "F:\\dataset_sri\\4811.m4a\n",
      "F:\\dataset_sri\\4812.m4a\n",
      "F:\\dataset_sri\\4813.m4a\n",
      "F:\\dataset_sri\\4814.m4a\n",
      "F:\\dataset_sri\\4815.m4a\n",
      "F:\\dataset_sri\\4816.m4a\n",
      "F:\\dataset_sri\\4817.m4a\n",
      "F:\\dataset_sri\\4818.m4a\n",
      "F:\\dataset_sri\\4819.m4a\n",
      "F:\\dataset_sri\\482.m4a\n",
      "F:\\dataset_sri\\4820.m4a\n",
      "F:\\dataset_sri\\4821.m4a\n",
      "F:\\dataset_sri\\4822.m4a\n",
      "F:\\dataset_sri\\4823.m4a\n",
      "F:\\dataset_sri\\4824.m4a\n",
      "F:\\dataset_sri\\4825.m4a\n",
      "F:\\dataset_sri\\4826.m4a\n",
      "F:\\dataset_sri\\4827.m4a\n",
      "F:\\dataset_sri\\4828.m4a\n",
      "F:\\dataset_sri\\4829.m4a\n",
      "F:\\dataset_sri\\483.m4a\n",
      "F:\\dataset_sri\\4830.m4a\n",
      "F:\\dataset_sri\\4831.m4a\n",
      "F:\\dataset_sri\\4832.m4a\n",
      "F:\\dataset_sri\\4833.m4a\n",
      "F:\\dataset_sri\\4834.m4a\n",
      "F:\\dataset_sri\\4835.m4a\n",
      "F:\\dataset_sri\\4836.m4a\n",
      "F:\\dataset_sri\\4837.m4a\n",
      "F:\\dataset_sri\\4838.m4a\n",
      "F:\\dataset_sri\\4839.m4a\n",
      "F:\\dataset_sri\\484.m4a\n",
      "F:\\dataset_sri\\4840.m4a\n",
      "F:\\dataset_sri\\4841.m4a\n",
      "F:\\dataset_sri\\4842.m4a\n",
      "F:\\dataset_sri\\4843.m4a\n",
      "F:\\dataset_sri\\4844.m4a\n",
      "F:\\dataset_sri\\4845.m4a\n",
      "F:\\dataset_sri\\4846.m4a\n",
      "F:\\dataset_sri\\4847.m4a\n",
      "F:\\dataset_sri\\4848.m4a\n",
      "F:\\dataset_sri\\4849.m4a\n",
      "F:\\dataset_sri\\485.m4a\n",
      "F:\\dataset_sri\\4850.m4a\n",
      "F:\\dataset_sri\\4851.m4a\n",
      "F:\\dataset_sri\\4852.m4a\n",
      "F:\\dataset_sri\\4853.m4a\n",
      "F:\\dataset_sri\\4854.m4a\n",
      "F:\\dataset_sri\\4855.m4a\n",
      "F:\\dataset_sri\\4856.m4a\n",
      "F:\\dataset_sri\\4857.m4a\n",
      "F:\\dataset_sri\\4858.m4a\n",
      "F:\\dataset_sri\\4859.m4a\n",
      "F:\\dataset_sri\\486.m4a\n",
      "F:\\dataset_sri\\4860.m4a\n",
      "F:\\dataset_sri\\4861.m4a\n",
      "F:\\dataset_sri\\4862.m4a\n",
      "F:\\dataset_sri\\4863.m4a\n",
      "F:\\dataset_sri\\4864.m4a\n",
      "F:\\dataset_sri\\4865.m4a\n",
      "F:\\dataset_sri\\4866.m4a\n",
      "F:\\dataset_sri\\4867.m4a\n",
      "F:\\dataset_sri\\4868.m4a\n",
      "F:\\dataset_sri\\4869.m4a\n",
      "F:\\dataset_sri\\487.m4a\n",
      "F:\\dataset_sri\\4870.m4a\n",
      "F:\\dataset_sri\\4871.m4a\n",
      "F:\\dataset_sri\\4872.m4a\n",
      "F:\\dataset_sri\\4873.m4a\n",
      "F:\\dataset_sri\\4874.m4a\n",
      "F:\\dataset_sri\\4875.m4a\n",
      "F:\\dataset_sri\\4876.m4a\n",
      "F:\\dataset_sri\\4877.m4a\n",
      "F:\\dataset_sri\\4878.m4a\n",
      "F:\\dataset_sri\\4879.m4a\n",
      "F:\\dataset_sri\\488.m4a\n",
      "F:\\dataset_sri\\4880.m4a\n",
      "F:\\dataset_sri\\4881.m4a\n",
      "F:\\dataset_sri\\4882.m4a\n",
      "F:\\dataset_sri\\4883.m4a\n",
      "F:\\dataset_sri\\4884.m4a\n",
      "F:\\dataset_sri\\4885.m4a\n",
      "F:\\dataset_sri\\4886.m4a\n",
      "F:\\dataset_sri\\4887.m4a\n",
      "F:\\dataset_sri\\4888.m4a\n",
      "F:\\dataset_sri\\4889.m4a\n",
      "F:\\dataset_sri\\489.m4a\n",
      "F:\\dataset_sri\\4890.m4a\n",
      "F:\\dataset_sri\\4891.m4a\n",
      "F:\\dataset_sri\\4892.m4a\n",
      "F:\\dataset_sri\\4893.m4a\n",
      "F:\\dataset_sri\\4894.m4a\n",
      "F:\\dataset_sri\\4895.m4a\n",
      "F:\\dataset_sri\\4896.m4a\n",
      "F:\\dataset_sri\\4897.m4a\n",
      "F:\\dataset_sri\\4898.m4a\n",
      "F:\\dataset_sri\\4899.m4a\n",
      "F:\\dataset_sri\\49.m4a\n",
      "F:\\dataset_sri\\490.m4a\n",
      "F:\\dataset_sri\\4900.m4a\n",
      "F:\\dataset_sri\\4901.m4a\n",
      "F:\\dataset_sri\\4902.m4a\n",
      "F:\\dataset_sri\\4903.m4a\n",
      "F:\\dataset_sri\\4904.m4a\n",
      "F:\\dataset_sri\\4905.m4a\n",
      "F:\\dataset_sri\\4906.m4a\n",
      "F:\\dataset_sri\\4907.m4a\n",
      "F:\\dataset_sri\\4908.m4a\n",
      "F:\\dataset_sri\\4909.m4a\n",
      "F:\\dataset_sri\\491.m4a\n",
      "F:\\dataset_sri\\4910.m4a\n",
      "F:\\dataset_sri\\4911.m4a\n",
      "F:\\dataset_sri\\4912.m4a\n",
      "F:\\dataset_sri\\4913.m4a\n",
      "F:\\dataset_sri\\4914.m4a\n",
      "F:\\dataset_sri\\4915.m4a\n",
      "F:\\dataset_sri\\4916.m4a\n",
      "F:\\dataset_sri\\4917.m4a\n",
      "F:\\dataset_sri\\4918.m4a\n",
      "F:\\dataset_sri\\4919.m4a\n",
      "F:\\dataset_sri\\492.m4a\n",
      "F:\\dataset_sri\\4920.m4a\n",
      "F:\\dataset_sri\\4921.m4a\n",
      "F:\\dataset_sri\\4922.m4a\n",
      "F:\\dataset_sri\\4923.m4a\n",
      "F:\\dataset_sri\\4924.m4a\n",
      "F:\\dataset_sri\\4925.m4a\n",
      "F:\\dataset_sri\\4926.m4a\n",
      "F:\\dataset_sri\\4927.m4a\n",
      "F:\\dataset_sri\\4928.m4a\n",
      "F:\\dataset_sri\\4929.m4a\n",
      "F:\\dataset_sri\\493.m4a\n",
      "F:\\dataset_sri\\4930.m4a\n",
      "F:\\dataset_sri\\4931.m4a\n",
      "F:\\dataset_sri\\4932.m4a\n",
      "F:\\dataset_sri\\4933.m4a\n",
      "F:\\dataset_sri\\4934.m4a\n",
      "F:\\dataset_sri\\4935.m4a\n",
      "F:\\dataset_sri\\4936.m4a\n",
      "F:\\dataset_sri\\4937.m4a\n",
      "F:\\dataset_sri\\4938.m4a\n",
      "F:\\dataset_sri\\4939.m4a\n",
      "F:\\dataset_sri\\494.m4a\n",
      "F:\\dataset_sri\\4940.m4a\n",
      "F:\\dataset_sri\\4941.m4a\n",
      "F:\\dataset_sri\\4942.m4a\n",
      "F:\\dataset_sri\\4943.m4a\n",
      "F:\\dataset_sri\\4944.m4a\n",
      "F:\\dataset_sri\\4945.m4a\n",
      "F:\\dataset_sri\\4946.m4a\n",
      "F:\\dataset_sri\\4947.m4a\n",
      "F:\\dataset_sri\\4948.m4a\n",
      "F:\\dataset_sri\\4949.m4a\n",
      "F:\\dataset_sri\\495.m4a\n",
      "F:\\dataset_sri\\4950.m4a\n",
      "F:\\dataset_sri\\4951.m4a\n",
      "F:\\dataset_sri\\4952.m4a\n",
      "F:\\dataset_sri\\4953.m4a\n",
      "F:\\dataset_sri\\4954.m4a\n",
      "F:\\dataset_sri\\4955.m4a\n",
      "F:\\dataset_sri\\4956.m4a\n",
      "F:\\dataset_sri\\4957.m4a\n",
      "F:\\dataset_sri\\4958.m4a\n",
      "F:\\dataset_sri\\4959.m4a\n",
      "F:\\dataset_sri\\496.m4a\n",
      "F:\\dataset_sri\\4960.m4a\n",
      "F:\\dataset_sri\\4961.m4a\n",
      "F:\\dataset_sri\\4962.m4a\n",
      "F:\\dataset_sri\\4963.m4a\n",
      "F:\\dataset_sri\\4964.m4a\n",
      "F:\\dataset_sri\\4965.m4a\n",
      "F:\\dataset_sri\\4966.m4a\n",
      "F:\\dataset_sri\\4967.m4a\n",
      "F:\\dataset_sri\\4968.m4a\n",
      "F:\\dataset_sri\\4969.m4a\n",
      "F:\\dataset_sri\\497.m4a\n",
      "F:\\dataset_sri\\4970.m4a\n",
      "F:\\dataset_sri\\4971.m4a\n",
      "F:\\dataset_sri\\4972.m4a\n",
      "F:\\dataset_sri\\4973.m4a\n",
      "F:\\dataset_sri\\4974.m4a\n",
      "F:\\dataset_sri\\4975.m4a\n",
      "F:\\dataset_sri\\4976.m4a\n",
      "F:\\dataset_sri\\4977.m4a\n",
      "F:\\dataset_sri\\4978.m4a\n",
      "F:\\dataset_sri\\4979.m4a\n",
      "F:\\dataset_sri\\498.m4a\n",
      "F:\\dataset_sri\\4980.m4a\n",
      "F:\\dataset_sri\\4981.m4a\n",
      "F:\\dataset_sri\\4982.m4a\n",
      "F:\\dataset_sri\\4983.m4a\n",
      "F:\\dataset_sri\\4984.m4a\n",
      "F:\\dataset_sri\\4985.m4a\n",
      "F:\\dataset_sri\\4986.m4a\n",
      "F:\\dataset_sri\\4987.m4a\n",
      "F:\\dataset_sri\\4988.m4a\n",
      "F:\\dataset_sri\\4989.m4a\n",
      "F:\\dataset_sri\\499.m4a\n",
      "F:\\dataset_sri\\4990.m4a\n",
      "F:\\dataset_sri\\4991.m4a\n",
      "F:\\dataset_sri\\4992.m4a\n",
      "F:\\dataset_sri\\4993.m4a\n",
      "F:\\dataset_sri\\4994.m4a\n",
      "F:\\dataset_sri\\4995.m4a\n",
      "F:\\dataset_sri\\4996.m4a\n",
      "F:\\dataset_sri\\4997.m4a\n",
      "F:\\dataset_sri\\4998.m4a\n",
      "F:\\dataset_sri\\4999.m4a\n",
      "F:\\dataset_sri\\5.m4a\n",
      "F:\\dataset_sri\\50.m4a\n",
      "F:\\dataset_sri\\500.m4a\n",
      "F:\\dataset_sri\\5000.m4a\n",
      "F:\\dataset_sri\\5001.m4a\n",
      "F:\\dataset_sri\\5002.m4a\n",
      "F:\\dataset_sri\\5003.m4a\n",
      "F:\\dataset_sri\\5004.m4a\n",
      "F:\\dataset_sri\\5005.m4a\n",
      "F:\\dataset_sri\\5006.m4a\n",
      "F:\\dataset_sri\\5007.m4a\n",
      "F:\\dataset_sri\\5008.m4a\n",
      "F:\\dataset_sri\\5009.m4a\n",
      "F:\\dataset_sri\\501.m4a\n",
      "F:\\dataset_sri\\5010.m4a\n",
      "F:\\dataset_sri\\5011.m4a\n",
      "F:\\dataset_sri\\5012.m4a\n",
      "F:\\dataset_sri\\5013.m4a\n",
      "F:\\dataset_sri\\5014.m4a\n",
      "F:\\dataset_sri\\5015.m4a\n",
      "F:\\dataset_sri\\5016.m4a\n",
      "F:\\dataset_sri\\5017.m4a\n",
      "F:\\dataset_sri\\5018.m4a\n",
      "F:\\dataset_sri\\5019.m4a\n",
      "F:\\dataset_sri\\502.m4a\n",
      "F:\\dataset_sri\\5020.m4a\n",
      "F:\\dataset_sri\\5021.m4a\n",
      "F:\\dataset_sri\\5022.m4a\n",
      "F:\\dataset_sri\\5023.m4a\n",
      "F:\\dataset_sri\\5024.m4a\n",
      "F:\\dataset_sri\\5025.m4a\n",
      "F:\\dataset_sri\\5026.m4a\n",
      "F:\\dataset_sri\\5027.m4a\n",
      "F:\\dataset_sri\\5028.m4a\n",
      "F:\\dataset_sri\\5029.m4a\n",
      "F:\\dataset_sri\\503.m4a\n",
      "F:\\dataset_sri\\5030.m4a\n",
      "F:\\dataset_sri\\5031.m4a\n",
      "F:\\dataset_sri\\5032.m4a\n",
      "F:\\dataset_sri\\5033.m4a\n",
      "F:\\dataset_sri\\5034.m4a\n",
      "F:\\dataset_sri\\5035.m4a\n",
      "F:\\dataset_sri\\5036.m4a\n",
      "F:\\dataset_sri\\5037.m4a\n",
      "F:\\dataset_sri\\5038.m4a\n",
      "F:\\dataset_sri\\5039.m4a\n",
      "F:\\dataset_sri\\504.m4a\n",
      "F:\\dataset_sri\\5040.m4a\n",
      "F:\\dataset_sri\\5041.m4a\n",
      "F:\\dataset_sri\\5042.m4a\n",
      "F:\\dataset_sri\\5043.m4a\n",
      "F:\\dataset_sri\\5044.m4a\n",
      "F:\\dataset_sri\\5045.m4a\n",
      "F:\\dataset_sri\\5046.m4a\n",
      "F:\\dataset_sri\\5047.m4a\n",
      "F:\\dataset_sri\\5048.m4a\n",
      "F:\\dataset_sri\\5049.m4a\n",
      "F:\\dataset_sri\\505.m4a\n",
      "F:\\dataset_sri\\5050.m4a\n",
      "F:\\dataset_sri\\5051.m4a\n",
      "F:\\dataset_sri\\5052.m4a\n",
      "F:\\dataset_sri\\5053.m4a\n",
      "F:\\dataset_sri\\5054.m4a\n",
      "F:\\dataset_sri\\5055.m4a\n",
      "F:\\dataset_sri\\5056.m4a\n",
      "F:\\dataset_sri\\5057.m4a\n",
      "F:\\dataset_sri\\5058.m4a\n",
      "F:\\dataset_sri\\5059.m4a\n",
      "F:\\dataset_sri\\506.m4a\n",
      "F:\\dataset_sri\\5060.m4a\n",
      "F:\\dataset_sri\\5061.m4a\n",
      "F:\\dataset_sri\\5062.m4a\n",
      "F:\\dataset_sri\\5063.m4a\n",
      "F:\\dataset_sri\\5064.m4a\n",
      "F:\\dataset_sri\\5065.m4a\n",
      "F:\\dataset_sri\\5066.m4a\n",
      "F:\\dataset_sri\\5067.m4a\n",
      "F:\\dataset_sri\\5068.m4a\n",
      "F:\\dataset_sri\\5069.m4a\n",
      "F:\\dataset_sri\\507.m4a\n",
      "F:\\dataset_sri\\5070.m4a\n",
      "F:\\dataset_sri\\5071.m4a\n",
      "F:\\dataset_sri\\5072.m4a\n",
      "F:\\dataset_sri\\5073.m4a\n",
      "F:\\dataset_sri\\5074.m4a\n",
      "F:\\dataset_sri\\5075.m4a\n",
      "F:\\dataset_sri\\5076.m4a\n",
      "F:\\dataset_sri\\5077.m4a\n",
      "F:\\dataset_sri\\5078.m4a\n",
      "F:\\dataset_sri\\5079.m4a\n",
      "F:\\dataset_sri\\508.m4a\n",
      "F:\\dataset_sri\\5080.m4a\n",
      "F:\\dataset_sri\\5081.m4a\n",
      "F:\\dataset_sri\\5082.m4a\n",
      "F:\\dataset_sri\\5083.m4a\n",
      "F:\\dataset_sri\\5084.m4a\n",
      "F:\\dataset_sri\\5085.m4a\n",
      "F:\\dataset_sri\\5086.m4a\n",
      "F:\\dataset_sri\\5087.m4a\n",
      "F:\\dataset_sri\\5088.m4a\n",
      "F:\\dataset_sri\\5089.m4a\n",
      "F:\\dataset_sri\\509.m4a\n",
      "F:\\dataset_sri\\5090.m4a\n",
      "F:\\dataset_sri\\5091.m4a\n",
      "F:\\dataset_sri\\5092.m4a\n",
      "F:\\dataset_sri\\5093.m4a\n",
      "F:\\dataset_sri\\5094.m4a\n",
      "F:\\dataset_sri\\5095.m4a\n",
      "F:\\dataset_sri\\5096.m4a\n",
      "F:\\dataset_sri\\5097.m4a\n",
      "F:\\dataset_sri\\5098.m4a\n",
      "F:\\dataset_sri\\5099.m4a\n",
      "F:\\dataset_sri\\51.m4a\n",
      "F:\\dataset_sri\\510.m4a\n",
      "F:\\dataset_sri\\5100.m4a\n",
      "F:\\dataset_sri\\5101.m4a\n",
      "F:\\dataset_sri\\5102.m4a\n",
      "F:\\dataset_sri\\5103.m4a\n",
      "F:\\dataset_sri\\5104.m4a\n",
      "F:\\dataset_sri\\5105.m4a\n",
      "F:\\dataset_sri\\5106.m4a\n",
      "F:\\dataset_sri\\5107.m4a\n",
      "F:\\dataset_sri\\5108.m4a\n",
      "F:\\dataset_sri\\5109.m4a\n",
      "F:\\dataset_sri\\511.m4a\n",
      "F:\\dataset_sri\\5110.m4a\n",
      "F:\\dataset_sri\\5111.m4a\n",
      "F:\\dataset_sri\\5112.m4a\n",
      "F:\\dataset_sri\\5113.m4a\n",
      "F:\\dataset_sri\\5114.m4a\n",
      "F:\\dataset_sri\\5115.m4a\n",
      "F:\\dataset_sri\\5116.m4a\n",
      "F:\\dataset_sri\\5117.m4a\n",
      "F:\\dataset_sri\\5118.m4a\n",
      "F:\\dataset_sri\\5119.m4a\n",
      "F:\\dataset_sri\\512.m4a\n",
      "F:\\dataset_sri\\5120.m4a\n",
      "F:\\dataset_sri\\5121.m4a\n",
      "F:\\dataset_sri\\5122.m4a\n",
      "F:\\dataset_sri\\5123.m4a\n",
      "F:\\dataset_sri\\5124.m4a\n",
      "F:\\dataset_sri\\5125.m4a\n",
      "F:\\dataset_sri\\5126.m4a\n",
      "F:\\dataset_sri\\5127.m4a\n",
      "F:\\dataset_sri\\5128.m4a\n",
      "F:\\dataset_sri\\5129.m4a\n",
      "F:\\dataset_sri\\513.m4a\n",
      "F:\\dataset_sri\\5130.m4a\n",
      "F:\\dataset_sri\\5131.m4a\n",
      "F:\\dataset_sri\\5132.m4a\n",
      "F:\\dataset_sri\\5133.m4a\n",
      "F:\\dataset_sri\\5134.m4a\n",
      "F:\\dataset_sri\\5135.m4a\n",
      "F:\\dataset_sri\\5136.m4a\n",
      "F:\\dataset_sri\\5137.m4a\n",
      "F:\\dataset_sri\\5138.m4a\n",
      "F:\\dataset_sri\\5139.m4a\n",
      "F:\\dataset_sri\\514.m4a\n",
      "F:\\dataset_sri\\5140.m4a\n",
      "F:\\dataset_sri\\5141.m4a\n",
      "F:\\dataset_sri\\5142.m4a\n",
      "F:\\dataset_sri\\5143.m4a\n",
      "F:\\dataset_sri\\5144.m4a\n",
      "F:\\dataset_sri\\5145.m4a\n",
      "F:\\dataset_sri\\5146.m4a\n",
      "F:\\dataset_sri\\5147.m4a\n",
      "F:\\dataset_sri\\5148.m4a\n",
      "F:\\dataset_sri\\5149.m4a\n",
      "F:\\dataset_sri\\515.m4a\n",
      "F:\\dataset_sri\\5150.m4a\n",
      "F:\\dataset_sri\\5151.m4a\n",
      "F:\\dataset_sri\\5152.m4a\n",
      "F:\\dataset_sri\\5153.m4a\n",
      "F:\\dataset_sri\\5154.m4a\n",
      "F:\\dataset_sri\\5155.m4a\n",
      "F:\\dataset_sri\\5156.m4a\n",
      "F:\\dataset_sri\\5157.m4a\n",
      "F:\\dataset_sri\\5158.m4a\n",
      "F:\\dataset_sri\\5159.m4a\n",
      "F:\\dataset_sri\\516.m4a\n",
      "F:\\dataset_sri\\5160.m4a\n",
      "F:\\dataset_sri\\5161.m4a\n",
      "F:\\dataset_sri\\5162.m4a\n",
      "F:\\dataset_sri\\5163.m4a\n",
      "F:\\dataset_sri\\5164.m4a\n",
      "F:\\dataset_sri\\5165.m4a\n",
      "F:\\dataset_sri\\5166.m4a\n",
      "F:\\dataset_sri\\5167.m4a\n",
      "F:\\dataset_sri\\5168.m4a\n",
      "F:\\dataset_sri\\5169.m4a\n",
      "F:\\dataset_sri\\517.m4a\n",
      "F:\\dataset_sri\\5170.m4a\n",
      "F:\\dataset_sri\\5171.m4a\n",
      "F:\\dataset_sri\\5172.m4a\n",
      "F:\\dataset_sri\\5173.m4a\n",
      "F:\\dataset_sri\\5174.m4a\n",
      "F:\\dataset_sri\\5175.m4a\n",
      "F:\\dataset_sri\\5176.m4a\n",
      "F:\\dataset_sri\\5177.m4a\n",
      "F:\\dataset_sri\\5178.m4a\n",
      "F:\\dataset_sri\\5179.m4a\n",
      "F:\\dataset_sri\\518.m4a\n",
      "F:\\dataset_sri\\5180.m4a\n",
      "F:\\dataset_sri\\5181.m4a\n",
      "F:\\dataset_sri\\5182.m4a\n",
      "F:\\dataset_sri\\5183.m4a\n",
      "F:\\dataset_sri\\5184.m4a\n",
      "F:\\dataset_sri\\5185.m4a\n",
      "F:\\dataset_sri\\5186.m4a\n",
      "F:\\dataset_sri\\5187.m4a\n",
      "F:\\dataset_sri\\5188.m4a\n",
      "F:\\dataset_sri\\5189.m4a\n",
      "F:\\dataset_sri\\519.m4a\n",
      "F:\\dataset_sri\\5190.m4a\n",
      "F:\\dataset_sri\\5191.m4a\n",
      "F:\\dataset_sri\\5192.m4a\n",
      "F:\\dataset_sri\\5193.m4a\n",
      "F:\\dataset_sri\\5194.m4a\n",
      "F:\\dataset_sri\\5195.m4a\n",
      "F:\\dataset_sri\\5196.m4a\n",
      "F:\\dataset_sri\\5197.m4a\n",
      "F:\\dataset_sri\\5198.m4a\n",
      "F:\\dataset_sri\\5199.m4a\n",
      "F:\\dataset_sri\\52.m4a\n",
      "F:\\dataset_sri\\520.m4a\n",
      "F:\\dataset_sri\\5200.m4a\n",
      "F:\\dataset_sri\\5201.m4a\n",
      "F:\\dataset_sri\\5202.m4a\n",
      "F:\\dataset_sri\\5203.m4a\n",
      "F:\\dataset_sri\\5204.m4a\n",
      "F:\\dataset_sri\\5205.m4a\n",
      "F:\\dataset_sri\\5206.m4a\n",
      "F:\\dataset_sri\\5207.m4a\n",
      "F:\\dataset_sri\\5208.m4a\n",
      "F:\\dataset_sri\\5209.m4a\n",
      "F:\\dataset_sri\\521.m4a\n",
      "F:\\dataset_sri\\5210.m4a\n",
      "F:\\dataset_sri\\5211.m4a\n",
      "F:\\dataset_sri\\5212.m4a\n",
      "F:\\dataset_sri\\5213.m4a\n",
      "F:\\dataset_sri\\5214.m4a\n",
      "F:\\dataset_sri\\5215.m4a\n",
      "F:\\dataset_sri\\5216.m4a\n",
      "F:\\dataset_sri\\5217.m4a\n",
      "F:\\dataset_sri\\5218.m4a\n",
      "F:\\dataset_sri\\5219.m4a\n",
      "F:\\dataset_sri\\522.m4a\n",
      "F:\\dataset_sri\\5220.m4a\n",
      "F:\\dataset_sri\\5221.m4a\n",
      "F:\\dataset_sri\\5222.m4a\n",
      "F:\\dataset_sri\\5223.m4a\n",
      "F:\\dataset_sri\\5224.m4a\n",
      "F:\\dataset_sri\\5225.m4a\n",
      "F:\\dataset_sri\\5226.m4a\n",
      "F:\\dataset_sri\\5227.m4a\n",
      "F:\\dataset_sri\\5228.m4a\n",
      "F:\\dataset_sri\\5229.m4a\n",
      "F:\\dataset_sri\\523.m4a\n",
      "F:\\dataset_sri\\5230.m4a\n",
      "F:\\dataset_sri\\5231.m4a\n",
      "F:\\dataset_sri\\5232.m4a\n",
      "F:\\dataset_sri\\5233.m4a\n",
      "F:\\dataset_sri\\5234.m4a\n",
      "F:\\dataset_sri\\5235.m4a\n",
      "F:\\dataset_sri\\5236.m4a\n",
      "F:\\dataset_sri\\5237.m4a\n",
      "F:\\dataset_sri\\5238.m4a\n",
      "F:\\dataset_sri\\5239.m4a\n",
      "F:\\dataset_sri\\524.m4a\n",
      "F:\\dataset_sri\\5240.m4a\n",
      "F:\\dataset_sri\\5241.m4a\n",
      "F:\\dataset_sri\\5242.m4a\n",
      "F:\\dataset_sri\\5243.m4a\n",
      "F:\\dataset_sri\\5244.m4a\n",
      "F:\\dataset_sri\\5245.m4a\n",
      "F:\\dataset_sri\\5246.m4a\n",
      "F:\\dataset_sri\\5247.m4a\n",
      "F:\\dataset_sri\\5248.m4a\n",
      "F:\\dataset_sri\\5249.m4a\n",
      "F:\\dataset_sri\\525.m4a\n",
      "F:\\dataset_sri\\5250.m4a\n",
      "F:\\dataset_sri\\5251.m4a\n",
      "F:\\dataset_sri\\5252.m4a\n",
      "F:\\dataset_sri\\5253.m4a\n",
      "F:\\dataset_sri\\5254.m4a\n",
      "F:\\dataset_sri\\5255.m4a\n",
      "F:\\dataset_sri\\5256.m4a\n",
      "F:\\dataset_sri\\5257.m4a\n",
      "F:\\dataset_sri\\5258.m4a\n",
      "F:\\dataset_sri\\5259.m4a\n",
      "F:\\dataset_sri\\526.m4a\n",
      "F:\\dataset_sri\\5260.m4a\n",
      "F:\\dataset_sri\\5261.m4a\n",
      "F:\\dataset_sri\\5262.m4a\n",
      "F:\\dataset_sri\\5263.m4a\n",
      "F:\\dataset_sri\\5264.m4a\n",
      "F:\\dataset_sri\\5265.m4a\n",
      "F:\\dataset_sri\\5266.m4a\n",
      "F:\\dataset_sri\\5267.m4a\n",
      "F:\\dataset_sri\\5268.m4a\n",
      "F:\\dataset_sri\\5269.m4a\n",
      "F:\\dataset_sri\\527.m4a\n",
      "F:\\dataset_sri\\5270.m4a\n",
      "F:\\dataset_sri\\5271.m4a\n",
      "F:\\dataset_sri\\5272.m4a\n",
      "F:\\dataset_sri\\5273.m4a\n",
      "F:\\dataset_sri\\5274.m4a\n",
      "F:\\dataset_sri\\5275.m4a\n",
      "F:\\dataset_sri\\5276.m4a\n",
      "F:\\dataset_sri\\5277.m4a\n",
      "F:\\dataset_sri\\5278.m4a\n",
      "F:\\dataset_sri\\5279.m4a\n",
      "F:\\dataset_sri\\528.m4a\n",
      "F:\\dataset_sri\\5280.m4a\n",
      "F:\\dataset_sri\\5281.m4a\n",
      "F:\\dataset_sri\\5282.m4a\n",
      "F:\\dataset_sri\\5283.m4a\n",
      "F:\\dataset_sri\\5284.m4a\n",
      "F:\\dataset_sri\\5285.m4a\n",
      "F:\\dataset_sri\\5286.m4a\n",
      "F:\\dataset_sri\\5287.m4a\n",
      "F:\\dataset_sri\\5288.m4a\n",
      "F:\\dataset_sri\\5289.m4a\n",
      "F:\\dataset_sri\\529.m4a\n",
      "F:\\dataset_sri\\5290.m4a\n",
      "F:\\dataset_sri\\5291.m4a\n",
      "F:\\dataset_sri\\5292.m4a\n",
      "F:\\dataset_sri\\5293.m4a\n",
      "F:\\dataset_sri\\5294.m4a\n",
      "F:\\dataset_sri\\5295.m4a\n",
      "F:\\dataset_sri\\5296.m4a\n",
      "F:\\dataset_sri\\5297.m4a\n",
      "F:\\dataset_sri\\5298.m4a\n",
      "F:\\dataset_sri\\5299.m4a\n",
      "F:\\dataset_sri\\53.m4a\n",
      "F:\\dataset_sri\\530.m4a\n",
      "F:\\dataset_sri\\5300.m4a\n",
      "F:\\dataset_sri\\5301.m4a\n",
      "F:\\dataset_sri\\5302.m4a\n",
      "F:\\dataset_sri\\5303.m4a\n",
      "F:\\dataset_sri\\5304.m4a\n",
      "F:\\dataset_sri\\5305.m4a\n",
      "F:\\dataset_sri\\5306.m4a\n",
      "F:\\dataset_sri\\5307.m4a\n",
      "F:\\dataset_sri\\5308.m4a\n",
      "F:\\dataset_sri\\5309.m4a\n",
      "F:\\dataset_sri\\531.m4a\n",
      "F:\\dataset_sri\\5310.m4a\n",
      "F:\\dataset_sri\\5311.m4a\n",
      "F:\\dataset_sri\\5312.m4a\n",
      "F:\\dataset_sri\\5313.m4a\n",
      "F:\\dataset_sri\\5314.m4a\n",
      "F:\\dataset_sri\\5315.m4a\n",
      "F:\\dataset_sri\\5316.m4a\n",
      "F:\\dataset_sri\\5317.m4a\n",
      "F:\\dataset_sri\\5318.m4a\n",
      "F:\\dataset_sri\\5319.m4a\n",
      "F:\\dataset_sri\\532.m4a\n",
      "F:\\dataset_sri\\5320.m4a\n",
      "F:\\dataset_sri\\5321.m4a\n",
      "F:\\dataset_sri\\5322.m4a\n",
      "F:\\dataset_sri\\5323.m4a\n",
      "F:\\dataset_sri\\5324.m4a\n",
      "F:\\dataset_sri\\5325.m4a\n",
      "F:\\dataset_sri\\5326.m4a\n",
      "F:\\dataset_sri\\5327.m4a\n",
      "F:\\dataset_sri\\5328.m4a\n",
      "F:\\dataset_sri\\5329.m4a\n",
      "F:\\dataset_sri\\533.m4a\n",
      "F:\\dataset_sri\\5330.m4a\n",
      "F:\\dataset_sri\\5331.m4a\n",
      "F:\\dataset_sri\\5332.m4a\n",
      "F:\\dataset_sri\\5333.m4a\n",
      "F:\\dataset_sri\\5334.m4a\n",
      "F:\\dataset_sri\\5335.m4a\n",
      "F:\\dataset_sri\\5336.m4a\n",
      "F:\\dataset_sri\\5337.m4a\n",
      "F:\\dataset_sri\\5338.m4a\n",
      "F:\\dataset_sri\\5339.m4a\n",
      "F:\\dataset_sri\\534.m4a\n",
      "F:\\dataset_sri\\5340.m4a\n",
      "F:\\dataset_sri\\5341.m4a\n",
      "F:\\dataset_sri\\5342.m4a\n",
      "F:\\dataset_sri\\5343.m4a\n",
      "F:\\dataset_sri\\5344.m4a\n",
      "F:\\dataset_sri\\5345.m4a\n",
      "F:\\dataset_sri\\5346.m4a\n",
      "F:\\dataset_sri\\5347.m4a\n",
      "F:\\dataset_sri\\5348.m4a\n",
      "F:\\dataset_sri\\5349.m4a\n",
      "F:\\dataset_sri\\535.m4a\n",
      "F:\\dataset_sri\\5350.m4a\n",
      "F:\\dataset_sri\\5351.m4a\n",
      "F:\\dataset_sri\\5352.m4a\n",
      "F:\\dataset_sri\\5353.m4a\n",
      "F:\\dataset_sri\\5354.m4a\n",
      "F:\\dataset_sri\\5355.m4a\n",
      "F:\\dataset_sri\\5356.m4a\n",
      "F:\\dataset_sri\\5357.m4a\n",
      "F:\\dataset_sri\\5358.m4a\n",
      "F:\\dataset_sri\\5359.m4a\n",
      "F:\\dataset_sri\\536.m4a\n",
      "F:\\dataset_sri\\5360.m4a\n",
      "F:\\dataset_sri\\5361.m4a\n",
      "F:\\dataset_sri\\5362.m4a\n",
      "F:\\dataset_sri\\5363.m4a\n",
      "F:\\dataset_sri\\5364.m4a\n",
      "F:\\dataset_sri\\5365.m4a\n",
      "F:\\dataset_sri\\5366.m4a\n",
      "F:\\dataset_sri\\5367.m4a\n",
      "F:\\dataset_sri\\5368.m4a\n",
      "F:\\dataset_sri\\5369.m4a\n",
      "F:\\dataset_sri\\537.m4a\n",
      "F:\\dataset_sri\\5370.m4a\n",
      "F:\\dataset_sri\\5371.m4a\n",
      "F:\\dataset_sri\\5372.m4a\n",
      "F:\\dataset_sri\\5373.m4a\n",
      "F:\\dataset_sri\\5374.m4a\n",
      "F:\\dataset_sri\\5375.m4a\n",
      "F:\\dataset_sri\\5376.m4a\n",
      "F:\\dataset_sri\\5377.m4a\n",
      "F:\\dataset_sri\\5378.m4a\n",
      "F:\\dataset_sri\\5379.m4a\n",
      "F:\\dataset_sri\\538.m4a\n",
      "F:\\dataset_sri\\5380.m4a\n",
      "F:\\dataset_sri\\5381.m4a\n",
      "F:\\dataset_sri\\5382.m4a\n",
      "F:\\dataset_sri\\5383.m4a\n",
      "F:\\dataset_sri\\5384.m4a\n",
      "F:\\dataset_sri\\5385.m4a\n",
      "F:\\dataset_sri\\5386.m4a\n",
      "F:\\dataset_sri\\5387.m4a\n",
      "F:\\dataset_sri\\5388.m4a\n",
      "F:\\dataset_sri\\5389.m4a\n",
      "F:\\dataset_sri\\539.m4a\n",
      "F:\\dataset_sri\\5390.m4a\n",
      "F:\\dataset_sri\\5391.m4a\n",
      "F:\\dataset_sri\\5392.m4a\n",
      "F:\\dataset_sri\\5393.m4a\n",
      "F:\\dataset_sri\\5394.m4a\n",
      "F:\\dataset_sri\\5395.m4a\n",
      "F:\\dataset_sri\\5396.m4a\n",
      "F:\\dataset_sri\\5397.m4a\n",
      "F:\\dataset_sri\\5398.m4a\n",
      "F:\\dataset_sri\\5399.m4a\n",
      "F:\\dataset_sri\\54.m4a\n",
      "F:\\dataset_sri\\540.m4a\n",
      "F:\\dataset_sri\\5400.m4a\n",
      "F:\\dataset_sri\\5401.m4a\n",
      "F:\\dataset_sri\\5402.m4a\n",
      "F:\\dataset_sri\\5403.m4a\n",
      "F:\\dataset_sri\\5404.m4a\n",
      "F:\\dataset_sri\\5405.m4a\n",
      "F:\\dataset_sri\\5406.m4a\n",
      "F:\\dataset_sri\\5407.m4a\n",
      "F:\\dataset_sri\\5408.m4a\n",
      "F:\\dataset_sri\\5409.m4a\n",
      "F:\\dataset_sri\\541.m4a\n",
      "F:\\dataset_sri\\5410.m4a\n",
      "F:\\dataset_sri\\5411.m4a\n",
      "F:\\dataset_sri\\5412.m4a\n",
      "F:\\dataset_sri\\5413.m4a\n",
      "F:\\dataset_sri\\5414.m4a\n",
      "F:\\dataset_sri\\5415.m4a\n",
      "F:\\dataset_sri\\5416.m4a\n",
      "F:\\dataset_sri\\5417.m4a\n",
      "F:\\dataset_sri\\5418.m4a\n",
      "F:\\dataset_sri\\5419.m4a\n",
      "F:\\dataset_sri\\542.m4a\n",
      "F:\\dataset_sri\\5420.m4a\n",
      "F:\\dataset_sri\\5421.m4a\n",
      "F:\\dataset_sri\\5422.m4a\n",
      "F:\\dataset_sri\\5423.m4a\n",
      "F:\\dataset_sri\\5424.m4a\n",
      "F:\\dataset_sri\\5425.m4a\n",
      "F:\\dataset_sri\\5426.m4a\n",
      "F:\\dataset_sri\\5427.m4a\n",
      "F:\\dataset_sri\\5428.m4a\n",
      "F:\\dataset_sri\\5429.m4a\n",
      "F:\\dataset_sri\\543.m4a\n",
      "F:\\dataset_sri\\5430.m4a\n",
      "F:\\dataset_sri\\5431.m4a\n",
      "F:\\dataset_sri\\5432.m4a\n",
      "F:\\dataset_sri\\5433.m4a\n",
      "F:\\dataset_sri\\5434.m4a\n",
      "F:\\dataset_sri\\5435.m4a\n",
      "F:\\dataset_sri\\5436.m4a\n",
      "F:\\dataset_sri\\5437.m4a\n",
      "F:\\dataset_sri\\5438.m4a\n",
      "F:\\dataset_sri\\5439.m4a\n",
      "F:\\dataset_sri\\544.m4a\n",
      "F:\\dataset_sri\\5440.m4a\n",
      "F:\\dataset_sri\\5441.m4a\n",
      "F:\\dataset_sri\\5442.m4a\n",
      "F:\\dataset_sri\\5443.m4a\n",
      "F:\\dataset_sri\\5444.m4a\n",
      "F:\\dataset_sri\\5445.m4a\n",
      "F:\\dataset_sri\\5446.m4a\n",
      "F:\\dataset_sri\\5447.m4a\n",
      "F:\\dataset_sri\\5448.m4a\n",
      "F:\\dataset_sri\\5449.m4a\n",
      "F:\\dataset_sri\\545.m4a\n",
      "F:\\dataset_sri\\5450.m4a\n",
      "F:\\dataset_sri\\5451.m4a\n",
      "F:\\dataset_sri\\5452.m4a\n",
      "F:\\dataset_sri\\5453.m4a\n",
      "F:\\dataset_sri\\5454.m4a\n",
      "F:\\dataset_sri\\5455.m4a\n",
      "F:\\dataset_sri\\5456.m4a\n",
      "F:\\dataset_sri\\5457.m4a\n",
      "F:\\dataset_sri\\5458.m4a\n",
      "F:\\dataset_sri\\5459.m4a\n",
      "F:\\dataset_sri\\546.m4a\n",
      "F:\\dataset_sri\\5460.m4a\n",
      "F:\\dataset_sri\\5461.m4a\n",
      "F:\\dataset_sri\\5462.m4a\n",
      "F:\\dataset_sri\\5463.m4a\n",
      "F:\\dataset_sri\\5464.m4a\n",
      "F:\\dataset_sri\\5465.m4a\n",
      "F:\\dataset_sri\\5466.m4a\n",
      "F:\\dataset_sri\\5467.m4a\n",
      "F:\\dataset_sri\\5468.m4a\n",
      "F:\\dataset_sri\\5469.m4a\n",
      "F:\\dataset_sri\\547.m4a\n",
      "F:\\dataset_sri\\5470.m4a\n",
      "F:\\dataset_sri\\5471.m4a\n",
      "F:\\dataset_sri\\5472.m4a\n",
      "F:\\dataset_sri\\5473.m4a\n",
      "F:\\dataset_sri\\5474.m4a\n",
      "F:\\dataset_sri\\5475.m4a\n",
      "F:\\dataset_sri\\5476.m4a\n",
      "F:\\dataset_sri\\5477.m4a\n",
      "F:\\dataset_sri\\5478.m4a\n",
      "F:\\dataset_sri\\5479.m4a\n",
      "F:\\dataset_sri\\548.m4a\n",
      "F:\\dataset_sri\\5480.m4a\n",
      "F:\\dataset_sri\\5481.m4a\n",
      "F:\\dataset_sri\\5482.m4a\n",
      "F:\\dataset_sri\\5483.m4a\n",
      "F:\\dataset_sri\\5484.m4a\n",
      "F:\\dataset_sri\\5485.m4a\n",
      "F:\\dataset_sri\\5486.m4a\n",
      "F:\\dataset_sri\\5487.m4a\n",
      "F:\\dataset_sri\\5488.m4a\n",
      "F:\\dataset_sri\\5489.m4a\n",
      "F:\\dataset_sri\\549.m4a\n",
      "F:\\dataset_sri\\5490.m4a\n",
      "F:\\dataset_sri\\5491.m4a\n",
      "F:\\dataset_sri\\5492.m4a\n",
      "F:\\dataset_sri\\5493.m4a\n",
      "F:\\dataset_sri\\5494.m4a\n",
      "F:\\dataset_sri\\5495.m4a\n",
      "F:\\dataset_sri\\5496.m4a\n",
      "F:\\dataset_sri\\5497.m4a\n",
      "F:\\dataset_sri\\5498.m4a\n",
      "F:\\dataset_sri\\5499.m4a\n",
      "F:\\dataset_sri\\55.m4a\n",
      "F:\\dataset_sri\\550.m4a\n",
      "F:\\dataset_sri\\5500.m4a\n",
      "F:\\dataset_sri\\5501.m4a\n",
      "F:\\dataset_sri\\5502.m4a\n",
      "F:\\dataset_sri\\5503.m4a\n",
      "F:\\dataset_sri\\5504.m4a\n",
      "F:\\dataset_sri\\5505.m4a\n",
      "F:\\dataset_sri\\5506.m4a\n",
      "F:\\dataset_sri\\5507.m4a\n",
      "F:\\dataset_sri\\5508.m4a\n",
      "F:\\dataset_sri\\5509.m4a\n",
      "F:\\dataset_sri\\551.m4a\n",
      "F:\\dataset_sri\\5510.m4a\n",
      "F:\\dataset_sri\\5511.m4a\n",
      "F:\\dataset_sri\\5512.m4a\n",
      "F:\\dataset_sri\\5513.m4a\n",
      "F:\\dataset_sri\\5514.m4a\n",
      "F:\\dataset_sri\\5515.m4a\n",
      "F:\\dataset_sri\\5516.m4a\n",
      "F:\\dataset_sri\\5517.m4a\n",
      "F:\\dataset_sri\\5518.m4a\n",
      "F:\\dataset_sri\\5519.m4a\n",
      "F:\\dataset_sri\\552.m4a\n",
      "F:\\dataset_sri\\5520.m4a\n",
      "F:\\dataset_sri\\5521.m4a\n",
      "F:\\dataset_sri\\5522.m4a\n",
      "F:\\dataset_sri\\5523.m4a\n",
      "F:\\dataset_sri\\5524.m4a\n",
      "F:\\dataset_sri\\5525.m4a\n",
      "F:\\dataset_sri\\5526.m4a\n",
      "F:\\dataset_sri\\5527.m4a\n",
      "F:\\dataset_sri\\5528.m4a\n",
      "F:\\dataset_sri\\5529.m4a\n",
      "F:\\dataset_sri\\553.m4a\n",
      "F:\\dataset_sri\\5530.m4a\n",
      "F:\\dataset_sri\\5531.m4a\n",
      "F:\\dataset_sri\\5532.m4a\n",
      "F:\\dataset_sri\\5533.m4a\n",
      "F:\\dataset_sri\\5534.m4a\n",
      "F:\\dataset_sri\\5535.m4a\n",
      "F:\\dataset_sri\\5536.m4a\n",
      "F:\\dataset_sri\\5537.m4a\n",
      "F:\\dataset_sri\\5538.m4a\n",
      "F:\\dataset_sri\\5539.m4a\n",
      "F:\\dataset_sri\\554.m4a\n",
      "F:\\dataset_sri\\5540.m4a\n",
      "F:\\dataset_sri\\5541.m4a\n",
      "F:\\dataset_sri\\5542.m4a\n",
      "F:\\dataset_sri\\5543.m4a\n",
      "F:\\dataset_sri\\5544.m4a\n",
      "F:\\dataset_sri\\5545.m4a\n",
      "F:\\dataset_sri\\5546.m4a\n",
      "F:\\dataset_sri\\5547.m4a\n",
      "F:\\dataset_sri\\5548.m4a\n",
      "F:\\dataset_sri\\5549.m4a\n",
      "F:\\dataset_sri\\555.m4a\n",
      "F:\\dataset_sri\\5550.m4a\n",
      "F:\\dataset_sri\\5551.m4a\n",
      "F:\\dataset_sri\\5552.m4a\n",
      "F:\\dataset_sri\\5553.m4a\n",
      "F:\\dataset_sri\\5554.m4a\n",
      "F:\\dataset_sri\\5555.m4a\n",
      "F:\\dataset_sri\\5556.m4a\n",
      "F:\\dataset_sri\\5557.m4a\n",
      "F:\\dataset_sri\\5558.m4a\n",
      "F:\\dataset_sri\\5559.m4a\n",
      "F:\\dataset_sri\\556.m4a\n",
      "F:\\dataset_sri\\5560.m4a\n",
      "F:\\dataset_sri\\5561.m4a\n",
      "F:\\dataset_sri\\5562.m4a\n",
      "F:\\dataset_sri\\5563.m4a\n",
      "F:\\dataset_sri\\5564.m4a\n",
      "F:\\dataset_sri\\5565.m4a\n",
      "F:\\dataset_sri\\5566.m4a\n",
      "F:\\dataset_sri\\5567.m4a\n",
      "F:\\dataset_sri\\5568.m4a\n",
      "F:\\dataset_sri\\5569.m4a\n",
      "F:\\dataset_sri\\557.m4a\n",
      "F:\\dataset_sri\\5570.m4a\n",
      "F:\\dataset_sri\\5571.m4a\n",
      "F:\\dataset_sri\\5572.m4a\n",
      "F:\\dataset_sri\\5573.m4a\n",
      "F:\\dataset_sri\\5574.m4a\n",
      "F:\\dataset_sri\\5575.m4a\n",
      "F:\\dataset_sri\\5576.m4a\n",
      "F:\\dataset_sri\\5577.m4a\n",
      "F:\\dataset_sri\\5578.m4a\n",
      "F:\\dataset_sri\\5579.m4a\n",
      "F:\\dataset_sri\\558.m4a\n",
      "F:\\dataset_sri\\5580.m4a\n",
      "F:\\dataset_sri\\5581.m4a\n",
      "F:\\dataset_sri\\5582.m4a\n",
      "F:\\dataset_sri\\5583.m4a\n",
      "F:\\dataset_sri\\5584.m4a\n",
      "F:\\dataset_sri\\5585.m4a\n",
      "F:\\dataset_sri\\5586.m4a\n",
      "F:\\dataset_sri\\5587.m4a\n",
      "F:\\dataset_sri\\5588.m4a\n",
      "F:\\dataset_sri\\5589.m4a\n",
      "F:\\dataset_sri\\559.m4a\n",
      "F:\\dataset_sri\\5590.m4a\n",
      "F:\\dataset_sri\\5591.m4a\n",
      "F:\\dataset_sri\\5592.m4a\n",
      "F:\\dataset_sri\\5593.m4a\n",
      "F:\\dataset_sri\\5594.m4a\n",
      "F:\\dataset_sri\\5595.m4a\n",
      "F:\\dataset_sri\\5596.m4a\n",
      "F:\\dataset_sri\\5597.m4a\n",
      "F:\\dataset_sri\\5598.m4a\n",
      "F:\\dataset_sri\\5599.m4a\n",
      "F:\\dataset_sri\\56.m4a\n",
      "F:\\dataset_sri\\560.m4a\n",
      "F:\\dataset_sri\\5600.m4a\n",
      "F:\\dataset_sri\\5601.m4a\n",
      "F:\\dataset_sri\\5602.m4a\n",
      "F:\\dataset_sri\\5603.m4a\n",
      "F:\\dataset_sri\\5604.m4a\n",
      "F:\\dataset_sri\\5605.m4a\n",
      "F:\\dataset_sri\\5606.m4a\n",
      "F:\\dataset_sri\\5607.m4a\n",
      "F:\\dataset_sri\\5608.m4a\n",
      "F:\\dataset_sri\\5609.m4a\n",
      "F:\\dataset_sri\\561.m4a\n",
      "F:\\dataset_sri\\5610.m4a\n",
      "F:\\dataset_sri\\5611.m4a\n",
      "F:\\dataset_sri\\5612.m4a\n",
      "F:\\dataset_sri\\5613.m4a\n",
      "F:\\dataset_sri\\5614.m4a\n",
      "F:\\dataset_sri\\5615.m4a\n",
      "F:\\dataset_sri\\5616.m4a\n",
      "F:\\dataset_sri\\5617.m4a\n",
      "F:\\dataset_sri\\5618.m4a\n",
      "F:\\dataset_sri\\5619.m4a\n",
      "F:\\dataset_sri\\562.m4a\n",
      "F:\\dataset_sri\\5620.m4a\n",
      "F:\\dataset_sri\\5621.m4a\n",
      "F:\\dataset_sri\\5622.m4a\n",
      "F:\\dataset_sri\\5623.m4a\n",
      "F:\\dataset_sri\\5624.m4a\n",
      "F:\\dataset_sri\\5625.m4a\n",
      "F:\\dataset_sri\\5626.m4a\n",
      "F:\\dataset_sri\\5627.m4a\n",
      "F:\\dataset_sri\\5628.m4a\n",
      "F:\\dataset_sri\\5629.m4a\n",
      "F:\\dataset_sri\\563.m4a\n",
      "F:\\dataset_sri\\5630.m4a\n",
      "F:\\dataset_sri\\5631.m4a\n",
      "F:\\dataset_sri\\5632.m4a\n",
      "F:\\dataset_sri\\5633.m4a\n",
      "F:\\dataset_sri\\5634.m4a\n",
      "F:\\dataset_sri\\5635.m4a\n",
      "F:\\dataset_sri\\5636.m4a\n",
      "F:\\dataset_sri\\5637.m4a\n",
      "F:\\dataset_sri\\5638.m4a\n",
      "F:\\dataset_sri\\5639.m4a\n",
      "F:\\dataset_sri\\564.m4a\n",
      "F:\\dataset_sri\\5640.m4a\n",
      "F:\\dataset_sri\\5641.m4a\n",
      "F:\\dataset_sri\\5642.m4a\n",
      "F:\\dataset_sri\\5643.m4a\n",
      "F:\\dataset_sri\\5644.m4a\n",
      "F:\\dataset_sri\\5645.m4a\n",
      "F:\\dataset_sri\\5646.m4a\n",
      "F:\\dataset_sri\\5647.m4a\n",
      "F:\\dataset_sri\\5648.m4a\n",
      "F:\\dataset_sri\\5649.m4a\n",
      "F:\\dataset_sri\\565.m4a\n",
      "F:\\dataset_sri\\5650.m4a\n",
      "F:\\dataset_sri\\5651.m4a\n",
      "F:\\dataset_sri\\5652.m4a\n",
      "F:\\dataset_sri\\5653.m4a\n",
      "F:\\dataset_sri\\5654.m4a\n",
      "F:\\dataset_sri\\5655.m4a\n",
      "F:\\dataset_sri\\5656.m4a\n",
      "F:\\dataset_sri\\5657.m4a\n",
      "F:\\dataset_sri\\5658.m4a\n",
      "F:\\dataset_sri\\5659.m4a\n",
      "F:\\dataset_sri\\566.m4a\n",
      "F:\\dataset_sri\\5660.m4a\n",
      "F:\\dataset_sri\\5661.m4a\n",
      "F:\\dataset_sri\\5662.m4a\n",
      "F:\\dataset_sri\\5663.m4a\n",
      "F:\\dataset_sri\\5664.m4a\n",
      "F:\\dataset_sri\\5665.m4a\n",
      "F:\\dataset_sri\\5666.m4a\n",
      "F:\\dataset_sri\\5667.m4a\n",
      "F:\\dataset_sri\\5668.m4a\n",
      "F:\\dataset_sri\\5669.m4a\n",
      "F:\\dataset_sri\\567.m4a\n",
      "F:\\dataset_sri\\5670.m4a\n",
      "F:\\dataset_sri\\5671.m4a\n",
      "F:\\dataset_sri\\5672.m4a\n",
      "F:\\dataset_sri\\5673.m4a\n",
      "F:\\dataset_sri\\5674.m4a\n",
      "F:\\dataset_sri\\5675.m4a\n",
      "F:\\dataset_sri\\5676.m4a\n",
      "F:\\dataset_sri\\5677.m4a\n",
      "F:\\dataset_sri\\5678.m4a\n",
      "F:\\dataset_sri\\5679.m4a\n",
      "F:\\dataset_sri\\568.m4a\n",
      "F:\\dataset_sri\\5680.m4a\n",
      "F:\\dataset_sri\\5681.m4a\n",
      "F:\\dataset_sri\\5682.m4a\n",
      "F:\\dataset_sri\\5683.m4a\n",
      "F:\\dataset_sri\\5684.m4a\n",
      "F:\\dataset_sri\\5685.m4a\n",
      "F:\\dataset_sri\\5686.m4a\n",
      "F:\\dataset_sri\\5687.m4a\n",
      "F:\\dataset_sri\\5688.m4a\n",
      "F:\\dataset_sri\\5689.m4a\n",
      "F:\\dataset_sri\\569.m4a\n",
      "F:\\dataset_sri\\5690.m4a\n",
      "F:\\dataset_sri\\5691.m4a\n",
      "F:\\dataset_sri\\5692.m4a\n",
      "F:\\dataset_sri\\5693.m4a\n",
      "F:\\dataset_sri\\5694.m4a\n",
      "F:\\dataset_sri\\5695.m4a\n",
      "F:\\dataset_sri\\5696.m4a\n",
      "F:\\dataset_sri\\5697.m4a\n",
      "F:\\dataset_sri\\5698.m4a\n",
      "F:\\dataset_sri\\5699.m4a\n",
      "F:\\dataset_sri\\57.m4a\n",
      "F:\\dataset_sri\\570.m4a\n",
      "F:\\dataset_sri\\5700.m4a\n",
      "F:\\dataset_sri\\5701.m4a\n",
      "F:\\dataset_sri\\5702.m4a\n",
      "F:\\dataset_sri\\5703.m4a\n",
      "F:\\dataset_sri\\5704.m4a\n",
      "F:\\dataset_sri\\5705.m4a\n",
      "F:\\dataset_sri\\5706.m4a\n",
      "F:\\dataset_sri\\5707.m4a\n",
      "F:\\dataset_sri\\5708.m4a\n",
      "F:\\dataset_sri\\5709.m4a\n",
      "F:\\dataset_sri\\571.m4a\n",
      "F:\\dataset_sri\\5710.m4a\n",
      "F:\\dataset_sri\\5711.m4a\n",
      "F:\\dataset_sri\\5712.m4a\n",
      "F:\\dataset_sri\\5713.m4a\n",
      "F:\\dataset_sri\\5714.m4a\n",
      "F:\\dataset_sri\\5715.m4a\n",
      "F:\\dataset_sri\\5716.m4a\n",
      "F:\\dataset_sri\\5717.m4a\n",
      "F:\\dataset_sri\\5718.m4a\n",
      "F:\\dataset_sri\\5719.m4a\n",
      "F:\\dataset_sri\\572.m4a\n",
      "F:\\dataset_sri\\5720.m4a\n",
      "F:\\dataset_sri\\5721.m4a\n",
      "F:\\dataset_sri\\5722.m4a\n",
      "F:\\dataset_sri\\5723.m4a\n",
      "F:\\dataset_sri\\5724.m4a\n",
      "F:\\dataset_sri\\5725.m4a\n",
      "F:\\dataset_sri\\5726.m4a\n",
      "F:\\dataset_sri\\5727.m4a\n",
      "F:\\dataset_sri\\5728.m4a\n",
      "F:\\dataset_sri\\5729.m4a\n",
      "F:\\dataset_sri\\573.m4a\n",
      "F:\\dataset_sri\\5730.m4a\n",
      "F:\\dataset_sri\\5731.m4a\n",
      "F:\\dataset_sri\\5732.m4a\n",
      "F:\\dataset_sri\\5733.m4a\n",
      "F:\\dataset_sri\\5734.m4a\n",
      "F:\\dataset_sri\\5735.m4a\n",
      "F:\\dataset_sri\\5736.m4a\n",
      "F:\\dataset_sri\\5737.m4a\n",
      "F:\\dataset_sri\\5738.m4a\n",
      "F:\\dataset_sri\\5739.m4a\n",
      "F:\\dataset_sri\\574.m4a\n",
      "F:\\dataset_sri\\5740.m4a\n",
      "F:\\dataset_sri\\5741.m4a\n",
      "F:\\dataset_sri\\5742.m4a\n",
      "F:\\dataset_sri\\5743.m4a\n",
      "F:\\dataset_sri\\5744.m4a\n",
      "F:\\dataset_sri\\5745.m4a\n",
      "F:\\dataset_sri\\5746.m4a\n",
      "F:\\dataset_sri\\5747.m4a\n",
      "F:\\dataset_sri\\5748.m4a\n",
      "F:\\dataset_sri\\5749.m4a\n",
      "F:\\dataset_sri\\575.m4a\n",
      "F:\\dataset_sri\\5750.m4a\n",
      "F:\\dataset_sri\\5751.m4a\n",
      "F:\\dataset_sri\\5752.m4a\n",
      "F:\\dataset_sri\\5753.m4a\n",
      "F:\\dataset_sri\\5754.m4a\n",
      "F:\\dataset_sri\\5755.m4a\n",
      "F:\\dataset_sri\\5756.m4a\n",
      "F:\\dataset_sri\\5757.m4a\n",
      "F:\\dataset_sri\\5758.m4a\n",
      "F:\\dataset_sri\\5759.m4a\n",
      "F:\\dataset_sri\\576.m4a\n",
      "F:\\dataset_sri\\5760.m4a\n",
      "F:\\dataset_sri\\5761.m4a\n",
      "F:\\dataset_sri\\5762.m4a\n",
      "F:\\dataset_sri\\5763.m4a\n",
      "F:\\dataset_sri\\5764.m4a\n",
      "F:\\dataset_sri\\5765.m4a\n",
      "F:\\dataset_sri\\5766.m4a\n",
      "F:\\dataset_sri\\5767.m4a\n",
      "F:\\dataset_sri\\5768.m4a\n",
      "F:\\dataset_sri\\5769.m4a\n",
      "F:\\dataset_sri\\577.m4a\n",
      "F:\\dataset_sri\\5770.m4a\n",
      "F:\\dataset_sri\\5771.m4a\n",
      "F:\\dataset_sri\\5772.m4a\n",
      "F:\\dataset_sri\\5773.m4a\n",
      "F:\\dataset_sri\\5774.m4a\n",
      "F:\\dataset_sri\\5775.m4a\n",
      "F:\\dataset_sri\\5776.m4a\n",
      "F:\\dataset_sri\\5777.m4a\n",
      "F:\\dataset_sri\\5778.m4a\n",
      "F:\\dataset_sri\\5779.m4a\n",
      "F:\\dataset_sri\\578.m4a\n",
      "F:\\dataset_sri\\5780.m4a\n",
      "F:\\dataset_sri\\5781.m4a\n",
      "F:\\dataset_sri\\5782.m4a\n",
      "F:\\dataset_sri\\5783.m4a\n",
      "F:\\dataset_sri\\5784.m4a\n",
      "F:\\dataset_sri\\5785.m4a\n",
      "F:\\dataset_sri\\5786.m4a\n",
      "F:\\dataset_sri\\5787.m4a\n",
      "F:\\dataset_sri\\5788.m4a\n",
      "F:\\dataset_sri\\5789.m4a\n",
      "F:\\dataset_sri\\579.m4a\n",
      "F:\\dataset_sri\\5790.m4a\n",
      "F:\\dataset_sri\\5791.m4a\n",
      "F:\\dataset_sri\\5792.m4a\n",
      "F:\\dataset_sri\\5793.m4a\n",
      "F:\\dataset_sri\\5794.m4a\n",
      "F:\\dataset_sri\\5795.m4a\n",
      "F:\\dataset_sri\\5796.m4a\n",
      "F:\\dataset_sri\\5797.m4a\n",
      "F:\\dataset_sri\\5798.m4a\n",
      "F:\\dataset_sri\\5799.m4a\n",
      "F:\\dataset_sri\\58.m4a\n",
      "F:\\dataset_sri\\580.m4a\n",
      "F:\\dataset_sri\\5800.m4a\n",
      "F:\\dataset_sri\\5801.m4a\n",
      "F:\\dataset_sri\\5802.m4a\n",
      "F:\\dataset_sri\\5803.m4a\n",
      "F:\\dataset_sri\\5804.m4a\n",
      "F:\\dataset_sri\\5805.m4a\n",
      "F:\\dataset_sri\\5806.m4a\n",
      "F:\\dataset_sri\\5807.m4a\n",
      "F:\\dataset_sri\\5808.m4a\n",
      "F:\\dataset_sri\\5809.m4a\n",
      "F:\\dataset_sri\\581.m4a\n",
      "F:\\dataset_sri\\5810.m4a\n",
      "F:\\dataset_sri\\5811.m4a\n",
      "F:\\dataset_sri\\5812.m4a\n",
      "F:\\dataset_sri\\5813.m4a\n",
      "F:\\dataset_sri\\5814.m4a\n",
      "F:\\dataset_sri\\5815.m4a\n",
      "F:\\dataset_sri\\5816.m4a\n",
      "F:\\dataset_sri\\5817.m4a\n",
      "F:\\dataset_sri\\5818.m4a\n",
      "F:\\dataset_sri\\5819.m4a\n",
      "F:\\dataset_sri\\582.m4a\n",
      "F:\\dataset_sri\\5820.m4a\n",
      "F:\\dataset_sri\\5821.m4a\n",
      "F:\\dataset_sri\\5822.m4a\n",
      "F:\\dataset_sri\\5823.m4a\n",
      "F:\\dataset_sri\\5824.m4a\n",
      "F:\\dataset_sri\\5825.m4a\n",
      "F:\\dataset_sri\\5826.m4a\n",
      "F:\\dataset_sri\\5827.m4a\n",
      "F:\\dataset_sri\\5828.m4a\n",
      "F:\\dataset_sri\\5829.m4a\n",
      "F:\\dataset_sri\\583.m4a\n",
      "F:\\dataset_sri\\5830.m4a\n",
      "F:\\dataset_sri\\5831.m4a\n",
      "F:\\dataset_sri\\5832.m4a\n",
      "F:\\dataset_sri\\5833.m4a\n",
      "F:\\dataset_sri\\5834.m4a\n",
      "F:\\dataset_sri\\5835.m4a\n",
      "F:\\dataset_sri\\5836.m4a\n",
      "F:\\dataset_sri\\5837.m4a\n",
      "F:\\dataset_sri\\5838.m4a\n",
      "F:\\dataset_sri\\5839.m4a\n",
      "F:\\dataset_sri\\584.m4a\n",
      "F:\\dataset_sri\\5840.m4a\n",
      "F:\\dataset_sri\\5841.m4a\n",
      "F:\\dataset_sri\\5842.m4a\n",
      "F:\\dataset_sri\\5843.m4a\n",
      "F:\\dataset_sri\\5844.m4a\n",
      "F:\\dataset_sri\\5845.m4a\n",
      "F:\\dataset_sri\\5846.m4a\n",
      "F:\\dataset_sri\\5847.m4a\n",
      "F:\\dataset_sri\\5848.m4a\n",
      "F:\\dataset_sri\\5849.m4a\n",
      "F:\\dataset_sri\\585.m4a\n",
      "F:\\dataset_sri\\5850.m4a\n",
      "F:\\dataset_sri\\5851.m4a\n",
      "F:\\dataset_sri\\5852.m4a\n",
      "F:\\dataset_sri\\5853.m4a\n",
      "F:\\dataset_sri\\5854.m4a\n",
      "F:\\dataset_sri\\5855.m4a\n",
      "F:\\dataset_sri\\5856.m4a\n",
      "F:\\dataset_sri\\5857.m4a\n",
      "F:\\dataset_sri\\5858.m4a\n",
      "F:\\dataset_sri\\5859.m4a\n",
      "F:\\dataset_sri\\586.m4a\n",
      "F:\\dataset_sri\\5860.m4a\n",
      "F:\\dataset_sri\\5861.m4a\n",
      "F:\\dataset_sri\\5862.m4a\n",
      "F:\\dataset_sri\\5863.m4a\n",
      "F:\\dataset_sri\\5864.m4a\n",
      "F:\\dataset_sri\\5865.m4a\n",
      "F:\\dataset_sri\\5866.m4a\n",
      "F:\\dataset_sri\\5867.m4a\n",
      "F:\\dataset_sri\\5868.m4a\n",
      "F:\\dataset_sri\\5869.m4a\n",
      "F:\\dataset_sri\\587.m4a\n",
      "F:\\dataset_sri\\5870.m4a\n",
      "F:\\dataset_sri\\5871.m4a\n",
      "F:\\dataset_sri\\5872.m4a\n",
      "F:\\dataset_sri\\5873.m4a\n",
      "F:\\dataset_sri\\5874.m4a\n",
      "F:\\dataset_sri\\5875.m4a\n",
      "F:\\dataset_sri\\5876.m4a\n",
      "F:\\dataset_sri\\5877.m4a\n",
      "F:\\dataset_sri\\5878.m4a\n",
      "F:\\dataset_sri\\5879.m4a\n",
      "F:\\dataset_sri\\588.m4a\n",
      "F:\\dataset_sri\\5880.m4a\n",
      "F:\\dataset_sri\\5881.m4a\n",
      "F:\\dataset_sri\\5882.m4a\n",
      "F:\\dataset_sri\\5883.m4a\n",
      "F:\\dataset_sri\\5884.m4a\n",
      "F:\\dataset_sri\\5885.m4a\n",
      "F:\\dataset_sri\\5886.m4a\n",
      "F:\\dataset_sri\\5887.m4a\n",
      "F:\\dataset_sri\\5888.m4a\n",
      "F:\\dataset_sri\\5889.m4a\n",
      "F:\\dataset_sri\\589.m4a\n",
      "F:\\dataset_sri\\5890.m4a\n",
      "F:\\dataset_sri\\5891.m4a\n",
      "F:\\dataset_sri\\5892.m4a\n",
      "F:\\dataset_sri\\5893.m4a\n",
      "F:\\dataset_sri\\5894.m4a\n",
      "F:\\dataset_sri\\5895.m4a\n",
      "F:\\dataset_sri\\5896.m4a\n",
      "F:\\dataset_sri\\5897.m4a\n",
      "F:\\dataset_sri\\5898.m4a\n",
      "F:\\dataset_sri\\5899.m4a\n",
      "F:\\dataset_sri\\59.m4a\n",
      "F:\\dataset_sri\\590.m4a\n",
      "F:\\dataset_sri\\5900.m4a\n",
      "F:\\dataset_sri\\5901.m4a\n",
      "F:\\dataset_sri\\5902.m4a\n",
      "F:\\dataset_sri\\5903.m4a\n",
      "F:\\dataset_sri\\5904.m4a\n",
      "F:\\dataset_sri\\5905.m4a\n",
      "F:\\dataset_sri\\5906.m4a\n",
      "F:\\dataset_sri\\5907.m4a\n",
      "F:\\dataset_sri\\5908.m4a\n",
      "F:\\dataset_sri\\5909.m4a\n",
      "F:\\dataset_sri\\591.m4a\n",
      "F:\\dataset_sri\\5910.m4a\n",
      "F:\\dataset_sri\\5911.m4a\n",
      "F:\\dataset_sri\\5912.m4a\n",
      "F:\\dataset_sri\\5913.m4a\n",
      "F:\\dataset_sri\\5914.m4a\n",
      "F:\\dataset_sri\\5915.m4a\n",
      "F:\\dataset_sri\\5916.m4a\n",
      "F:\\dataset_sri\\5917.m4a\n",
      "F:\\dataset_sri\\5918.m4a\n",
      "F:\\dataset_sri\\5919.m4a\n",
      "F:\\dataset_sri\\592.m4a\n",
      "F:\\dataset_sri\\5920.m4a\n",
      "F:\\dataset_sri\\5921.m4a\n",
      "F:\\dataset_sri\\5922.m4a\n",
      "F:\\dataset_sri\\5923.m4a\n",
      "F:\\dataset_sri\\5924.m4a\n",
      "F:\\dataset_sri\\5925.m4a\n",
      "F:\\dataset_sri\\5926.m4a\n",
      "F:\\dataset_sri\\5927.m4a\n",
      "F:\\dataset_sri\\5928.m4a\n",
      "F:\\dataset_sri\\5929.m4a\n",
      "F:\\dataset_sri\\593.m4a\n",
      "F:\\dataset_sri\\5930.m4a\n",
      "F:\\dataset_sri\\5931.m4a\n",
      "F:\\dataset_sri\\5932.m4a\n",
      "F:\\dataset_sri\\5933.m4a\n",
      "F:\\dataset_sri\\5934.m4a\n",
      "F:\\dataset_sri\\5935.m4a\n",
      "F:\\dataset_sri\\5936.m4a\n",
      "F:\\dataset_sri\\5937.m4a\n",
      "F:\\dataset_sri\\5938.m4a\n",
      "F:\\dataset_sri\\5939.m4a\n",
      "F:\\dataset_sri\\594.m4a\n",
      "F:\\dataset_sri\\5940.m4a\n",
      "F:\\dataset_sri\\5941.m4a\n",
      "F:\\dataset_sri\\5942.m4a\n",
      "F:\\dataset_sri\\5943.m4a\n",
      "F:\\dataset_sri\\5944.m4a\n",
      "F:\\dataset_sri\\5945.m4a\n",
      "F:\\dataset_sri\\5946.m4a\n",
      "F:\\dataset_sri\\5947.m4a\n",
      "F:\\dataset_sri\\5948.m4a\n",
      "F:\\dataset_sri\\5949.m4a\n",
      "F:\\dataset_sri\\595.m4a\n",
      "F:\\dataset_sri\\5950.m4a\n",
      "F:\\dataset_sri\\5951.m4a\n",
      "F:\\dataset_sri\\5952.m4a\n",
      "F:\\dataset_sri\\5953.m4a\n",
      "F:\\dataset_sri\\5954.m4a\n",
      "F:\\dataset_sri\\5955.m4a\n",
      "F:\\dataset_sri\\5956.m4a\n",
      "F:\\dataset_sri\\5957.m4a\n",
      "F:\\dataset_sri\\5958.m4a\n",
      "F:\\dataset_sri\\5959.m4a\n",
      "F:\\dataset_sri\\596.m4a\n",
      "F:\\dataset_sri\\5960.m4a\n",
      "F:\\dataset_sri\\5961.m4a\n",
      "F:\\dataset_sri\\5962.m4a\n",
      "F:\\dataset_sri\\5963.m4a\n",
      "F:\\dataset_sri\\5964.m4a\n",
      "F:\\dataset_sri\\5965.m4a\n",
      "F:\\dataset_sri\\5966.m4a\n",
      "F:\\dataset_sri\\5967.m4a\n",
      "F:\\dataset_sri\\5968.m4a\n",
      "F:\\dataset_sri\\5969.m4a\n",
      "F:\\dataset_sri\\597.m4a\n",
      "F:\\dataset_sri\\5970.m4a\n",
      "F:\\dataset_sri\\5971.m4a\n",
      "F:\\dataset_sri\\5972.m4a\n",
      "F:\\dataset_sri\\5973.m4a\n",
      "F:\\dataset_sri\\5974.m4a\n",
      "F:\\dataset_sri\\5975.m4a\n",
      "F:\\dataset_sri\\5976.m4a\n",
      "F:\\dataset_sri\\5977.m4a\n",
      "F:\\dataset_sri\\5978.m4a\n",
      "F:\\dataset_sri\\5979.m4a\n",
      "F:\\dataset_sri\\598.m4a\n",
      "F:\\dataset_sri\\5980.m4a\n",
      "F:\\dataset_sri\\5981.m4a\n",
      "F:\\dataset_sri\\5982.m4a\n",
      "F:\\dataset_sri\\5983.m4a\n",
      "F:\\dataset_sri\\5984.m4a\n",
      "F:\\dataset_sri\\5985.m4a\n",
      "F:\\dataset_sri\\5986.m4a\n",
      "F:\\dataset_sri\\5987.m4a\n",
      "F:\\dataset_sri\\5988.m4a\n",
      "F:\\dataset_sri\\5989.m4a\n",
      "F:\\dataset_sri\\599.m4a\n",
      "F:\\dataset_sri\\5990.m4a\n",
      "F:\\dataset_sri\\5991.m4a\n",
      "F:\\dataset_sri\\5992.m4a\n",
      "F:\\dataset_sri\\6.m4a\n",
      "F:\\dataset_sri\\60.m4a\n",
      "F:\\dataset_sri\\600.m4a\n",
      "F:\\dataset_sri\\601.m4a\n",
      "F:\\dataset_sri\\602.m4a\n",
      "F:\\dataset_sri\\603.m4a\n",
      "F:\\dataset_sri\\604.m4a\n",
      "F:\\dataset_sri\\605.m4a\n",
      "F:\\dataset_sri\\606.m4a\n",
      "F:\\dataset_sri\\607.m4a\n",
      "F:\\dataset_sri\\608.m4a\n",
      "F:\\dataset_sri\\609.m4a\n",
      "F:\\dataset_sri\\61.m4a\n",
      "F:\\dataset_sri\\610.m4a\n",
      "F:\\dataset_sri\\611.m4a\n",
      "F:\\dataset_sri\\612.m4a\n",
      "F:\\dataset_sri\\613.m4a\n",
      "F:\\dataset_sri\\614.m4a\n",
      "F:\\dataset_sri\\615.m4a\n",
      "F:\\dataset_sri\\616.m4a\n",
      "F:\\dataset_sri\\617.m4a\n",
      "F:\\dataset_sri\\618.m4a\n",
      "F:\\dataset_sri\\619.m4a\n",
      "F:\\dataset_sri\\62.m4a\n",
      "F:\\dataset_sri\\620.m4a\n",
      "F:\\dataset_sri\\621.m4a\n",
      "F:\\dataset_sri\\622.m4a\n",
      "F:\\dataset_sri\\623.m4a\n",
      "F:\\dataset_sri\\624.m4a\n",
      "F:\\dataset_sri\\625.m4a\n",
      "F:\\dataset_sri\\626.m4a\n",
      "F:\\dataset_sri\\627.m4a\n",
      "F:\\dataset_sri\\628.m4a\n",
      "F:\\dataset_sri\\629.m4a\n",
      "F:\\dataset_sri\\63.m4a\n",
      "F:\\dataset_sri\\630.m4a\n",
      "F:\\dataset_sri\\631.m4a\n",
      "F:\\dataset_sri\\632.m4a\n",
      "F:\\dataset_sri\\633.m4a\n",
      "F:\\dataset_sri\\634.m4a\n",
      "F:\\dataset_sri\\635.m4a\n",
      "F:\\dataset_sri\\636.m4a\n",
      "F:\\dataset_sri\\637.m4a\n",
      "F:\\dataset_sri\\638.m4a\n",
      "F:\\dataset_sri\\639.m4a\n",
      "F:\\dataset_sri\\64.m4a\n",
      "F:\\dataset_sri\\640.m4a\n",
      "F:\\dataset_sri\\641.m4a\n",
      "F:\\dataset_sri\\642.m4a\n",
      "F:\\dataset_sri\\643.m4a\n",
      "F:\\dataset_sri\\644.m4a\n",
      "F:\\dataset_sri\\645.m4a\n",
      "F:\\dataset_sri\\646.m4a\n",
      "F:\\dataset_sri\\647.m4a\n",
      "F:\\dataset_sri\\648.m4a\n",
      "F:\\dataset_sri\\649.m4a\n",
      "F:\\dataset_sri\\65.m4a\n",
      "F:\\dataset_sri\\650.m4a\n",
      "F:\\dataset_sri\\651.m4a\n",
      "F:\\dataset_sri\\652.m4a\n",
      "F:\\dataset_sri\\653.m4a\n",
      "F:\\dataset_sri\\654.m4a\n",
      "F:\\dataset_sri\\655.m4a\n",
      "F:\\dataset_sri\\656.m4a\n",
      "F:\\dataset_sri\\657.m4a\n",
      "F:\\dataset_sri\\658.m4a\n",
      "F:\\dataset_sri\\659.m4a\n",
      "F:\\dataset_sri\\66.m4a\n",
      "F:\\dataset_sri\\660.m4a\n",
      "F:\\dataset_sri\\661.m4a\n",
      "F:\\dataset_sri\\662.m4a\n",
      "F:\\dataset_sri\\663.m4a\n",
      "F:\\dataset_sri\\664.m4a\n",
      "F:\\dataset_sri\\665.m4a\n",
      "F:\\dataset_sri\\666.m4a\n",
      "F:\\dataset_sri\\667.m4a\n",
      "F:\\dataset_sri\\668.m4a\n",
      "F:\\dataset_sri\\669.m4a\n",
      "F:\\dataset_sri\\67.m4a\n",
      "F:\\dataset_sri\\670.m4a\n",
      "F:\\dataset_sri\\671.m4a\n",
      "F:\\dataset_sri\\672.m4a\n",
      "F:\\dataset_sri\\673.m4a\n",
      "F:\\dataset_sri\\674.m4a\n",
      "F:\\dataset_sri\\675.m4a\n",
      "F:\\dataset_sri\\676.m4a\n",
      "F:\\dataset_sri\\677.m4a\n",
      "F:\\dataset_sri\\678.m4a\n",
      "F:\\dataset_sri\\679.m4a\n",
      "F:\\dataset_sri\\68.m4a\n",
      "F:\\dataset_sri\\680.m4a\n",
      "F:\\dataset_sri\\681.m4a\n",
      "F:\\dataset_sri\\682.m4a\n",
      "F:\\dataset_sri\\683.m4a\n",
      "F:\\dataset_sri\\684.m4a\n",
      "F:\\dataset_sri\\685.m4a\n",
      "F:\\dataset_sri\\686.m4a\n",
      "F:\\dataset_sri\\687.m4a\n",
      "F:\\dataset_sri\\688.m4a\n",
      "F:\\dataset_sri\\689.m4a\n",
      "F:\\dataset_sri\\69.m4a\n",
      "F:\\dataset_sri\\690.m4a\n",
      "F:\\dataset_sri\\691.m4a\n",
      "F:\\dataset_sri\\692.m4a\n",
      "F:\\dataset_sri\\693.m4a\n",
      "F:\\dataset_sri\\694.m4a\n",
      "F:\\dataset_sri\\695.m4a\n",
      "F:\\dataset_sri\\696.m4a\n",
      "F:\\dataset_sri\\697.m4a\n",
      "F:\\dataset_sri\\698.m4a\n",
      "F:\\dataset_sri\\699.m4a\n",
      "F:\\dataset_sri\\7.m4a\n",
      "F:\\dataset_sri\\70.m4a\n",
      "F:\\dataset_sri\\700.m4a\n",
      "F:\\dataset_sri\\701.m4a\n",
      "F:\\dataset_sri\\702.m4a\n",
      "F:\\dataset_sri\\703.m4a\n",
      "F:\\dataset_sri\\704.m4a\n",
      "F:\\dataset_sri\\705.m4a\n",
      "F:\\dataset_sri\\706.m4a\n",
      "F:\\dataset_sri\\707.m4a\n",
      "F:\\dataset_sri\\708.m4a\n",
      "F:\\dataset_sri\\709.m4a\n",
      "F:\\dataset_sri\\71.m4a\n",
      "F:\\dataset_sri\\710.m4a\n",
      "F:\\dataset_sri\\711.m4a\n",
      "F:\\dataset_sri\\712.m4a\n",
      "F:\\dataset_sri\\713.m4a\n",
      "F:\\dataset_sri\\714.m4a\n",
      "F:\\dataset_sri\\715.m4a\n",
      "F:\\dataset_sri\\716.m4a\n",
      "F:\\dataset_sri\\717.m4a\n",
      "F:\\dataset_sri\\718.m4a\n",
      "F:\\dataset_sri\\719.m4a\n",
      "F:\\dataset_sri\\72.m4a\n",
      "F:\\dataset_sri\\720.m4a\n",
      "F:\\dataset_sri\\721.m4a\n",
      "F:\\dataset_sri\\722.m4a\n",
      "F:\\dataset_sri\\723.m4a\n",
      "F:\\dataset_sri\\724.m4a\n",
      "F:\\dataset_sri\\725.m4a\n",
      "F:\\dataset_sri\\726.m4a\n",
      "F:\\dataset_sri\\727.m4a\n",
      "F:\\dataset_sri\\728.m4a\n",
      "F:\\dataset_sri\\729.m4a\n",
      "F:\\dataset_sri\\73.m4a\n",
      "F:\\dataset_sri\\730.m4a\n",
      "F:\\dataset_sri\\731.m4a\n",
      "F:\\dataset_sri\\732.m4a\n",
      "F:\\dataset_sri\\733.m4a\n",
      "F:\\dataset_sri\\734.m4a\n",
      "F:\\dataset_sri\\735.m4a\n",
      "F:\\dataset_sri\\736.m4a\n",
      "F:\\dataset_sri\\737.m4a\n",
      "F:\\dataset_sri\\738.m4a\n",
      "F:\\dataset_sri\\739.m4a\n",
      "F:\\dataset_sri\\74.m4a\n",
      "F:\\dataset_sri\\740.m4a\n",
      "F:\\dataset_sri\\741.m4a\n",
      "F:\\dataset_sri\\742.m4a\n",
      "F:\\dataset_sri\\743.m4a\n",
      "F:\\dataset_sri\\744.m4a\n",
      "F:\\dataset_sri\\745.m4a\n",
      "F:\\dataset_sri\\746.m4a\n",
      "F:\\dataset_sri\\747.m4a\n",
      "F:\\dataset_sri\\748.m4a\n",
      "F:\\dataset_sri\\749.m4a\n",
      "F:\\dataset_sri\\75.m4a\n",
      "F:\\dataset_sri\\750.m4a\n",
      "F:\\dataset_sri\\751.m4a\n",
      "F:\\dataset_sri\\752.m4a\n",
      "F:\\dataset_sri\\753.m4a\n",
      "F:\\dataset_sri\\754.m4a\n",
      "F:\\dataset_sri\\755.m4a\n",
      "F:\\dataset_sri\\756.m4a\n",
      "F:\\dataset_sri\\757.m4a\n",
      "F:\\dataset_sri\\758.m4a\n",
      "F:\\dataset_sri\\759.m4a\n",
      "F:\\dataset_sri\\76.m4a\n",
      "F:\\dataset_sri\\760.m4a\n",
      "F:\\dataset_sri\\761.m4a\n",
      "F:\\dataset_sri\\762.m4a\n",
      "F:\\dataset_sri\\763.m4a\n",
      "F:\\dataset_sri\\764.m4a\n",
      "F:\\dataset_sri\\765.m4a\n",
      "F:\\dataset_sri\\766.m4a\n",
      "F:\\dataset_sri\\767.m4a\n",
      "F:\\dataset_sri\\768.m4a\n",
      "F:\\dataset_sri\\769.m4a\n",
      "F:\\dataset_sri\\77.m4a\n",
      "F:\\dataset_sri\\770.m4a\n",
      "F:\\dataset_sri\\771.m4a\n",
      "F:\\dataset_sri\\772.m4a\n",
      "F:\\dataset_sri\\773.m4a\n",
      "F:\\dataset_sri\\774.m4a\n",
      "F:\\dataset_sri\\775.m4a\n",
      "F:\\dataset_sri\\776.m4a\n",
      "F:\\dataset_sri\\777.m4a\n",
      "F:\\dataset_sri\\778.m4a\n",
      "F:\\dataset_sri\\779.m4a\n",
      "F:\\dataset_sri\\78.m4a\n",
      "F:\\dataset_sri\\780.m4a\n",
      "F:\\dataset_sri\\781.m4a\n",
      "F:\\dataset_sri\\782.m4a\n",
      "F:\\dataset_sri\\783.m4a\n",
      "F:\\dataset_sri\\784.m4a\n",
      "F:\\dataset_sri\\785.m4a\n",
      "F:\\dataset_sri\\786.m4a\n",
      "F:\\dataset_sri\\787.m4a\n",
      "F:\\dataset_sri\\788.m4a\n",
      "F:\\dataset_sri\\789.m4a\n",
      "F:\\dataset_sri\\79.m4a\n",
      "F:\\dataset_sri\\790.m4a\n",
      "F:\\dataset_sri\\791.m4a\n",
      "F:\\dataset_sri\\792.m4a\n",
      "F:\\dataset_sri\\793.m4a\n",
      "F:\\dataset_sri\\794.m4a\n",
      "F:\\dataset_sri\\795.m4a\n",
      "F:\\dataset_sri\\796.m4a\n",
      "F:\\dataset_sri\\797.m4a\n",
      "F:\\dataset_sri\\798.m4a\n",
      "F:\\dataset_sri\\799.m4a\n",
      "F:\\dataset_sri\\8.m4a\n",
      "F:\\dataset_sri\\80.m4a\n",
      "F:\\dataset_sri\\800.m4a\n",
      "F:\\dataset_sri\\801.m4a\n",
      "F:\\dataset_sri\\802.m4a\n",
      "F:\\dataset_sri\\803.m4a\n",
      "F:\\dataset_sri\\804.m4a\n",
      "F:\\dataset_sri\\805.m4a\n",
      "F:\\dataset_sri\\806.m4a\n",
      "F:\\dataset_sri\\807.m4a\n",
      "F:\\dataset_sri\\808.m4a\n",
      "F:\\dataset_sri\\809.m4a\n",
      "F:\\dataset_sri\\81.m4a\n",
      "F:\\dataset_sri\\810.m4a\n",
      "F:\\dataset_sri\\811.m4a\n",
      "F:\\dataset_sri\\812.m4a\n",
      "F:\\dataset_sri\\813.m4a\n",
      "F:\\dataset_sri\\814.m4a\n",
      "F:\\dataset_sri\\815.m4a\n",
      "F:\\dataset_sri\\816.m4a\n",
      "F:\\dataset_sri\\817.m4a\n",
      "F:\\dataset_sri\\818.m4a\n",
      "F:\\dataset_sri\\819.m4a\n",
      "F:\\dataset_sri\\82.m4a\n",
      "F:\\dataset_sri\\820.m4a\n",
      "F:\\dataset_sri\\821.m4a\n",
      "F:\\dataset_sri\\822.m4a\n",
      "F:\\dataset_sri\\823.m4a\n",
      "F:\\dataset_sri\\824.m4a\n",
      "F:\\dataset_sri\\825.m4a\n",
      "F:\\dataset_sri\\826.m4a\n",
      "F:\\dataset_sri\\827.m4a\n",
      "F:\\dataset_sri\\828.m4a\n",
      "F:\\dataset_sri\\829.m4a\n",
      "F:\\dataset_sri\\83.m4a\n",
      "F:\\dataset_sri\\830.m4a\n",
      "F:\\dataset_sri\\831.m4a\n",
      "F:\\dataset_sri\\832.m4a\n",
      "F:\\dataset_sri\\833.m4a\n",
      "F:\\dataset_sri\\834.m4a\n",
      "F:\\dataset_sri\\835.m4a\n",
      "F:\\dataset_sri\\836.m4a\n",
      "F:\\dataset_sri\\837.m4a\n",
      "F:\\dataset_sri\\838.m4a\n",
      "F:\\dataset_sri\\839.m4a\n",
      "F:\\dataset_sri\\84.m4a\n",
      "F:\\dataset_sri\\840.m4a\n",
      "F:\\dataset_sri\\841.m4a\n",
      "F:\\dataset_sri\\842.m4a\n",
      "F:\\dataset_sri\\843.m4a\n",
      "F:\\dataset_sri\\844.m4a\n",
      "F:\\dataset_sri\\845.m4a\n",
      "F:\\dataset_sri\\846.m4a\n",
      "F:\\dataset_sri\\847.m4a\n",
      "F:\\dataset_sri\\848.m4a\n",
      "F:\\dataset_sri\\849.m4a\n",
      "F:\\dataset_sri\\85.m4a\n",
      "F:\\dataset_sri\\850.m4a\n",
      "F:\\dataset_sri\\851.m4a\n",
      "F:\\dataset_sri\\852.m4a\n",
      "F:\\dataset_sri\\853.m4a\n",
      "F:\\dataset_sri\\854.m4a\n",
      "F:\\dataset_sri\\855.m4a\n",
      "F:\\dataset_sri\\856.m4a\n",
      "F:\\dataset_sri\\857.m4a\n",
      "F:\\dataset_sri\\858.m4a\n",
      "F:\\dataset_sri\\859.m4a\n",
      "F:\\dataset_sri\\86.m4a\n",
      "F:\\dataset_sri\\860.m4a\n",
      "F:\\dataset_sri\\861.m4a\n",
      "F:\\dataset_sri\\862.m4a\n",
      "F:\\dataset_sri\\863.m4a\n",
      "F:\\dataset_sri\\864.m4a\n",
      "F:\\dataset_sri\\865.m4a\n",
      "F:\\dataset_sri\\866.m4a\n",
      "F:\\dataset_sri\\867.m4a\n",
      "F:\\dataset_sri\\868.m4a\n",
      "F:\\dataset_sri\\869.m4a\n",
      "F:\\dataset_sri\\87.m4a\n",
      "F:\\dataset_sri\\870.m4a\n",
      "F:\\dataset_sri\\871.m4a\n",
      "F:\\dataset_sri\\872.m4a\n",
      "F:\\dataset_sri\\873.m4a\n",
      "F:\\dataset_sri\\874.m4a\n",
      "F:\\dataset_sri\\875.m4a\n",
      "F:\\dataset_sri\\876.m4a\n",
      "F:\\dataset_sri\\877.m4a\n",
      "F:\\dataset_sri\\878.m4a\n",
      "F:\\dataset_sri\\879.m4a\n",
      "F:\\dataset_sri\\88.m4a\n",
      "F:\\dataset_sri\\880.m4a\n",
      "F:\\dataset_sri\\881.m4a\n",
      "F:\\dataset_sri\\882.m4a\n",
      "F:\\dataset_sri\\883.m4a\n",
      "F:\\dataset_sri\\884.m4a\n",
      "F:\\dataset_sri\\885.m4a\n",
      "F:\\dataset_sri\\886.m4a\n",
      "F:\\dataset_sri\\887.m4a\n",
      "F:\\dataset_sri\\888.m4a\n",
      "F:\\dataset_sri\\889.m4a\n",
      "F:\\dataset_sri\\89.m4a\n",
      "F:\\dataset_sri\\890.m4a\n",
      "F:\\dataset_sri\\891.m4a\n",
      "F:\\dataset_sri\\892.m4a\n",
      "F:\\dataset_sri\\893.m4a\n",
      "F:\\dataset_sri\\894.m4a\n",
      "F:\\dataset_sri\\895.m4a\n",
      "F:\\dataset_sri\\896.m4a\n",
      "F:\\dataset_sri\\897.m4a\n",
      "F:\\dataset_sri\\898.m4a\n",
      "F:\\dataset_sri\\899.m4a\n",
      "F:\\dataset_sri\\9.m4a\n",
      "F:\\dataset_sri\\90.m4a\n",
      "F:\\dataset_sri\\900.m4a\n",
      "F:\\dataset_sri\\901.m4a\n",
      "F:\\dataset_sri\\902.m4a\n",
      "F:\\dataset_sri\\903.m4a\n",
      "F:\\dataset_sri\\904.m4a\n",
      "F:\\dataset_sri\\905.m4a\n",
      "F:\\dataset_sri\\906.m4a\n",
      "F:\\dataset_sri\\907.m4a\n",
      "F:\\dataset_sri\\908.m4a\n",
      "F:\\dataset_sri\\909.m4a\n",
      "F:\\dataset_sri\\91.m4a\n",
      "F:\\dataset_sri\\910.m4a\n",
      "F:\\dataset_sri\\911.m4a\n",
      "F:\\dataset_sri\\912.m4a\n",
      "F:\\dataset_sri\\913.m4a\n",
      "F:\\dataset_sri\\914.m4a\n",
      "F:\\dataset_sri\\915.m4a\n",
      "F:\\dataset_sri\\916.m4a\n",
      "F:\\dataset_sri\\917.m4a\n",
      "F:\\dataset_sri\\918.m4a\n",
      "F:\\dataset_sri\\919.m4a\n",
      "F:\\dataset_sri\\92.m4a\n",
      "F:\\dataset_sri\\920.m4a\n",
      "F:\\dataset_sri\\921.m4a\n",
      "F:\\dataset_sri\\922.m4a\n",
      "F:\\dataset_sri\\923.m4a\n",
      "F:\\dataset_sri\\924.m4a\n",
      "F:\\dataset_sri\\925.m4a\n",
      "F:\\dataset_sri\\926.m4a\n",
      "F:\\dataset_sri\\927.m4a\n",
      "F:\\dataset_sri\\928.m4a\n",
      "F:\\dataset_sri\\929.m4a\n",
      "F:\\dataset_sri\\93.m4a\n",
      "F:\\dataset_sri\\930.m4a\n",
      "F:\\dataset_sri\\931.m4a\n",
      "F:\\dataset_sri\\932.m4a\n",
      "F:\\dataset_sri\\933.m4a\n",
      "F:\\dataset_sri\\934.m4a\n",
      "F:\\dataset_sri\\935.m4a\n",
      "F:\\dataset_sri\\936.m4a\n",
      "F:\\dataset_sri\\937.m4a\n",
      "F:\\dataset_sri\\938.m4a\n",
      "F:\\dataset_sri\\939.m4a\n",
      "F:\\dataset_sri\\94.m4a\n",
      "F:\\dataset_sri\\940.m4a\n",
      "F:\\dataset_sri\\941.m4a\n",
      "F:\\dataset_sri\\942.m4a\n",
      "F:\\dataset_sri\\943.m4a\n",
      "F:\\dataset_sri\\944.m4a\n",
      "F:\\dataset_sri\\945.m4a\n",
      "F:\\dataset_sri\\946.m4a\n",
      "F:\\dataset_sri\\947.m4a\n",
      "F:\\dataset_sri\\948.m4a\n",
      "F:\\dataset_sri\\949.m4a\n",
      "F:\\dataset_sri\\95.m4a\n",
      "F:\\dataset_sri\\950.m4a\n",
      "F:\\dataset_sri\\951.m4a\n",
      "F:\\dataset_sri\\952.m4a\n",
      "F:\\dataset_sri\\953.m4a\n",
      "F:\\dataset_sri\\954.m4a\n",
      "F:\\dataset_sri\\955.m4a\n",
      "F:\\dataset_sri\\956.m4a\n",
      "F:\\dataset_sri\\957.m4a\n",
      "F:\\dataset_sri\\958.m4a\n",
      "F:\\dataset_sri\\959.m4a\n",
      "F:\\dataset_sri\\96.m4a\n",
      "F:\\dataset_sri\\960.m4a\n",
      "F:\\dataset_sri\\961.m4a\n",
      "F:\\dataset_sri\\962.m4a\n",
      "F:\\dataset_sri\\963.m4a\n",
      "F:\\dataset_sri\\964.m4a\n",
      "F:\\dataset_sri\\965.m4a\n",
      "F:\\dataset_sri\\966.m4a\n",
      "F:\\dataset_sri\\967.m4a\n",
      "F:\\dataset_sri\\968.m4a\n",
      "F:\\dataset_sri\\969.m4a\n",
      "F:\\dataset_sri\\97.m4a\n",
      "F:\\dataset_sri\\970.m4a\n",
      "F:\\dataset_sri\\971.m4a\n",
      "F:\\dataset_sri\\972.m4a\n",
      "F:\\dataset_sri\\973.m4a\n",
      "F:\\dataset_sri\\974.m4a\n",
      "F:\\dataset_sri\\975.m4a\n",
      "F:\\dataset_sri\\976.m4a\n",
      "F:\\dataset_sri\\977.m4a\n",
      "F:\\dataset_sri\\978.m4a\n",
      "F:\\dataset_sri\\979.m4a\n",
      "F:\\dataset_sri\\98.m4a\n",
      "F:\\dataset_sri\\980.m4a\n",
      "F:\\dataset_sri\\981.m4a\n",
      "F:\\dataset_sri\\982.m4a\n",
      "F:\\dataset_sri\\983.m4a\n",
      "F:\\dataset_sri\\984.m4a\n",
      "F:\\dataset_sri\\985.m4a\n",
      "F:\\dataset_sri\\986.m4a\n",
      "F:\\dataset_sri\\987.m4a\n",
      "F:\\dataset_sri\\988.m4a\n",
      "F:\\dataset_sri\\989.m4a\n",
      "F:\\dataset_sri\\99.m4a\n",
      "F:\\dataset_sri\\990.m4a\n",
      "F:\\dataset_sri\\991.m4a\n",
      "F:\\dataset_sri\\992.m4a\n",
      "F:\\dataset_sri\\993.m4a\n",
      "F:\\dataset_sri\\994.m4a\n",
      "F:\\dataset_sri\\995.m4a\n",
      "F:\\dataset_sri\\996.m4a\n",
      "F:\\dataset_sri\\997.m4a\n",
      "F:\\dataset_sri\\998.m4a\n",
      "F:\\dataset_sri\\999.m4a\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 124946 and the array at index 1 has size 51730",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_directory, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     60\u001b[0m \u001b[39m# Extract, reduce, and save features\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m pca_model \u001b[39m=\u001b[39m extract_and_save_features(wav_files, output_directory)\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36mextract_and_save_features\u001b[1;34m(file_paths, output_directory, pca_model)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(file)\n\u001b[0;32m     25\u001b[0m \u001b[39m# Stack all features into one 2D array\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m all_features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack(all_features)\n\u001b[0;32m     28\u001b[0m \u001b[39m# If a PCA model is not provided, create and fit one\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m pca_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 124946 and the array at index 1 has size 51730"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "directory = r'F:\\dataset_sri'\n",
    "\n",
    "def extract_and_save_features(file_paths, output_directory, pca_model=None):\n",
    "    all_features = []\n",
    "\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract features\n",
    "        melscale_features = extract_melscale_features(wav_file_path)\n",
    "        melspectrogram = extract_melspectrogram(wav_file_path)\n",
    "        audio_features = extract_audio_features(wav_file_path)\n",
    "\n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([melscale_features, melspectrogram, audio_features])\n",
    "\n",
    "        # Append features to list\n",
    "        all_features.append(combined_features)\n",
    "        print(file)\n",
    "\n",
    "    # Stack all features into one 2D array\n",
    "    all_features = np.vstack(all_features)\n",
    "\n",
    "    # If a PCA model is not provided, create and fit one\n",
    "    if pca_model is None:\n",
    "        pca_model = PCA(n_components=60)\n",
    "        pca_model.fit(all_features)\n",
    "\n",
    "    # Use the PCA model to reduce the dimensions of all data\n",
    "    reduced_features = pca_model.transform(all_features)\n",
    "\n",
    "    # Save each file's features as a .pt file\n",
    "    for i, file in enumerate(file_paths):\n",
    "        # Convert array to torch tensor\n",
    "        reduced_feature_tensor = torch.tensor(reduced_features[i])\n",
    "\n",
    "        # Construct output file name by replacing .m4a with .pt and changing the directory\n",
    "        output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "\n",
    "        # Save to a PyTorch file (.pt)\n",
    "        torch.save(reduced_feature_tensor, output_file)\n",
    "\n",
    "    # Return the PCA model in case we want to use the same model for other data\n",
    "    return pca_model\n",
    "\n",
    "\n",
    "# Load all .m4a files\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_directory = r'F:\\reduced_feature'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Extract, reduce, and save features\n",
    "pca_model = extract_and_save_features(wav_files, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import fnmatch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(file_path, output_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "def extract_melscale_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "    return mels_db.flatten() # Flatten the feature array\n",
    "\n",
    "def extract_melspectrogram(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    return spectrogram.flatten() # Flatten the spectrogram\n",
    "\n",
    "def extract_audio_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    # Change here: Find max pitch for each frame and then take their mean as overall pitch\n",
    "    pitch = np.mean([pitch[magnitude.argmax()] for pitch, magnitude in zip(pitches, magnitudes)])\n",
    "    fft = np.abs(np.fft.fft(y))[:len(y)//2]\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.hstack([mfccs.mean(axis=1), spectral_centroids.mean(), spectral_rolloff.mean(), zero_crossing_rate.mean(), pitch, fft.mean()])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "\n",
    "directory = r'F:\\dataset_sri'\n",
    "output_directory= r'F:\\dataset_c_feature'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "for file in wav_files:\n",
    "    # Convert m4a file to wav  \n",
    "    wav_file_path = file.replace('.m4a', '.wav')\n",
    "    convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "    # Extract features\n",
    "    melscale_features = extract_melscale_features(wav_file_path)\n",
    "    melspectrogram = extract_melspectrogram(wav_file_path)\n",
    "    audio_features = extract_audio_features(wav_file_path)\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.concatenate([melscale_features, melspectrogram, audio_features])\n",
    "\n",
    "    # Convert array to torch tensor\n",
    "    combined_features = torch.tensor(combined_features)\n",
    "\n",
    "    # Construct output file name by replacing .m4a with .pt and changing the directory\n",
    "    output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "    \n",
    "    # Save to a PyTorch file (.pt)\n",
    "    torch.save(combined_features, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'F:\\data' # Replace with the directory path containing the files  # Replace with the directory path containing the files\n",
    "\n",
    "start_index = 0  # Starting index for renaming\n",
    "end_index = 5993  # Ending index for renaming\n",
    "offset = 2312  # Offset to add to the second range\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pt\"):\n",
    "        original_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Extract the numeric index from the filename\n",
    "        original_index = int(filename[:-3])\n",
    "\n",
    "        # Check if the file index falls within the desired range\n",
    "        if 0 <= original_index <= 2311:\n",
    "            # Calculate the new index for the first range\n",
    "            new_index = original_index\n",
    "        elif 7040 <= original_index <= 10721:\n",
    "            # Calculate the new index for the second range\n",
    "            new_index = original_index - 7040 + offset\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Create the new filename\n",
    "        new_filename = str(new_index) + \".pt\"\n",
    "        new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        # Skip renaming if the target file already exists\n",
    "        if os.path.exists(new_path):\n",
    "            continue\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(original_path, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       711\n",
      "           1       0.90      0.88      0.89       488\n",
      "\n",
      "    accuracy                           0.91      1199\n",
      "   macro avg       0.91      0.91      0.91      1199\n",
      "weighted avg       0.91      0.91      0.91      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(file_path, output_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "def extract_melscale_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "    return mels_db.flatten() # Flatten the feature array\n",
    "\n",
    "def extract_melspectrogram(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    return spectrogram.flatten() # Flatten the spectrogram\n",
    "\n",
    "def extract_audio_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y, sr=sr)\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.hstack([mfccs.mean(axis=1), spectral_centroids.mean(), spectral_rolloff.mean(), zero_crossing_rate.mean()])\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "\n",
    "def extract_embeddings(file_name):\n",
    "    # Load audio file\n",
    "    audio, _ = librosa.load(file_name)\n",
    "    # Resample to 16kHz\n",
    "    audio = librosa.resample(audio, orig_sr=44100, target_sr=16000)\n",
    "    # Process with Wav2Vec2 processor\n",
    "    input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "    # Get embeddings from Wav2Vec2 model\n",
    "    embeddings = model(input_values).last_hidden_state\n",
    "    # Average over time dimension to get a single embedding vector\n",
    "    embeddings = torch.mean(embeddings, dim=1)\n",
    "    # Convert to numpy array\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    \n",
    "    return embeddings    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(file_name):\n",
    "    # Load audio file\n",
    "    audio, _ = librosa.load(file_name)\n",
    "    # Resample to 16kHz\n",
    "    audio = librosa.resample(audio, orig_sr=44100, target_sr=16000)\n",
    "    # Process with Wav2Vec2 processor\n",
    "    input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "    # Get embeddings from Wav2Vec2 model\n",
    "    embeddings = model(input_values).last_hidden_state\n",
    "    # Average over time dimension to get a single embedding vector\n",
    "    embeddings = torch.mean(embeddings, dim=1)\n",
    "    # Convert to numpy array\n",
    "    embeddings = embeddings.detach().numpy()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ee5f3a1d714ae483ab44fe5bb0ddf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6006afa602a4c19835ca9da7c1dced0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb18195143147c287d3a0d76c204f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()rocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b6425e06e94393a128111df1546c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()okenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6298456f4b1243f595ac4e11c9845de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2771e7c3e2674e978217c4ba472e33e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Mel scale features, Mel spectrogram, embeddings, and other audio features\n",
    "melscale_features = [extract_melscale_features(file) for file in wav_files]\n",
    "melspectrograms = [extract_melspectrogram(file) for file in wav_files]\n",
    "embeddings = [extract_embeddings(file) for file in wav_files]\n",
    "audio_features = [extract_audio_features(file) for file in wav_files]\n",
    "\n",
    "# Combine all features\n",
    "all_features = np.concatenate([melscale_features, embeddings, audio_features], axis=1)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       711\n",
      "           1       0.91      0.88      0.90       488\n",
      "\n",
      "    accuracy                           0.92      1199\n",
      "   macro avg       0.91      0.91      0.91      1199\n",
      "weighted avg       0.92      0.92      0.92      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='linear')  # linear kernel\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1069\n",
      "           1       0.90      0.88      0.89       729\n",
      "\n",
      "    accuracy                           0.91      1798\n",
      "   macro avg       0.91      0.91      0.91      1798\n",
      "weighted avg       0.91      0.91      0.91      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       900\n",
      "           1       0.90      0.89      0.89       599\n",
      "\n",
      "    accuracy                           0.92      1499\n",
      "   macro avg       0.91      0.91      0.91      1499\n",
      "weighted avg       0.92      0.92      0.92      1499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1069\n",
      "           1       0.89      0.87      0.88       729\n",
      "\n",
      "    accuracy                           0.91      1798\n",
      "   macro avg       0.90      0.90      0.90      1798\n",
      "weighted avg       0.91      0.91      0.91      1798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)  # Use 100 decision trees\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       900\n",
      "           1       0.88      0.87      0.88       599\n",
      "\n",
      "    accuracy                           0.90      1499\n",
      "   macro avg       0.90      0.90      0.90      1499\n",
      "weighted avg       0.90      0.90      0.90      1499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)  # Use 100 decision trees\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      1445\n",
      "           1       0.88      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.90      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)  # Use 100 decision trees\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       711\n",
      "           1       0.88      0.87      0.87       488\n",
      "\n",
      "    accuracy                           0.90      1199\n",
      "   macro avg       0.89      0.89      0.89      1199\n",
      "weighted avg       0.90      0.90      0.90      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)  # Use 100 decision trees\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      1227\n",
      "           1       0.90      0.89      0.90       771\n",
      "\n",
      "    accuracy                           0.92      1998\n",
      "   macro avg       0.92      0.92      0.92      1998\n",
      "weighted avg       0.92      0.92      0.92      1998\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1228\n",
      "           1       0.90      0.89      0.90       770\n",
      "\n",
      "    accuracy                           0.92      1998\n",
      "   macro avg       0.92      0.92      0.92      1998\n",
      "weighted avg       0.92      0.92      0.92      1998\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1227\n",
      "           1       0.90      0.87      0.89       770\n",
      "\n",
      "    accuracy                           0.91      1997\n",
      "   macro avg       0.91      0.91      0.91      1997\n",
      "weighted avg       0.91      0.91      0.91      1997\n",
      "\n",
      "Average accuracy: 0.9182372992254481\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "# Initialize data and labels list\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# model = svm.SVC(kernel='linear')  # linear kernel\n",
    "\n",
    "# Perform cross-validation\n",
    "accuracies = []\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute accuracy and add it to the list\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute and print the average accuracy\n",
    "print('Average accuracy:', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       368\n",
      "           1       0.87      0.90      0.89       232\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.90      0.91      0.91       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       369\n",
      "           1       0.92      0.89      0.91       231\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.92      0.93       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       369\n",
      "           1       0.93      0.86      0.89       231\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.92      0.91      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m y_train, y_test \u001b[39m=\u001b[39m labels[train_index], labels[test_index]\n\u001b[0;32m     49\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     52\u001b[0m \u001b[39m# Test the model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    253\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    332\u001b[0m     X,\n\u001b[0;32m    333\u001b[0m     y,\n\u001b[0;32m    334\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    336\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[0;32m    338\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    339\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    340\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    341\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    342\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    343\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    344\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    345\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    346\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    347\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    348\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    349\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    350\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "# Initialize data and labels list\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "# Initialize Logistic Regression model\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='linear')  # linear kernel\n",
    "\n",
    "# Perform cross-validation\n",
    "accuracies = []\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute accuracy and add it to the list\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute and print the average accuracy\n",
    "print('Average accuracy:', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993\n",
      "5993\n",
      "5993\n",
      "5993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       368\n",
      "           1       0.87      0.91      0.89       232\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.91      0.91      0.91       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       369\n",
      "           1       0.92      0.89      0.91       231\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.92      0.92       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       369\n",
      "           1       0.92      0.87      0.89       231\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.92      0.91      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       368\n",
      "           1       0.91      0.91      0.91       231\n",
      "\n",
      "    accuracy                           0.93       599\n",
      "   macro avg       0.93      0.93      0.93       599\n",
      "weighted avg       0.93      0.93      0.93       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       368\n",
      "           1       0.92      0.89      0.91       231\n",
      "\n",
      "    accuracy                           0.93       599\n",
      "   macro avg       0.93      0.92      0.92       599\n",
      "weighted avg       0.93      0.93      0.93       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       368\n",
      "           1       0.88      0.89      0.89       231\n",
      "\n",
      "    accuracy                           0.91       599\n",
      "   macro avg       0.91      0.91      0.91       599\n",
      "weighted avg       0.91      0.91      0.91       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       368\n",
      "           1       0.86      0.89      0.88       231\n",
      "\n",
      "    accuracy                           0.90       599\n",
      "   macro avg       0.90      0.90      0.90       599\n",
      "weighted avg       0.90      0.90      0.90       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       368\n",
      "           1       0.91      0.88      0.89       231\n",
      "\n",
      "    accuracy                           0.92       599\n",
      "   macro avg       0.92      0.91      0.92       599\n",
      "weighted avg       0.92      0.92      0.92       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       368\n",
      "           1       0.88      0.89      0.88       231\n",
      "\n",
      "    accuracy                           0.91       599\n",
      "   macro avg       0.90      0.91      0.91       599\n",
      "weighted avg       0.91      0.91      0.91       599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       368\n",
      "           1       0.92      0.84      0.88       231\n",
      "\n",
      "    accuracy                           0.91       599\n",
      "   macro avg       0.91      0.90      0.90       599\n",
      "weighted avg       0.91      0.91      0.91       599\n",
      "\n",
      "Average accuracy: 0.9179028937117419\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "\n",
    "output_directory = r'F:\\dains' \n",
    "\n",
    "# Initialize data and labels list\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    # Assign labels: first 11 files are female, next 11 files are male\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Ensure the number of samples are consistent between `data` and `labels`\n",
    "assert len(data) == len(labels), \"Mismatched sample sizes: {} vs {}\".format(len(data), len(labels))\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "# Initialize Logistic Regression model\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "# linear kernel\n",
    "\n",
    "# Perform cross-validation\n",
    "accuracies = []\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute accuracy and add it to the list\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Compute and print the average accuracy\n",
    "print('Average accuracy:', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "     ----                                     0.2/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------                                0.4/1.7 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------                          0.7/1.7 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------                    0.9/1.7 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------              1.2/1.7 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       1.5/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "                                              0.0/272.8 MB ? eta -:--:--\n",
      "                                              0.2/272.8 MB 6.1 MB/s eta 0:00:45\n",
      "                                              0.6/272.8 MB 7.6 MB/s eta 0:00:36\n",
      "                                              1.0/272.8 MB 8.3 MB/s eta 0:00:33\n",
      "                                              1.5/272.8 MB 8.7 MB/s eta 0:00:32\n",
      "                                              1.9/272.8 MB 8.8 MB/s eta 0:00:31\n",
      "                                              2.4/272.8 MB 9.0 MB/s eta 0:00:31\n",
      "                                              2.8/272.8 MB 9.1 MB/s eta 0:00:30\n",
      "                                              3.3/272.8 MB 9.1 MB/s eta 0:00:30\n",
      "                                              3.8/272.8 MB 9.2 MB/s eta 0:00:30\n",
      "                                              4.2/272.8 MB 9.2 MB/s eta 0:00:30\n",
      "                                              4.7/272.8 MB 9.3 MB/s eta 0:00:29\n",
      "                                              5.1/272.8 MB 9.3 MB/s eta 0:00:29\n",
      "                                              5.6/272.8 MB 9.3 MB/s eta 0:00:29\n",
      "                                              6.0/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "                                              6.5/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "     -                                        6.9/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "     -                                        7.4/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "     -                                        7.8/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "     -                                        8.3/272.8 MB 9.4 MB/s eta 0:00:29\n",
      "     -                                        8.8/272.8 MB 9.5 MB/s eta 0:00:28\n",
      "     -                                        9.2/272.8 MB 9.5 MB/s eta 0:00:28\n",
      "     -                                        9.6/272.8 MB 9.4 MB/s eta 0:00:28\n",
      "     -                                       10.1/272.8 MB 9.5 MB/s eta 0:00:28\n",
      "     -                                       10.5/272.8 MB 9.6 MB/s eta 0:00:28\n",
      "     -                                       11.0/272.8 MB 9.6 MB/s eta 0:00:28\n",
      "     -                                       11.4/272.8 MB 9.6 MB/s eta 0:00:28\n",
      "     -                                       11.9/272.8 MB 9.6 MB/s eta 0:00:28\n",
      "     -                                       12.3/272.8 MB 9.6 MB/s eta 0:00:28\n",
      "     -                                       12.8/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     -                                       13.2/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     -                                       13.7/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      14.1/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      14.6/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      15.0/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      15.5/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      15.9/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      16.4/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      16.8/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      17.3/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      17.7/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      18.2/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      18.6/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      19.1/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      19.5/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      20.0/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      20.4/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     --                                      20.9/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     ---                                     21.3/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     ---                                     21.8/272.8 MB 9.8 MB/s eta 0:00:26\n",
      "     ---                                     22.3/272.8 MB 9.6 MB/s eta 0:00:27\n",
      "     ---                                     22.7/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     23.1/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     23.6/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     24.1/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     24.5/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     25.0/272.8 MB 9.8 MB/s eta 0:00:26\n",
      "     ---                                     25.4/272.8 MB 9.8 MB/s eta 0:00:26\n",
      "     ---                                     25.9/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     26.3/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     26.8/272.8 MB 9.8 MB/s eta 0:00:26\n",
      "     ---                                     27.2/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ---                                     27.7/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ----                                    28.1/272.8 MB 9.6 MB/s eta 0:00:26\n",
      "     ----                                    28.5/272.8 MB 9.5 MB/s eta 0:00:26\n",
      "     ----                                    28.8/272.8 MB 9.5 MB/s eta 0:00:26\n",
      "     ----                                    29.1/272.8 MB 9.4 MB/s eta 0:00:27\n",
      "     ----                                    29.3/272.8 MB 9.1 MB/s eta 0:00:27\n",
      "     ----                                    29.4/272.8 MB 9.0 MB/s eta 0:00:28\n",
      "     ----                                    29.4/272.8 MB 9.0 MB/s eta 0:00:28\n",
      "     ----                                    29.7/272.8 MB 8.4 MB/s eta 0:00:29\n",
      "     ----                                    30.2/272.8 MB 8.4 MB/s eta 0:00:29\n",
      "     ----                                    30.4/272.8 MB 8.2 MB/s eta 0:00:30\n",
      "     ----                                    30.5/272.8 MB 8.2 MB/s eta 0:00:30\n",
      "     ----                                    30.9/272.8 MB 8.0 MB/s eta 0:00:31\n",
      "     ----                                    31.2/272.8 MB 7.8 MB/s eta 0:00:31\n",
      "     ----                                    31.5/272.8 MB 7.8 MB/s eta 0:00:31\n",
      "     ----                                    31.8/272.8 MB 7.7 MB/s eta 0:00:32\n",
      "     ----                                    32.1/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     ----                                    32.5/272.8 MB 7.5 MB/s eta 0:00:32\n",
      "     ----                                    32.8/272.8 MB 7.5 MB/s eta 0:00:32\n",
      "     ----                                    33.4/272.8 MB 7.5 MB/s eta 0:00:32\n",
      "     ----                                    33.9/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     ----                                    34.3/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     ----                                    34.8/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     -----                                   35.2/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     -----                                   35.7/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     -----                                   36.2/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     -----                                   36.6/272.8 MB 7.6 MB/s eta 0:00:32\n",
      "     -----                                   37.0/272.8 MB 7.6 MB/s eta 0:00:31\n",
      "     -----                                   37.5/272.8 MB 7.6 MB/s eta 0:00:31\n",
      "     -----                                   38.0/272.8 MB 7.6 MB/s eta 0:00:31\n",
      "     -----                                   38.4/272.8 MB 7.6 MB/s eta 0:00:31\n",
      "     -----                                   38.9/272.8 MB 7.7 MB/s eta 0:00:31\n",
      "     -----                                   39.3/272.8 MB 7.8 MB/s eta 0:00:30\n",
      "     -----                                   39.8/272.8 MB 8.6 MB/s eta 0:00:28\n",
      "     -----                                   40.2/272.8 MB 8.5 MB/s eta 0:00:28\n",
      "     -----                                   40.7/272.8 MB 8.8 MB/s eta 0:00:27\n",
      "     -----                                   41.1/272.8 MB 9.1 MB/s eta 0:00:26\n",
      "     -----                                   41.6/272.8 MB 9.4 MB/s eta 0:00:25\n",
      "     ------                                  42.0/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  42.5/272.8 MB 9.8 MB/s eta 0:00:24\n",
      "     ------                                  42.9/272.8 MB 9.8 MB/s eta 0:00:24\n",
      "     ------                                  43.4/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  43.8/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  44.3/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  44.7/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  45.2/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  45.6/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  46.1/272.8 MB 9.8 MB/s eta 0:00:24\n",
      "     ------                                  46.4/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  46.9/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  47.5/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  47.9/272.8 MB 9.8 MB/s eta 0:00:24\n",
      "     ------                                  48.4/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     ------                                  48.8/272.8 MB 9.8 MB/s eta 0:00:23\n",
      "     -------                                 49.2/272.8 MB 9.5 MB/s eta 0:00:24\n",
      "     -------                                 49.7/272.8 MB 9.8 MB/s eta 0:00:23\n",
      "     -------                                 50.2/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     -------                                 50.6/272.8 MB 9.6 MB/s eta 0:00:24\n",
      "     -------                                 51.1/272.8 MB 9.8 MB/s eta 0:00:23\n",
      "     -------                                 51.5/272.8 MB 9.6 MB/s eta 0:00:23\n",
      "     -------                                 51.9/272.8 MB 9.6 MB/s eta 0:00:23\n",
      "     -------                                 52.4/272.8 MB 9.6 MB/s eta 0:00:23\n",
      "     -------                                 52.7/272.8 MB 9.5 MB/s eta 0:00:24\n",
      "     -------                                 53.0/272.8 MB 9.4 MB/s eta 0:00:24\n",
      "     -------                                 53.3/272.8 MB 9.4 MB/s eta 0:00:24\n",
      "     -------                                 53.5/272.8 MB 9.1 MB/s eta 0:00:25\n",
      "     -------                                 53.8/272.8 MB 9.0 MB/s eta 0:00:25\n",
      "     -------                                 54.5/272.8 MB 9.1 MB/s eta 0:00:25\n",
      "     -------                                 55.0/272.8 MB 9.2 MB/s eta 0:00:24\n",
      "     -------                                 55.4/272.8 MB 9.2 MB/s eta 0:00:24\n",
      "     -------                                 55.9/272.8 MB 9.2 MB/s eta 0:00:24\n",
      "     --------                                56.4/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                56.8/272.8 MB 9.4 MB/s eta 0:00:24\n",
      "     --------                                57.3/272.8 MB 9.2 MB/s eta 0:00:24\n",
      "     --------                                57.7/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                58.1/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                58.6/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                59.1/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                59.5/272.8 MB 9.2 MB/s eta 0:00:24\n",
      "     --------                                60.0/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                60.4/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                60.8/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                61.3/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                61.7/272.8 MB 9.1 MB/s eta 0:00:24\n",
      "     --------                                62.0/272.8 MB 9.0 MB/s eta 0:00:24\n",
      "     --------                                62.4/272.8 MB 8.8 MB/s eta 0:00:24\n",
      "     --------                                62.6/272.8 MB 8.7 MB/s eta 0:00:25\n",
      "     --------                                62.9/272.8 MB 8.7 MB/s eta 0:00:25\n",
      "     ---------                               63.2/272.8 MB 8.7 MB/s eta 0:00:25\n",
      "     ---------                               63.5/272.8 MB 8.7 MB/s eta 0:00:24\n",
      "     ---------                               63.8/272.8 MB 8.8 MB/s eta 0:00:24\n",
      "     ---------                               64.0/272.8 MB 8.7 MB/s eta 0:00:24\n",
      "     ---------                               64.1/272.8 MB 8.5 MB/s eta 0:00:25\n",
      "     ---------                               64.3/272.8 MB 8.3 MB/s eta 0:00:26\n",
      "     ---------                               64.5/272.8 MB 8.1 MB/s eta 0:00:26\n",
      "     ---------                               64.7/272.8 MB 7.9 MB/s eta 0:00:27\n",
      "     ---------                               64.9/272.8 MB 7.7 MB/s eta 0:00:27\n",
      "     ---------                               65.3/272.8 MB 7.7 MB/s eta 0:00:27\n",
      "     ---------                               65.8/272.8 MB 7.7 MB/s eta 0:00:27\n",
      "     ---------                               66.3/272.8 MB 7.7 MB/s eta 0:00:27\n",
      "     ---------                               66.9/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               67.3/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               67.8/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               68.2/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               68.7/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               69.2/272.8 MB 7.8 MB/s eta 0:00:27\n",
      "     ---------                               69.4/272.8 MB 7.7 MB/s eta 0:00:27\n",
      "     ---------                               69.7/272.8 MB 7.6 MB/s eta 0:00:27\n",
      "     ----------                              70.0/272.8 MB 7.5 MB/s eta 0:00:27\n",
      "     ----------                              70.5/272.8 MB 7.5 MB/s eta 0:00:27\n",
      "     ----------                              70.9/272.8 MB 7.4 MB/s eta 0:00:28\n",
      "     ----------                              71.3/272.8 MB 7.5 MB/s eta 0:00:27\n",
      "     ----------                              71.9/272.8 MB 7.5 MB/s eta 0:00:27\n",
      "     ----------                              72.4/272.8 MB 7.8 MB/s eta 0:00:26\n",
      "     ----------                              72.9/272.8 MB 7.8 MB/s eta 0:00:26\n",
      "     ----------                              73.3/272.8 MB 8.0 MB/s eta 0:00:25\n",
      "     ----------                              73.8/272.8 MB 8.2 MB/s eta 0:00:25\n",
      "     ----------                              74.2/272.8 MB 8.5 MB/s eta 0:00:24\n",
      "     ----------                              74.7/272.8 MB 9.1 MB/s eta 0:00:22\n",
      "     ----------                              75.2/272.8 MB 9.5 MB/s eta 0:00:21\n",
      "     ----------                              75.6/272.8 MB 9.5 MB/s eta 0:00:21\n",
      "     ----------                              75.9/272.8 MB 9.4 MB/s eta 0:00:22\n",
      "     ----------                              76.2/272.8 MB 9.2 MB/s eta 0:00:22\n",
      "     ----------                              76.5/272.8 MB 9.1 MB/s eta 0:00:22\n",
      "     ----------                              76.8/272.8 MB 9.0 MB/s eta 0:00:22\n",
      "     -----------                             77.0/272.8 MB 9.0 MB/s eta 0:00:22\n",
      "     -----------                             78.0/272.8 MB 9.1 MB/s eta 0:00:22\n",
      "     -----------                             78.5/272.8 MB 9.2 MB/s eta 0:00:22\n",
      "     -----------                             78.9/272.8 MB 9.1 MB/s eta 0:00:22\n",
      "     -----------                             79.4/272.8 MB 9.2 MB/s eta 0:00:21\n",
      "     -----------                             79.8/272.8 MB 9.4 MB/s eta 0:00:21\n",
      "     -----------                             80.3/272.8 MB 9.6 MB/s eta 0:00:20\n",
      "     -----------                             80.7/272.8 MB 9.5 MB/s eta 0:00:21\n",
      "     -----------                             81.2/272.8 MB 9.6 MB/s eta 0:00:20\n",
      "     -----------                             81.7/272.8 MB 9.6 MB/s eta 0:00:20\n",
      "     -----------                             82.1/272.8 MB 9.5 MB/s eta 0:00:21\n",
      "     -----------                             82.6/272.8 MB 9.5 MB/s eta 0:00:21\n",
      "     -----------                             83.0/272.8 MB 9.5 MB/s eta 0:00:20\n",
      "     -----------                             83.4/272.8 MB 9.5 MB/s eta 0:00:20\n",
      "     -----------                             83.9/272.8 MB 9.4 MB/s eta 0:00:21\n",
      "     ------------                            84.3/272.8 MB 9.4 MB/s eta 0:00:21\n",
      "     ------------                            84.6/272.8 MB 9.2 MB/s eta 0:00:21\n",
      "     ------------                            84.9/272.8 MB 9.1 MB/s eta 0:00:21\n",
      "     ------------                            85.3/272.8 MB 9.1 MB/s eta 0:00:21\n",
      "     ------------                            85.9/272.8 MB 9.2 MB/s eta 0:00:21\n",
      "     ------------                            86.5/272.8 MB 9.5 MB/s eta 0:00:20\n",
      "     ------------                            86.9/272.8 MB 9.8 MB/s eta 0:00:20\n",
      "     ------------                            87.4/272.8 MB 9.9 MB/s eta 0:00:19\n",
      "     ------------                            87.8/272.8 MB 9.5 MB/s eta 0:00:20\n",
      "     ------------                            88.1/272.8 MB 9.4 MB/s eta 0:00:20\n",
      "     ------------                            88.4/272.8 MB 9.1 MB/s eta 0:00:21\n",
      "     ------------                            88.6/272.8 MB 9.0 MB/s eta 0:00:21\n",
      "     ------------                            89.1/272.8 MB 9.0 MB/s eta 0:00:21\n",
      "     ------------                            89.5/272.8 MB 8.8 MB/s eta 0:00:21\n",
      "     ------------                            89.9/272.8 MB 8.8 MB/s eta 0:00:21\n",
      "     ------------                            90.4/272.8 MB 9.0 MB/s eta 0:00:21\n",
      "     ------------                            90.9/272.8 MB 9.0 MB/s eta 0:00:21\n",
      "     -------------                           91.2/272.8 MB 8.7 MB/s eta 0:00:21\n",
      "     -------------                           91.8/272.8 MB 8.8 MB/s eta 0:00:21\n",
      "     -------------                           92.4/272.8 MB 8.8 MB/s eta 0:00:21\n",
      "     -------------                           92.8/272.8 MB 8.6 MB/s eta 0:00:21\n",
      "     -------------                           93.1/272.8 MB 8.5 MB/s eta 0:00:22\n",
      "     -------------                           93.4/272.8 MB 8.5 MB/s eta 0:00:22\n",
      "     -------------                           93.9/272.8 MB 8.4 MB/s eta 0:00:22\n",
      "     -------------                           94.6/272.8 MB 8.5 MB/s eta 0:00:21\n",
      "     -------------                           95.1/272.8 MB 8.6 MB/s eta 0:00:21\n",
      "     -------------                           95.4/272.8 MB 8.6 MB/s eta 0:00:21\n",
      "     -------------                           95.8/272.8 MB 8.5 MB/s eta 0:00:21\n",
      "     -------------                           96.1/272.8 MB 8.3 MB/s eta 0:00:22\n",
      "     -------------                           96.4/272.8 MB 8.2 MB/s eta 0:00:22\n",
      "     -------------                           97.1/272.8 MB 8.3 MB/s eta 0:00:22\n",
      "     -------------                           97.6/272.8 MB 8.3 MB/s eta 0:00:22\n",
      "     --------------                          97.9/272.8 MB 8.5 MB/s eta 0:00:21\n",
      "     --------------                          98.3/272.8 MB 8.5 MB/s eta 0:00:21\n",
      "     --------------                          98.7/272.8 MB 8.6 MB/s eta 0:00:21\n",
      "     --------------                          99.0/272.8 MB 8.7 MB/s eta 0:00:20\n",
      "     --------------                          99.3/272.8 MB 8.6 MB/s eta 0:00:21\n",
      "     --------------                          99.6/272.8 MB 8.4 MB/s eta 0:00:21\n",
      "     --------------                          99.9/272.8 MB 8.3 MB/s eta 0:00:21\n",
      "     -------------                          100.1/272.8 MB 8.1 MB/s eta 0:00:22\n",
      "     -------------                          100.3/272.8 MB 8.0 MB/s eta 0:00:22\n",
      "     -------------                          100.5/272.8 MB 7.8 MB/s eta 0:00:23\n",
      "     --------------                         100.7/272.8 MB 7.6 MB/s eta 0:00:23\n",
      "     --------------                         100.9/272.8 MB 7.4 MB/s eta 0:00:24\n",
      "     --------------                         101.0/272.8 MB 7.4 MB/s eta 0:00:24\n",
      "     --------------                         101.3/272.8 MB 7.3 MB/s eta 0:00:24\n",
      "     --------------                         101.5/272.8 MB 7.2 MB/s eta 0:00:24\n",
      "     --------------                         101.9/272.8 MB 7.1 MB/s eta 0:00:24\n",
      "     --------------                         102.5/272.8 MB 7.1 MB/s eta 0:00:24\n",
      "     --------------                         103.1/272.8 MB 7.3 MB/s eta 0:00:24\n",
      "     --------------                         103.3/272.8 MB 7.3 MB/s eta 0:00:24\n",
      "     --------------                         103.7/272.8 MB 7.3 MB/s eta 0:00:24\n",
      "     --------------                         104.2/272.8 MB 7.4 MB/s eta 0:00:23\n",
      "     --------------                         104.6/272.8 MB 7.3 MB/s eta 0:00:24\n",
      "     --------------                         104.9/272.8 MB 7.2 MB/s eta 0:00:24\n",
      "     --------------                         105.5/272.8 MB 7.4 MB/s eta 0:00:23\n",
      "     --------------                         106.0/272.8 MB 7.5 MB/s eta 0:00:23\n",
      "     --------------                         106.4/272.8 MB 7.5 MB/s eta 0:00:23\n",
      "     --------------                         106.9/272.8 MB 7.5 MB/s eta 0:00:23\n",
      "     --------------                         107.2/272.8 MB 7.4 MB/s eta 0:00:23\n",
      "     ---------------                        107.8/272.8 MB 7.4 MB/s eta 0:00:23\n",
      "     ---------------                        108.1/272.8 MB 7.3 MB/s eta 0:00:23\n",
      "     ---------------                        108.5/272.8 MB 7.4 MB/s eta 0:00:23\n",
      "     ---------------                        109.1/272.8 MB 7.6 MB/s eta 0:00:22\n",
      "     ---------------                        109.6/272.8 MB 7.7 MB/s eta 0:00:22\n",
      "     ---------------                        109.9/272.8 MB 7.7 MB/s eta 0:00:22\n",
      "     ---------------                        110.3/272.8 MB 8.0 MB/s eta 0:00:21\n",
      "     ---------------                        110.9/272.8 MB 8.5 MB/s eta 0:00:20\n",
      "     ---------------                        111.4/272.8 MB 9.1 MB/s eta 0:00:18\n",
      "     ---------------                        111.8/272.8 MB 9.5 MB/s eta 0:00:17\n",
      "     ---------------                        112.1/272.8 MB 9.2 MB/s eta 0:00:18\n",
      "     ---------------                        112.5/272.8 MB 9.2 MB/s eta 0:00:18\n",
      "     ---------------                        113.0/272.8 MB 9.2 MB/s eta 0:00:18\n",
      "     ---------------                        113.3/272.8 MB 9.1 MB/s eta 0:00:18\n",
      "     ---------------                        113.6/272.8 MB 9.1 MB/s eta 0:00:18\n",
      "     ---------------                        113.7/272.8 MB 9.0 MB/s eta 0:00:18\n",
      "     ---------------                        113.9/272.8 MB 8.8 MB/s eta 0:00:18\n",
      "     ---------------                        114.6/272.8 MB 8.8 MB/s eta 0:00:18\n",
      "     ----------------                       115.1/272.8 MB 9.0 MB/s eta 0:00:18\n",
      "     ----------------                       115.4/272.8 MB 9.0 MB/s eta 0:00:18\n",
      "     ----------------                       115.7/272.8 MB 8.6 MB/s eta 0:00:19\n",
      "     ----------------                       116.1/272.8 MB 8.5 MB/s eta 0:00:19\n",
      "     ----------------                       116.7/272.8 MB 8.5 MB/s eta 0:00:19\n",
      "     ----------------                       117.6/272.8 MB 8.6 MB/s eta 0:00:19\n",
      "     ----------------                       118.1/272.8 MB 8.7 MB/s eta 0:00:18\n",
      "     ----------------                       118.7/272.8 MB 8.7 MB/s eta 0:00:18\n",
      "     ----------------                       119.2/272.8 MB 8.6 MB/s eta 0:00:18\n",
      "     ----------------                       119.8/272.8 MB 8.5 MB/s eta 0:00:18\n",
      "     ----------------                       120.5/272.8 MB 8.7 MB/s eta 0:00:18\n",
      "     ----------------                       121.0/272.8 MB 8.6 MB/s eta 0:00:18\n",
      "     ----------------                       121.7/272.8 MB 8.6 MB/s eta 0:00:18\n",
      "     -----------------                      122.2/272.8 MB 8.7 MB/s eta 0:00:18\n",
      "     -----------------                      122.9/272.8 MB 8.7 MB/s eta 0:00:18\n",
      "     -----------------                      123.5/272.8 MB 8.8 MB/s eta 0:00:17\n",
      "     -----------------                      124.4/272.8 MB 9.2 MB/s eta 0:00:17\n",
      "     -----------------                      125.1/272.8 MB 9.2 MB/s eta 0:00:17\n",
      "     -----------------                      125.7/272.8 MB 9.5 MB/s eta 0:00:16\n",
      "     -----------------                      126.3/272.8 MB 9.6 MB/s eta 0:00:16\n",
      "     -----------------                      126.7/272.8 MB 9.9 MB/s eta 0:00:15\n",
      "     -----------------                      127.2/272.8 MB 9.6 MB/s eta 0:00:16\n",
      "     -----------------                      127.7/272.8 MB 9.6 MB/s eta 0:00:16\n",
      "     -----------------                      128.1/272.8 MB 9.6 MB/s eta 0:00:16\n",
      "     -----------------                      128.6/272.8 MB 9.6 MB/s eta 0:00:15\n",
      "     -----------------                      129.1/272.8 MB 9.6 MB/s eta 0:00:15\n",
      "     ------------------                     129.5/272.8 MB 9.8 MB/s eta 0:00:15\n",
      "     ------------------                     129.9/272.8 MB 9.6 MB/s eta 0:00:15\n",
      "     ------------------                     130.3/272.8 MB 9.4 MB/s eta 0:00:16\n",
      "     ------------------                     130.5/272.8 MB 9.2 MB/s eta 0:00:16\n",
      "     ------------------                     130.8/272.8 MB 9.1 MB/s eta 0:00:16\n",
      "     ------------------                     131.1/272.8 MB 9.1 MB/s eta 0:00:16\n",
      "     ------------------                     131.4/272.8 MB 9.0 MB/s eta 0:00:16\n",
      "     ------------------                     131.7/272.8 MB 8.8 MB/s eta 0:00:16\n",
      "     ------------------                     132.0/272.8 MB 8.7 MB/s eta 0:00:17\n",
      "     ------------------                     132.3/272.8 MB 8.6 MB/s eta 0:00:17\n",
      "     ------------------                     132.6/272.8 MB 8.5 MB/s eta 0:00:17\n",
      "     ------------------                     132.7/272.8 MB 8.3 MB/s eta 0:00:17\n",
      "     ------------------                     132.9/272.8 MB 8.1 MB/s eta 0:00:18\n",
      "     ------------------                     133.2/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     ------------------                     133.5/272.8 MB 7.9 MB/s eta 0:00:18\n",
      "     ------------------                     134.0/272.8 MB 7.9 MB/s eta 0:00:18\n",
      "     ------------------                     134.6/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     ------------------                     135.1/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     ------------------                     135.5/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     ------------------                     136.0/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     -------------------                    136.4/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     -------------------                    136.9/272.8 MB 8.0 MB/s eta 0:00:18\n",
      "     -------------------                    137.5/272.8 MB 8.0 MB/s eta 0:00:17\n",
      "     -------------------                    137.9/272.8 MB 8.0 MB/s eta 0:00:17\n",
      "     -------------------                    138.5/272.8 MB 8.0 MB/s eta 0:00:17\n",
      "     -------------------                    138.9/272.8 MB 8.0 MB/s eta 0:00:17\n",
      "     -------------------                    139.4/272.8 MB 8.0 MB/s eta 0:00:17\n",
      "     -------------------                    139.8/272.8 MB 7.9 MB/s eta 0:00:17\n",
      "     -------------------                    140.3/272.8 MB 8.1 MB/s eta 0:00:17\n",
      "     -------------------                    140.7/272.8 MB 8.3 MB/s eta 0:00:16\n",
      "     -------------------                    141.2/272.8 MB 8.4 MB/s eta 0:00:16\n",
      "     -------------------                    141.6/272.8 MB 8.6 MB/s eta 0:00:16\n",
      "     -------------------                    142.1/272.8 MB 8.6 MB/s eta 0:00:16\n",
      "     -------------------                    142.6/272.8 MB 9.0 MB/s eta 0:00:15\n",
      "     -------------------                    143.0/272.8 MB 9.4 MB/s eta 0:00:14\n",
      "     -------------------                    143.5/272.8 MB 9.6 MB/s eta 0:00:14\n",
      "     --------------------                   143.9/272.8 MB 9.8 MB/s eta 0:00:14\n",
      "     --------------------                   144.4/272.8 MB 9.8 MB/s eta 0:00:14\n",
      "     --------------------                   144.8/272.8 MB 9.8 MB/s eta 0:00:14\n",
      "     --------------------                   145.2/272.8 MB 9.8 MB/s eta 0:00:14\n",
      "     --------------------                   145.7/272.8 MB 9.6 MB/s eta 0:00:14\n",
      "     --------------------                   146.1/272.8 MB 9.8 MB/s eta 0:00:13\n",
      "     --------------------                   146.5/272.8 MB 9.8 MB/s eta 0:00:13\n",
      "     --------------------                   147.0/272.8 MB 9.5 MB/s eta 0:00:14\n",
      "     --------------------                   147.4/272.8 MB 9.9 MB/s eta 0:00:13\n",
      "     --------------------                   147.9/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     --------------------                   148.3/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     --------------------                   148.8/272.8 MB 9.8 MB/s eta 0:00:13\n",
      "     --------------------                   149.3/272.8 MB 9.8 MB/s eta 0:00:13\n",
      "     --------------------                   149.7/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     --------------------                   150.1/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     --------------------                   150.6/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     ---------------------                  151.0/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     ---------------------                  151.5/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     ---------------------                  151.9/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     ---------------------                  152.4/272.8 MB 9.6 MB/s eta 0:00:13\n",
      "     ---------------------                  152.7/272.8 MB 9.4 MB/s eta 0:00:13\n",
      "     ---------------------                  153.0/272.8 MB 9.5 MB/s eta 0:00:13\n",
      "     ---------------------                  153.4/272.8 MB 9.4 MB/s eta 0:00:13\n",
      "     ---------------------                  153.7/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  154.2/272.8 MB 9.1 MB/s eta 0:00:14\n",
      "     ---------------------                  154.7/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  155.2/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  155.7/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  156.1/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  156.6/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ---------------------                  157.1/272.8 MB 9.4 MB/s eta 0:00:13\n",
      "     ---------------------                  157.5/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 158.0/272.8 MB 9.4 MB/s eta 0:00:13\n",
      "     ----------------------                 158.4/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 158.9/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 159.3/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 159.9/272.8 MB 9.4 MB/s eta 0:00:13\n",
      "     ----------------------                 160.4/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 160.8/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 161.3/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 161.7/272.8 MB 9.2 MB/s eta 0:00:13\n",
      "     ----------------------                 162.2/272.8 MB 9.4 MB/s eta 0:00:12\n",
      "     ----------------------                 162.6/272.8 MB 9.2 MB/s eta 0:00:12\n",
      "     ----------------------                 163.1/272.8 MB 9.4 MB/s eta 0:00:12\n",
      "     ----------------------                 163.7/272.8 MB 9.6 MB/s eta 0:00:12\n",
      "     ----------------------                 164.1/272.8 MB 9.9 MB/s eta 0:00:11\n",
      "     ----------------------                 164.6/272.8 MB 9.6 MB/s eta 0:00:12\n",
      "     ----------------------                 165.0/272.8 MB 9.6 MB/s eta 0:00:12\n",
      "     -----------------------                165.5/272.8 MB 9.8 MB/s eta 0:00:11\n",
      "     -----------------------                166.0/272.8 MB 9.6 MB/s eta 0:00:12\n",
      "     -----------------------                166.4/272.8 MB 9.6 MB/s eta 0:00:12\n",
      "     -----------------------                166.8/272.8 MB 9.8 MB/s eta 0:00:11\n",
      "     -----------------------                167.3/272.8 MB 9.6 MB/s eta 0:00:11\n",
      "     -----------------------                167.5/272.8 MB 9.5 MB/s eta 0:00:12\n",
      "     -----------------------                167.9/272.8 MB 9.5 MB/s eta 0:00:12\n",
      "     -----------------------                168.1/272.8 MB 9.4 MB/s eta 0:00:12\n",
      "     -----------------------                168.4/272.8 MB 9.2 MB/s eta 0:00:12\n",
      "     -----------------------                168.8/272.8 MB 9.2 MB/s eta 0:00:12\n",
      "     -----------------------                168.9/272.8 MB 9.1 MB/s eta 0:00:12\n",
      "     -----------------------                169.2/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     -----------------------                169.7/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     -----------------------                170.0/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     -----------------------                170.5/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     -----------------------                171.0/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     -----------------------                171.5/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     -----------------------                171.9/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               172.4/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               172.9/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               173.3/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               173.8/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               174.2/272.8 MB 8.8 MB/s eta 0:00:12\n",
      "     ------------------------               174.7/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     ------------------------               175.1/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     ------------------------               175.6/272.8 MB 8.8 MB/s eta 0:00:11\n",
      "     ------------------------               176.0/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     ------------------------               176.4/272.8 MB 8.7 MB/s eta 0:00:12\n",
      "     ------------------------               176.9/272.8 MB 8.7 MB/s eta 0:00:11\n",
      "     ------------------------               177.3/272.8 MB 8.7 MB/s eta 0:00:11\n",
      "     ------------------------               177.8/272.8 MB 8.8 MB/s eta 0:00:11\n",
      "     ------------------------               178.3/272.8 MB 9.1 MB/s eta 0:00:11\n",
      "     ------------------------               178.7/272.8 MB 9.2 MB/s eta 0:00:11\n",
      "     ------------------------               179.1/272.8 MB 9.4 MB/s eta 0:00:11\n",
      "     -------------------------              179.6/272.8 MB 9.6 MB/s eta 0:00:10\n",
      "     -------------------------              180.1/272.8 MB 9.8 MB/s eta 0:00:10\n",
      "     -------------------------              180.5/272.8 MB 9.8 MB/s eta 0:00:10\n",
      "     -------------------------              181.0/272.8 MB 9.8 MB/s eta 0:00:10\n",
      "     -------------------------              181.4/272.8 MB 9.6 MB/s eta 0:00:10\n",
      "     -------------------------              181.8/272.8 MB 9.6 MB/s eta 0:00:10\n",
      "     -------------------------              182.1/272.8 MB 9.4 MB/s eta 0:00:10\n",
      "     -------------------------              182.3/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              182.7/272.8 MB 9.1 MB/s eta 0:00:10\n",
      "     -------------------------              183.2/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              183.7/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              184.2/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              184.6/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              185.1/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              185.5/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              186.0/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     -------------------------              186.4/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             186.9/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             187.3/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             187.8/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             188.2/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             188.7/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             189.1/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             189.6/272.8 MB 9.2 MB/s eta 0:00:10\n",
      "     --------------------------             190.1/272.8 MB 9.4 MB/s eta 0:00:09\n",
      "     --------------------------             190.6/272.8 MB 9.4 MB/s eta 0:00:09\n",
      "     --------------------------             191.0/272.8 MB 9.4 MB/s eta 0:00:09\n",
      "     --------------------------             191.4/272.8 MB 9.4 MB/s eta 0:00:09\n",
      "     --------------------------             191.9/272.8 MB 9.4 MB/s eta 0:00:09\n",
      "     --------------------------             192.3/272.8 MB 9.5 MB/s eta 0:00:09\n",
      "     --------------------------             192.8/272.8 MB 9.8 MB/s eta 0:00:09\n",
      "     --------------------------             193.3/272.8 MB 9.9 MB/s eta 0:00:09\n",
      "     --------------------------             193.8/272.8 MB 9.6 MB/s eta 0:00:09\n",
      "     ---------------------------            194.2/272.8 MB 9.6 MB/s eta 0:00:09\n",
      "     ---------------------------            194.6/272.8 MB 9.5 MB/s eta 0:00:09\n",
      "     ---------------------------            195.2/272.8 MB 9.6 MB/s eta 0:00:09\n",
      "     ---------------------------            195.6/272.8 MB 9.6 MB/s eta 0:00:09\n",
      "     ---------------------------            196.1/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            196.5/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            197.0/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            197.4/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            197.9/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            198.3/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            198.8/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            199.3/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            199.8/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            200.3/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ---------------------------            200.7/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ----------------------------           201.2/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ----------------------------           201.6/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ----------------------------           202.0/272.8 MB 9.5 MB/s eta 0:00:08\n",
      "     ----------------------------           202.3/272.8 MB 9.4 MB/s eta 0:00:08\n",
      "     ----------------------------           202.6/272.8 MB 9.4 MB/s eta 0:00:08\n",
      "     ----------------------------           203.2/272.8 MB 9.4 MB/s eta 0:00:08\n",
      "     ----------------------------           203.7/272.8 MB 9.5 MB/s eta 0:00:08\n",
      "     ----------------------------           204.2/272.8 MB 9.5 MB/s eta 0:00:08\n",
      "     ----------------------------           204.7/272.8 MB 9.6 MB/s eta 0:00:08\n",
      "     ----------------------------           205.1/272.8 MB 9.5 MB/s eta 0:00:08\n",
      "     ----------------------------           205.4/272.8 MB 9.5 MB/s eta 0:00:08\n",
      "     ----------------------------           205.6/272.8 MB 9.4 MB/s eta 0:00:08\n",
      "     ----------------------------           205.9/272.8 MB 9.0 MB/s eta 0:00:08\n",
      "     ----------------------------           206.0/272.8 MB 9.1 MB/s eta 0:00:08\n",
      "     ----------------------------           206.4/272.8 MB 8.8 MB/s eta 0:00:08\n",
      "     ----------------------------           206.7/272.8 MB 8.6 MB/s eta 0:00:08\n",
      "     ----------------------------           206.9/272.8 MB 8.5 MB/s eta 0:00:08\n",
      "     ----------------------------           207.2/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     ----------------------------           207.6/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     ----------------------------           208.1/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          208.5/272.8 MB 8.4 MB/s eta 0:00:08\n",
      "     -----------------------------          209.0/272.8 MB 8.4 MB/s eta 0:00:08\n",
      "     -----------------------------          209.5/272.8 MB 8.4 MB/s eta 0:00:08\n",
      "     -----------------------------          209.7/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          210.3/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          210.7/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          211.0/272.8 MB 8.2 MB/s eta 0:00:08\n",
      "     -----------------------------          211.5/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          212.0/272.8 MB 8.3 MB/s eta 0:00:08\n",
      "     -----------------------------          212.5/272.8 MB 8.5 MB/s eta 0:00:08\n",
      "     -----------------------------          213.0/272.8 MB 8.5 MB/s eta 0:00:08\n",
      "     -----------------------------          213.4/272.8 MB 8.5 MB/s eta 0:00:07\n",
      "     -----------------------------          213.9/272.8 MB 8.5 MB/s eta 0:00:07\n",
      "     -----------------------------          214.3/272.8 MB 8.4 MB/s eta 0:00:07\n",
      "     -----------------------------          214.8/272.8 MB 8.4 MB/s eta 0:00:07\n",
      "     -----------------------------          215.2/272.8 MB 8.4 MB/s eta 0:00:07\n",
      "     ------------------------------         215.7/272.8 MB 8.6 MB/s eta 0:00:07\n",
      "     ------------------------------         216.1/272.8 MB 8.8 MB/s eta 0:00:07\n",
      "     ------------------------------         216.6/272.8 MB 9.1 MB/s eta 0:00:07\n",
      "     ------------------------------         217.0/272.8 MB 9.4 MB/s eta 0:00:06\n",
      "     ------------------------------         217.4/272.8 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------         217.9/272.8 MB 9.6 MB/s eta 0:00:06\n",
      "     ------------------------------         218.4/272.8 MB 9.6 MB/s eta 0:00:06\n",
      "     ------------------------------         218.8/272.8 MB 9.6 MB/s eta 0:00:06\n",
      "     ------------------------------         219.4/272.8 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------         219.9/272.8 MB 9.6 MB/s eta 0:00:06\n",
      "     ------------------------------         220.3/272.8 MB 9.6 MB/s eta 0:00:06\n",
      "     ------------------------------         220.7/272.8 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------         221.0/272.8 MB 9.4 MB/s eta 0:00:06\n",
      "     ------------------------------         221.3/272.8 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------         221.5/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     ------------------------------         222.3/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        222.7/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        223.2/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        223.7/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        224.1/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        224.6/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        225.0/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        225.5/272.8 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------        225.9/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        226.4/272.8 MB 9.2 MB/s eta 0:00:06\n",
      "     -------------------------------        226.8/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        227.3/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        227.7/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        228.2/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        228.6/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        229.0/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     -------------------------------        229.3/272.8 MB 9.1 MB/s eta 0:00:05\n",
      "     -------------------------------        229.7/272.8 MB 9.1 MB/s eta 0:00:05\n",
      "     --------------------------------       230.0/272.8 MB 8.8 MB/s eta 0:00:05\n",
      "     --------------------------------       230.4/272.8 MB 9.0 MB/s eta 0:00:05\n",
      "     --------------------------------       230.8/272.8 MB 8.8 MB/s eta 0:00:05\n",
      "     --------------------------------       231.4/272.8 MB 9.2 MB/s eta 0:00:05\n",
      "     --------------------------------       231.8/272.8 MB 9.6 MB/s eta 0:00:05\n",
      "     --------------------------------       232.3/272.8 MB 9.5 MB/s eta 0:00:05\n",
      "     --------------------------------       232.7/272.8 MB 9.4 MB/s eta 0:00:05\n",
      "     --------------------------------       233.3/272.8 MB 9.4 MB/s eta 0:00:05\n",
      "     --------------------------------       233.8/272.8 MB 9.4 MB/s eta 0:00:05\n",
      "     --------------------------------       234.3/272.8 MB 9.4 MB/s eta 0:00:05\n",
      "     --------------------------------       234.7/272.8 MB 9.5 MB/s eta 0:00:05\n",
      "     --------------------------------       235.2/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     --------------------------------       235.6/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     --------------------------------       236.1/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     --------------------------------       236.5/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------------------------------      237.0/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     ---------------------------------      237.4/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     ---------------------------------      238.0/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------------------------------      238.5/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------------------------------      238.9/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     ---------------------------------      239.4/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     ---------------------------------      239.8/272.8 MB 9.6 MB/s eta 0:00:04\n",
      "     ---------------------------------      240.3/272.8 MB 9.8 MB/s eta 0:00:04\n",
      "     ---------------------------------      240.7/272.8 MB 9.9 MB/s eta 0:00:04\n",
      "     ---------------------------------      241.2/272.8 MB 9.8 MB/s eta 0:00:04\n",
      "     ---------------------------------      241.6/272.8 MB 9.8 MB/s eta 0:00:04\n",
      "     ---------------------------------      241.9/272.8 MB 9.5 MB/s eta 0:00:04\n",
      "     ---------------------------------      242.2/272.8 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------------------------------      242.5/272.8 MB 9.2 MB/s eta 0:00:04\n",
      "     ---------------------------------      242.8/272.8 MB 9.1 MB/s eta 0:00:04\n",
      "     ---------------------------------      243.1/272.8 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------      243.5/272.8 MB 8.8 MB/s eta 0:00:04\n",
      "     ---------------------------------      243.8/272.8 MB 8.7 MB/s eta 0:00:04\n",
      "     ----------------------------------     244.4/272.8 MB 8.8 MB/s eta 0:00:04\n",
      "     ----------------------------------     245.1/272.8 MB 8.8 MB/s eta 0:00:04\n",
      "     ----------------------------------     245.5/272.8 MB 8.8 MB/s eta 0:00:04\n",
      "     ----------------------------------     246.0/272.8 MB 8.8 MB/s eta 0:00:04\n",
      "     ----------------------------------     246.5/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     246.9/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     247.3/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     247.8/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     248.2/272.8 MB 9.0 MB/s eta 0:00:03\n",
      "     ----------------------------------     248.7/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     249.1/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     249.6/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     250.0/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     ----------------------------------     250.4/272.8 MB 8.7 MB/s eta 0:00:03\n",
      "     ----------------------------------     250.7/272.8 MB 8.7 MB/s eta 0:00:03\n",
      "     ----------------------------------     251.1/272.8 MB 8.6 MB/s eta 0:00:03\n",
      "     -----------------------------------    251.6/272.8 MB 8.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    252.1/272.8 MB 8.8 MB/s eta 0:00:03\n",
      "     -----------------------------------    252.6/272.8 MB 9.1 MB/s eta 0:00:03\n",
      "     -----------------------------------    253.1/272.8 MB 9.4 MB/s eta 0:00:03\n",
      "     -----------------------------------    253.6/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    254.0/272.8 MB 9.8 MB/s eta 0:00:02\n",
      "     -----------------------------------    254.5/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    255.0/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    255.4/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    255.9/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    256.3/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    256.8/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    257.2/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     -----------------------------------    257.7/272.8 MB 9.5 MB/s eta 0:00:02\n",
      "     -----------------------------------    258.2/272.8 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------   258.6/272.8 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------   259.1/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     ------------------------------------   259.5/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     ------------------------------------   260.0/272.8 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------   260.4/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     ------------------------------------   260.9/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     ------------------------------------   261.3/272.8 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------   261.8/272.8 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------   262.2/272.8 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------   262.7/272.8 MB 9.8 MB/s eta 0:00:02\n",
      "     ------------------------------------   263.1/272.8 MB 9.6 MB/s eta 0:00:02\n",
      "     ------------------------------------   263.6/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------   264.0/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------   264.5/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------------------   264.9/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------------------   265.4/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  265.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  266.3/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  266.7/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  267.2/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  267.7/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  268.2/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  268.6/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  269.1/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  269.5/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  270.0/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  270.4/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  270.9/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  271.4/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  271.8/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.3/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.7/272.8 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.8/272.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 272.8/272.8 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "                                              0.0/126.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "                                              0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading h5py-3.9.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "                                              0.0/2.7 MB ? eta -:--:--\n",
      "     ------                                   0.4/2.7 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------                             0.9/2.7 MB 9.1 MB/s eta 0:00:01\n",
      "     ---------------                          1.0/2.7 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------                          1.0/2.7 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------                          1.0/2.7 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------                     1.4/2.7 MB 4.9 MB/s eta 0:00:01\n",
      "     --------------------------               1.8/2.7 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------          2.1/2.7 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------          2.1/2.7 MB 5.8 MB/s eta 0:00:01\n",
      "     --------------------------------         2.2/2.7 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.7/2.7 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting jax>=0.3.15 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading jax-0.4.12.tar.gz (1.3 MB)\n",
      "                                              0.0/1.3 MB ? eta -:--:--\n",
      "     ---------------                          0.5/1.3 MB 10.5 MB/s eta 0:00:01\n",
      "     -----------------------------            1.0/1.3 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.3 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 8.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "                                              0.0/24.4 MB ? eta -:--:--\n",
      "                                              0.4/24.4 MB 8.5 MB/s eta 0:00:03\n",
      "     -                                        0.9/24.4 MB 9.2 MB/s eta 0:00:03\n",
      "     --                                       1.2/24.4 MB 9.8 MB/s eta 0:00:03\n",
      "     --                                       1.6/24.4 MB 8.7 MB/s eta 0:00:03\n",
      "     ---                                      1.9/24.4 MB 8.2 MB/s eta 0:00:03\n",
      "     ---                                      2.1/24.4 MB 7.5 MB/s eta 0:00:03\n",
      "     ---                                      2.4/24.4 MB 7.6 MB/s eta 0:00:03\n",
      "     ---                                      2.4/24.4 MB 7.4 MB/s eta 0:00:03\n",
      "     ---                                      2.4/24.4 MB 7.4 MB/s eta 0:00:03\n",
      "     ---                                      2.4/24.4 MB 7.4 MB/s eta 0:00:03\n",
      "     -----                                    3.3/24.4 MB 6.6 MB/s eta 0:00:04\n",
      "     -----                                    3.6/24.4 MB 6.5 MB/s eta 0:00:04\n",
      "     ------                                   3.8/24.4 MB 6.4 MB/s eta 0:00:04\n",
      "     ------                                   4.0/24.4 MB 6.2 MB/s eta 0:00:04\n",
      "     -------                                  4.5/24.4 MB 6.5 MB/s eta 0:00:04\n",
      "     --------                                 5.1/24.4 MB 6.9 MB/s eta 0:00:03\n",
      "     ---------                                5.5/24.4 MB 7.0 MB/s eta 0:00:03\n",
      "     ----------                               6.1/24.4 MB 7.3 MB/s eta 0:00:03\n",
      "     -----------                              6.9/24.4 MB 7.4 MB/s eta 0:00:03\n",
      "     ------------                             7.4/24.4 MB 7.5 MB/s eta 0:00:03\n",
      "     ------------                             7.8/24.4 MB 7.6 MB/s eta 0:00:03\n",
      "     -------------                            8.3/24.4 MB 7.7 MB/s eta 0:00:03\n",
      "     --------------                           8.8/24.4 MB 7.8 MB/s eta 0:00:03\n",
      "     ---------------                          9.3/24.4 MB 7.9 MB/s eta 0:00:02\n",
      "     ----------------                         10.1/24.4 MB 8.0 MB/s eta 0:00:02\n",
      "     -----------------                        10.5/24.4 MB 8.0 MB/s eta 0:00:02\n",
      "     ------------------                       11.2/24.4 MB 8.0 MB/s eta 0:00:02\n",
      "     -------------------                      11.6/24.4 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------------                      12.1/24.4 MB 8.2 MB/s eta 0:00:02\n",
      "     --------------------                     12.6/24.4 MB 8.5 MB/s eta 0:00:02\n",
      "     ---------------------                    13.2/24.4 MB 9.2 MB/s eta 0:00:02\n",
      "     ----------------------                   13.7/24.4 MB 9.2 MB/s eta 0:00:02\n",
      "     -----------------------                  14.2/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "     -----------------------                  14.6/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------                 15.1/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------                15.6/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     --------------------------               16.0/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------              16.6/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------             17.2/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------             17.6/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     -----------------------------            18.1/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------           18.7/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------          19.1/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     --------------------------------         19.6/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     --------------------------------         20.0/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        20.5/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       20.9/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       21.3/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      21.7/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     22.1/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     22.4/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    22.8/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   23.5/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.8/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.2/24.4 MB 9.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.4/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.4/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.4/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.4/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  24.4/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 24.4/24.4 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "                                              0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading grpcio-1.54.2-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "                                              0.0/4.1 MB ? eta -:--:--\n",
      "     ------                                   0.6/4.1 MB 13.3 MB/s eta 0:00:01\n",
      "     ----------                               1.0/4.1 MB 11.0 MB/s eta 0:00:01\n",
      "     --------------                           1.5/4.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------                       1.9/4.1 MB 10.2 MB/s eta 0:00:01\n",
      "     ----------------------                   2.3/4.1 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------------              2.8/4.1 MB 10.1 MB/s eta 0:00:01\n",
      "     -------------------------------          3.3/4.1 MB 10.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     3.7/4.1 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.1/4.1 MB 10.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "                                              0.0/5.6 MB ? eta -:--:--\n",
      "     ----                                     0.6/5.6 MB 12.4 MB/s eta 0:00:01\n",
      "     -------                                  1.0/5.6 MB 12.7 MB/s eta 0:00:01\n",
      "     -----------                              1.6/5.6 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------                          2.2/5.6 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------                     2.9/5.6 MB 10.1 MB/s eta 0:00:01\n",
      "     -----------------------                  3.4/5.6 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------              3.9/5.6 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------------------           4.3/5.6 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------        4.8/5.6 MB 10.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     5.2/5.6 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 10.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "                                              0.0/440.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 440.7/440.7 kB 13.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     ----------------                         0.6/1.5 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------           1.1/1.5 MB 12.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 7.9 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "                                              0.0/938.4 kB ? eta -:--:--\n",
      "     ------------                          327.7/938.4 kB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------               593.9/938.4 kB 7.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  931.8/938.4 kB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 938.4/938.4 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "                                              0.0/93.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 93.9/93.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "                                              0.0/151.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.12-py3-none-any.whl size=1498562 sha256=71cfbb99b886f9e86771e4ef1c3d48804893fa660a481cf53d22b470963d5c95\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\ca\\6c\\0b\\dab434867ee492673dd15dbf9f6cce85781b555432a92bfb10\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, opt-einsum, oauthlib, ml-dtypes, h5py, grpcio, google-pasta, gast, absl-py, requests-oauthlib, markdown, jax, astunparse, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.9.0 jax-0.4.12 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.12.3 tensorboard-data-server-0.7.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 wheel-0.40.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 26ms/step - loss: 0.6435 - accuracy: 0.6249 - val_loss: 0.5833 - val_accuracy: 0.6622\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.5106 - accuracy: 0.7520 - val_loss: 0.3799 - val_accuracy: 0.8365\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 16ms/step - loss: 0.4479 - accuracy: 0.7977 - val_loss: 0.3753 - val_accuracy: 0.8440\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4019 - accuracy: 0.8177 - val_loss: 0.3042 - val_accuracy: 0.8891\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3890 - accuracy: 0.8306 - val_loss: 0.3680 - val_accuracy: 0.8465\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3800 - accuracy: 0.8360 - val_loss: 0.3025 - val_accuracy: 0.8749\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.3494 - accuracy: 0.8517 - val_loss: 0.3059 - val_accuracy: 0.8724\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3438 - accuracy: 0.8584 - val_loss: 0.2715 - val_accuracy: 0.8941\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3431 - accuracy: 0.8525 - val_loss: 0.2737 - val_accuracy: 0.8899\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.3309 - accuracy: 0.8602 - val_loss: 0.2798 - val_accuracy: 0.8899\n",
      "CNN Test loss: 0.2797713279724121\n",
      "CNN Test accuracy: 0.8899082541465759\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the directory\n",
    "directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Reshape the input data to match the CNN input shape (n_samples, height, width, channels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def _init_(self):\n",
    "        super(SelfAttention, self)._init_()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(input_shape[-1])\n",
    "        self.key = Dense(input_shape[-1])\n",
    "        self.value = Dense(input_shape[-1])\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_features\n",
    "        \n",
    "# Define the model\n",
    "def get_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 1), activation='softmax', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "   \n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Changed to softmax for multi-class\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "cnn_model = get_cnn_model()\n",
    "cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_score = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('CNN Test loss:', cnn_score[0])\n",
    "print('CNN Test accuracy:', cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\775678391.py\", line 67, in <module>\n      model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [1280,2] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1039820]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m# Create and train the model\u001b[39;00m\n\u001b[0;32m     66\u001b[0m model \u001b[39m=\u001b[39m get_model(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:], np\u001b[39m.\u001b[39munique(labels)\u001b[39m.\u001b[39msize)\n\u001b[1;32m---> 67\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n\u001b[0;32m     69\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m     53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\775678391.py\", line 67, in <module>\n      model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n    File \"c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [1280,2] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1039820]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, TimeDistributed\n",
    "from keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "directory = r'F:\\dains'\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)  # Assuming 2310 is the threshold between the classes\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Attention Mechanism\n",
    "class Attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "# Define the DNN model\n",
    "def get_model(input_shape, output_units):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Dense(units=64, activation='relu'), input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Attention(return_sequences=True))  # Add Attention layer after TimeDistributed Dense\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_units, activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "    # Compile the model with appropriate loss function, optimizer, and metrics\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = get_model(X_train.shape[1:], np.unique(labels).size)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 14s 52ms/step - loss: 0.5227 - accuracy: 0.7428 - val_loss: 0.4743 - val_accuracy: 0.7898\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.4492 - accuracy: 0.7972 - val_loss: 0.4471 - val_accuracy: 0.7932\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 8s 51ms/step - loss: 0.4358 - accuracy: 0.8106 - val_loss: 0.4371 - val_accuracy: 0.8123\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 8s 54ms/step - loss: 0.4260 - accuracy: 0.8150 - val_loss: 0.4447 - val_accuracy: 0.8057\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 9s 57ms/step - loss: 0.4194 - accuracy: 0.8204 - val_loss: 0.4093 - val_accuracy: 0.8165\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.4020 - accuracy: 0.8298 - val_loss: 0.3968 - val_accuracy: 0.8207\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 0.3915 - accuracy: 0.8319 - val_loss: 0.4037 - val_accuracy: 0.8274\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3796 - accuracy: 0.8398 - val_loss: 0.4376 - val_accuracy: 0.8182\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 0.3747 - accuracy: 0.8467 - val_loss: 0.3888 - val_accuracy: 0.8265\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 9s 58ms/step - loss: 0.3667 - accuracy: 0.8458 - val_loss: 0.3712 - val_accuracy: 0.8424\n",
      "Test loss: 0.37117454409599304\n",
      "Test accuracy: 0.8423686623573303\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Flatten, TimeDistributed\n",
    "from keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "# Directory containing the .pt files\n",
    "directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)  # Assuming 2310 is the threshold between the classes\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Attention Mechanism\n",
    "class Attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(Attention,self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(Attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        return K.sum(output, axis=1)\n",
    "\n",
    "# Define the LSTM model\n",
    "def get_model(input_shape, output_units):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Attention(return_sequences=True))  # Add Attention layer after LSTM\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(units=64, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_units, activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "    # Compile the model with appropriate loss function, optimizer, and metrics\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = get_model(X_train.shape[1:], np.unique(labels).size)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 3s 7ms/step - loss: 0.7406 - accuracy: 0.5668 - val_loss: 0.6761 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6718 - accuracy: 0.6097 - val_loss: 0.6749 - val_accuracy: 0.5930\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6661 - accuracy: 0.6133 - val_loss: 0.6716 - val_accuracy: 0.5930\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6620 - accuracy: 0.6218 - val_loss: 0.6687 - val_accuracy: 0.5930\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6593 - accuracy: 0.6164 - val_loss: 0.6629 - val_accuracy: 0.5930\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6565 - accuracy: 0.6204 - val_loss: 0.6576 - val_accuracy: 0.5930\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6499 - accuracy: 0.6256 - val_loss: 0.6504 - val_accuracy: 0.5930\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6440 - accuracy: 0.6333 - val_loss: 0.6553 - val_accuracy: 0.5930\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6471 - accuracy: 0.6300 - val_loss: 0.6492 - val_accuracy: 0.6005\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6384 - accuracy: 0.6379 - val_loss: 0.6387 - val_accuracy: 0.6214\n",
      "CNN Test loss: 0.638651967048645\n",
      "CNN Test accuracy: 0.6213511228561401\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the directory\n",
    "directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "n_components = 10  # The size of the reduced data, tweak this as needed\n",
    "\n",
    "nmf = NMF(n_components=n_components, init='random', random_state=0)\n",
    "\n",
    "# Flatten your data and apply NMF\n",
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "X_train_flat = X_train_flat - np.min(X_train_flat)\n",
    "X_test_flat = X_test_flat - np.min(X_test_flat)\n",
    "\n",
    "X_train_nmf = nmf.fit_transform(X_train_flat)\n",
    "X_test_nmf = nmf.transform(X_test_flat)\n",
    "\n",
    "# Now reshape your data back into 2D\n",
    "X_train = X_train_nmf.reshape(-1, n_components, 1, 1)\n",
    "X_test = X_test_nmf.reshape(-1, n_components, 1, 1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(input_shape[-1])\n",
    "        self.key = Dense(input_shape[-1])\n",
    "        self.value = Dense(input_shape[-1])\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_features\n",
    "        \n",
    "# Define the model\n",
    "def get_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((-1, 64)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Changed to softmax for multi-class\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "cnn_model = get_cnn_model()\n",
    "cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_score = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('CNN Test loss:', cnn_score[0])\n",
    "print('CNN Test accuracy:', cnn_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (1, 40)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\data'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load the MFCC features and corresponding labels from .pt files\n",
    "# Load the MFCC features and corresponding labels from .pt files\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pt\"):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "\n",
    "        data.append(feature.view(1, -1).numpy())\n",
    "        labels.append(int(filename[:-3]))  # Extract the label from the filename\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(1, -1).numpy())\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to match the CNN input shape\n",
    "input_shape = (data[0].shape[1], 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[2], 1)\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Now you can define and train your CNN as before\n",
    "# ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the CNN model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (1, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 40, 1] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 76\u001b[0m\n\u001b[0;32m     72\u001b[0m     model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> 76\u001b[0m cnn_model \u001b[39m=\u001b[39m get_cnn_model()\n\u001b[0;32m     77\u001b[0m cnn_model\u001b[39m.\u001b[39mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n\u001b[0;32m     78\u001b[0m cnn_score \u001b[39m=\u001b[39m cnn_model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[86], line 59\u001b[0m, in \u001b[0;36mget_cnn_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cnn_model\u001b[39m():\n\u001b[0;32m     58\u001b[0m     model \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m---> 59\u001b[0m     model\u001b[39m.\u001b[39;49madd(Conv2D(\u001b[39m32\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)))\n\u001b[0;32m     60\u001b[0m     model\u001b[39m.\u001b[39madd(MaxPooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)))\n\u001b[0;32m     61\u001b[0m     model\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.25\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m try:\n\u001b[0;32m    204\u001b[0m   result = method(self, *args, **kwargs)\n\u001b[1;32m--> 205\u001b[0m finally:\n\u001b[0;32m    206\u001b[0m   self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n\u001b[0;32m    207\u001b[0m return result\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 1, 40, 1] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(1, -1).numpy())\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to match the CNN input shape\n",
    "input_shape = (data[0].shape[1], 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[2], 1)\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Now you can define and train your CNN as before\n",
    "# ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(data[0].shape[0], data[0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn_model = get_cnn_model()\n",
    "cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "cnn_score = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('CNN Test loss:', cnn_score[0])\n",
    "print('CNN Test accuracy:', cnn_score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\data'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5994):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(output_directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2311 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 6ms/step - loss: 0.3505 - accuracy: 0.8561\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2643 - accuracy: 0.8995\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2451 - accuracy: 0.9077\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2182 - accuracy: 0.9182\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2044 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1964 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9301\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9290\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9323\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9375\n",
      "Score for fold 1: loss of 0.21882927417755127; accuracy of 92.166668176651%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 7ms/step - loss: 0.4206 - accuracy: 0.8405\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2580 - accuracy: 0.9012\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2252 - accuracy: 0.9151\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.2080 - accuracy: 0.9225\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9229\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1928 - accuracy: 0.9281\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1799 - accuracy: 0.9353\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9401\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9407\n",
      "Score for fold 2: loss of 0.2675410509109497; accuracy of 90.66666960716248%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 5ms/step - loss: 0.4579 - accuracy: 0.8331\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2863 - accuracy: 0.8893\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2462 - accuracy: 0.9112\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2375 - accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2153 - accuracy: 0.9234\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9218\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1954 - accuracy: 0.9264\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1889 - accuracy: 0.9284\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1830 - accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9355\n",
      "Score for fold 3: loss of 0.18807533383369446; accuracy of 92.33333468437195%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 6ms/step - loss: 0.4310 - accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2528 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2273 - accuracy: 0.9153\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2165 - accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2048 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1960 - accuracy: 0.9286\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1950 - accuracy: 0.9303\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9355\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9349\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1592 - accuracy: 0.9442\n",
      "Score for fold 4: loss of 0.20940279960632324; accuracy of 92.3205316066742%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 6ms/step - loss: 0.4211 - accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2668 - accuracy: 0.8978\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2418 - accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2203 - accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2127 - accuracy: 0.9169\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9257\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1940 - accuracy: 0.9271\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.9360\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9377\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1564 - accuracy: 0.9461\n",
      "Score for fold 5: loss of 0.23818564414978027; accuracy of 91.65275692939758%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8330\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2497 - accuracy: 0.9038\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2214 - accuracy: 0.9210\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9214\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9214\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9360\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1757 - accuracy: 0.9334\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1611 - accuracy: 0.9422\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1524 - accuracy: 0.9448\n",
      "Score for fold 6: loss of 0.27194729447364807; accuracy of 90.4841423034668%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.3898 - accuracy: 0.8435\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2543 - accuracy: 0.8997\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2291 - accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2029 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9325\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.9410\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9410\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9451\n",
      "Score for fold 7: loss of 0.2685133218765259; accuracy of 90.65108299255371%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 6ms/step - loss: 0.3858 - accuracy: 0.8417\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2487 - accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2292 - accuracy: 0.9151\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2153 - accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1990 - accuracy: 0.9303\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.9321\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1787 - accuracy: 0.9344\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1662 - accuracy: 0.9418\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9466\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1426 - accuracy: 0.9490\n",
      "Score for fold 8: loss of 0.24607716500759125; accuracy of 91.3188636302948%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 5ms/step - loss: 0.4096 - accuracy: 0.8432\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2461 - accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9232\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9234\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1920 - accuracy: 0.9316\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1806 - accuracy: 0.9355\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1713 - accuracy: 0.9385\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.9425\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.9407\n",
      "Score for fold 9: loss of 0.27814167737960815; accuracy of 89.81636166572571%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4654 - accuracy: 0.8213\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2624 - accuracy: 0.9032\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9106\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2253 - accuracy: 0.9160\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2062 - accuracy: 0.9251\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2029 - accuracy: 0.9229\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1961 - accuracy: 0.9271\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1851 - accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1790 - accuracy: 0.9329\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1647 - accuracy: 0.9396\n",
      "Score for fold 10: loss of 0.24361158907413483; accuracy of 90.4841423034668%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(output_directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(directory):  \u001b[39m# Ensure the file exists in the directory\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     feature \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_directory, filename))\n\u001b[0;32m     25\u001b[0m     \u001b[39m# Reshape the feature to a 2D array with a single row and 40 columns\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     data\u001b[39m.\u001b[39mappend(feature\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnumpy())  \u001b[39m# Adjusted this line\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_directory' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize total and count to keep track of total accuracy and number of samples\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "\n",
    "total_acc = 0\n",
    "count = 0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    # Keep track of total accuracy and number of samples\n",
    "    total_acc += scores[1] * len(test)\n",
    "    count += len(test)\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# Compute the overall weighted accuracy\n",
    "overall_acc = total_acc / count\n",
    "print(f'Overall accuracy: {overall_acc*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.3911 - accuracy: 0.8481\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2460 - accuracy: 0.9080\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2161 - accuracy: 0.9206\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9319\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1842 - accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1695 - accuracy: 0.9381\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1639 - accuracy: 0.9418\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.9436\n",
      "Score for fold 1: loss of 0.2617400884628296; accuracy of 89.49999809265137%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.4040 - accuracy: 0.8405\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2638 - accuracy: 0.8969\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2551 - accuracy: 0.9041\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2294 - accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9331\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1912 - accuracy: 0.9319\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9394\n",
      "Score for fold 2: loss of 0.2178260236978531; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.3870 - accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2516 - accuracy: 0.9043\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2408 - accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.9184\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9243\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1902 - accuracy: 0.9321\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1813 - accuracy: 0.9340\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1691 - accuracy: 0.9401\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.9472\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1468 - accuracy: 0.9477\n",
      "Score for fold 3: loss of 0.251756489276886; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.3834 - accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2476 - accuracy: 0.9053\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2271 - accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.2057 - accuracy: 0.9258\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1958 - accuracy: 0.9297\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 8ms/step - loss: 0.1820 - accuracy: 0.9338\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1722 - accuracy: 0.9418\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1574 - accuracy: 0.9425\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1452 - accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1373 - accuracy: 0.9503\n",
      "Score for fold 4: loss of 0.1910034716129303; accuracy of 92.98831224441528%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.3915 - accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.2532 - accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2152 - accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9225\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1922 - accuracy: 0.9323\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1867 - accuracy: 0.9314\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9314\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9364\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9433\n",
      "Score for fold 5: loss of 0.19666515290737152; accuracy of 92.3205316066742%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 5ms/step - loss: 0.4012 - accuracy: 0.8459\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2569 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2360 - accuracy: 0.9099\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2188 - accuracy: 0.9207\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2058 - accuracy: 0.9249\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1973 - accuracy: 0.9268\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9283\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9344\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9318\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1606 - accuracy: 0.9429\n",
      "Score for fold 6: loss of 0.2475574016571045; accuracy of 92.82137155532837%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 5ms/step - loss: 0.3501 - accuracy: 0.8641\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9190\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.9307\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9342\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1728 - accuracy: 0.9327\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1562 - accuracy: 0.9427\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1454 - accuracy: 0.9483\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1338 - accuracy: 0.9516\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1295 - accuracy: 0.9525\n",
      "Score for fold 7: loss of 0.35150986909866333; accuracy of 88.81469368934631%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 6ms/step - loss: 0.3927 - accuracy: 0.8478\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.9049\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2230 - accuracy: 0.9169\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2074 - accuracy: 0.9234\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1958 - accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1816 - accuracy: 0.9342\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9390\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1679 - accuracy: 0.9392\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1535 - accuracy: 0.9425\n",
      "Score for fold 8: loss of 0.22604013979434967; accuracy of 91.15191698074341%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.4028 - accuracy: 0.8450\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.2520 - accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2333 - accuracy: 0.9142\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2193 - accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2034 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 6ms/step - loss: 0.1989 - accuracy: 0.9258\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1851 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1802 - accuracy: 0.9288\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9377\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9401\n",
      "Score for fold 9: loss of 0.2645578682422638; accuracy of 90.8180296421051%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/10\n",
      "169/169 [==============================] - 2s 5ms/step - loss: 0.4081 - accuracy: 0.8346\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2589 - accuracy: 0.8986\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9079\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.9177\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9320\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1847 - accuracy: 0.9320\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 1s 7ms/step - loss: 0.1785 - accuracy: 0.9301\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 1s 5ms/step - loss: 0.1638 - accuracy: 0.9386\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9425\n",
      "Score for fold 10: loss of 0.24329747259616852; accuracy of 91.65275692939758%\n",
      "Overall accuracy: 91.3398967488628%\n"
     ]
    }
   ],
   "source": [
    "# Initialize total and count to keep track of total accuracy and number of samples\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(output_directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "\n",
    "total_acc = 0\n",
    "count = 0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    # Keep track of total accuracy and number of samples\n",
    "    total_acc += scores[1] * len(test)\n",
    "    count += len(test)\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# Compute the overall weighted accuracy\n",
    "overall_acc = total_acc / count\n",
    "print(f'Overall accuracy: {overall_acc*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.8265\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2544 - accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9181\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2031 - accuracy: 0.9242\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9332\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1716 - accuracy: 0.9334\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9474\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9512\n",
      "Score for fold 1: loss of 0.2931080162525177; accuracy of 90.14014005661011%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.4125 - accuracy: 0.8240\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2608 - accuracy: 0.8996\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9089\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9229\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9234\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9189\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9277\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9327\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9369\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9419\n",
      "Score for fold 2: loss of 0.2258950024843216; accuracy of 91.19119048118591%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.8163\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2673 - accuracy: 0.8986\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1999 - accuracy: 0.9302\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1821 - accuracy: 0.9332\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.1830 - accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1693 - accuracy: 0.9389\n",
      "Score for fold 3: loss of 0.23827499151229858; accuracy of 91.18677973747253%\n",
      "Overall accuracy: 90.8393121225178%\n"
     ]
    }
   ],
   "source": [
    "# Initialize total and count to keep track of total accuracy and number of samples\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "\n",
    "total_acc = 0\n",
    "count = 0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    # Keep track of total accuracy and number of samples\n",
    "    total_acc += scores[1] * len(test)\n",
    "    count += len(test)\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# Compute the overall weighted accuracy\n",
    "overall_acc = total_acc / count\n",
    "print(f'Overall accuracy: {overall_acc*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5994,)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8519\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.9068\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9183\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9232\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9296\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9415\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1563 - accuracy: 0.9451\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9471\n",
      "Score for fold 1: loss of 0.21111410856246948; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9070\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2266 - accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2134 - accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9255\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1713 - accuracy: 0.9388\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1633 - accuracy: 0.9429\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1482 - accuracy: 0.9449\n",
      "Score for fold 2: loss of 0.23037000000476837; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.5036 - accuracy: 0.8352\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2384 - accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1957 - accuracy: 0.9259\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1764 - accuracy: 0.9341\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9393\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9439\n",
      "Score for fold 3: loss of 0.3531700074672699; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8320\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2550 - accuracy: 0.9024\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.9102\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9206\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9304\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9371\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1763 - accuracy: 0.9343\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1738 - accuracy: 0.9353\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9419\n",
      "WARNING:tensorflow:5 out of the last 70 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EFDE10A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 4: loss of 0.38954082131385803; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3778 - accuracy: 0.8477\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2591 - accuracy: 0.9001\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2411 - accuracy: 0.9078\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9233\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2088 - accuracy: 0.9213\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9302\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9282\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9373\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1740 - accuracy: 0.9343\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9414\n",
      "WARNING:tensorflow:6 out of the last 72 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011E8FAF31F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Score for fold 5: loss of 0.2863517105579376; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3535 - accuracy: 0.8583\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2465 - accuracy: 0.9063\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2248 - accuracy: 0.9152\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9225\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9267\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1824 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9355\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1611 - accuracy: 0.9424\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9432\n",
      "Score for fold 6: loss of 0.16656634211540222; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2558 - accuracy: 0.9038\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2263 - accuracy: 0.9135\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9196\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2087 - accuracy: 0.9233\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9299\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9397\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9407\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9473\n",
      "Score for fold 7: loss of 0.13620737195014954; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.8477\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.9055\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9184\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9274\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9306\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1759 - accuracy: 0.9358\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9361\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9405\n",
      "Score for fold 8: loss of 0.3430894911289215; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4035 - accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9021\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9311\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.9353\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9432\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.9449\n",
      "Score for fold 9: loss of 0.14949382841587067; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3841 - accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2303 - accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2176 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9277\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9361\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1754 - accuracy: 0.9338\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9400\n",
      "Score for fold 10: loss of 0.21314172446727753; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 11 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3860 - accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2602 - accuracy: 0.8996\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9176\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9314\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9356\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1684 - accuracy: 0.9376\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1619 - accuracy: 0.9397\n",
      "Score for fold 11: loss of 0.14728450775146484; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 12 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.8311\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2516 - accuracy: 0.9034\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2114 - accuracy: 0.9183\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9265\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9311\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9425\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9473\n",
      "Score for fold 12: loss of 0.2766883671283722; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 13 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8556\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2733 - accuracy: 0.8947\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2247 - accuracy: 0.9191\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9331\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1810 - accuracy: 0.9324\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9422\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9457\n",
      "Score for fold 13: loss of 0.457619309425354; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 14 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 5ms/step - loss: 0.3502 - accuracy: 0.8622\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2520 - accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9125\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9238\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9277\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9376\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1668 - accuracy: 0.9358\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9403\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9466\n",
      "Score for fold 14: loss of 0.13194085657596588; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 15 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4032 - accuracy: 0.8466\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.9088\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2289 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9169\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9200\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9279\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9331\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1758 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1657 - accuracy: 0.9398\n",
      "Score for fold 15: loss of 0.16682776808738708; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 16 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3881 - accuracy: 0.8544\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2434 - accuracy: 0.9114\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2330 - accuracy: 0.9166\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2063 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9304\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9324\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9366\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9424\n",
      "Score for fold 16: loss of 0.4614604413509369; accuracy of 83.33333134651184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 17 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3782 - accuracy: 0.8495\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.8997\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2338 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9183\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1956 - accuracy: 0.9279\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1872 - accuracy: 0.9316\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9319\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1707 - accuracy: 0.9346\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1604 - accuracy: 0.9414\n",
      "Score for fold 17: loss of 0.2793932855129242; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 18 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2653 - accuracy: 0.8952\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2348 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9157\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9269\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1926 - accuracy: 0.9309\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9301\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9353\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1711 - accuracy: 0.9353\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9410\n",
      "Score for fold 18: loss of 0.22579330205917358; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 19 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3829 - accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2482 - accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9171\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9243\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1917 - accuracy: 0.9302\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9358\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1665 - accuracy: 0.9400\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1605 - accuracy: 0.9397\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1527 - accuracy: 0.9451\n",
      "Score for fold 19: loss of 0.19920164346694946; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 20 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3529 - accuracy: 0.8569\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2293 - accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1977 - accuracy: 0.9274\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1767 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9427\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9432\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1468 - accuracy: 0.9476\n",
      "Score for fold 20: loss of 0.22664876282215118; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 21 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8576\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.9006\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9080\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.9184\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2036 - accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1812 - accuracy: 0.9319\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9380\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1635 - accuracy: 0.9370\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9420\n",
      "Score for fold 21: loss of 0.2503429353237152; accuracy of 83.33333134651184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 22 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3929 - accuracy: 0.8419\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9070\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2178 - accuracy: 0.9198\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2008 - accuracy: 0.9225\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.9306\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1757 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1649 - accuracy: 0.9387\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1622 - accuracy: 0.9412\n",
      "Score for fold 22: loss of 0.1821063607931137; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 23 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3797 - accuracy: 0.8529\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2497 - accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2346 - accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9205\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2047 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9311\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9363\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1502 - accuracy: 0.9471\n",
      "Score for fold 23: loss of 0.3396894633769989; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 24 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.8357\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.9014\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.9080\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9248\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1967 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1837 - accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1801 - accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9407\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1559 - accuracy: 0.9420\n",
      "Score for fold 24: loss of 0.36226481199264526; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 25 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4137 - accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9070\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.9122\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2253 - accuracy: 0.9139\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9201\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9294\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9323\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1701 - accuracy: 0.9376\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9392\n",
      "Score for fold 25: loss of 0.42585232853889465; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 26 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8443\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2275 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9289\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9398\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9434\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9442\n",
      "Score for fold 26: loss of 0.4630762040615082; accuracy of 85.00000238418579%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 27 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3949 - accuracy: 0.8455\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2569 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.9107\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.9189\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9232\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9309\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.9312\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9383\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9405\n",
      "Score for fold 27: loss of 0.08440900593996048; accuracy of 98.33333492279053%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 28 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.3575 - accuracy: 0.8532\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2516 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2213 - accuracy: 0.9176\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1889 - accuracy: 0.9323\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1807 - accuracy: 0.9316\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9370\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1577 - accuracy: 0.9437\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9467\n",
      "Score for fold 28: loss of 0.40728047490119934; accuracy of 83.33333134651184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 29 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.8431\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9053\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2348 - accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9146\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9292\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9328\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1780 - accuracy: 0.9338\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1549 - accuracy: 0.9447\n",
      "Score for fold 29: loss of 0.16361592710018158; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 30 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4117 - accuracy: 0.8345\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2521 - accuracy: 0.9063\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9115\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9270\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9282\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9382\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9380\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9488\n",
      "Score for fold 30: loss of 0.17201866209506989; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 31 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3687 - accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9028\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2063 - accuracy: 0.9215\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1974 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9368\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9397\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9437\n",
      "Score for fold 31: loss of 0.06875424087047577; accuracy of 100.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 32 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4114 - accuracy: 0.8362\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2165 - accuracy: 0.9168\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9213\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9284\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1844 - accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1790 - accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9390\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1545 - accuracy: 0.9429\n",
      "Score for fold 32: loss of 0.15644697844982147; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 33 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8446\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2504 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2285 - accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2091 - accuracy: 0.9211\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1978 - accuracy: 0.9285\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9317\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9392\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1652 - accuracy: 0.9380\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9417\n",
      "Score for fold 33: loss of 0.13035914301872253; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 34 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8365\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2456 - accuracy: 0.9070\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2303 - accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9221\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9307\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1850 - accuracy: 0.9312\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9378\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1617 - accuracy: 0.9407\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9447\n",
      "Score for fold 34: loss of 0.19980113208293915; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 35 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8564\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9221\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9264\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9302\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9314\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1681 - accuracy: 0.9368\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9432\n",
      "Score for fold 35: loss of 0.17469361424446106; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 36 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.8962\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9105\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9179\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9284\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1877 - accuracy: 0.9324\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1808 - accuracy: 0.9319\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9385\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9405\n",
      "Score for fold 36: loss of 0.4025578498840332; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 37 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 5ms/step - loss: 0.3525 - accuracy: 0.8613\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2364 - accuracy: 0.9103\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2299 - accuracy: 0.9171\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.9243\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1948 - accuracy: 0.9277\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1844 - accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9326\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1690 - accuracy: 0.9385\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1610 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1465 - accuracy: 0.9447\n",
      "Score for fold 37: loss of 0.28253307938575745; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 38 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3768 - accuracy: 0.8475\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2279 - accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1940 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1869 - accuracy: 0.9306\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1758 - accuracy: 0.9356\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9360\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9447\n",
      "Score for fold 38: loss of 0.2203318178653717; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 39 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2591 - accuracy: 0.9009\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2253 - accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9316\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1898 - accuracy: 0.9297\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1729 - accuracy: 0.9360\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9410\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1625 - accuracy: 0.9392\n",
      "Score for fold 39: loss of 0.4052288830280304; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 40 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.8475\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2444 - accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2413 - accuracy: 0.9088\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2089 - accuracy: 0.9208\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1944 - accuracy: 0.9289\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1881 - accuracy: 0.9289\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1843 - accuracy: 0.9331\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1763 - accuracy: 0.9353\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1627 - accuracy: 0.9388\n",
      "Score for fold 40: loss of 0.37499016523361206; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 41 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8605\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2551 - accuracy: 0.9006\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2068 - accuracy: 0.9205\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9323\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1784 - accuracy: 0.9331\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9400\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9479\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9491\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1272 - accuracy: 0.9560\n",
      "Score for fold 41: loss of 0.17662878334522247; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 42 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2652 - accuracy: 0.8999\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9122\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2200 - accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2130 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9277\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9279\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9316\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1698 - accuracy: 0.9346\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9387\n",
      "Score for fold 42: loss of 0.21651922166347504; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 43 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3868 - accuracy: 0.8495\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2548 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2251 - accuracy: 0.9127\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1924 - accuracy: 0.9294\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1841 - accuracy: 0.9331\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9338\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9373\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9402\n",
      "Score for fold 43: loss of 0.15363970398902893; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 44 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3886 - accuracy: 0.8446\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2592 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2294 - accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9291\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9341\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9452\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9474\n",
      "Score for fold 44: loss of 0.20658248662948608; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 45 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3508 - accuracy: 0.8557\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2518 - accuracy: 0.9065\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2309 - accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9228\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1861 - accuracy: 0.9306\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1793 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9393\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1599 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1508 - accuracy: 0.9454\n",
      "Score for fold 45: loss of 0.3146298825740814; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 46 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2505 - accuracy: 0.9051\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2234 - accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9220\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2006 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1889 - accuracy: 0.9311\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1673 - accuracy: 0.9403\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1631 - accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9442\n",
      "Score for fold 46: loss of 0.2753826677799225; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 47 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3955 - accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2463 - accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2265 - accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9289\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9296\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.9309\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9350\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1564 - accuracy: 0.9419\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.9462\n",
      "Score for fold 47: loss of 0.23645184934139252; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 48 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8610\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9039\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2061 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9259\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9326\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9334\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9373\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9412\n",
      "Score for fold 48: loss of 0.20677687227725983; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 49 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2541 - accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9238\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2003 - accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9304\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9361\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9356\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9397\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9434\n",
      "Score for fold 49: loss of 0.31441450119018555; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 50 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8561\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2276 - accuracy: 0.9135\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9198\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9230\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1956 - accuracy: 0.9267\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1869 - accuracy: 0.9317\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1631 - accuracy: 0.9390\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9439\n",
      "Score for fold 50: loss of 0.0823480412364006; accuracy of 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 51 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.8561\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2489 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9211\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9272\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9343\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1765 - accuracy: 0.9361\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9434\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9444\n",
      "Score for fold 51: loss of 0.18355263769626617; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 52 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.8465\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2693 - accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2313 - accuracy: 0.9103\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2135 - accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2058 - accuracy: 0.9221\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1970 - accuracy: 0.9240\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1831 - accuracy: 0.9319\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1847 - accuracy: 0.9299\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9383\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9414\n",
      "Score for fold 52: loss of 0.3365652859210968; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 53 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8411\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9080\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2254 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9269\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9269\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1710 - accuracy: 0.9370\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9430\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9437\n",
      "Score for fold 53: loss of 0.2786998450756073; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 54 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8394\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2509 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9115\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9306\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1829 - accuracy: 0.9371\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9321\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9439\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.9434\n",
      "Score for fold 54: loss of 0.2764461636543274; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 55 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8386\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2524 - accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9114\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9292\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.9316\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1804 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9366\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1599 - accuracy: 0.9419\n",
      "Score for fold 55: loss of 0.2423354834318161; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 56 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8404\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2538 - accuracy: 0.9019\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9144\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2230 - accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2098 - accuracy: 0.9203\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9292\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1884 - accuracy: 0.9279\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9360\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9370\n",
      "Score for fold 56: loss of 0.11220084875822067; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 57 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8628\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2424 - accuracy: 0.9092\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2096 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1957 - accuracy: 0.9284\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1902 - accuracy: 0.9267\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1779 - accuracy: 0.9338\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9385\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1621 - accuracy: 0.9437\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9437\n",
      "Score for fold 57: loss of 0.4139217138290405; accuracy of 83.33333134651184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 58 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8477\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2476 - accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9220\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1909 - accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1783 - accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1642 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1609 - accuracy: 0.9420\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9491\n",
      "Score for fold 58: loss of 0.2536061704158783; accuracy of 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 59 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4070 - accuracy: 0.8446\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8970\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2285 - accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9226\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9296\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9317\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1705 - accuracy: 0.9350\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9408\n",
      "Score for fold 59: loss of 0.24187514185905457; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 60 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3956 - accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2574 - accuracy: 0.9001\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9144\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9193\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9201\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1958 - accuracy: 0.9257\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1856 - accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1803 - accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9373\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1626 - accuracy: 0.9405\n",
      "Score for fold 60: loss of 0.12873810529708862; accuracy of 98.33333492279053%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 61 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8524\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2213 - accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9193\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2010 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9282\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1767 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9360\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1572 - accuracy: 0.9425\n",
      "Score for fold 61: loss of 0.29339540004730225; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 62 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.8215\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2502 - accuracy: 0.9065\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2235 - accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9232\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2006 - accuracy: 0.9270\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1882 - accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.9343\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1518 - accuracy: 0.9462\n",
      "Score for fold 62: loss of 0.4516305923461914; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 63 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4313 - accuracy: 0.8411\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2624 - accuracy: 0.8974\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2327 - accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2218 - accuracy: 0.9171\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9223\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9291\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1930 - accuracy: 0.9291\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1892 - accuracy: 0.9311\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1747 - accuracy: 0.9350\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1624 - accuracy: 0.9410\n",
      "Score for fold 63: loss of 0.28592929244041443; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 64 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8418\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2493 - accuracy: 0.9018\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2095 - accuracy: 0.9183\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9213\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1888 - accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1741 - accuracy: 0.9351\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9434\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1458 - accuracy: 0.9441\n",
      "Score for fold 64: loss of 0.10426754504442215; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 65 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8426\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2591 - accuracy: 0.9033\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2511 - accuracy: 0.9098\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9127\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2052 - accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1926 - accuracy: 0.9301\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1766 - accuracy: 0.9328\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1753 - accuracy: 0.9344\n",
      "Score for fold 65: loss of 0.12086819112300873; accuracy of 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 66 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8551\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2367 - accuracy: 0.9105\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2223 - accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2116 - accuracy: 0.9230\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9285\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1815 - accuracy: 0.9331\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1660 - accuracy: 0.9407\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1635 - accuracy: 0.9378\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1499 - accuracy: 0.9432\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1367 - accuracy: 0.9530\n",
      "Score for fold 66: loss of 0.1486974060535431; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 67 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.8487\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2498 - accuracy: 0.9073\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2296 - accuracy: 0.9119\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2073 - accuracy: 0.9206\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1869 - accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1792 - accuracy: 0.9360\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1741 - accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9366\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1517 - accuracy: 0.9437\n",
      "Score for fold 67: loss of 0.5325979590415955; accuracy of 85.00000238418579%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 68 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2493 - accuracy: 0.9066\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9171\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9215\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2010 - accuracy: 0.9243\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1996 - accuracy: 0.9235\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.9311\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1723 - accuracy: 0.9380\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9378\n",
      "Score for fold 68: loss of 0.1460273563861847; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 69 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8357\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2619 - accuracy: 0.8997\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2322 - accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9179\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.9267\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1943 - accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.9341\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.9397\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1569 - accuracy: 0.9437\n",
      "Score for fold 69: loss of 0.18336637318134308; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 70 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.8295\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2548 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2357 - accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9208\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2025 - accuracy: 0.9252\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1846 - accuracy: 0.9314\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9366\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1746 - accuracy: 0.9376\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9424\n",
      "Score for fold 70: loss of 0.24433112144470215; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 71 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8482\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2486 - accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2341 - accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.1894 - accuracy: 0.9299\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9339\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1827 - accuracy: 0.9307\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9405\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9405\n",
      "Score for fold 71: loss of 0.23002977669239044; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 72 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.4391 - accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2589 - accuracy: 0.9012\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2233 - accuracy: 0.9166\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2092 - accuracy: 0.9243\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1927 - accuracy: 0.9262\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1814 - accuracy: 0.9324\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1779 - accuracy: 0.9350\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9449\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9441\n",
      "Score for fold 72: loss of 0.16294094920158386; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 73 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3905 - accuracy: 0.8463\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2447 - accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2197 - accuracy: 0.9166\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9235\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2012 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.9346\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9407\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1625 - accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9451\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9506\n",
      "Score for fold 73: loss of 0.604982316493988; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 74 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4173 - accuracy: 0.8455\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2565 - accuracy: 0.9014\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.9173\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2160 - accuracy: 0.9205\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9274\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9260\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1825 - accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1755 - accuracy: 0.9376\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1715 - accuracy: 0.9373\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.9414\n",
      "Score for fold 74: loss of 0.3527633249759674; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 75 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.8996\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2367 - accuracy: 0.9102\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2174 - accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.2071 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1984 - accuracy: 0.9247\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1909 - accuracy: 0.9270\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1707 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1571 - accuracy: 0.9437\n",
      "Score for fold 75: loss of 0.13250617682933807; accuracy of 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 76 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 5ms/step - loss: 0.3959 - accuracy: 0.8399\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.9075\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2395 - accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2179 - accuracy: 0.9184\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2028 - accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1994 - accuracy: 0.9252\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1858 - accuracy: 0.9319\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9338\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1715 - accuracy: 0.9368\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1605 - accuracy: 0.9403\n",
      "Score for fold 76: loss of 0.41512787342071533; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 77 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 5ms/step - loss: 0.4799 - accuracy: 0.8155\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2590 - accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2321 - accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9233\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9240\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2014 - accuracy: 0.9253\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1889 - accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1850 - accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1702 - accuracy: 0.9393\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9454\n",
      "Score for fold 77: loss of 0.28039953112602234; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 78 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8517\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9034\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2274 - accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2334 - accuracy: 0.9146\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2094 - accuracy: 0.9215\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9252\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9291\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1867 - accuracy: 0.9282\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9350\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1667 - accuracy: 0.9387\n",
      "Score for fold 78: loss of 0.1357629895210266; accuracy of 96.66666388511658%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 79 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3808 - accuracy: 0.8505\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2597 - accuracy: 0.9018\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2311 - accuracy: 0.9125\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2159 - accuracy: 0.9203\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9363\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9346\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9425\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1555 - accuracy: 0.9474\n",
      "Score for fold 79: loss of 0.18205475807189941; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 80 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8451\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2350 - accuracy: 0.9102\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9247\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1864 - accuracy: 0.9326\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9380\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9380\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.9429\n",
      "Score for fold 80: loss of 0.17963913083076477; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 81 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3828 - accuracy: 0.8450\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2456 - accuracy: 0.9098\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9216\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2028 - accuracy: 0.9221\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9311\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9361\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9429\n",
      "Score for fold 81: loss of 0.36550724506378174; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 82 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3963 - accuracy: 0.8492\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2474 - accuracy: 0.9050\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2303 - accuracy: 0.9147\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1952 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9370\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9382\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.9442\n",
      "Score for fold 82: loss of 0.1964794248342514; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 83 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.8697\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2397 - accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2189 - accuracy: 0.9193\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9226\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1972 - accuracy: 0.9306\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1856 - accuracy: 0.9321\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9338\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9462\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1402 - accuracy: 0.9479\n",
      "Score for fold 83: loss of 0.32632988691329956; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 84 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 2s 5ms/step - loss: 0.3611 - accuracy: 0.8564\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2561 - accuracy: 0.9028\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2227 - accuracy: 0.9196\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2111 - accuracy: 0.9232\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9272\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9240\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.9306\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1761 - accuracy: 0.9344\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.9410\n",
      "Score for fold 84: loss of 0.35636916756629944; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 85 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.8574\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.2464 - accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2374 - accuracy: 0.9087\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9242\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1936 - accuracy: 0.9309\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1817 - accuracy: 0.9329\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1754 - accuracy: 0.9329\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1595 - accuracy: 0.9454\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.9494\n",
      "Score for fold 85: loss of 0.2992566227912903; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 86 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2586 - accuracy: 0.9009\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2277 - accuracy: 0.9176\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9208\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2013 - accuracy: 0.9264\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1879 - accuracy: 0.9296\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1793 - accuracy: 0.9343\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1709 - accuracy: 0.9373\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1541 - accuracy: 0.9446\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1472 - accuracy: 0.9452\n",
      "Score for fold 86: loss of 0.3402791917324066; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 87 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4259 - accuracy: 0.8365\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2549 - accuracy: 0.9034\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2287 - accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2143 - accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9243\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9280\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1804 - accuracy: 0.9338\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9376\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9417\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1589 - accuracy: 0.9415\n",
      "Score for fold 87: loss of 0.25387483835220337; accuracy of 93.33333373069763%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 88 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2531 - accuracy: 0.9001\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9166\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2172 - accuracy: 0.9176\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2002 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1881 - accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1718 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9419\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1566 - accuracy: 0.9432\n",
      "Score for fold 88: loss of 0.09543456882238388; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 89 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8227\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2646 - accuracy: 0.8952\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2326 - accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9161\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2090 - accuracy: 0.9201\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2023 - accuracy: 0.9257\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1973 - accuracy: 0.9259\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1828 - accuracy: 0.9334\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9348\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1681 - accuracy: 0.9344\n",
      "Score for fold 89: loss of 0.061563003808259964; accuracy of 98.33333492279053%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 90 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4836 - accuracy: 0.8340\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2431 - accuracy: 0.9097\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9120\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1929 - accuracy: 0.9255\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9270\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1806 - accuracy: 0.9311\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9368\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1623 - accuracy: 0.9402\n",
      "Score for fold 90: loss of 0.1978079378604889; accuracy of 94.9999988079071%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 91 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8453\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2642 - accuracy: 0.9038\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2309 - accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9119\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.9270\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1994 - accuracy: 0.9240\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.9309\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1659 - accuracy: 0.9402\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1512 - accuracy: 0.9466\n",
      "Score for fold 91: loss of 0.2545378506183624; accuracy of 86.66666746139526%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 92 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3605 - accuracy: 0.8547\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9095\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2207 - accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1864 - accuracy: 0.9274\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1752 - accuracy: 0.9331\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1656 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1481 - accuracy: 0.9447\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9466\n",
      "Score for fold 92: loss of 0.31553414463996887; accuracy of 89.99999761581421%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 93 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.8322\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2608 - accuracy: 0.9024\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.9098\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9171\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9216\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9294\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1966 - accuracy: 0.9284\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1912 - accuracy: 0.9296\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9348\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1607 - accuracy: 0.9425\n",
      "Score for fold 93: loss of 0.21768483519554138; accuracy of 91.66666865348816%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 94 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.8271\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2581 - accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2286 - accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1899 - accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1853 - accuracy: 0.9311\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1765 - accuracy: 0.9355\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9430\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1605 - accuracy: 0.9429\n",
      "Score for fold 94: loss of 0.25703954696655273; accuracy of 88.33333253860474%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 95 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3743 - accuracy: 0.8588\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2478 - accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2289 - accuracy: 0.9171\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2198 - accuracy: 0.9196\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1994 - accuracy: 0.9270\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1984 - accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1966 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1803 - accuracy: 0.9323\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9410\n",
      "Score for fold 95: loss of 0.26326364278793335; accuracy of 91.52542352676392%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 96 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8590\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2468 - accuracy: 0.9028\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9208\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9282\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9361\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1624 - accuracy: 0.9387\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1596 - accuracy: 0.9442\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1517 - accuracy: 0.9464\n",
      "Score for fold 96: loss of 0.20415517687797546; accuracy of 94.91525292396545%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 97 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8482\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2415 - accuracy: 0.9077\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9169\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9240\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9291\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.9307\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1766 - accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9425\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1566 - accuracy: 0.9410\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1496 - accuracy: 0.9459\n",
      "Score for fold 97: loss of 0.43520334362983704; accuracy of 88.13559412956238%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 98 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.3761 - accuracy: 0.8564\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2421 - accuracy: 0.9112\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2349 - accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1914 - accuracy: 0.9281\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1772 - accuracy: 0.9353\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1662 - accuracy: 0.9392\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9425\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9457\n",
      "Score for fold 98: loss of 0.2715185582637787; accuracy of 86.44067645072937%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 99 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.4016 - accuracy: 0.8352\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2490 - accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2233 - accuracy: 0.9152\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1951 - accuracy: 0.9269\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1896 - accuracy: 0.9274\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1717 - accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.9420\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.9452\n",
      "Score for fold 99: loss of 0.2432396113872528; accuracy of 86.44067645072937%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 100 ...\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8605\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9124\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2226 - accuracy: 0.9161\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9233\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1845 - accuracy: 0.9328\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.1738 - accuracy: 0.9336\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1703 - accuracy: 0.9378\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9425\n",
      "Score for fold 100: loss of 0.18197229504585266; accuracy of 94.91525292396545%\n",
      "Overall accuracy: 91.20787428166814%\n"
     ]
    }
   ],
   "source": [
    "# Initialize total and count to keep track of total accuracy and number of samples\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "directory = r'F:\\data'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5994):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(output_directory, filename))\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2311 else 0)\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "# Now you should be able to get a 3D shape from each element in data\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# The input shape will now be (40, 1)\n",
    "input_shape = (data[0].shape[0], data[0].shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(labels))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=100, shuffle=True)\n",
    "\n",
    "\n",
    "total_acc = 0\n",
    "count = 0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(data, labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train_fold = keras.utils.to_categorical(labels[train], num_classes)\n",
    "    y_test_fold = keras.utils.to_categorical(labels[test], num_classes)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model.fit(data[train], y_train_fold, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(data[test], y_test_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    # Keep track of total accuracy and number of samples\n",
    "    total_acc += scores[1] * len(test)\n",
    "    count += len(test)\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# Compute the overall weighted accuracy\n",
    "overall_acc = total_acc / count\n",
    "print(f'Overall accuracy: {overall_acc*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.27697441601779754\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))  # Corrected the path to the directory\n",
    "        # Reshape the feature to a 2D array with a single row and 40 columns\n",
    "        data.append(feature.view(1, -1).numpy()[0])  # Adjusted this line to flatten the data\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define and fit the Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=num_classes, random_state=42)\n",
    "gmm.fit(X_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = gmm.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade tensorflow\n",
    "! pip install --upgrade keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 14s 52ms/step - loss: 0.4694 - accuracy: 0.7833 - val_loss: 0.4316 - val_accuracy: 0.7990\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.4252 - accuracy: 0.8150 - val_loss: 0.4200 - val_accuracy: 0.8157\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.3936 - accuracy: 0.8304 - val_loss: 0.3967 - val_accuracy: 0.8265\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 0.3730 - accuracy: 0.8423 - val_loss: 0.3881 - val_accuracy: 0.8265\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.3635 - accuracy: 0.8431 - val_loss: 0.3808 - val_accuracy: 0.8332\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.3527 - accuracy: 0.8479 - val_loss: 0.3635 - val_accuracy: 0.8390\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.3454 - accuracy: 0.8571 - val_loss: 0.3664 - val_accuracy: 0.8324\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.3371 - accuracy: 0.8544 - val_loss: 0.3652 - val_accuracy: 0.8449\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 7s 44ms/step - loss: 0.3297 - accuracy: 0.8609 - val_loss: 0.3703 - val_accuracy: 0.8415\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 7s 43ms/step - loss: 0.3264 - accuracy: 0.8611 - val_loss: 0.3635 - val_accuracy: 0.8449\n",
      "Test loss: 0.3635075092315674\n",
      "Test accuracy: 0.8448707461357117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "def get_model(op_nodes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True), input_shape=(data[0].shape[0], data[0].shape[1])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Bidirectional(LSTM(units=32)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(op_nodes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the BiLSTM model\n",
    "model = get_model(num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 11s 47ms/step - loss: 0.4800 - accuracy: 0.7839 - val_loss: 0.4546 - val_accuracy: 0.8032\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 0.4428 - accuracy: 0.8083 - val_loss: 0.4476 - val_accuracy: 0.8048\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.4250 - accuracy: 0.8181 - val_loss: 0.4305 - val_accuracy: 0.8107\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 0.4094 - accuracy: 0.8214 - val_loss: 0.4024 - val_accuracy: 0.8307\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.4025 - accuracy: 0.8283 - val_loss: 0.4000 - val_accuracy: 0.8165\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.3893 - accuracy: 0.8310 - val_loss: 0.3860 - val_accuracy: 0.8307\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 7s 47ms/step - loss: 0.3826 - accuracy: 0.8327 - val_loss: 0.3741 - val_accuracy: 0.8315\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.3711 - accuracy: 0.8406 - val_loss: 0.3933 - val_accuracy: 0.8182\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.3634 - accuracy: 0.8456 - val_loss: 0.3676 - val_accuracy: 0.8432\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.3552 - accuracy: 0.8511 - val_loss: 0.3592 - val_accuracy: 0.8457\n",
      "Test loss: 0.35916468501091003\n",
      "Test accuracy: 0.8457047343254089\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Directory containing the .pt files\n",
    "directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)  # Assuming 2310 is the threshold between the classes\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "def get_model(input_shape, output_units):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_units, activation='softmax'))  # Use softmax for multi-class classification\n",
    "\n",
    "    # Compile the model with appropriate loss function, optimizer, and metrics\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = get_model(X_train.shape[1:], np.unique(labels).size)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels: (5993,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\439863856.py:42: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 3ms/step - loss: 0.8198 - accuracy: 0.7860\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8849\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8927\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.9149\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8942\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9246\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9168\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9196\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9074\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.7272 - accuracy: 0.7901\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8921\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.9008\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9193\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9115\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8967\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9199\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9174\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.9049\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.6610 - accuracy: 0.8107\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8702\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9033\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8783\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9089\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9130\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9071\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9124\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.9080\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.9538 - accuracy: 0.7747\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8936\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8967\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9068\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9074\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9096\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9024\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9190\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9136\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9186\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9230\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9246\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9362\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9337\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9340\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9318\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9268\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9208\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9299\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9321\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.9068\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.8176 - accuracy: 0.8110\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8952\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9014\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9068\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9130\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9165\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9146\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9215\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9262\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9215\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9237\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9058\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9318\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9346\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9384\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9459\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9424\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9471\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9465\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9387\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.9111\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 1.3676 - accuracy: 0.7650\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8733\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9039\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8933\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9152\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.9143\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8964\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.9102\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9190\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9227\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9199\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9271\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9249\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9324\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9274\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9343\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1816 - accuracy: 0.9365\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9446\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9330\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9374\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9149\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 2.4145 - accuracy: 0.7218\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8933\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.9055\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9099\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9183\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2228 - accuracy: 0.9161\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9246\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9174\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9230\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.9118\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 1.3426 - accuracy: 0.6990\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8745\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.9046\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9102\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9121\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9140\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9190\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9212\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9271\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9155\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.9011\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 1.1915 - accuracy: 0.7419\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9240\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9174\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9262\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9218\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9212\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8874\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 1.5437 - accuracy: 0.7137\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2898 - accuracy: 0.8849\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9008\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9074\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9136\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9190\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9190\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9193\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9218\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9224\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9321\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9312\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9324\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9406\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9105\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9293\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9449\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9406\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9136\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 0.7877 - accuracy: 0.7369\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8921\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9055\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9143\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9183\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9196\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9071\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9268\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9190\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9249\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9293\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9190\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9337\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9349\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9362\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9409\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9418\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9427\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9434\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9462\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9099\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 0.7048 - accuracy: 0.7922\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8817\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8952\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8874\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.9099\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.9086\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8999\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9158\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9230\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9277\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9108\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.9024\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9302\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9337\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9312\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9249\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9330\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9265\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.9130\n",
      "Epoch 1/20\n",
      "75/75 [==============================] - 1s 2ms/step - loss: 0.9026 - accuracy: 0.7922\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9045\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.9095\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9093\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9099\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9176\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9105\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9182\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9232\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9297\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9180\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9259\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9299\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9343\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9282\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9282\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9314\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9234\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9324\n",
      "Best Hyperparameters: {'batch_size': 64, 'epochs': 20}\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8957\n",
      "Test accuracy: 0.8957464694976807\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels:\", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier wrapper for use in scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameters to tune and their respective values\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20],\n",
    "}\n",
    "\n",
    "# Perform grid search using cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Calculate accuracy using score method\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels: (5993,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\277589820.py:55: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 2ms/step - loss: 0.6465 - accuracy: 0.8364\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8967\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8967\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.9046\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9105\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9115\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9074\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9180\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9152\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9152\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8942\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 2.4514 - accuracy: 0.7732\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8983\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2869 - accuracy: 0.8914\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9183\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9124\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9190\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9309\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9212\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8849\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8432\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.9011\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.9027\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9105\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9105\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9212\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9190\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9227\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9221\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9193\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.8331 - accuracy: 0.8007\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8942\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.9043\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9077\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9105\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9115\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9133\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9199\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9271\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9190\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9183\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9305\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9262\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9371\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9343\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9334\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9324\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9324\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9390\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8824\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.8263\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8802\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.9089\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9136\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9143\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9102\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.9105\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9130\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9305\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9083\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9290\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9174\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9415\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9287\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9246\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9309\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9431\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9399\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8967\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.8794 - accuracy: 0.7875\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.9043\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8980\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9105\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9046\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.9002\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9058\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9174\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9130\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9161\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.9265\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9312\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9265\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9309\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9274\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9280\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9409\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9377\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9396\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9412\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9149\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 4ms/step - loss: 3.9607 - accuracy: 0.7062\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9186\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9287\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2344 - accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9299\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9143\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 3ms/step - loss: 3.6445 - accuracy: 0.7031\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9105\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9108\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.9049\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9174\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.9180\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2568 - accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.9068\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.9105\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 1.2067 - accuracy: 0.7819\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8830\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.9115\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9102\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9224\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9036\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8467\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 3ms/step - loss: 1.8736 - accuracy: 0.7284\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8964\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.9036\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.9008\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.9083\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9127\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9046\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9283\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9080\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9130\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9174\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9121\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.9039\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9330\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9365\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9349\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9393\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.9387\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9312\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9215\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8617\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.8166\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.9039\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9108\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9215\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9008\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.9136\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9196\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9252\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9227\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9249\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9268\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9387\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9262\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9368\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9368\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9355\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9265\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9471\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9305\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9061\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 2.3188 - accuracy: 0.7744\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8958\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8917\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9121\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.9077\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9102\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2197 - accuracy: 0.9212\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9183\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9174\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9277\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9237\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9271\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9124\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8971\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9161\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9233\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9365\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9309\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.9018\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 1.1612 - accuracy: 0.8306\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9095\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.9128\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9207\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9226\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9247\n",
      "Best Hyperparameters: {'batch_size': 32, 'epochs': 10}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator KerasClassifier should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m voting_classifier \u001b[39m=\u001b[39m VotingClassifier(classifiers, voting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[39m# Train the voting classifier on the reduced features\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m voting_classifier\u001b[39m.\u001b[39;49mfit(X_train_reduced, y_train)\n\u001b[0;32m     85\u001b[0m \u001b[39m# Calculate accuracy on the reduced features\u001b[39;00m\n\u001b[0;32m     86\u001b[0m accuracy \u001b[39m=\u001b[39m voting_classifier\u001b[39m.\u001b[39mscore(X_test_reduced, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m    344\u001b[0m transformed_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mle_\u001b[39m.\u001b[39mtransform(y)\n\u001b[1;32m--> 346\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, transformed_y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:73\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m@abstractmethod\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     72\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     names, clfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimators()\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators):\n\u001b[0;32m     76\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\u001b[39m}\u001b[39;00m\u001b[39m weights, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators)\u001b[39m}\u001b[39;00m\u001b[39m estimators\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:303\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mfor\u001b[39;00m est \u001b[39min\u001b[39;00m estimators:\n\u001b[0;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m est \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_estimator_type(est):\n\u001b[1;32m--> 303\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    304\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe estimator \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m should be a \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    305\u001b[0m                 est\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, is_estimator_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m[\u001b[39m3\u001b[39m:]\n\u001b[0;32m    306\u001b[0m             )\n\u001b[0;32m    307\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m names, estimators\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator KerasClassifier should be a classifier."
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "# Reshape data to have 2 dimensions\n",
    "data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "# Apply feature selection\n",
    "selector = SelectKBest(f_classif, k='all')  # Adjust k as needed\n",
    "data_selected = selector.fit_transform(data, labels)\n",
    "\n",
    "# Apply feature ensemble\n",
    "ensemble_data = np.concatenate((data, data_selected), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ensemble_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels:\", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(ensemble_data.shape[1], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier wrapper for use in scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameters to tune and their respective values\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20],\n",
    "}\n",
    "\n",
    "# Perform grid search using cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Apply feature reduction with PCA\n",
    "pca = PCA(n_components=50)  # Adjust the number of components as needed\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "# Create a voting classifier with the best model and reduced features\n",
    "classifiers = [('best_model', best_model)]\n",
    "voting_classifier = VotingClassifier(classifiers, voting='soft')\n",
    "\n",
    "# Train the voting classifier on the reduced features\n",
    "voting_classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Calculate accuracy on the reduced features\n",
    "accuracy = voting_classifier.score(X_test_reduced, y_test)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 2s 5ms/step - loss: 0.4819 - accuracy: 0.8471 - val_loss: 0.3191 - val_accuracy: 0.8882\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.8986 - val_loss: 0.2692 - val_accuracy: 0.8941\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2523 - accuracy: 0.9099 - val_loss: 0.2547 - val_accuracy: 0.9033\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2838 - accuracy: 0.9013 - val_loss: 0.2535 - val_accuracy: 0.9058\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.9141 - val_loss: 0.2816 - val_accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.8978 - val_loss: 0.2855 - val_accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9155 - val_loss: 0.2792 - val_accuracy: 0.9041\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2494 - accuracy: 0.9166 - val_loss: 0.2905 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9164 - val_loss: 0.4959 - val_accuracy: 0.8240\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9216 - val_loss: 0.2499 - val_accuracy: 0.8991\n",
      "Test loss: 0.2498769611120224\n",
      "Test accuracy: 0.8990825414657593\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 2s 6ms/step - loss: 5.6764\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.3523\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.3089\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.2942\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 5.1531\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.2710\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 5.4589\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 5.7336\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.8009\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 5.6245\n",
      "150/150 [==============================] - 1s 3ms/step\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Test accuracy: 0.8590492076730609\n",
      "Test probabilities: [[0.95730611 0.04269389]\n",
      " [0.12249191 0.87750809]\n",
      " [0.5        0.5       ]\n",
      " ...\n",
      " [0.7627103  0.2372897 ]\n",
      " [0.98027933 0.01972067]\n",
      " [0.96632911 0.03367089]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "# Defining CNN model\n",
    "def get_cnn_model():\n",
    "    inputs = keras.Input(shape=(data[0].shape[0], 1))\n",
    "    x = keras.layers.Conv1D(32, 3, activation='relu')(inputs)\n",
    "    x = keras.layers.MaxPooling1D(2)(x)\n",
    "    x = keras.layers.Conv1D(64, 3, activation='relu')(x)\n",
    "    x = keras.layers.MaxPooling1D(2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(128)(x)  # this layer will be used as the feature extractor\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "# Training CNN\n",
    "cnn_model = get_cnn_model()\n",
    "cnn_model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# Extracting features\n",
    "X_train_features = cnn_model.predict(X_train)\n",
    "X_test_features = cnn_model.predict(X_test)\n",
    "\n",
    "# Training SVM on extracted features\n",
    "svm_model = svm.SVC(probability=True)  # probability=True enables probability estimates\n",
    "svm_model.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluating SVM\n",
    "score = svm_model.score(X_test_features, y_test)\n",
    "print('Test accuracy:', score)\n",
    "\n",
    "# Predicting probabilities\n",
    "y_test_probs = svm_model.predict_proba(X_test_features)\n",
    "print('Test probabilities:', y_test_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 4s 14ms/step - loss: 0.7657 - accuracy: 0.7920 - val_loss: 0.3881 - val_accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.3503 - accuracy: 0.8567 - val_loss: 0.3598 - val_accuracy: 0.8582\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2988 - accuracy: 0.8821 - val_loss: 0.3314 - val_accuracy: 0.8641\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2972 - accuracy: 0.8821 - val_loss: 0.3244 - val_accuracy: 0.8624\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.2639 - accuracy: 0.9001 - val_loss: 0.2794 - val_accuracy: 0.8849\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2663 - accuracy: 0.9001 - val_loss: 0.3059 - val_accuracy: 0.8832\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2577 - accuracy: 0.9003 - val_loss: 0.2676 - val_accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.2389 - accuracy: 0.9063 - val_loss: 0.2652 - val_accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2298 - accuracy: 0.9126 - val_loss: 0.2618 - val_accuracy: 0.8982\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.2254 - accuracy: 0.9145 - val_loss: 0.2641 - val_accuracy: 0.9024\n",
      "Test loss: 0.2641274034976959\n",
      "Test accuracy: 0.9024186730384827\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def _init_(self):\n",
    "        super(SelfAttention, self)._init_()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(input_shape[-1])\n",
    "        self.key = Dense(input_shape[-1])\n",
    "        self.value = Dense(input_shape[-1])\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 6s 6ms/step - loss: 0.5143 - accuracy: 0.8164 - val_loss: 0.3821 - val_accuracy: 0.8474\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3482 - accuracy: 0.8584 - val_loss: 0.3234 - val_accuracy: 0.8716\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.3051 - accuracy: 0.8813 - val_loss: 0.3278 - val_accuracy: 0.8749\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2834 - accuracy: 0.8874 - val_loss: 0.2842 - val_accuracy: 0.8957\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2615 - accuracy: 0.8995 - val_loss: 0.2707 - val_accuracy: 0.8932\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2549 - accuracy: 0.9047 - val_loss: 0.2691 - val_accuracy: 0.8907\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2411 - accuracy: 0.9086 - val_loss: 0.3648 - val_accuracy: 0.8741\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2767 - accuracy: 0.8876 - val_loss: 0.2885 - val_accuracy: 0.8899\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2339 - accuracy: 0.9107 - val_loss: 0.2710 - val_accuracy: 0.8982\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2307 - accuracy: 0.9103 - val_loss: 0.2649 - val_accuracy: 0.8957\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2323 - accuracy: 0.9049 - val_loss: 0.2585 - val_accuracy: 0.9008\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2274 - accuracy: 0.9068 - val_loss: 0.2681 - val_accuracy: 0.8957\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2154 - accuracy: 0.9172 - val_loss: 0.2996 - val_accuracy: 0.8841\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9257 - val_loss: 0.2736 - val_accuracy: 0.8924\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.2304 - accuracy: 0.9105 - val_loss: 0.2721 - val_accuracy: 0.8874\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.2116 - accuracy: 0.9234 - val_loss: 0.2842 - val_accuracy: 0.8991\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.1908 - accuracy: 0.9276 - val_loss: 0.3220 - val_accuracy: 0.8882\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1895 - accuracy: 0.9268 - val_loss: 0.2584 - val_accuracy: 0.9083\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.1704 - accuracy: 0.9347 - val_loss: 0.2938 - val_accuracy: 0.8982\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.1801 - accuracy: 0.9362 - val_loss: 0.3175 - val_accuracy: 0.8982\n",
      "Test loss: 0.31753695011138916\n",
      "Test accuracy: 0.898248553276062\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def _init_(self):\n",
    "        super(SelfAttention, self)._init_()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(input_shape[-1])\n",
    "        self.key = Dense(input_shape[-1])\n",
    "        self.value = Dense(input_shape[-1])\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=8, epochs=20, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/20\n",
      "150/150 [==============================] - 3s 7ms/step - loss: 0.4375 - accuracy: 0.7887 - val_loss: 0.4752 - val_accuracy: 0.7973\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3089 - accuracy: 0.8763 - val_loss: 0.3161 - val_accuracy: 0.8841\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2747 - accuracy: 0.8934 - val_loss: 0.3021 - val_accuracy: 0.8832\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2641 - accuracy: 0.8957 - val_loss: 0.3117 - val_accuracy: 0.8866\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2500 - accuracy: 0.8999 - val_loss: 0.3037 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2344 - accuracy: 0.9070 - val_loss: 0.3173 - val_accuracy: 0.8882\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2232 - accuracy: 0.9124 - val_loss: 0.3045 - val_accuracy: 0.8857\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2116 - accuracy: 0.9132 - val_loss: 0.3372 - val_accuracy: 0.8641\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2094 - accuracy: 0.9103 - val_loss: 0.3212 - val_accuracy: 0.8624\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2084 - accuracy: 0.9132 - val_loss: 0.2887 - val_accuracy: 0.8891\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2033 - accuracy: 0.9201 - val_loss: 0.2936 - val_accuracy: 0.8907\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1891 - accuracy: 0.9249 - val_loss: 0.3284 - val_accuracy: 0.8832\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1859 - accuracy: 0.9264 - val_loss: 0.3118 - val_accuracy: 0.8907\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1788 - accuracy: 0.9295 - val_loss: 0.3116 - val_accuracy: 0.8891\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1672 - accuracy: 0.9345 - val_loss: 0.3407 - val_accuracy: 0.8841\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.9385 - val_loss: 0.3239 - val_accuracy: 0.8841\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1511 - accuracy: 0.9374 - val_loss: 0.3654 - val_accuracy: 0.8766\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.1576 - accuracy: 0.9360 - val_loss: 0.3340 - val_accuracy: 0.8807\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1429 - accuracy: 0.9428 - val_loss: 0.3523 - val_accuracy: 0.8866\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1439 - accuracy: 0.9389 - val_loss: 0.3287 - val_accuracy: 0.8866\n",
      "Test loss: 0.3287131190299988\n",
      "Test accuracy: 0.8865721225738525\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(input_shape[-1])\n",
    "        self.key = Dense(input_shape[-1])\n",
    "        self.value = Dense(input_shape[-1])\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "# Apply feature selection\n",
    "k = 30  # Adjust the number of selected features as needed, less than 40\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "X_test_selected = selector.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "# Apply feature reduction\n",
    "n_components = 20  # Adjust the number of reduced components as needed, less than k\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_reduced = pca.fit_transform(X_train_selected)\n",
    "X_test_reduced = pca.transform(X_test_selected)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(n_components, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train_reduced.reshape(X_train_reduced.shape[0], X_train_reduced.shape[1], 1), y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test_reduced.reshape(X_test_reduced.shape[0], X_test_reduced.shape[1], 1), y_test))\n",
    "score = model.evaluate(X_test_reduced.reshape(X_test_reduced.shape[0], X_test_reduced.shape[1], 1), y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1280x1 and 40x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 124\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 124\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train(model, train_dataloader, criterion, optimizer)\n\u001b[0;32m    125\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_dataloader, criterion)\n\u001b[0;32m    127\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[78], line 64\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     63\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 64\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     65\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39msqueeze(), labels)\n\u001b[0;32m     66\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[78], line 40\u001b[0m, in \u001b[0;36mAttentionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 40\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[0;32m     41\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# (seq_len, batch_size, input_size)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(x, x, x)  \u001b[39m# self-attention\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1280x1 and 40x64)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_heads, num_layers):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, input_size)\n",
    "        x, _ = self.attention(x, x, x)  # self-attention\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(X, y, batch_size):\n",
    "    dataset = TensorDataset(torch.Tensor(X), torch.Tensor(y))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (outputs > 0.5).squeeze().long()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).squeeze().long()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "input_size = data[0].shape[0]\n",
    "hidden_size = 64\n",
    "num_heads = 4\n",
    "num_layers = 1\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the model\n",
    "model = AttentionModel(input_size, hidden_size, num_heads, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = get_dataloader(X_train, y_train, batch_size)\n",
    "test_dataloader = get_dataloader(X_test, y_test, batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, criterion, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_dataloader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 38, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 19, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 17, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 8, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 64, 8)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,336\n",
      "Trainable params: 6,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 64, 8)\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 38, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 19, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 17, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 8, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 64, 8)             0         \n",
      "                                                                 \n",
      " multi_head_self_attention_1  (None, None, 1536)       41472     \n",
      " 0 (MultiHeadSelfAttention)                                      \n",
      "                                                                 \n",
      " global_average_pooling1d_7   (None, 1536)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,808\n",
      "Trainable params: 47,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 1536)\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 38, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 19, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 17, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 8, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 64, 8)             0         \n",
      "                                                                 \n",
      " multi_head_self_attention_1  (None, None, 1536)       41472     \n",
      " 0 (MultiHeadSelfAttention)                                      \n",
      "                                                                 \n",
      " global_average_pooling1d_7   (None, 1536)             0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               196736    \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261,185\n",
      "Trainable params: 261,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 25s 151ms/step - loss: 0.5222 - accuracy: 0.7418 - val_loss: 0.4197 - val_accuracy: 0.8148\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 22s 149ms/step - loss: 0.3966 - accuracy: 0.8329 - val_loss: 0.4090 - val_accuracy: 0.8232\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 21s 143ms/step - loss: 0.3761 - accuracy: 0.8404 - val_loss: 0.4017 - val_accuracy: 0.8349\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 25s 169ms/step - loss: 0.3664 - accuracy: 0.8469 - val_loss: 0.3868 - val_accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 24s 158ms/step - loss: 0.3555 - accuracy: 0.8523 - val_loss: 0.3968 - val_accuracy: 0.8249\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 25s 169ms/step - loss: 0.3553 - accuracy: 0.8488 - val_loss: 0.4079 - val_accuracy: 0.8198\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 23s 151ms/step - loss: 0.3402 - accuracy: 0.8546 - val_loss: 0.3899 - val_accuracy: 0.8440\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 23s 153ms/step - loss: 0.3325 - accuracy: 0.8615 - val_loss: 0.3766 - val_accuracy: 0.8432\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 25s 164ms/step - loss: 0.3254 - accuracy: 0.8634 - val_loss: 0.3711 - val_accuracy: 0.8457\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 22s 145ms/step - loss: 0.3151 - accuracy: 0.8705 - val_loss: 0.3542 - val_accuracy: 0.8540\n",
      "Test loss: 0.35424119234085083\n",
      "Test accuracy: 0.854045033454895\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape, Concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        \n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, head_dim):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.total_dim = num_heads * head_dim\n",
    "\n",
    "        self.query = Dense(self.total_dim)\n",
    "        self.key = Dense(self.total_dim)\n",
    "        self.value = Dense(self.total_dim)\n",
    "\n",
    "        self.concatenation = Concatenate(axis=-1)\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MultiHeadSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        query = tf.reshape(query, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        query = tf.transpose(query, perm=[0, 2, 1, 3])\n",
    "\n",
    "        key = tf.reshape(key, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        key = tf.transpose(key, perm=[0, 2, 1, 3])\n",
    "\n",
    "        value = tf.reshape(value, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        value = tf.transpose(value, perm=[0, 2, 1, 3])\n",
    "\n",
    "        attention_weights = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(attention_weights, axis=-1)\n",
    "\n",
    "        self.attention_weights = attention_weights\n",
    "\n",
    "        attended_features = tf.matmul(attention_weights, value)\n",
    "        attended_features = tf.transpose(attended_features, perm=[0, 2, 1, 3])\n",
    "        attended_features = tf.reshape(attended_features, (batch_size, -1, self.total_dim))\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Multi-Head Self-Attention\n",
    "    model.summary()  # Summary after adding Reshape layer\n",
    "    print(model.output_shape)  # Print the output shape after the Reshape layer\n",
    "    \n",
    "    model.add(MultiHeadSelfAttention(num_heads=12, head_dim=128))\n",
    "    model.add(GlobalAveragePooling1D())  # Add this line\n",
    "    model.summary()  # Summary after adding MultiHeadSelfAttention layer\n",
    "    print(model.output_shape)  # Print the output shape after the MultiHeadSelfAttention layer\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5530 - accuracy: 0.8348 - val_loss: 0.2687 - val_accuracy: 0.8982\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8894 - val_loss: 0.2740 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2858 - accuracy: 0.9009 - val_loss: 0.2412 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2862 - accuracy: 0.9005 - val_loss: 0.2665 - val_accuracy: 0.9008\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2948 - accuracy: 0.8959 - val_loss: 0.4442 - val_accuracy: 0.8407\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.9099 - val_loss: 0.2439 - val_accuracy: 0.9099\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.3062 - accuracy: 0.8932 - val_loss: 0.3539 - val_accuracy: 0.8682\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2707 - accuracy: 0.9076 - val_loss: 0.4237 - val_accuracy: 0.8474\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.9180 - val_loss: 0.2389 - val_accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2556 - accuracy: 0.9141 - val_loss: 0.2338 - val_accuracy: 0.9124\n",
      "Test loss: 0.2338208258152008\n",
      "Test accuracy: 0.9124270081520081\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.20.0-cp39-cp39-win_amd64.whl (746 kB)\n",
      "                                              0.0/746.7 kB ? eta -:--:--\n",
      "     -----                                  112.6/746.7 kB 2.2 MB/s eta 0:00:01\n",
      "     ---------                              194.6/746.7 kB 2.0 MB/s eta 0:00:01\n",
      "     --------------                         276.5/746.7 kB 1.9 MB/s eta 0:00:01\n",
      "     ------------------                     358.4/746.7 kB 2.0 MB/s eta 0:00:01\n",
      "     ----------------------                 440.3/746.7 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------            532.5/746.7 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------        624.6/746.7 kB 2.0 MB/s eta 0:00:01\n",
      "     -----------------------------------    706.6/746.7 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 746.7/746.7 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_addons) (23.0)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Duplicate registrations for type 'experimentalOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdains\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Replace with the directory path containing the .pt files\u001b[39;00m\n\u001b[0;32m     10\u001b[0m data \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Local project imports\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\callbacks\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Additional callbacks that conform to Keras API.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maverage_model_checkpoint\u001b[39;00m \u001b[39mimport\u001b[39;00m AverageModelCheckpoint\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtime_stopping\u001b[39;00m \u001b[39mimport\u001b[39;00m TimeStopping\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtqdm_progress_bar\u001b[39;00m \u001b[39mimport\u001b[39;00m TQDMProgressBar\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\callbacks\\time_stopping.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypeguard\u001b[39;00m \u001b[39mimport\u001b[39;00m typechecked\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback\n\u001b[0;32m     25\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mregister_keras_serializable(package\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAddons\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTimeStopping\u001b[39;00m(Callback):\n\u001b[0;32m     27\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Stop training when a specified amount of time has passed.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m        verbose: verbosity mode. Defaults to 0.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\api\\_v2\\keras\\callbacks\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m BackupAndRestore\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseLogger\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m CSVLogger\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\functional.py:25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute_coordinator_utils \u001b[39mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor_api \u001b[39mas\u001b[39;00m dtensor\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\keras_tensor.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n\u001b[0;32m     21\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\__init__.py:53\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_file\n\u001b[0;32m     52\u001b[0m \u001b[39m# Preprocessing utils\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_space\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureSpace\n\u001b[0;32m     55\u001b[0m \u001b[39m# Internal\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\feature_space.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_lib\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization_lib\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m---> 40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization_lib\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\mixed_precision\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras mixed precision API.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mSee [the mixed precision guide](\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m  https://www.tensorflow.org/guide/keras/mixed_precision) to learn how to\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39muse the API.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloss_scale_optimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m LossScaleOptimizer\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolicy\u001b[39;00m \u001b[39mimport\u001b[39;00m Policy\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolicy\u001b[39;00m \u001b[39mimport\u001b[39;00m global_policy\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\mixed_precision\\loss_scale_optimizer.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizers\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m utils \u001b[39mas\u001b[39;00m dtensor_utils\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m adadelta\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m adafactor\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m adagrad\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\adadelta.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Adadelta optimizer implementation.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mobject_registration\u001b[39;00m \u001b[39mimport\u001b[39;00m register_keras_serializable\n\u001b[0;32m     22\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1395\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m   1394\u001b[0m \u001b[39m# Register the optimizer for loading from saved_model purpose.\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload\u001b[39m.\u001b[39;49mregister_revived_type(\n\u001b[0;32m   1396\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mexperimentalOptimizer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1397\u001b[0m     \u001b[39mlambda\u001b[39;49;00m obj: \u001b[39misinstance\u001b[39;49m(obj, Optimizer),\n\u001b[0;32m   1398\u001b[0m     versions\u001b[39m=\u001b[39;49m[\n\u001b[0;32m   1399\u001b[0m         tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload\u001b[39m.\u001b[39;49mVersionedTypeRegistration(\n\u001b[0;32m   1400\u001b[0m             object_factory\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m proto: RestoredOptimizer(),\n\u001b[0;32m   1401\u001b[0m             version\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m   1402\u001b[0m             min_producer_version\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1403\u001b[0m             min_consumer_version\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1404\u001b[0m         )\n\u001b[0;32m   1405\u001b[0m     ],\n\u001b[0;32m   1406\u001b[0m )\n\u001b[0;32m   1408\u001b[0m Optimizer\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m Optimizer\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\u001b[39m.\u001b[39mreplace(\n\u001b[0;32m   1409\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39m\u001b[39mbase_optimizer_keyword_args}}\u001b[39m\u001b[39m\"\u001b[39m, base_optimizer_keyword_args\n\u001b[0;32m   1410\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\revived_types.py:133\u001b[0m, in \u001b[0;36mregister_revived_type\u001b[1;34m(identifier, predicate, versions)\u001b[0m\n\u001b[0;32m    129\u001b[0m   \u001b[39mif\u001b[39;00m registration\u001b[39m.\u001b[39mversion \u001b[39min\u001b[39;00m version_numbers:\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot multiple registrations with version \u001b[39m\u001b[39m{\u001b[39;00mregistration\u001b[39m.\u001b[39mversion\u001b[39m}\u001b[39;00m\u001b[39m for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00midentifier\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m   version_numbers\u001b[39m.\u001b[39madd(registration\u001b[39m.\u001b[39mversion)\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m identifier \u001b[39min\u001b[39;00m _REVIVED_TYPE_REGISTRY:\n\u001b[0;32m    136\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDuplicate registrations for type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00midentifier\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Duplicate registrations for type 'experimentalOptimizer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Reshape\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def _init_(self):\n",
    "        super(SelfAttention, self)._init_()\n",
    "        self.query = Dense(self.units)\n",
    "        self.key = Dense(self.units)\n",
    "        self.value = Dense(self.units)\n",
    "        self.multihead_attention = tfa.layers.MultiHeadAttention(num_heads=8, key_dim=self.units)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query(inputs)\n",
    "        key = self.key(inputs)\n",
    "        value = self.value(inputs)\n",
    "\n",
    "        attention_weights = self.multihead_attention(query, key, value)\n",
    "        attended_features = tf.reduce_mean(attention_weights, axis=1)\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((64, -1)))  # Reshape for Self-Attention\n",
    "    model.add(SelfAttention())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pt\n",
      "1.pt\n",
      "2.pt\n",
      "3.pt\n",
      "4.pt\n",
      "5.pt\n",
      "6.pt\n",
      "7.pt\n",
      "8.pt\n",
      "9.pt\n",
      "10.pt\n",
      "11.pt\n",
      "12.pt\n",
      "13.pt\n",
      "14.pt\n",
      "15.pt\n",
      "16.pt\n",
      "17.pt\n",
      "18.pt\n",
      "19.pt\n",
      "20.pt\n",
      "21.pt\n",
      "22.pt\n",
      "23.pt\n",
      "24.pt\n",
      "25.pt\n",
      "26.pt\n",
      "27.pt\n",
      "28.pt\n",
      "29.pt\n",
      "30.pt\n",
      "31.pt\n",
      "32.pt\n",
      "33.pt\n",
      "34.pt\n",
      "35.pt\n",
      "36.pt\n",
      "37.pt\n",
      "38.pt\n",
      "39.pt\n",
      "40.pt\n",
      "41.pt\n",
      "42.pt\n",
      "43.pt\n",
      "44.pt\n",
      "45.pt\n",
      "46.pt\n",
      "47.pt\n",
      "48.pt\n",
      "49.pt\n",
      "50.pt\n",
      "51.pt\n",
      "52.pt\n",
      "53.pt\n",
      "54.pt\n",
      "55.pt\n",
      "56.pt\n",
      "57.pt\n",
      "58.pt\n",
      "59.pt\n",
      "60.pt\n",
      "61.pt\n",
      "62.pt\n",
      "63.pt\n",
      "64.pt\n",
      "65.pt\n",
      "66.pt\n",
      "67.pt\n",
      "68.pt\n",
      "69.pt\n",
      "70.pt\n",
      "71.pt\n",
      "72.pt\n",
      "73.pt\n",
      "74.pt\n",
      "75.pt\n",
      "76.pt\n",
      "77.pt\n",
      "78.pt\n",
      "79.pt\n",
      "80.pt\n",
      "81.pt\n",
      "82.pt\n",
      "83.pt\n",
      "84.pt\n",
      "85.pt\n",
      "86.pt\n",
      "87.pt\n",
      "88.pt\n",
      "89.pt\n",
      "90.pt\n",
      "91.pt\n",
      "92.pt\n",
      "93.pt\n",
      "94.pt\n",
      "95.pt\n",
      "96.pt\n",
      "97.pt\n",
      "98.pt\n",
      "99.pt\n",
      "100.pt\n",
      "101.pt\n",
      "102.pt\n",
      "103.pt\n",
      "104.pt\n",
      "105.pt\n",
      "106.pt\n",
      "107.pt\n",
      "108.pt\n",
      "109.pt\n",
      "110.pt\n",
      "111.pt\n",
      "112.pt\n",
      "113.pt\n",
      "114.pt\n",
      "115.pt\n",
      "116.pt\n",
      "117.pt\n",
      "118.pt\n",
      "119.pt\n",
      "120.pt\n",
      "121.pt\n",
      "122.pt\n",
      "123.pt\n",
      "124.pt\n",
      "125.pt\n",
      "126.pt\n",
      "127.pt\n",
      "128.pt\n",
      "129.pt\n",
      "130.pt\n",
      "131.pt\n",
      "132.pt\n",
      "133.pt\n",
      "134.pt\n",
      "135.pt\n",
      "136.pt\n",
      "137.pt\n",
      "138.pt\n",
      "139.pt\n",
      "140.pt\n",
      "141.pt\n",
      "142.pt\n",
      "143.pt\n",
      "144.pt\n",
      "145.pt\n",
      "146.pt\n",
      "147.pt\n",
      "148.pt\n",
      "149.pt\n",
      "150.pt\n",
      "151.pt\n",
      "152.pt\n",
      "153.pt\n",
      "154.pt\n",
      "155.pt\n",
      "156.pt\n",
      "157.pt\n",
      "158.pt\n",
      "159.pt\n",
      "160.pt\n",
      "161.pt\n",
      "162.pt\n",
      "163.pt\n",
      "164.pt\n",
      "165.pt\n",
      "166.pt\n",
      "167.pt\n",
      "168.pt\n",
      "169.pt\n",
      "170.pt\n",
      "171.pt\n",
      "172.pt\n",
      "173.pt\n",
      "174.pt\n",
      "175.pt\n",
      "176.pt\n",
      "177.pt\n",
      "178.pt\n",
      "179.pt\n",
      "180.pt\n",
      "181.pt\n",
      "182.pt\n",
      "183.pt\n",
      "184.pt\n",
      "185.pt\n",
      "186.pt\n",
      "187.pt\n",
      "188.pt\n",
      "189.pt\n",
      "190.pt\n",
      "191.pt\n",
      "192.pt\n",
      "193.pt\n",
      "194.pt\n",
      "195.pt\n",
      "196.pt\n",
      "197.pt\n",
      "198.pt\n",
      "199.pt\n",
      "200.pt\n",
      "201.pt\n",
      "202.pt\n",
      "203.pt\n",
      "204.pt\n",
      "205.pt\n",
      "206.pt\n",
      "207.pt\n",
      "208.pt\n",
      "209.pt\n",
      "210.pt\n",
      "211.pt\n",
      "212.pt\n",
      "213.pt\n",
      "214.pt\n",
      "215.pt\n",
      "216.pt\n",
      "217.pt\n",
      "218.pt\n",
      "219.pt\n",
      "220.pt\n",
      "221.pt\n",
      "222.pt\n",
      "223.pt\n",
      "224.pt\n",
      "225.pt\n",
      "226.pt\n",
      "227.pt\n",
      "228.pt\n",
      "229.pt\n",
      "230.pt\n",
      "231.pt\n",
      "232.pt\n",
      "233.pt\n",
      "234.pt\n",
      "235.pt\n",
      "236.pt\n",
      "237.pt\n",
      "238.pt\n",
      "239.pt\n",
      "240.pt\n",
      "241.pt\n",
      "242.pt\n",
      "243.pt\n",
      "244.pt\n",
      "245.pt\n",
      "246.pt\n",
      "247.pt\n",
      "248.pt\n",
      "249.pt\n",
      "250.pt\n",
      "251.pt\n",
      "252.pt\n",
      "253.pt\n",
      "254.pt\n",
      "255.pt\n",
      "256.pt\n",
      "257.pt\n",
      "258.pt\n",
      "259.pt\n",
      "260.pt\n",
      "261.pt\n",
      "262.pt\n",
      "263.pt\n",
      "264.pt\n",
      "265.pt\n",
      "266.pt\n",
      "267.pt\n",
      "268.pt\n",
      "269.pt\n",
      "270.pt\n",
      "271.pt\n",
      "272.pt\n",
      "273.pt\n",
      "274.pt\n",
      "275.pt\n",
      "276.pt\n",
      "277.pt\n",
      "278.pt\n",
      "279.pt\n",
      "280.pt\n",
      "281.pt\n",
      "282.pt\n",
      "283.pt\n",
      "284.pt\n",
      "285.pt\n",
      "286.pt\n",
      "287.pt\n",
      "288.pt\n",
      "289.pt\n",
      "290.pt\n",
      "291.pt\n",
      "292.pt\n",
      "293.pt\n",
      "294.pt\n",
      "295.pt\n",
      "296.pt\n",
      "297.pt\n",
      "298.pt\n",
      "299.pt\n",
      "300.pt\n",
      "301.pt\n",
      "302.pt\n",
      "303.pt\n",
      "304.pt\n",
      "305.pt\n",
      "306.pt\n",
      "307.pt\n",
      "308.pt\n",
      "309.pt\n",
      "310.pt\n",
      "311.pt\n",
      "312.pt\n",
      "313.pt\n",
      "314.pt\n",
      "315.pt\n",
      "316.pt\n",
      "317.pt\n",
      "318.pt\n",
      "319.pt\n",
      "320.pt\n",
      "321.pt\n",
      "322.pt\n",
      "323.pt\n",
      "324.pt\n",
      "325.pt\n",
      "326.pt\n",
      "327.pt\n",
      "328.pt\n",
      "329.pt\n",
      "330.pt\n",
      "331.pt\n",
      "332.pt\n",
      "333.pt\n",
      "334.pt\n",
      "335.pt\n",
      "336.pt\n",
      "337.pt\n",
      "338.pt\n",
      "339.pt\n",
      "340.pt\n",
      "341.pt\n",
      "342.pt\n",
      "343.pt\n",
      "344.pt\n",
      "345.pt\n",
      "346.pt\n",
      "347.pt\n",
      "348.pt\n",
      "349.pt\n",
      "350.pt\n",
      "351.pt\n",
      "352.pt\n",
      "353.pt\n",
      "354.pt\n",
      "355.pt\n",
      "356.pt\n",
      "357.pt\n",
      "358.pt\n",
      "359.pt\n",
      "360.pt\n",
      "361.pt\n",
      "362.pt\n",
      "363.pt\n",
      "364.pt\n",
      "365.pt\n",
      "366.pt\n",
      "367.pt\n",
      "368.pt\n",
      "369.pt\n",
      "370.pt\n",
      "371.pt\n",
      "372.pt\n",
      "373.pt\n",
      "374.pt\n",
      "375.pt\n",
      "376.pt\n",
      "377.pt\n",
      "378.pt\n",
      "379.pt\n",
      "380.pt\n",
      "381.pt\n",
      "382.pt\n",
      "383.pt\n",
      "384.pt\n",
      "385.pt\n",
      "386.pt\n",
      "387.pt\n",
      "388.pt\n",
      "389.pt\n",
      "390.pt\n",
      "391.pt\n",
      "392.pt\n",
      "393.pt\n",
      "394.pt\n",
      "395.pt\n",
      "396.pt\n",
      "397.pt\n",
      "398.pt\n",
      "399.pt\n",
      "400.pt\n",
      "401.pt\n",
      "402.pt\n",
      "403.pt\n",
      "404.pt\n",
      "405.pt\n",
      "406.pt\n",
      "407.pt\n",
      "408.pt\n",
      "409.pt\n",
      "410.pt\n",
      "411.pt\n",
      "412.pt\n",
      "413.pt\n",
      "414.pt\n",
      "415.pt\n",
      "416.pt\n",
      "417.pt\n",
      "418.pt\n",
      "419.pt\n",
      "420.pt\n",
      "421.pt\n",
      "422.pt\n",
      "423.pt\n",
      "424.pt\n",
      "425.pt\n",
      "426.pt\n",
      "427.pt\n",
      "428.pt\n",
      "429.pt\n",
      "430.pt\n",
      "431.pt\n",
      "432.pt\n",
      "433.pt\n",
      "434.pt\n",
      "435.pt\n",
      "436.pt\n",
      "437.pt\n",
      "438.pt\n",
      "439.pt\n",
      "440.pt\n",
      "441.pt\n",
      "442.pt\n",
      "443.pt\n",
      "444.pt\n",
      "445.pt\n",
      "446.pt\n",
      "447.pt\n",
      "448.pt\n",
      "449.pt\n",
      "450.pt\n",
      "451.pt\n",
      "452.pt\n",
      "453.pt\n",
      "454.pt\n",
      "455.pt\n",
      "456.pt\n",
      "457.pt\n",
      "458.pt\n",
      "459.pt\n",
      "460.pt\n",
      "461.pt\n",
      "462.pt\n",
      "463.pt\n",
      "464.pt\n",
      "465.pt\n",
      "466.pt\n",
      "467.pt\n",
      "468.pt\n",
      "469.pt\n",
      "470.pt\n",
      "471.pt\n",
      "472.pt\n",
      "473.pt\n",
      "474.pt\n",
      "475.pt\n",
      "476.pt\n",
      "477.pt\n",
      "478.pt\n",
      "479.pt\n",
      "480.pt\n",
      "481.pt\n",
      "482.pt\n",
      "483.pt\n",
      "484.pt\n",
      "485.pt\n",
      "486.pt\n",
      "487.pt\n",
      "488.pt\n",
      "489.pt\n",
      "490.pt\n",
      "491.pt\n",
      "492.pt\n",
      "493.pt\n",
      "494.pt\n",
      "495.pt\n",
      "496.pt\n",
      "497.pt\n",
      "498.pt\n",
      "499.pt\n",
      "500.pt\n",
      "501.pt\n",
      "502.pt\n",
      "503.pt\n",
      "504.pt\n",
      "505.pt\n",
      "506.pt\n",
      "507.pt\n",
      "508.pt\n",
      "509.pt\n",
      "510.pt\n",
      "511.pt\n",
      "512.pt\n",
      "513.pt\n",
      "514.pt\n",
      "515.pt\n",
      "516.pt\n",
      "517.pt\n",
      "518.pt\n",
      "519.pt\n",
      "520.pt\n",
      "521.pt\n",
      "522.pt\n",
      "523.pt\n",
      "524.pt\n",
      "525.pt\n",
      "526.pt\n",
      "527.pt\n",
      "528.pt\n",
      "529.pt\n",
      "530.pt\n",
      "531.pt\n",
      "532.pt\n",
      "533.pt\n",
      "534.pt\n",
      "535.pt\n",
      "536.pt\n",
      "537.pt\n",
      "538.pt\n",
      "539.pt\n",
      "540.pt\n",
      "541.pt\n",
      "542.pt\n",
      "543.pt\n",
      "544.pt\n",
      "545.pt\n",
      "546.pt\n",
      "547.pt\n",
      "548.pt\n",
      "549.pt\n",
      "550.pt\n",
      "551.pt\n",
      "552.pt\n",
      "553.pt\n",
      "554.pt\n",
      "555.pt\n",
      "556.pt\n",
      "557.pt\n",
      "558.pt\n",
      "559.pt\n",
      "560.pt\n",
      "561.pt\n",
      "562.pt\n",
      "563.pt\n",
      "564.pt\n",
      "565.pt\n",
      "566.pt\n",
      "567.pt\n",
      "568.pt\n",
      "569.pt\n",
      "570.pt\n",
      "571.pt\n",
      "572.pt\n",
      "573.pt\n",
      "574.pt\n",
      "575.pt\n",
      "576.pt\n",
      "577.pt\n",
      "578.pt\n",
      "579.pt\n",
      "580.pt\n",
      "581.pt\n",
      "582.pt\n",
      "583.pt\n",
      "584.pt\n",
      "585.pt\n",
      "586.pt\n",
      "587.pt\n",
      "588.pt\n",
      "589.pt\n",
      "590.pt\n",
      "591.pt\n",
      "592.pt\n",
      "593.pt\n",
      "594.pt\n",
      "595.pt\n",
      "596.pt\n",
      "597.pt\n",
      "598.pt\n",
      "599.pt\n",
      "600.pt\n",
      "601.pt\n",
      "602.pt\n",
      "603.pt\n",
      "604.pt\n",
      "605.pt\n",
      "606.pt\n",
      "607.pt\n",
      "608.pt\n",
      "609.pt\n",
      "610.pt\n",
      "611.pt\n",
      "612.pt\n",
      "613.pt\n",
      "614.pt\n",
      "615.pt\n",
      "616.pt\n",
      "617.pt\n",
      "618.pt\n",
      "619.pt\n",
      "620.pt\n",
      "621.pt\n",
      "622.pt\n",
      "623.pt\n",
      "624.pt\n",
      "625.pt\n",
      "626.pt\n",
      "627.pt\n",
      "628.pt\n",
      "629.pt\n",
      "630.pt\n",
      "631.pt\n",
      "632.pt\n",
      "633.pt\n",
      "634.pt\n",
      "635.pt\n",
      "636.pt\n",
      "637.pt\n",
      "638.pt\n",
      "639.pt\n",
      "640.pt\n",
      "641.pt\n",
      "642.pt\n",
      "643.pt\n",
      "644.pt\n",
      "645.pt\n",
      "646.pt\n",
      "647.pt\n",
      "648.pt\n",
      "649.pt\n",
      "650.pt\n",
      "651.pt\n",
      "652.pt\n",
      "653.pt\n",
      "654.pt\n",
      "655.pt\n",
      "656.pt\n",
      "657.pt\n",
      "658.pt\n",
      "659.pt\n",
      "660.pt\n",
      "661.pt\n",
      "662.pt\n",
      "663.pt\n",
      "664.pt\n",
      "665.pt\n",
      "666.pt\n",
      "667.pt\n",
      "668.pt\n",
      "669.pt\n",
      "670.pt\n",
      "671.pt\n",
      "672.pt\n",
      "673.pt\n",
      "674.pt\n",
      "675.pt\n",
      "676.pt\n",
      "677.pt\n",
      "678.pt\n",
      "679.pt\n",
      "680.pt\n",
      "681.pt\n",
      "682.pt\n",
      "683.pt\n",
      "684.pt\n",
      "685.pt\n",
      "686.pt\n",
      "687.pt\n",
      "688.pt\n",
      "689.pt\n",
      "690.pt\n",
      "691.pt\n",
      "692.pt\n",
      "693.pt\n",
      "694.pt\n",
      "695.pt\n",
      "696.pt\n",
      "697.pt\n",
      "698.pt\n",
      "699.pt\n",
      "700.pt\n",
      "701.pt\n",
      "702.pt\n",
      "703.pt\n",
      "704.pt\n",
      "705.pt\n",
      "706.pt\n",
      "707.pt\n",
      "708.pt\n",
      "709.pt\n",
      "710.pt\n",
      "711.pt\n",
      "712.pt\n",
      "713.pt\n",
      "714.pt\n",
      "715.pt\n",
      "716.pt\n",
      "717.pt\n",
      "718.pt\n",
      "719.pt\n",
      "720.pt\n",
      "721.pt\n",
      "722.pt\n",
      "723.pt\n",
      "724.pt\n",
      "725.pt\n",
      "726.pt\n",
      "727.pt\n",
      "728.pt\n",
      "729.pt\n",
      "730.pt\n",
      "731.pt\n",
      "732.pt\n",
      "733.pt\n",
      "734.pt\n",
      "735.pt\n",
      "736.pt\n",
      "737.pt\n",
      "738.pt\n",
      "739.pt\n",
      "740.pt\n",
      "741.pt\n",
      "742.pt\n",
      "743.pt\n",
      "744.pt\n",
      "745.pt\n",
      "746.pt\n",
      "747.pt\n",
      "748.pt\n",
      "749.pt\n",
      "750.pt\n",
      "751.pt\n",
      "752.pt\n",
      "753.pt\n",
      "754.pt\n",
      "755.pt\n",
      "756.pt\n",
      "757.pt\n",
      "758.pt\n",
      "759.pt\n",
      "760.pt\n",
      "761.pt\n",
      "762.pt\n",
      "763.pt\n",
      "764.pt\n",
      "765.pt\n",
      "766.pt\n",
      "767.pt\n",
      "768.pt\n",
      "769.pt\n",
      "770.pt\n",
      "771.pt\n",
      "772.pt\n",
      "773.pt\n",
      "774.pt\n",
      "775.pt\n",
      "776.pt\n",
      "777.pt\n",
      "778.pt\n",
      "779.pt\n",
      "780.pt\n",
      "781.pt\n",
      "782.pt\n",
      "783.pt\n",
      "784.pt\n",
      "785.pt\n",
      "786.pt\n",
      "787.pt\n",
      "788.pt\n",
      "789.pt\n",
      "790.pt\n",
      "791.pt\n",
      "792.pt\n",
      "793.pt\n",
      "794.pt\n",
      "795.pt\n",
      "796.pt\n",
      "797.pt\n",
      "798.pt\n",
      "799.pt\n",
      "800.pt\n",
      "801.pt\n",
      "802.pt\n",
      "803.pt\n",
      "804.pt\n",
      "805.pt\n",
      "806.pt\n",
      "807.pt\n",
      "808.pt\n",
      "809.pt\n",
      "810.pt\n",
      "811.pt\n",
      "812.pt\n",
      "813.pt\n",
      "814.pt\n",
      "815.pt\n",
      "816.pt\n",
      "817.pt\n",
      "818.pt\n",
      "819.pt\n",
      "820.pt\n",
      "821.pt\n",
      "822.pt\n",
      "823.pt\n",
      "824.pt\n",
      "825.pt\n",
      "826.pt\n",
      "827.pt\n",
      "828.pt\n",
      "829.pt\n",
      "830.pt\n",
      "831.pt\n",
      "832.pt\n",
      "833.pt\n",
      "834.pt\n",
      "835.pt\n",
      "836.pt\n",
      "837.pt\n",
      "838.pt\n",
      "839.pt\n",
      "840.pt\n",
      "841.pt\n",
      "842.pt\n",
      "843.pt\n",
      "844.pt\n",
      "845.pt\n",
      "846.pt\n",
      "847.pt\n",
      "848.pt\n",
      "849.pt\n",
      "850.pt\n",
      "851.pt\n",
      "852.pt\n",
      "853.pt\n",
      "854.pt\n",
      "855.pt\n",
      "856.pt\n",
      "857.pt\n",
      "858.pt\n",
      "859.pt\n",
      "860.pt\n",
      "861.pt\n",
      "862.pt\n",
      "863.pt\n",
      "864.pt\n",
      "865.pt\n",
      "866.pt\n",
      "867.pt\n",
      "868.pt\n",
      "869.pt\n",
      "870.pt\n",
      "871.pt\n",
      "872.pt\n",
      "873.pt\n",
      "874.pt\n",
      "875.pt\n",
      "876.pt\n",
      "877.pt\n",
      "878.pt\n",
      "879.pt\n",
      "880.pt\n",
      "881.pt\n",
      "882.pt\n",
      "883.pt\n",
      "884.pt\n",
      "885.pt\n",
      "886.pt\n",
      "887.pt\n",
      "888.pt\n",
      "889.pt\n",
      "890.pt\n",
      "891.pt\n",
      "892.pt\n",
      "893.pt\n",
      "894.pt\n",
      "895.pt\n",
      "896.pt\n",
      "897.pt\n",
      "898.pt\n",
      "899.pt\n",
      "900.pt\n",
      "901.pt\n",
      "902.pt\n",
      "903.pt\n",
      "904.pt\n",
      "905.pt\n",
      "906.pt\n",
      "907.pt\n",
      "908.pt\n",
      "909.pt\n",
      "910.pt\n",
      "911.pt\n",
      "912.pt\n",
      "913.pt\n",
      "914.pt\n",
      "915.pt\n",
      "916.pt\n",
      "917.pt\n",
      "918.pt\n",
      "919.pt\n",
      "920.pt\n",
      "921.pt\n",
      "922.pt\n",
      "923.pt\n",
      "924.pt\n",
      "925.pt\n",
      "926.pt\n",
      "927.pt\n",
      "928.pt\n",
      "929.pt\n",
      "930.pt\n",
      "931.pt\n",
      "932.pt\n",
      "933.pt\n",
      "934.pt\n",
      "935.pt\n",
      "936.pt\n",
      "937.pt\n",
      "938.pt\n",
      "939.pt\n",
      "940.pt\n",
      "941.pt\n",
      "942.pt\n",
      "943.pt\n",
      "944.pt\n",
      "945.pt\n",
      "946.pt\n",
      "947.pt\n",
      "948.pt\n",
      "949.pt\n",
      "950.pt\n",
      "951.pt\n",
      "952.pt\n",
      "953.pt\n",
      "954.pt\n",
      "955.pt\n",
      "956.pt\n",
      "957.pt\n",
      "958.pt\n",
      "959.pt\n",
      "960.pt\n",
      "961.pt\n",
      "962.pt\n",
      "963.pt\n",
      "964.pt\n",
      "965.pt\n",
      "966.pt\n",
      "967.pt\n",
      "968.pt\n",
      "969.pt\n",
      "970.pt\n",
      "971.pt\n",
      "972.pt\n",
      "973.pt\n",
      "974.pt\n",
      "975.pt\n",
      "976.pt\n",
      "977.pt\n",
      "978.pt\n",
      "979.pt\n",
      "980.pt\n",
      "981.pt\n",
      "982.pt\n",
      "983.pt\n",
      "984.pt\n",
      "985.pt\n",
      "986.pt\n",
      "987.pt\n",
      "988.pt\n",
      "989.pt\n",
      "990.pt\n",
      "991.pt\n",
      "992.pt\n",
      "993.pt\n",
      "994.pt\n",
      "995.pt\n",
      "996.pt\n",
      "997.pt\n",
      "998.pt\n",
      "999.pt\n",
      "1000.pt\n",
      "1001.pt\n",
      "1002.pt\n",
      "1003.pt\n",
      "1004.pt\n",
      "1005.pt\n",
      "1006.pt\n",
      "1007.pt\n",
      "1008.pt\n",
      "1009.pt\n",
      "1010.pt\n",
      "1011.pt\n",
      "1012.pt\n",
      "1013.pt\n",
      "1014.pt\n",
      "1015.pt\n",
      "1016.pt\n",
      "1017.pt\n",
      "1018.pt\n",
      "1019.pt\n",
      "1020.pt\n",
      "1021.pt\n",
      "1022.pt\n",
      "1023.pt\n",
      "1024.pt\n",
      "1025.pt\n",
      "1026.pt\n",
      "1027.pt\n",
      "1028.pt\n",
      "1029.pt\n",
      "1030.pt\n",
      "1031.pt\n",
      "1032.pt\n",
      "1033.pt\n",
      "1034.pt\n",
      "1035.pt\n",
      "1036.pt\n",
      "1037.pt\n",
      "1038.pt\n",
      "1039.pt\n",
      "1040.pt\n",
      "1041.pt\n",
      "1042.pt\n",
      "1043.pt\n",
      "1044.pt\n",
      "1045.pt\n",
      "1046.pt\n",
      "1047.pt\n",
      "1048.pt\n",
      "1049.pt\n",
      "1050.pt\n",
      "1051.pt\n",
      "1052.pt\n",
      "1053.pt\n",
      "1054.pt\n",
      "1055.pt\n",
      "1056.pt\n",
      "1057.pt\n",
      "1058.pt\n",
      "1059.pt\n",
      "1060.pt\n",
      "1061.pt\n",
      "1062.pt\n",
      "1063.pt\n",
      "1064.pt\n",
      "1065.pt\n",
      "1066.pt\n",
      "1067.pt\n",
      "1068.pt\n",
      "1069.pt\n",
      "1070.pt\n",
      "1071.pt\n",
      "1072.pt\n",
      "1073.pt\n",
      "1074.pt\n",
      "1075.pt\n",
      "1076.pt\n",
      "1077.pt\n",
      "1078.pt\n",
      "1079.pt\n",
      "1080.pt\n",
      "1081.pt\n",
      "1082.pt\n",
      "1083.pt\n",
      "1084.pt\n",
      "1085.pt\n",
      "1086.pt\n",
      "1087.pt\n",
      "1088.pt\n",
      "1089.pt\n",
      "1090.pt\n",
      "1091.pt\n",
      "1092.pt\n",
      "1093.pt\n",
      "1094.pt\n",
      "1095.pt\n",
      "1096.pt\n",
      "1097.pt\n",
      "1098.pt\n",
      "1099.pt\n",
      "1100.pt\n",
      "1101.pt\n",
      "1102.pt\n",
      "1103.pt\n",
      "1104.pt\n",
      "1105.pt\n",
      "1106.pt\n",
      "1107.pt\n",
      "1108.pt\n",
      "1109.pt\n",
      "1110.pt\n",
      "1111.pt\n",
      "1112.pt\n",
      "1113.pt\n",
      "1114.pt\n",
      "1115.pt\n",
      "1116.pt\n",
      "1117.pt\n",
      "1118.pt\n",
      "1119.pt\n",
      "1120.pt\n",
      "1121.pt\n",
      "1122.pt\n",
      "1123.pt\n",
      "1124.pt\n",
      "1125.pt\n",
      "1126.pt\n",
      "1127.pt\n",
      "1128.pt\n",
      "1129.pt\n",
      "1130.pt\n",
      "1131.pt\n",
      "1132.pt\n",
      "1133.pt\n",
      "1134.pt\n",
      "1135.pt\n",
      "1136.pt\n",
      "1137.pt\n",
      "1138.pt\n",
      "1139.pt\n",
      "1140.pt\n",
      "1141.pt\n",
      "1142.pt\n",
      "1143.pt\n",
      "1144.pt\n",
      "1145.pt\n",
      "1146.pt\n",
      "1147.pt\n",
      "1148.pt\n",
      "1149.pt\n",
      "1150.pt\n",
      "1151.pt\n",
      "1152.pt\n",
      "1153.pt\n",
      "1154.pt\n",
      "1155.pt\n",
      "1156.pt\n",
      "1157.pt\n",
      "1158.pt\n",
      "1159.pt\n",
      "1160.pt\n",
      "1161.pt\n",
      "1162.pt\n",
      "1163.pt\n",
      "1164.pt\n",
      "1165.pt\n",
      "1166.pt\n",
      "1167.pt\n",
      "1168.pt\n",
      "1169.pt\n",
      "1170.pt\n",
      "1171.pt\n",
      "1172.pt\n",
      "1173.pt\n",
      "1174.pt\n",
      "1175.pt\n",
      "1176.pt\n",
      "1177.pt\n",
      "1178.pt\n",
      "1179.pt\n",
      "1180.pt\n",
      "1181.pt\n",
      "1182.pt\n",
      "1183.pt\n",
      "1184.pt\n",
      "1185.pt\n",
      "1186.pt\n",
      "1187.pt\n",
      "1188.pt\n",
      "1189.pt\n",
      "1190.pt\n",
      "1191.pt\n",
      "1192.pt\n",
      "1193.pt\n",
      "1194.pt\n",
      "1195.pt\n",
      "1196.pt\n",
      "1197.pt\n",
      "1198.pt\n",
      "1199.pt\n",
      "1200.pt\n",
      "1201.pt\n",
      "1202.pt\n",
      "1203.pt\n",
      "1204.pt\n",
      "1205.pt\n",
      "1206.pt\n",
      "1207.pt\n",
      "1208.pt\n",
      "1209.pt\n",
      "1210.pt\n",
      "1211.pt\n",
      "1212.pt\n",
      "1213.pt\n",
      "1214.pt\n",
      "1215.pt\n",
      "1216.pt\n",
      "1217.pt\n",
      "1218.pt\n",
      "1219.pt\n",
      "1220.pt\n",
      "1221.pt\n",
      "1222.pt\n",
      "1223.pt\n",
      "1224.pt\n",
      "1225.pt\n",
      "1226.pt\n",
      "1227.pt\n",
      "1228.pt\n",
      "1229.pt\n",
      "1230.pt\n",
      "1231.pt\n",
      "1232.pt\n",
      "1233.pt\n",
      "1234.pt\n",
      "1235.pt\n",
      "1236.pt\n",
      "1237.pt\n",
      "1238.pt\n",
      "1239.pt\n",
      "1240.pt\n",
      "1241.pt\n",
      "1242.pt\n",
      "1243.pt\n",
      "1244.pt\n",
      "1245.pt\n",
      "1246.pt\n",
      "1247.pt\n",
      "1248.pt\n",
      "1249.pt\n",
      "1250.pt\n",
      "1251.pt\n",
      "1252.pt\n",
      "1253.pt\n",
      "1254.pt\n",
      "1255.pt\n",
      "1256.pt\n",
      "1257.pt\n",
      "1258.pt\n",
      "1259.pt\n",
      "1260.pt\n",
      "1261.pt\n",
      "1262.pt\n",
      "1263.pt\n",
      "1264.pt\n",
      "1265.pt\n",
      "1266.pt\n",
      "1267.pt\n",
      "1268.pt\n",
      "1269.pt\n",
      "1270.pt\n",
      "1271.pt\n",
      "1272.pt\n",
      "1273.pt\n",
      "1274.pt\n",
      "1275.pt\n",
      "1276.pt\n",
      "1277.pt\n",
      "1278.pt\n",
      "1279.pt\n",
      "1280.pt\n",
      "1281.pt\n",
      "1282.pt\n",
      "1283.pt\n",
      "1284.pt\n",
      "1285.pt\n",
      "1286.pt\n",
      "1287.pt\n",
      "1288.pt\n",
      "1289.pt\n",
      "1290.pt\n",
      "1291.pt\n",
      "1292.pt\n",
      "1293.pt\n",
      "1294.pt\n",
      "1295.pt\n",
      "1296.pt\n",
      "1297.pt\n",
      "1298.pt\n",
      "1299.pt\n",
      "1300.pt\n",
      "1301.pt\n",
      "1302.pt\n",
      "1303.pt\n",
      "1304.pt\n",
      "1305.pt\n",
      "1306.pt\n",
      "1307.pt\n",
      "1308.pt\n",
      "1309.pt\n",
      "1310.pt\n",
      "1311.pt\n",
      "1312.pt\n",
      "1313.pt\n",
      "1314.pt\n",
      "1315.pt\n",
      "1316.pt\n",
      "1317.pt\n",
      "1318.pt\n",
      "1319.pt\n",
      "1320.pt\n",
      "1321.pt\n",
      "1322.pt\n",
      "1323.pt\n",
      "1324.pt\n",
      "1325.pt\n",
      "1326.pt\n",
      "1327.pt\n",
      "1328.pt\n",
      "1329.pt\n",
      "1330.pt\n",
      "1331.pt\n",
      "1332.pt\n",
      "1333.pt\n",
      "1334.pt\n",
      "1335.pt\n",
      "1336.pt\n",
      "1337.pt\n",
      "1338.pt\n",
      "1339.pt\n",
      "1340.pt\n",
      "1341.pt\n",
      "1342.pt\n",
      "1343.pt\n",
      "1344.pt\n",
      "1345.pt\n",
      "1346.pt\n",
      "1347.pt\n",
      "1348.pt\n",
      "1349.pt\n",
      "1350.pt\n",
      "1351.pt\n",
      "1352.pt\n",
      "1353.pt\n",
      "1354.pt\n",
      "1355.pt\n",
      "1356.pt\n",
      "1357.pt\n",
      "1358.pt\n",
      "1359.pt\n",
      "1360.pt\n",
      "1361.pt\n",
      "1362.pt\n",
      "1363.pt\n",
      "1364.pt\n",
      "1365.pt\n",
      "1366.pt\n",
      "1367.pt\n",
      "1368.pt\n",
      "1369.pt\n",
      "1370.pt\n",
      "1371.pt\n",
      "1372.pt\n",
      "1373.pt\n",
      "1374.pt\n",
      "1375.pt\n",
      "1376.pt\n",
      "1377.pt\n",
      "1378.pt\n",
      "1379.pt\n",
      "1380.pt\n",
      "1381.pt\n",
      "1382.pt\n",
      "1383.pt\n",
      "1384.pt\n",
      "1385.pt\n",
      "1386.pt\n",
      "1387.pt\n",
      "1388.pt\n",
      "1389.pt\n",
      "1390.pt\n",
      "1391.pt\n",
      "1392.pt\n",
      "1393.pt\n",
      "1394.pt\n",
      "1395.pt\n",
      "1396.pt\n",
      "1397.pt\n",
      "1398.pt\n",
      "1399.pt\n",
      "1400.pt\n",
      "1401.pt\n",
      "1402.pt\n",
      "1403.pt\n",
      "1404.pt\n",
      "1405.pt\n",
      "1406.pt\n",
      "1407.pt\n",
      "1408.pt\n",
      "1409.pt\n",
      "1410.pt\n",
      "1411.pt\n",
      "1412.pt\n",
      "1413.pt\n",
      "1414.pt\n",
      "1415.pt\n",
      "1416.pt\n",
      "1417.pt\n",
      "1418.pt\n",
      "1419.pt\n",
      "1420.pt\n",
      "1421.pt\n",
      "1422.pt\n",
      "1423.pt\n",
      "1424.pt\n",
      "1425.pt\n",
      "1426.pt\n",
      "1427.pt\n",
      "1428.pt\n",
      "1429.pt\n",
      "1430.pt\n",
      "1431.pt\n",
      "1432.pt\n",
      "1433.pt\n",
      "1434.pt\n",
      "1435.pt\n",
      "1436.pt\n",
      "1437.pt\n",
      "1438.pt\n",
      "1439.pt\n",
      "1440.pt\n",
      "1441.pt\n",
      "1442.pt\n",
      "1443.pt\n",
      "1444.pt\n",
      "1445.pt\n",
      "1446.pt\n",
      "1447.pt\n",
      "1448.pt\n",
      "1449.pt\n",
      "1450.pt\n",
      "1451.pt\n",
      "1452.pt\n",
      "1453.pt\n",
      "1454.pt\n",
      "1455.pt\n",
      "1456.pt\n",
      "1457.pt\n",
      "1458.pt\n",
      "1459.pt\n",
      "1460.pt\n",
      "1461.pt\n",
      "1462.pt\n",
      "1463.pt\n",
      "1464.pt\n",
      "1465.pt\n",
      "1466.pt\n",
      "1467.pt\n",
      "1468.pt\n",
      "1469.pt\n",
      "1470.pt\n",
      "1471.pt\n",
      "1472.pt\n",
      "1473.pt\n",
      "1474.pt\n",
      "1475.pt\n",
      "1476.pt\n",
      "1477.pt\n",
      "1478.pt\n",
      "1479.pt\n",
      "1480.pt\n",
      "1481.pt\n",
      "1482.pt\n",
      "1483.pt\n",
      "1484.pt\n",
      "1485.pt\n",
      "1486.pt\n",
      "1487.pt\n",
      "1488.pt\n",
      "1489.pt\n",
      "1490.pt\n",
      "1491.pt\n",
      "1492.pt\n",
      "1493.pt\n",
      "1494.pt\n",
      "1495.pt\n",
      "1496.pt\n",
      "1497.pt\n",
      "1498.pt\n",
      "1499.pt\n",
      "1500.pt\n",
      "1501.pt\n",
      "1502.pt\n",
      "1503.pt\n",
      "1504.pt\n",
      "1505.pt\n",
      "1506.pt\n",
      "1507.pt\n",
      "1508.pt\n",
      "1509.pt\n",
      "1510.pt\n",
      "1511.pt\n",
      "1512.pt\n",
      "1513.pt\n",
      "1514.pt\n",
      "1515.pt\n",
      "1516.pt\n",
      "1517.pt\n",
      "1518.pt\n",
      "1519.pt\n",
      "1520.pt\n",
      "1521.pt\n",
      "1522.pt\n",
      "1523.pt\n",
      "1524.pt\n",
      "1525.pt\n",
      "1526.pt\n",
      "1527.pt\n",
      "1528.pt\n",
      "1529.pt\n",
      "1530.pt\n",
      "1531.pt\n",
      "1532.pt\n",
      "1533.pt\n",
      "1534.pt\n",
      "1535.pt\n",
      "1536.pt\n",
      "1537.pt\n",
      "1538.pt\n",
      "1539.pt\n",
      "1540.pt\n",
      "1541.pt\n",
      "1542.pt\n",
      "1543.pt\n",
      "1544.pt\n",
      "1545.pt\n",
      "1546.pt\n",
      "1547.pt\n",
      "1548.pt\n",
      "1549.pt\n",
      "1550.pt\n",
      "1551.pt\n",
      "1552.pt\n",
      "1553.pt\n",
      "1554.pt\n",
      "1555.pt\n",
      "1556.pt\n",
      "1557.pt\n",
      "1558.pt\n",
      "1559.pt\n",
      "1560.pt\n",
      "1561.pt\n",
      "1562.pt\n",
      "1563.pt\n",
      "1564.pt\n",
      "1565.pt\n",
      "1566.pt\n",
      "1567.pt\n",
      "1568.pt\n",
      "1569.pt\n",
      "1570.pt\n",
      "1571.pt\n",
      "1572.pt\n",
      "1573.pt\n",
      "1574.pt\n",
      "1575.pt\n",
      "1576.pt\n",
      "1577.pt\n",
      "1578.pt\n",
      "1579.pt\n",
      "1580.pt\n",
      "1581.pt\n",
      "1582.pt\n",
      "1583.pt\n",
      "1584.pt\n",
      "1585.pt\n",
      "1586.pt\n",
      "1587.pt\n",
      "1588.pt\n",
      "1589.pt\n",
      "1590.pt\n",
      "1591.pt\n",
      "1592.pt\n",
      "1593.pt\n",
      "1594.pt\n",
      "1595.pt\n",
      "1596.pt\n",
      "1597.pt\n",
      "1598.pt\n",
      "1599.pt\n",
      "1600.pt\n",
      "1601.pt\n",
      "1602.pt\n",
      "1603.pt\n",
      "1604.pt\n",
      "1605.pt\n",
      "1606.pt\n",
      "1607.pt\n",
      "1608.pt\n",
      "1609.pt\n",
      "1610.pt\n",
      "1611.pt\n",
      "1612.pt\n",
      "1613.pt\n",
      "1614.pt\n",
      "1615.pt\n",
      "1616.pt\n",
      "1617.pt\n",
      "1618.pt\n",
      "1619.pt\n",
      "1620.pt\n",
      "1621.pt\n",
      "1622.pt\n",
      "1623.pt\n",
      "1624.pt\n",
      "1625.pt\n",
      "1626.pt\n",
      "1627.pt\n",
      "1628.pt\n",
      "1629.pt\n",
      "1630.pt\n",
      "1631.pt\n",
      "1632.pt\n",
      "1633.pt\n",
      "1634.pt\n",
      "1635.pt\n",
      "1636.pt\n",
      "1637.pt\n",
      "1638.pt\n",
      "1639.pt\n",
      "1640.pt\n",
      "1641.pt\n",
      "1642.pt\n",
      "1643.pt\n",
      "1644.pt\n",
      "1645.pt\n",
      "1646.pt\n",
      "1647.pt\n",
      "1648.pt\n",
      "1649.pt\n",
      "1650.pt\n",
      "1651.pt\n",
      "1652.pt\n",
      "1653.pt\n",
      "1654.pt\n",
      "1655.pt\n",
      "1656.pt\n",
      "1657.pt\n",
      "1658.pt\n",
      "1659.pt\n",
      "1660.pt\n",
      "1661.pt\n",
      "1662.pt\n",
      "1663.pt\n",
      "1664.pt\n",
      "1665.pt\n",
      "1666.pt\n",
      "1667.pt\n",
      "1668.pt\n",
      "1669.pt\n",
      "1670.pt\n",
      "1671.pt\n",
      "1672.pt\n",
      "1673.pt\n",
      "1674.pt\n",
      "1675.pt\n",
      "1676.pt\n",
      "1677.pt\n",
      "1678.pt\n",
      "1679.pt\n",
      "1680.pt\n",
      "1681.pt\n",
      "1682.pt\n",
      "1683.pt\n",
      "1684.pt\n",
      "1685.pt\n",
      "1686.pt\n",
      "1687.pt\n",
      "1688.pt\n",
      "1689.pt\n",
      "1690.pt\n",
      "1691.pt\n",
      "1692.pt\n",
      "1693.pt\n",
      "1694.pt\n",
      "1695.pt\n",
      "1696.pt\n",
      "1697.pt\n",
      "1698.pt\n",
      "1699.pt\n",
      "1700.pt\n",
      "1701.pt\n",
      "1702.pt\n",
      "1703.pt\n",
      "1704.pt\n",
      "1705.pt\n",
      "1706.pt\n",
      "1707.pt\n",
      "1708.pt\n",
      "1709.pt\n",
      "1710.pt\n",
      "1711.pt\n",
      "1712.pt\n",
      "1713.pt\n",
      "1714.pt\n",
      "1715.pt\n",
      "1716.pt\n",
      "1717.pt\n",
      "1718.pt\n",
      "1719.pt\n",
      "1720.pt\n",
      "1721.pt\n",
      "1722.pt\n",
      "1723.pt\n",
      "1724.pt\n",
      "1725.pt\n",
      "1726.pt\n",
      "1727.pt\n",
      "1728.pt\n",
      "1729.pt\n",
      "1730.pt\n",
      "1731.pt\n",
      "1732.pt\n",
      "1733.pt\n",
      "1734.pt\n",
      "1735.pt\n",
      "1736.pt\n",
      "1737.pt\n",
      "1738.pt\n",
      "1739.pt\n",
      "1740.pt\n",
      "1741.pt\n",
      "1742.pt\n",
      "1743.pt\n",
      "1744.pt\n",
      "1745.pt\n",
      "1746.pt\n",
      "1747.pt\n",
      "1748.pt\n",
      "1749.pt\n",
      "1750.pt\n",
      "1751.pt\n",
      "1752.pt\n",
      "1753.pt\n",
      "1754.pt\n",
      "1755.pt\n",
      "1756.pt\n",
      "1757.pt\n",
      "1758.pt\n",
      "1759.pt\n",
      "1760.pt\n",
      "1761.pt\n",
      "1762.pt\n",
      "1763.pt\n",
      "1764.pt\n",
      "1765.pt\n",
      "1766.pt\n",
      "1767.pt\n",
      "1768.pt\n",
      "1769.pt\n",
      "1770.pt\n",
      "1771.pt\n",
      "1772.pt\n",
      "1773.pt\n",
      "1774.pt\n",
      "1775.pt\n",
      "1776.pt\n",
      "1777.pt\n",
      "1778.pt\n",
      "1779.pt\n",
      "1780.pt\n",
      "1781.pt\n",
      "1782.pt\n",
      "1783.pt\n",
      "1784.pt\n",
      "1785.pt\n",
      "1786.pt\n",
      "1787.pt\n",
      "1788.pt\n",
      "1789.pt\n",
      "1790.pt\n",
      "1791.pt\n",
      "1792.pt\n",
      "1793.pt\n",
      "1794.pt\n",
      "1795.pt\n",
      "1796.pt\n",
      "1797.pt\n",
      "1798.pt\n",
      "1799.pt\n",
      "1800.pt\n",
      "1801.pt\n",
      "1802.pt\n",
      "1803.pt\n",
      "1804.pt\n",
      "1805.pt\n",
      "1806.pt\n",
      "1807.pt\n",
      "1808.pt\n",
      "1809.pt\n",
      "1810.pt\n",
      "1811.pt\n",
      "1812.pt\n",
      "1813.pt\n",
      "1814.pt\n",
      "1815.pt\n",
      "1816.pt\n",
      "1817.pt\n",
      "1818.pt\n",
      "1819.pt\n",
      "1820.pt\n",
      "1821.pt\n",
      "1822.pt\n",
      "1823.pt\n",
      "1824.pt\n",
      "1825.pt\n",
      "1826.pt\n",
      "1827.pt\n",
      "1828.pt\n",
      "1829.pt\n",
      "1830.pt\n",
      "1831.pt\n",
      "1832.pt\n",
      "1833.pt\n",
      "1834.pt\n",
      "1835.pt\n",
      "1836.pt\n",
      "1837.pt\n",
      "1838.pt\n",
      "1839.pt\n",
      "1840.pt\n",
      "1841.pt\n",
      "1842.pt\n",
      "1843.pt\n",
      "1844.pt\n",
      "1845.pt\n",
      "1846.pt\n",
      "1847.pt\n",
      "1848.pt\n",
      "1849.pt\n",
      "1850.pt\n",
      "1851.pt\n",
      "1852.pt\n",
      "1853.pt\n",
      "1854.pt\n",
      "1855.pt\n",
      "1856.pt\n",
      "1857.pt\n",
      "1858.pt\n",
      "1859.pt\n",
      "1860.pt\n",
      "1861.pt\n",
      "1862.pt\n",
      "1863.pt\n",
      "1864.pt\n",
      "1865.pt\n",
      "1866.pt\n",
      "1867.pt\n",
      "1868.pt\n",
      "1869.pt\n",
      "1870.pt\n",
      "1871.pt\n",
      "1872.pt\n",
      "1873.pt\n",
      "1874.pt\n",
      "1875.pt\n",
      "1876.pt\n",
      "1877.pt\n",
      "1878.pt\n",
      "1879.pt\n",
      "1880.pt\n",
      "1881.pt\n",
      "1882.pt\n",
      "1883.pt\n",
      "1884.pt\n",
      "1885.pt\n",
      "1886.pt\n",
      "1887.pt\n",
      "1888.pt\n",
      "1889.pt\n",
      "1890.pt\n",
      "1891.pt\n",
      "1892.pt\n",
      "1893.pt\n",
      "1894.pt\n",
      "1895.pt\n",
      "1896.pt\n",
      "1897.pt\n",
      "1898.pt\n",
      "1899.pt\n",
      "1900.pt\n",
      "1901.pt\n",
      "1902.pt\n",
      "1903.pt\n",
      "1904.pt\n",
      "1905.pt\n",
      "1906.pt\n",
      "1907.pt\n",
      "1908.pt\n",
      "1909.pt\n",
      "1910.pt\n",
      "1911.pt\n",
      "1912.pt\n",
      "1913.pt\n",
      "1914.pt\n",
      "1915.pt\n",
      "1916.pt\n",
      "1917.pt\n",
      "1918.pt\n",
      "1919.pt\n",
      "1920.pt\n",
      "1921.pt\n",
      "1922.pt\n",
      "1923.pt\n",
      "1924.pt\n",
      "1925.pt\n",
      "1926.pt\n",
      "1927.pt\n",
      "1928.pt\n",
      "1929.pt\n",
      "1930.pt\n",
      "1931.pt\n",
      "1932.pt\n",
      "1933.pt\n",
      "1934.pt\n",
      "1935.pt\n",
      "1936.pt\n",
      "1937.pt\n",
      "1938.pt\n",
      "1939.pt\n",
      "1940.pt\n",
      "1941.pt\n",
      "1942.pt\n",
      "1943.pt\n",
      "1944.pt\n",
      "1945.pt\n",
      "1946.pt\n",
      "1947.pt\n",
      "1948.pt\n",
      "1949.pt\n",
      "1950.pt\n",
      "1951.pt\n",
      "1952.pt\n",
      "1953.pt\n",
      "1954.pt\n",
      "1955.pt\n",
      "1956.pt\n",
      "1957.pt\n",
      "1958.pt\n",
      "1959.pt\n",
      "1960.pt\n",
      "1961.pt\n",
      "1962.pt\n",
      "1963.pt\n",
      "1964.pt\n",
      "1965.pt\n",
      "1966.pt\n",
      "1967.pt\n",
      "1968.pt\n",
      "1969.pt\n",
      "1970.pt\n",
      "1971.pt\n",
      "1972.pt\n",
      "1973.pt\n",
      "1974.pt\n",
      "1975.pt\n",
      "1976.pt\n",
      "1977.pt\n",
      "1978.pt\n",
      "1979.pt\n",
      "1980.pt\n",
      "1981.pt\n",
      "1982.pt\n",
      "1983.pt\n",
      "1984.pt\n",
      "1985.pt\n",
      "1986.pt\n",
      "1987.pt\n",
      "1988.pt\n",
      "1989.pt\n",
      "1990.pt\n",
      "1991.pt\n",
      "1992.pt\n",
      "1993.pt\n",
      "1994.pt\n",
      "1995.pt\n",
      "1996.pt\n",
      "1997.pt\n",
      "1998.pt\n",
      "1999.pt\n",
      "2000.pt\n",
      "2001.pt\n",
      "2002.pt\n",
      "2003.pt\n",
      "2004.pt\n",
      "2005.pt\n",
      "2006.pt\n",
      "2007.pt\n",
      "2008.pt\n",
      "2009.pt\n",
      "2010.pt\n",
      "2011.pt\n",
      "2012.pt\n",
      "2013.pt\n",
      "2014.pt\n",
      "2015.pt\n",
      "2016.pt\n",
      "2017.pt\n",
      "2018.pt\n",
      "2019.pt\n",
      "2020.pt\n",
      "2021.pt\n",
      "2022.pt\n",
      "2023.pt\n",
      "2024.pt\n",
      "2025.pt\n",
      "2026.pt\n",
      "2027.pt\n",
      "2028.pt\n",
      "2029.pt\n",
      "2030.pt\n",
      "2031.pt\n",
      "2032.pt\n",
      "2033.pt\n",
      "2034.pt\n",
      "2035.pt\n",
      "2036.pt\n",
      "2037.pt\n",
      "2038.pt\n",
      "2039.pt\n",
      "2040.pt\n",
      "2041.pt\n",
      "2042.pt\n",
      "2043.pt\n",
      "2044.pt\n",
      "2045.pt\n",
      "2046.pt\n",
      "2047.pt\n",
      "2048.pt\n",
      "2049.pt\n",
      "2050.pt\n",
      "2051.pt\n",
      "2052.pt\n",
      "2053.pt\n",
      "2054.pt\n",
      "2055.pt\n",
      "2056.pt\n",
      "2057.pt\n",
      "2058.pt\n",
      "2059.pt\n",
      "2060.pt\n",
      "2061.pt\n",
      "2062.pt\n",
      "2063.pt\n",
      "2064.pt\n",
      "2065.pt\n",
      "2066.pt\n",
      "2067.pt\n",
      "2068.pt\n",
      "2069.pt\n",
      "2070.pt\n",
      "2071.pt\n",
      "2072.pt\n",
      "2073.pt\n",
      "2074.pt\n",
      "2075.pt\n",
      "2076.pt\n",
      "2077.pt\n",
      "2078.pt\n",
      "2079.pt\n",
      "2080.pt\n",
      "2081.pt\n",
      "2082.pt\n",
      "2083.pt\n",
      "2084.pt\n",
      "2085.pt\n",
      "2086.pt\n",
      "2087.pt\n",
      "2088.pt\n",
      "2089.pt\n",
      "2090.pt\n",
      "2091.pt\n",
      "2092.pt\n",
      "2093.pt\n",
      "2094.pt\n",
      "2095.pt\n",
      "2096.pt\n",
      "2097.pt\n",
      "2098.pt\n",
      "2099.pt\n",
      "2100.pt\n",
      "2101.pt\n",
      "2102.pt\n",
      "2103.pt\n",
      "2104.pt\n",
      "2105.pt\n",
      "2106.pt\n",
      "2107.pt\n",
      "2108.pt\n",
      "2109.pt\n",
      "2110.pt\n",
      "2111.pt\n",
      "2112.pt\n",
      "2113.pt\n",
      "2114.pt\n",
      "2115.pt\n",
      "2116.pt\n",
      "2117.pt\n",
      "2118.pt\n",
      "2119.pt\n",
      "2120.pt\n",
      "2121.pt\n",
      "2122.pt\n",
      "2123.pt\n",
      "2124.pt\n",
      "2125.pt\n",
      "2126.pt\n",
      "2127.pt\n",
      "2128.pt\n",
      "2129.pt\n",
      "2130.pt\n",
      "2131.pt\n",
      "2132.pt\n",
      "2133.pt\n",
      "2134.pt\n",
      "2135.pt\n",
      "2136.pt\n",
      "2137.pt\n",
      "2138.pt\n",
      "2139.pt\n",
      "2140.pt\n",
      "2141.pt\n",
      "2142.pt\n",
      "2143.pt\n",
      "2144.pt\n",
      "2145.pt\n",
      "2146.pt\n",
      "2147.pt\n",
      "2148.pt\n",
      "2149.pt\n",
      "2150.pt\n",
      "2151.pt\n",
      "2152.pt\n",
      "2153.pt\n",
      "2154.pt\n",
      "2155.pt\n",
      "2156.pt\n",
      "2157.pt\n",
      "2158.pt\n",
      "2159.pt\n",
      "2160.pt\n",
      "2161.pt\n",
      "2162.pt\n",
      "2163.pt\n",
      "2164.pt\n",
      "2165.pt\n",
      "2166.pt\n",
      "2167.pt\n",
      "2168.pt\n",
      "2169.pt\n",
      "2170.pt\n",
      "2171.pt\n",
      "2172.pt\n",
      "2173.pt\n",
      "2174.pt\n",
      "2175.pt\n",
      "2176.pt\n",
      "2177.pt\n",
      "2178.pt\n",
      "2179.pt\n",
      "2180.pt\n",
      "2181.pt\n",
      "2182.pt\n",
      "2183.pt\n",
      "2184.pt\n",
      "2185.pt\n",
      "2186.pt\n",
      "2187.pt\n",
      "2188.pt\n",
      "2189.pt\n",
      "2190.pt\n",
      "2191.pt\n",
      "2192.pt\n",
      "2193.pt\n",
      "2194.pt\n",
      "2195.pt\n",
      "2196.pt\n",
      "2197.pt\n",
      "2198.pt\n",
      "2199.pt\n",
      "2200.pt\n",
      "2201.pt\n",
      "2202.pt\n",
      "2203.pt\n",
      "2204.pt\n",
      "2205.pt\n",
      "2206.pt\n",
      "2207.pt\n",
      "2208.pt\n",
      "2209.pt\n",
      "2210.pt\n",
      "2211.pt\n",
      "2212.pt\n",
      "2213.pt\n",
      "2214.pt\n",
      "2215.pt\n",
      "2216.pt\n",
      "2217.pt\n",
      "2218.pt\n",
      "2219.pt\n",
      "2220.pt\n",
      "2221.pt\n",
      "2222.pt\n",
      "2223.pt\n",
      "2224.pt\n",
      "2225.pt\n",
      "2226.pt\n",
      "2227.pt\n",
      "2228.pt\n",
      "2229.pt\n",
      "2230.pt\n",
      "2231.pt\n",
      "2232.pt\n",
      "2233.pt\n",
      "2234.pt\n",
      "2235.pt\n",
      "2236.pt\n",
      "2237.pt\n",
      "2238.pt\n",
      "2239.pt\n",
      "2240.pt\n",
      "2241.pt\n",
      "2242.pt\n",
      "2243.pt\n",
      "2244.pt\n",
      "2245.pt\n",
      "2246.pt\n",
      "2247.pt\n",
      "2248.pt\n",
      "2249.pt\n",
      "2250.pt\n",
      "2251.pt\n",
      "2252.pt\n",
      "2253.pt\n",
      "2254.pt\n",
      "2255.pt\n",
      "2256.pt\n",
      "2257.pt\n",
      "2258.pt\n",
      "2259.pt\n",
      "2260.pt\n",
      "2261.pt\n",
      "2262.pt\n",
      "2263.pt\n",
      "2264.pt\n",
      "2265.pt\n",
      "2266.pt\n",
      "2267.pt\n",
      "2268.pt\n",
      "2269.pt\n",
      "2270.pt\n",
      "2271.pt\n",
      "2272.pt\n",
      "2273.pt\n",
      "2274.pt\n",
      "2275.pt\n",
      "2276.pt\n",
      "2277.pt\n",
      "2278.pt\n",
      "2279.pt\n",
      "2280.pt\n",
      "2281.pt\n",
      "2282.pt\n",
      "2283.pt\n",
      "2284.pt\n",
      "2285.pt\n",
      "2286.pt\n",
      "2287.pt\n",
      "2288.pt\n",
      "2289.pt\n",
      "2290.pt\n",
      "2291.pt\n",
      "2292.pt\n",
      "2293.pt\n",
      "2294.pt\n",
      "2295.pt\n",
      "2296.pt\n",
      "2297.pt\n",
      "2298.pt\n",
      "2299.pt\n",
      "2300.pt\n",
      "2301.pt\n",
      "2302.pt\n",
      "2303.pt\n",
      "2304.pt\n",
      "2305.pt\n",
      "2306.pt\n",
      "2307.pt\n",
      "2308.pt\n",
      "2309.pt\n",
      "2310.pt\n",
      "2311.pt\n",
      "2312.pt\n",
      "2313.pt\n",
      "2314.pt\n",
      "2315.pt\n",
      "2316.pt\n",
      "2317.pt\n",
      "2318.pt\n",
      "2319.pt\n",
      "2320.pt\n",
      "2321.pt\n",
      "2322.pt\n",
      "2323.pt\n",
      "2324.pt\n",
      "2325.pt\n",
      "2326.pt\n",
      "2327.pt\n",
      "2328.pt\n",
      "2329.pt\n",
      "2330.pt\n",
      "2331.pt\n",
      "2332.pt\n",
      "2333.pt\n",
      "2334.pt\n",
      "2335.pt\n",
      "2336.pt\n",
      "2337.pt\n",
      "2338.pt\n",
      "2339.pt\n",
      "2340.pt\n",
      "2341.pt\n",
      "2342.pt\n",
      "2343.pt\n",
      "2344.pt\n",
      "2345.pt\n",
      "2346.pt\n",
      "2347.pt\n",
      "2348.pt\n",
      "2349.pt\n",
      "2350.pt\n",
      "2351.pt\n",
      "2352.pt\n",
      "2353.pt\n",
      "2354.pt\n",
      "2355.pt\n",
      "2356.pt\n",
      "2357.pt\n",
      "2358.pt\n",
      "2359.pt\n",
      "2360.pt\n",
      "2361.pt\n",
      "2362.pt\n",
      "2363.pt\n",
      "2364.pt\n",
      "2365.pt\n",
      "2366.pt\n",
      "2367.pt\n",
      "2368.pt\n",
      "2369.pt\n",
      "2370.pt\n",
      "2371.pt\n",
      "2372.pt\n",
      "2373.pt\n",
      "2374.pt\n",
      "2375.pt\n",
      "2376.pt\n",
      "2377.pt\n",
      "2378.pt\n",
      "2379.pt\n",
      "2380.pt\n",
      "2381.pt\n",
      "2382.pt\n",
      "2383.pt\n",
      "2384.pt\n",
      "2385.pt\n",
      "2386.pt\n",
      "2387.pt\n",
      "2388.pt\n",
      "2389.pt\n",
      "2390.pt\n",
      "2391.pt\n",
      "2392.pt\n",
      "2393.pt\n",
      "2394.pt\n",
      "2395.pt\n",
      "2396.pt\n",
      "2397.pt\n",
      "2398.pt\n",
      "2399.pt\n",
      "2400.pt\n",
      "2401.pt\n",
      "2402.pt\n",
      "2403.pt\n",
      "2404.pt\n",
      "2405.pt\n",
      "2406.pt\n",
      "2407.pt\n",
      "2408.pt\n",
      "2409.pt\n",
      "2410.pt\n",
      "2411.pt\n",
      "2412.pt\n",
      "2413.pt\n",
      "2414.pt\n",
      "2415.pt\n",
      "2416.pt\n",
      "2417.pt\n",
      "2418.pt\n",
      "2419.pt\n",
      "2420.pt\n",
      "2421.pt\n",
      "2422.pt\n",
      "2423.pt\n",
      "2424.pt\n",
      "2425.pt\n",
      "2426.pt\n",
      "2427.pt\n",
      "2428.pt\n",
      "2429.pt\n",
      "2430.pt\n",
      "2431.pt\n",
      "2432.pt\n",
      "2433.pt\n",
      "2434.pt\n",
      "2435.pt\n",
      "2436.pt\n",
      "2437.pt\n",
      "2438.pt\n",
      "2439.pt\n",
      "2440.pt\n",
      "2441.pt\n",
      "2442.pt\n",
      "2443.pt\n",
      "2444.pt\n",
      "2445.pt\n",
      "2446.pt\n",
      "2447.pt\n",
      "2448.pt\n",
      "2449.pt\n",
      "2450.pt\n",
      "2451.pt\n",
      "2452.pt\n",
      "2453.pt\n",
      "2454.pt\n",
      "2455.pt\n",
      "2456.pt\n",
      "2457.pt\n",
      "2458.pt\n",
      "2459.pt\n",
      "2460.pt\n",
      "2461.pt\n",
      "2462.pt\n",
      "2463.pt\n",
      "2464.pt\n",
      "2465.pt\n",
      "2466.pt\n",
      "2467.pt\n",
      "2468.pt\n",
      "2469.pt\n",
      "2470.pt\n",
      "2471.pt\n",
      "2472.pt\n",
      "2473.pt\n",
      "2474.pt\n",
      "2475.pt\n",
      "2476.pt\n",
      "2477.pt\n",
      "2478.pt\n",
      "2479.pt\n",
      "2480.pt\n",
      "2481.pt\n",
      "2482.pt\n",
      "2483.pt\n",
      "2484.pt\n",
      "2485.pt\n",
      "2486.pt\n",
      "2487.pt\n",
      "2488.pt\n",
      "2489.pt\n",
      "2490.pt\n",
      "2491.pt\n",
      "2492.pt\n",
      "2493.pt\n",
      "2494.pt\n",
      "2495.pt\n",
      "2496.pt\n",
      "2497.pt\n",
      "2498.pt\n",
      "2499.pt\n",
      "2500.pt\n",
      "2501.pt\n",
      "2502.pt\n",
      "2503.pt\n",
      "2504.pt\n",
      "2505.pt\n",
      "2506.pt\n",
      "2507.pt\n",
      "2508.pt\n",
      "2509.pt\n",
      "2510.pt\n",
      "2511.pt\n",
      "2512.pt\n",
      "2513.pt\n",
      "2514.pt\n",
      "2515.pt\n",
      "2516.pt\n",
      "2517.pt\n",
      "2518.pt\n",
      "2519.pt\n",
      "2520.pt\n",
      "2521.pt\n",
      "2522.pt\n",
      "2523.pt\n",
      "2524.pt\n",
      "2525.pt\n",
      "2526.pt\n",
      "2527.pt\n",
      "2528.pt\n",
      "2529.pt\n",
      "2530.pt\n",
      "2531.pt\n",
      "2532.pt\n",
      "2533.pt\n",
      "2534.pt\n",
      "2535.pt\n",
      "2536.pt\n",
      "2537.pt\n",
      "2538.pt\n",
      "2539.pt\n",
      "2540.pt\n",
      "2541.pt\n",
      "2542.pt\n",
      "2543.pt\n",
      "2544.pt\n",
      "2545.pt\n",
      "2546.pt\n",
      "2547.pt\n",
      "2548.pt\n",
      "2549.pt\n",
      "2550.pt\n",
      "2551.pt\n",
      "2552.pt\n",
      "2553.pt\n",
      "2554.pt\n",
      "2555.pt\n",
      "2556.pt\n",
      "2557.pt\n",
      "2558.pt\n",
      "2559.pt\n",
      "2560.pt\n",
      "2561.pt\n",
      "2562.pt\n",
      "2563.pt\n",
      "2564.pt\n",
      "2565.pt\n",
      "2566.pt\n",
      "2567.pt\n",
      "2568.pt\n",
      "2569.pt\n",
      "2570.pt\n",
      "2571.pt\n",
      "2572.pt\n",
      "2573.pt\n",
      "2574.pt\n",
      "2575.pt\n",
      "2576.pt\n",
      "2577.pt\n",
      "2578.pt\n",
      "2579.pt\n",
      "2580.pt\n",
      "2581.pt\n",
      "2582.pt\n",
      "2583.pt\n",
      "2584.pt\n",
      "2585.pt\n",
      "2586.pt\n",
      "2587.pt\n",
      "2588.pt\n",
      "2589.pt\n",
      "2590.pt\n",
      "2591.pt\n",
      "2592.pt\n",
      "2593.pt\n",
      "2594.pt\n",
      "2595.pt\n",
      "2596.pt\n",
      "2597.pt\n",
      "2598.pt\n",
      "2599.pt\n",
      "2600.pt\n",
      "2601.pt\n",
      "2602.pt\n",
      "2603.pt\n",
      "2604.pt\n",
      "2605.pt\n",
      "2606.pt\n",
      "2607.pt\n",
      "2608.pt\n",
      "2609.pt\n",
      "2610.pt\n",
      "2611.pt\n",
      "2612.pt\n",
      "2613.pt\n",
      "2614.pt\n",
      "2615.pt\n",
      "2616.pt\n",
      "2617.pt\n",
      "2618.pt\n",
      "2619.pt\n",
      "2620.pt\n",
      "2621.pt\n",
      "2622.pt\n",
      "2623.pt\n",
      "2624.pt\n",
      "2625.pt\n",
      "2626.pt\n",
      "2627.pt\n",
      "2628.pt\n",
      "2629.pt\n",
      "2630.pt\n",
      "2631.pt\n",
      "2632.pt\n",
      "2633.pt\n",
      "2634.pt\n",
      "2635.pt\n",
      "2636.pt\n",
      "2637.pt\n",
      "2638.pt\n",
      "2639.pt\n",
      "2640.pt\n",
      "2641.pt\n",
      "2642.pt\n",
      "2643.pt\n",
      "2644.pt\n",
      "2645.pt\n",
      "2646.pt\n",
      "2647.pt\n",
      "2648.pt\n",
      "2649.pt\n",
      "2650.pt\n",
      "2651.pt\n",
      "2652.pt\n",
      "2653.pt\n",
      "2654.pt\n",
      "2655.pt\n",
      "2656.pt\n",
      "2657.pt\n",
      "2658.pt\n",
      "2659.pt\n",
      "2660.pt\n",
      "2661.pt\n",
      "2662.pt\n",
      "2663.pt\n",
      "2664.pt\n",
      "2665.pt\n",
      "2666.pt\n",
      "2667.pt\n",
      "2668.pt\n",
      "2669.pt\n",
      "2670.pt\n",
      "2671.pt\n",
      "2672.pt\n",
      "2673.pt\n",
      "2674.pt\n",
      "2675.pt\n",
      "2676.pt\n",
      "2677.pt\n",
      "2678.pt\n",
      "2679.pt\n",
      "2680.pt\n",
      "2681.pt\n",
      "2682.pt\n",
      "2683.pt\n",
      "2684.pt\n",
      "2685.pt\n",
      "2686.pt\n",
      "2687.pt\n",
      "2688.pt\n",
      "2689.pt\n",
      "2690.pt\n",
      "2691.pt\n",
      "2692.pt\n",
      "2693.pt\n",
      "2694.pt\n",
      "2695.pt\n",
      "2696.pt\n",
      "2697.pt\n",
      "2698.pt\n",
      "2699.pt\n",
      "2700.pt\n",
      "2701.pt\n",
      "2702.pt\n",
      "2703.pt\n",
      "2704.pt\n",
      "2705.pt\n",
      "2706.pt\n",
      "2707.pt\n",
      "2708.pt\n",
      "2709.pt\n",
      "2710.pt\n",
      "2711.pt\n",
      "2712.pt\n",
      "2713.pt\n",
      "2714.pt\n",
      "2715.pt\n",
      "2716.pt\n",
      "2717.pt\n",
      "2718.pt\n",
      "2719.pt\n",
      "2720.pt\n",
      "2721.pt\n",
      "2722.pt\n",
      "2723.pt\n",
      "2724.pt\n",
      "2725.pt\n",
      "2726.pt\n",
      "2727.pt\n",
      "2728.pt\n",
      "2729.pt\n",
      "2730.pt\n",
      "2731.pt\n",
      "2732.pt\n",
      "2733.pt\n",
      "2734.pt\n",
      "2735.pt\n",
      "2736.pt\n",
      "2737.pt\n",
      "2738.pt\n",
      "2739.pt\n",
      "2740.pt\n",
      "2741.pt\n",
      "2742.pt\n",
      "2743.pt\n",
      "2744.pt\n",
      "2745.pt\n",
      "2746.pt\n",
      "2747.pt\n",
      "2748.pt\n",
      "2749.pt\n",
      "2750.pt\n",
      "2751.pt\n",
      "2752.pt\n",
      "2753.pt\n",
      "2754.pt\n",
      "2755.pt\n",
      "2756.pt\n",
      "2757.pt\n",
      "2758.pt\n",
      "2759.pt\n",
      "2760.pt\n",
      "2761.pt\n",
      "2762.pt\n",
      "2763.pt\n",
      "2764.pt\n",
      "2765.pt\n",
      "2766.pt\n",
      "2767.pt\n",
      "2768.pt\n",
      "2769.pt\n",
      "2770.pt\n",
      "2771.pt\n",
      "2772.pt\n",
      "2773.pt\n",
      "2774.pt\n",
      "2775.pt\n",
      "2776.pt\n",
      "2777.pt\n",
      "2778.pt\n",
      "2779.pt\n",
      "2780.pt\n",
      "2781.pt\n",
      "2782.pt\n",
      "2783.pt\n",
      "2784.pt\n",
      "2785.pt\n",
      "2786.pt\n",
      "2787.pt\n",
      "2788.pt\n",
      "2789.pt\n",
      "2790.pt\n",
      "2791.pt\n",
      "2792.pt\n",
      "2793.pt\n",
      "2794.pt\n",
      "2795.pt\n",
      "2796.pt\n",
      "2797.pt\n",
      "2798.pt\n",
      "2799.pt\n",
      "2800.pt\n",
      "2801.pt\n",
      "2802.pt\n",
      "2803.pt\n",
      "2804.pt\n",
      "2805.pt\n",
      "2806.pt\n",
      "2807.pt\n",
      "2808.pt\n",
      "2809.pt\n",
      "2810.pt\n",
      "2811.pt\n",
      "2812.pt\n",
      "2813.pt\n",
      "2814.pt\n",
      "2815.pt\n",
      "2816.pt\n",
      "2817.pt\n",
      "2818.pt\n",
      "2819.pt\n",
      "2820.pt\n",
      "2821.pt\n",
      "2822.pt\n",
      "2823.pt\n",
      "2824.pt\n",
      "2825.pt\n",
      "2826.pt\n",
      "2827.pt\n",
      "2828.pt\n",
      "2829.pt\n",
      "2830.pt\n",
      "2831.pt\n",
      "2832.pt\n",
      "2833.pt\n",
      "2834.pt\n",
      "2835.pt\n",
      "2836.pt\n",
      "2837.pt\n",
      "2838.pt\n",
      "2839.pt\n",
      "2840.pt\n",
      "2841.pt\n",
      "2842.pt\n",
      "2843.pt\n",
      "2844.pt\n",
      "2845.pt\n",
      "2846.pt\n",
      "2847.pt\n",
      "2848.pt\n",
      "2849.pt\n",
      "2850.pt\n",
      "2851.pt\n",
      "2852.pt\n",
      "2853.pt\n",
      "2854.pt\n",
      "2855.pt\n",
      "2856.pt\n",
      "2857.pt\n",
      "2858.pt\n",
      "2859.pt\n",
      "2860.pt\n",
      "2861.pt\n",
      "2862.pt\n",
      "2863.pt\n",
      "2864.pt\n",
      "2865.pt\n",
      "2866.pt\n",
      "2867.pt\n",
      "2868.pt\n",
      "2869.pt\n",
      "2870.pt\n",
      "2871.pt\n",
      "2872.pt\n",
      "2873.pt\n",
      "2874.pt\n",
      "2875.pt\n",
      "2876.pt\n",
      "2877.pt\n",
      "2878.pt\n",
      "2879.pt\n",
      "2880.pt\n",
      "2881.pt\n",
      "2882.pt\n",
      "2883.pt\n",
      "2884.pt\n",
      "2885.pt\n",
      "2886.pt\n",
      "2887.pt\n",
      "2888.pt\n",
      "2889.pt\n",
      "2890.pt\n",
      "2891.pt\n",
      "2892.pt\n",
      "2893.pt\n",
      "2894.pt\n",
      "2895.pt\n",
      "2896.pt\n",
      "2897.pt\n",
      "2898.pt\n",
      "2899.pt\n",
      "2900.pt\n",
      "2901.pt\n",
      "2902.pt\n",
      "2903.pt\n",
      "2904.pt\n",
      "2905.pt\n",
      "2906.pt\n",
      "2907.pt\n",
      "2908.pt\n",
      "2909.pt\n",
      "2910.pt\n",
      "2911.pt\n",
      "2912.pt\n",
      "2913.pt\n",
      "2914.pt\n",
      "2915.pt\n",
      "2916.pt\n",
      "2917.pt\n",
      "2918.pt\n",
      "2919.pt\n",
      "2920.pt\n",
      "2921.pt\n",
      "2922.pt\n",
      "2923.pt\n",
      "2924.pt\n",
      "2925.pt\n",
      "2926.pt\n",
      "2927.pt\n",
      "2928.pt\n",
      "2929.pt\n",
      "2930.pt\n",
      "2931.pt\n",
      "2932.pt\n",
      "2933.pt\n",
      "2934.pt\n",
      "2935.pt\n",
      "2936.pt\n",
      "2937.pt\n",
      "2938.pt\n",
      "2939.pt\n",
      "2940.pt\n",
      "2941.pt\n",
      "2942.pt\n",
      "2943.pt\n",
      "2944.pt\n",
      "2945.pt\n",
      "2946.pt\n",
      "2947.pt\n",
      "2948.pt\n",
      "2949.pt\n",
      "2950.pt\n",
      "2951.pt\n",
      "2952.pt\n",
      "2953.pt\n",
      "2954.pt\n",
      "2955.pt\n",
      "2956.pt\n",
      "2957.pt\n",
      "2958.pt\n",
      "2959.pt\n",
      "2960.pt\n",
      "2961.pt\n",
      "2962.pt\n",
      "2963.pt\n",
      "2964.pt\n",
      "2965.pt\n",
      "2966.pt\n",
      "2967.pt\n",
      "2968.pt\n",
      "2969.pt\n",
      "2970.pt\n",
      "2971.pt\n",
      "2972.pt\n",
      "2973.pt\n",
      "2974.pt\n",
      "2975.pt\n",
      "2976.pt\n",
      "2977.pt\n",
      "2978.pt\n",
      "2979.pt\n",
      "2980.pt\n",
      "2981.pt\n",
      "2982.pt\n",
      "2983.pt\n",
      "2984.pt\n",
      "2985.pt\n",
      "2986.pt\n",
      "2987.pt\n",
      "2988.pt\n",
      "2989.pt\n",
      "2990.pt\n",
      "2991.pt\n",
      "2992.pt\n",
      "2993.pt\n",
      "2994.pt\n",
      "2995.pt\n",
      "2996.pt\n",
      "2997.pt\n",
      "2998.pt\n",
      "2999.pt\n",
      "3000.pt\n",
      "3001.pt\n",
      "3002.pt\n",
      "3003.pt\n",
      "3004.pt\n",
      "3005.pt\n",
      "3006.pt\n",
      "3007.pt\n",
      "3008.pt\n",
      "3009.pt\n",
      "3010.pt\n",
      "3011.pt\n",
      "3012.pt\n",
      "3013.pt\n",
      "3014.pt\n",
      "3015.pt\n",
      "3016.pt\n",
      "3017.pt\n",
      "3018.pt\n",
      "3019.pt\n",
      "3020.pt\n",
      "3021.pt\n",
      "3022.pt\n",
      "3023.pt\n",
      "3024.pt\n",
      "3025.pt\n",
      "3026.pt\n",
      "3027.pt\n",
      "3028.pt\n",
      "3029.pt\n",
      "3030.pt\n",
      "3031.pt\n",
      "3032.pt\n",
      "3033.pt\n",
      "3034.pt\n",
      "3035.pt\n",
      "3036.pt\n",
      "3037.pt\n",
      "3038.pt\n",
      "3039.pt\n",
      "3040.pt\n",
      "3041.pt\n",
      "3042.pt\n",
      "3043.pt\n",
      "3044.pt\n",
      "3045.pt\n",
      "3046.pt\n",
      "3047.pt\n",
      "3048.pt\n",
      "3049.pt\n",
      "3050.pt\n",
      "3051.pt\n",
      "3052.pt\n",
      "3053.pt\n",
      "3054.pt\n",
      "3055.pt\n",
      "3056.pt\n",
      "3057.pt\n",
      "3058.pt\n",
      "3059.pt\n",
      "3060.pt\n",
      "3061.pt\n",
      "3062.pt\n",
      "3063.pt\n",
      "3064.pt\n",
      "3065.pt\n",
      "3066.pt\n",
      "3067.pt\n",
      "3068.pt\n",
      "3069.pt\n",
      "3070.pt\n",
      "3071.pt\n",
      "3072.pt\n",
      "3073.pt\n",
      "3074.pt\n",
      "3075.pt\n",
      "3076.pt\n",
      "3077.pt\n",
      "3078.pt\n",
      "3079.pt\n",
      "3080.pt\n",
      "3081.pt\n",
      "3082.pt\n",
      "3083.pt\n",
      "3084.pt\n",
      "3085.pt\n",
      "3086.pt\n",
      "3087.pt\n",
      "3088.pt\n",
      "3089.pt\n",
      "3090.pt\n",
      "3091.pt\n",
      "3092.pt\n",
      "3093.pt\n",
      "3094.pt\n",
      "3095.pt\n",
      "3096.pt\n",
      "3097.pt\n",
      "3098.pt\n",
      "3099.pt\n",
      "3100.pt\n",
      "3101.pt\n",
      "3102.pt\n",
      "3103.pt\n",
      "3104.pt\n",
      "3105.pt\n",
      "3106.pt\n",
      "3107.pt\n",
      "3108.pt\n",
      "3109.pt\n",
      "3110.pt\n",
      "3111.pt\n",
      "3112.pt\n",
      "3113.pt\n",
      "3114.pt\n",
      "3115.pt\n",
      "3116.pt\n",
      "3117.pt\n",
      "3118.pt\n",
      "3119.pt\n",
      "3120.pt\n",
      "3121.pt\n",
      "3122.pt\n",
      "3123.pt\n",
      "3124.pt\n",
      "3125.pt\n",
      "3126.pt\n",
      "3127.pt\n",
      "3128.pt\n",
      "3129.pt\n",
      "3130.pt\n",
      "3131.pt\n",
      "3132.pt\n",
      "3133.pt\n",
      "3134.pt\n",
      "3135.pt\n",
      "3136.pt\n",
      "3137.pt\n",
      "3138.pt\n",
      "3139.pt\n",
      "3140.pt\n",
      "3141.pt\n",
      "3142.pt\n",
      "3143.pt\n",
      "3144.pt\n",
      "3145.pt\n",
      "3146.pt\n",
      "3147.pt\n",
      "3148.pt\n",
      "3149.pt\n",
      "3150.pt\n",
      "3151.pt\n",
      "3152.pt\n",
      "3153.pt\n",
      "3154.pt\n",
      "3155.pt\n",
      "3156.pt\n",
      "3157.pt\n",
      "3158.pt\n",
      "3159.pt\n",
      "3160.pt\n",
      "3161.pt\n",
      "3162.pt\n",
      "3163.pt\n",
      "3164.pt\n",
      "3165.pt\n",
      "3166.pt\n",
      "3167.pt\n",
      "3168.pt\n",
      "3169.pt\n",
      "3170.pt\n",
      "3171.pt\n",
      "3172.pt\n",
      "3173.pt\n",
      "3174.pt\n",
      "3175.pt\n",
      "3176.pt\n",
      "3177.pt\n",
      "3178.pt\n",
      "3179.pt\n",
      "3180.pt\n",
      "3181.pt\n",
      "3182.pt\n",
      "3183.pt\n",
      "3184.pt\n",
      "3185.pt\n",
      "3186.pt\n",
      "3187.pt\n",
      "3188.pt\n",
      "3189.pt\n",
      "3190.pt\n",
      "3191.pt\n",
      "3192.pt\n",
      "3193.pt\n",
      "3194.pt\n",
      "3195.pt\n",
      "3196.pt\n",
      "3197.pt\n",
      "3198.pt\n",
      "3199.pt\n",
      "3200.pt\n",
      "3201.pt\n",
      "3202.pt\n",
      "3203.pt\n",
      "3204.pt\n",
      "3205.pt\n",
      "3206.pt\n",
      "3207.pt\n",
      "3208.pt\n",
      "3209.pt\n",
      "3210.pt\n",
      "3211.pt\n",
      "3212.pt\n",
      "3213.pt\n",
      "3214.pt\n",
      "3215.pt\n",
      "3216.pt\n",
      "3217.pt\n",
      "3218.pt\n",
      "3219.pt\n",
      "3220.pt\n",
      "3221.pt\n",
      "3222.pt\n",
      "3223.pt\n",
      "3224.pt\n",
      "3225.pt\n",
      "3226.pt\n",
      "3227.pt\n",
      "3228.pt\n",
      "3229.pt\n",
      "3230.pt\n",
      "3231.pt\n",
      "3232.pt\n",
      "3233.pt\n",
      "3234.pt\n",
      "3235.pt\n",
      "3236.pt\n",
      "3237.pt\n",
      "3238.pt\n",
      "3239.pt\n",
      "3240.pt\n",
      "3241.pt\n",
      "3242.pt\n",
      "3243.pt\n",
      "3244.pt\n",
      "3245.pt\n",
      "3246.pt\n",
      "3247.pt\n",
      "3248.pt\n",
      "3249.pt\n",
      "3250.pt\n",
      "3251.pt\n",
      "3252.pt\n",
      "3253.pt\n",
      "3254.pt\n",
      "3255.pt\n",
      "3256.pt\n",
      "3257.pt\n",
      "3258.pt\n",
      "3259.pt\n",
      "3260.pt\n",
      "3261.pt\n",
      "3262.pt\n",
      "3263.pt\n",
      "3264.pt\n",
      "3265.pt\n",
      "3266.pt\n",
      "3267.pt\n",
      "3268.pt\n",
      "3269.pt\n",
      "3270.pt\n",
      "3271.pt\n",
      "3272.pt\n",
      "3273.pt\n",
      "3274.pt\n",
      "3275.pt\n",
      "3276.pt\n",
      "3277.pt\n",
      "3278.pt\n",
      "3279.pt\n",
      "3280.pt\n",
      "3281.pt\n",
      "3282.pt\n",
      "3283.pt\n",
      "3284.pt\n",
      "3285.pt\n",
      "3286.pt\n",
      "3287.pt\n",
      "3288.pt\n",
      "3289.pt\n",
      "3290.pt\n",
      "3291.pt\n",
      "3292.pt\n",
      "3293.pt\n",
      "3294.pt\n",
      "3295.pt\n",
      "3296.pt\n",
      "3297.pt\n",
      "3298.pt\n",
      "3299.pt\n",
      "3300.pt\n",
      "3301.pt\n",
      "3302.pt\n",
      "3303.pt\n",
      "3304.pt\n",
      "3305.pt\n",
      "3306.pt\n",
      "3307.pt\n",
      "3308.pt\n",
      "3309.pt\n",
      "3310.pt\n",
      "3311.pt\n",
      "3312.pt\n",
      "3313.pt\n",
      "3314.pt\n",
      "3315.pt\n",
      "3316.pt\n",
      "3317.pt\n",
      "3318.pt\n",
      "3319.pt\n",
      "3320.pt\n",
      "3321.pt\n",
      "3322.pt\n",
      "3323.pt\n",
      "3324.pt\n",
      "3325.pt\n",
      "3326.pt\n",
      "3327.pt\n",
      "3328.pt\n",
      "3329.pt\n",
      "3330.pt\n",
      "3331.pt\n",
      "3332.pt\n",
      "3333.pt\n",
      "3334.pt\n",
      "3335.pt\n",
      "3336.pt\n",
      "3337.pt\n",
      "3338.pt\n",
      "3339.pt\n",
      "3340.pt\n",
      "3341.pt\n",
      "3342.pt\n",
      "3343.pt\n",
      "3344.pt\n",
      "3345.pt\n",
      "3346.pt\n",
      "3347.pt\n",
      "3348.pt\n",
      "3349.pt\n",
      "3350.pt\n",
      "3351.pt\n",
      "3352.pt\n",
      "3353.pt\n",
      "3354.pt\n",
      "3355.pt\n",
      "3356.pt\n",
      "3357.pt\n",
      "3358.pt\n",
      "3359.pt\n",
      "3360.pt\n",
      "3361.pt\n",
      "3362.pt\n",
      "3363.pt\n",
      "3364.pt\n",
      "3365.pt\n",
      "3366.pt\n",
      "3367.pt\n",
      "3368.pt\n",
      "3369.pt\n",
      "3370.pt\n",
      "3371.pt\n",
      "3372.pt\n",
      "3373.pt\n",
      "3374.pt\n",
      "3375.pt\n",
      "3376.pt\n",
      "3377.pt\n",
      "3378.pt\n",
      "3379.pt\n",
      "3380.pt\n",
      "3381.pt\n",
      "3382.pt\n",
      "3383.pt\n",
      "3384.pt\n",
      "3385.pt\n",
      "3386.pt\n",
      "3387.pt\n",
      "3388.pt\n",
      "3389.pt\n",
      "3390.pt\n",
      "3391.pt\n",
      "3392.pt\n",
      "3393.pt\n",
      "3394.pt\n",
      "3395.pt\n",
      "3396.pt\n",
      "3397.pt\n",
      "3398.pt\n",
      "3399.pt\n",
      "3400.pt\n",
      "3401.pt\n",
      "3402.pt\n",
      "3403.pt\n",
      "3404.pt\n",
      "3405.pt\n",
      "3406.pt\n",
      "3407.pt\n",
      "3408.pt\n",
      "3409.pt\n",
      "3410.pt\n",
      "3411.pt\n",
      "3412.pt\n",
      "3413.pt\n",
      "3414.pt\n",
      "3415.pt\n",
      "3416.pt\n",
      "3417.pt\n",
      "3418.pt\n",
      "3419.pt\n",
      "3420.pt\n",
      "3421.pt\n",
      "3422.pt\n",
      "3423.pt\n",
      "3424.pt\n",
      "3425.pt\n",
      "3426.pt\n",
      "3427.pt\n",
      "3428.pt\n",
      "3429.pt\n",
      "3430.pt\n",
      "3431.pt\n",
      "3432.pt\n",
      "3433.pt\n",
      "3434.pt\n",
      "3435.pt\n",
      "3436.pt\n",
      "3437.pt\n",
      "3438.pt\n",
      "3439.pt\n",
      "3440.pt\n",
      "3441.pt\n",
      "3442.pt\n",
      "3443.pt\n",
      "3444.pt\n",
      "3445.pt\n",
      "3446.pt\n",
      "3447.pt\n",
      "3448.pt\n",
      "3449.pt\n",
      "3450.pt\n",
      "3451.pt\n",
      "3452.pt\n",
      "3453.pt\n",
      "3454.pt\n",
      "3455.pt\n",
      "3456.pt\n",
      "3457.pt\n",
      "3458.pt\n",
      "3459.pt\n",
      "3460.pt\n",
      "3461.pt\n",
      "3462.pt\n",
      "3463.pt\n",
      "3464.pt\n",
      "3465.pt\n",
      "3466.pt\n",
      "3467.pt\n",
      "3468.pt\n",
      "3469.pt\n",
      "3470.pt\n",
      "3471.pt\n",
      "3472.pt\n",
      "3473.pt\n",
      "3474.pt\n",
      "3475.pt\n",
      "3476.pt\n",
      "3477.pt\n",
      "3478.pt\n",
      "3479.pt\n",
      "3480.pt\n",
      "3481.pt\n",
      "3482.pt\n",
      "3483.pt\n",
      "3484.pt\n",
      "3485.pt\n",
      "3486.pt\n",
      "3487.pt\n",
      "3488.pt\n",
      "3489.pt\n",
      "3490.pt\n",
      "3491.pt\n",
      "3492.pt\n",
      "3493.pt\n",
      "3494.pt\n",
      "3495.pt\n",
      "3496.pt\n",
      "3497.pt\n",
      "3498.pt\n",
      "3499.pt\n",
      "3500.pt\n",
      "3501.pt\n",
      "3502.pt\n",
      "3503.pt\n",
      "3504.pt\n",
      "3505.pt\n",
      "3506.pt\n",
      "3507.pt\n",
      "3508.pt\n",
      "3509.pt\n",
      "3510.pt\n",
      "3511.pt\n",
      "3512.pt\n",
      "3513.pt\n",
      "3514.pt\n",
      "3515.pt\n",
      "3516.pt\n",
      "3517.pt\n",
      "3518.pt\n",
      "3519.pt\n",
      "3520.pt\n",
      "3521.pt\n",
      "3522.pt\n",
      "3523.pt\n",
      "3524.pt\n",
      "3525.pt\n",
      "3526.pt\n",
      "3527.pt\n",
      "3528.pt\n",
      "3529.pt\n",
      "3530.pt\n",
      "3531.pt\n",
      "3532.pt\n",
      "3533.pt\n",
      "3534.pt\n",
      "3535.pt\n",
      "3536.pt\n",
      "3537.pt\n",
      "3538.pt\n",
      "3539.pt\n",
      "3540.pt\n",
      "3541.pt\n",
      "3542.pt\n",
      "3543.pt\n",
      "3544.pt\n",
      "3545.pt\n",
      "3546.pt\n",
      "3547.pt\n",
      "3548.pt\n",
      "3549.pt\n",
      "3550.pt\n",
      "3551.pt\n",
      "3552.pt\n",
      "3553.pt\n",
      "3554.pt\n",
      "3555.pt\n",
      "3556.pt\n",
      "3557.pt\n",
      "3558.pt\n",
      "3559.pt\n",
      "3560.pt\n",
      "3561.pt\n",
      "3562.pt\n",
      "3563.pt\n",
      "3564.pt\n",
      "3565.pt\n",
      "3566.pt\n",
      "3567.pt\n",
      "3568.pt\n",
      "3569.pt\n",
      "3570.pt\n",
      "3571.pt\n",
      "3572.pt\n",
      "3573.pt\n",
      "3574.pt\n",
      "3575.pt\n",
      "3576.pt\n",
      "3577.pt\n",
      "3578.pt\n",
      "3579.pt\n",
      "3580.pt\n",
      "3581.pt\n",
      "3582.pt\n",
      "3583.pt\n",
      "3584.pt\n",
      "3585.pt\n",
      "3586.pt\n",
      "3587.pt\n",
      "3588.pt\n",
      "3589.pt\n",
      "3590.pt\n",
      "3591.pt\n",
      "3592.pt\n",
      "3593.pt\n",
      "3594.pt\n",
      "3595.pt\n",
      "3596.pt\n",
      "3597.pt\n",
      "3598.pt\n",
      "3599.pt\n",
      "3600.pt\n",
      "3601.pt\n",
      "3602.pt\n",
      "3603.pt\n",
      "3604.pt\n",
      "3605.pt\n",
      "3606.pt\n",
      "3607.pt\n",
      "3608.pt\n",
      "3609.pt\n",
      "3610.pt\n",
      "3611.pt\n",
      "3612.pt\n",
      "3613.pt\n",
      "3614.pt\n",
      "3615.pt\n",
      "3616.pt\n",
      "3617.pt\n",
      "3618.pt\n",
      "3619.pt\n",
      "3620.pt\n",
      "3621.pt\n",
      "3622.pt\n",
      "3623.pt\n",
      "3624.pt\n",
      "3625.pt\n",
      "3626.pt\n",
      "3627.pt\n",
      "3628.pt\n",
      "3629.pt\n",
      "3630.pt\n",
      "3631.pt\n",
      "3632.pt\n",
      "3633.pt\n",
      "3634.pt\n",
      "3635.pt\n",
      "3636.pt\n",
      "3637.pt\n",
      "3638.pt\n",
      "3639.pt\n",
      "3640.pt\n",
      "3641.pt\n",
      "3642.pt\n",
      "3643.pt\n",
      "3644.pt\n",
      "3645.pt\n",
      "3646.pt\n",
      "3647.pt\n",
      "3648.pt\n",
      "3649.pt\n",
      "3650.pt\n",
      "3651.pt\n",
      "3652.pt\n",
      "3653.pt\n",
      "3654.pt\n",
      "3655.pt\n",
      "3656.pt\n",
      "3657.pt\n",
      "3658.pt\n",
      "3659.pt\n",
      "3660.pt\n",
      "3661.pt\n",
      "3662.pt\n",
      "3663.pt\n",
      "3664.pt\n",
      "3665.pt\n",
      "3666.pt\n",
      "3667.pt\n",
      "3668.pt\n",
      "3669.pt\n",
      "3670.pt\n",
      "3671.pt\n",
      "3672.pt\n",
      "3673.pt\n",
      "3674.pt\n",
      "3675.pt\n",
      "3676.pt\n",
      "3677.pt\n",
      "3678.pt\n",
      "3679.pt\n",
      "3680.pt\n",
      "3681.pt\n",
      "3682.pt\n",
      "3683.pt\n",
      "3684.pt\n",
      "3685.pt\n",
      "3686.pt\n",
      "3687.pt\n",
      "3688.pt\n",
      "3689.pt\n",
      "3690.pt\n",
      "3691.pt\n",
      "3692.pt\n",
      "3693.pt\n",
      "3694.pt\n",
      "3695.pt\n",
      "3696.pt\n",
      "3697.pt\n",
      "3698.pt\n",
      "3699.pt\n",
      "3700.pt\n",
      "3701.pt\n",
      "3702.pt\n",
      "3703.pt\n",
      "3704.pt\n",
      "3705.pt\n",
      "3706.pt\n",
      "3707.pt\n",
      "3708.pt\n",
      "3709.pt\n",
      "3710.pt\n",
      "3711.pt\n",
      "3712.pt\n",
      "3713.pt\n",
      "3714.pt\n",
      "3715.pt\n",
      "3716.pt\n",
      "3717.pt\n",
      "3718.pt\n",
      "3719.pt\n",
      "3720.pt\n",
      "3721.pt\n",
      "3722.pt\n",
      "3723.pt\n",
      "3724.pt\n",
      "3725.pt\n",
      "3726.pt\n",
      "3727.pt\n",
      "3728.pt\n",
      "3729.pt\n",
      "3730.pt\n",
      "3731.pt\n",
      "3732.pt\n",
      "3733.pt\n",
      "3734.pt\n",
      "3735.pt\n",
      "3736.pt\n",
      "3737.pt\n",
      "3738.pt\n",
      "3739.pt\n",
      "3740.pt\n",
      "3741.pt\n",
      "3742.pt\n",
      "3743.pt\n",
      "3744.pt\n",
      "3745.pt\n",
      "3746.pt\n",
      "3747.pt\n",
      "3748.pt\n",
      "3749.pt\n",
      "3750.pt\n",
      "3751.pt\n",
      "3752.pt\n",
      "3753.pt\n",
      "3754.pt\n",
      "3755.pt\n",
      "3756.pt\n",
      "3757.pt\n",
      "3758.pt\n",
      "3759.pt\n",
      "3760.pt\n",
      "3761.pt\n",
      "3762.pt\n",
      "3763.pt\n",
      "3764.pt\n",
      "3765.pt\n",
      "3766.pt\n",
      "3767.pt\n",
      "3768.pt\n",
      "3769.pt\n",
      "3770.pt\n",
      "3771.pt\n",
      "3772.pt\n",
      "3773.pt\n",
      "3774.pt\n",
      "3775.pt\n",
      "3776.pt\n",
      "3777.pt\n",
      "3778.pt\n",
      "3779.pt\n",
      "3780.pt\n",
      "3781.pt\n",
      "3782.pt\n",
      "3783.pt\n",
      "3784.pt\n",
      "3785.pt\n",
      "3786.pt\n",
      "3787.pt\n",
      "3788.pt\n",
      "3789.pt\n",
      "3790.pt\n",
      "3791.pt\n",
      "3792.pt\n",
      "3793.pt\n",
      "3794.pt\n",
      "3795.pt\n",
      "3796.pt\n",
      "3797.pt\n",
      "3798.pt\n",
      "3799.pt\n",
      "3800.pt\n",
      "3801.pt\n",
      "3802.pt\n",
      "3803.pt\n",
      "3804.pt\n",
      "3805.pt\n",
      "3806.pt\n",
      "3807.pt\n",
      "3808.pt\n",
      "3809.pt\n",
      "3810.pt\n",
      "3811.pt\n",
      "3812.pt\n",
      "3813.pt\n",
      "3814.pt\n",
      "3815.pt\n",
      "3816.pt\n",
      "3817.pt\n",
      "3818.pt\n",
      "3819.pt\n",
      "3820.pt\n",
      "3821.pt\n",
      "3822.pt\n",
      "3823.pt\n",
      "3824.pt\n",
      "3825.pt\n",
      "3826.pt\n",
      "3827.pt\n",
      "3828.pt\n",
      "3829.pt\n",
      "3830.pt\n",
      "3831.pt\n",
      "3832.pt\n",
      "3833.pt\n",
      "3834.pt\n",
      "3835.pt\n",
      "3836.pt\n",
      "3837.pt\n",
      "3838.pt\n",
      "3839.pt\n",
      "3840.pt\n",
      "3841.pt\n",
      "3842.pt\n",
      "3843.pt\n",
      "3844.pt\n",
      "3845.pt\n",
      "3846.pt\n",
      "3847.pt\n",
      "3848.pt\n",
      "3849.pt\n",
      "3850.pt\n",
      "3851.pt\n",
      "3852.pt\n",
      "3853.pt\n",
      "3854.pt\n",
      "3855.pt\n",
      "3856.pt\n",
      "3857.pt\n",
      "3858.pt\n",
      "3859.pt\n",
      "3860.pt\n",
      "3861.pt\n",
      "3862.pt\n",
      "3863.pt\n",
      "3864.pt\n",
      "3865.pt\n",
      "3866.pt\n",
      "3867.pt\n",
      "3868.pt\n",
      "3869.pt\n",
      "3870.pt\n",
      "3871.pt\n",
      "3872.pt\n",
      "3873.pt\n",
      "3874.pt\n",
      "3875.pt\n",
      "3876.pt\n",
      "3877.pt\n",
      "3878.pt\n",
      "3879.pt\n",
      "3880.pt\n",
      "3881.pt\n",
      "3882.pt\n",
      "3883.pt\n",
      "3884.pt\n",
      "3885.pt\n",
      "3886.pt\n",
      "3887.pt\n",
      "3888.pt\n",
      "3889.pt\n",
      "3890.pt\n",
      "3891.pt\n",
      "3892.pt\n",
      "3893.pt\n",
      "3894.pt\n",
      "3895.pt\n",
      "3896.pt\n",
      "3897.pt\n",
      "3898.pt\n",
      "3899.pt\n",
      "3900.pt\n",
      "3901.pt\n",
      "3902.pt\n",
      "3903.pt\n",
      "3904.pt\n",
      "3905.pt\n",
      "3906.pt\n",
      "3907.pt\n",
      "3908.pt\n",
      "3909.pt\n",
      "3910.pt\n",
      "3911.pt\n",
      "3912.pt\n",
      "3913.pt\n",
      "3914.pt\n",
      "3915.pt\n",
      "3916.pt\n",
      "3917.pt\n",
      "3918.pt\n",
      "3919.pt\n",
      "3920.pt\n",
      "3921.pt\n",
      "3922.pt\n",
      "3923.pt\n",
      "3924.pt\n",
      "3925.pt\n",
      "3926.pt\n",
      "3927.pt\n",
      "3928.pt\n",
      "3929.pt\n",
      "3930.pt\n",
      "3931.pt\n",
      "3932.pt\n",
      "3933.pt\n",
      "3934.pt\n",
      "3935.pt\n",
      "3936.pt\n",
      "3937.pt\n",
      "3938.pt\n",
      "3939.pt\n",
      "3940.pt\n",
      "3941.pt\n",
      "3942.pt\n",
      "3943.pt\n",
      "3944.pt\n",
      "3945.pt\n",
      "3946.pt\n",
      "3947.pt\n",
      "3948.pt\n",
      "3949.pt\n",
      "3950.pt\n",
      "3951.pt\n",
      "3952.pt\n",
      "3953.pt\n",
      "3954.pt\n",
      "3955.pt\n",
      "3956.pt\n",
      "3957.pt\n",
      "3958.pt\n",
      "3959.pt\n",
      "3960.pt\n",
      "3961.pt\n",
      "3962.pt\n",
      "3963.pt\n",
      "3964.pt\n",
      "3965.pt\n",
      "3966.pt\n",
      "3967.pt\n",
      "3968.pt\n",
      "3969.pt\n",
      "3970.pt\n",
      "3971.pt\n",
      "3972.pt\n",
      "3973.pt\n",
      "3974.pt\n",
      "3975.pt\n",
      "3976.pt\n",
      "3977.pt\n",
      "3978.pt\n",
      "3979.pt\n",
      "3980.pt\n",
      "3981.pt\n",
      "3982.pt\n",
      "3983.pt\n",
      "3984.pt\n",
      "3985.pt\n",
      "3986.pt\n",
      "3987.pt\n",
      "3988.pt\n",
      "3989.pt\n",
      "3990.pt\n",
      "3991.pt\n",
      "3992.pt\n",
      "3993.pt\n",
      "3994.pt\n",
      "3995.pt\n",
      "3996.pt\n",
      "3997.pt\n",
      "3998.pt\n",
      "3999.pt\n",
      "4000.pt\n",
      "4001.pt\n",
      "4002.pt\n",
      "4003.pt\n",
      "4004.pt\n",
      "4005.pt\n",
      "4006.pt\n",
      "4007.pt\n",
      "4008.pt\n",
      "4009.pt\n",
      "4010.pt\n",
      "4011.pt\n",
      "4012.pt\n",
      "4013.pt\n",
      "4014.pt\n",
      "4015.pt\n",
      "4016.pt\n",
      "4017.pt\n",
      "4018.pt\n",
      "4019.pt\n",
      "4020.pt\n",
      "4021.pt\n",
      "4022.pt\n",
      "4023.pt\n",
      "4024.pt\n",
      "4025.pt\n",
      "4026.pt\n",
      "4027.pt\n",
      "4028.pt\n",
      "4029.pt\n",
      "4030.pt\n",
      "4031.pt\n",
      "4032.pt\n",
      "4033.pt\n",
      "4034.pt\n",
      "4035.pt\n",
      "4036.pt\n",
      "4037.pt\n",
      "4038.pt\n",
      "4039.pt\n",
      "4040.pt\n",
      "4041.pt\n",
      "4042.pt\n",
      "4043.pt\n",
      "4044.pt\n",
      "4045.pt\n",
      "4046.pt\n",
      "4047.pt\n",
      "4048.pt\n",
      "4049.pt\n",
      "4050.pt\n",
      "4051.pt\n",
      "4052.pt\n",
      "4053.pt\n",
      "4054.pt\n",
      "4055.pt\n",
      "4056.pt\n",
      "4057.pt\n",
      "4058.pt\n",
      "4059.pt\n",
      "4060.pt\n",
      "4061.pt\n",
      "4062.pt\n",
      "4063.pt\n",
      "4064.pt\n",
      "4065.pt\n",
      "4066.pt\n",
      "4067.pt\n",
      "4068.pt\n",
      "4069.pt\n",
      "4070.pt\n",
      "4071.pt\n",
      "4072.pt\n",
      "4073.pt\n",
      "4074.pt\n",
      "4075.pt\n",
      "4076.pt\n",
      "4077.pt\n",
      "4078.pt\n",
      "4079.pt\n",
      "4080.pt\n",
      "4081.pt\n",
      "4082.pt\n",
      "4083.pt\n",
      "4084.pt\n",
      "4085.pt\n",
      "4086.pt\n",
      "4087.pt\n",
      "4088.pt\n",
      "4089.pt\n",
      "4090.pt\n",
      "4091.pt\n",
      "4092.pt\n",
      "4093.pt\n",
      "4094.pt\n",
      "4095.pt\n",
      "4096.pt\n",
      "4097.pt\n",
      "4098.pt\n",
      "4099.pt\n",
      "4100.pt\n",
      "4101.pt\n",
      "4102.pt\n",
      "4103.pt\n",
      "4104.pt\n",
      "4105.pt\n",
      "4106.pt\n",
      "4107.pt\n",
      "4108.pt\n",
      "4109.pt\n",
      "4110.pt\n",
      "4111.pt\n",
      "4112.pt\n",
      "4113.pt\n",
      "4114.pt\n",
      "4115.pt\n",
      "4116.pt\n",
      "4117.pt\n",
      "4118.pt\n",
      "4119.pt\n",
      "4120.pt\n",
      "4121.pt\n",
      "4122.pt\n",
      "4123.pt\n",
      "4124.pt\n",
      "4125.pt\n",
      "4126.pt\n",
      "4127.pt\n",
      "4128.pt\n",
      "4129.pt\n",
      "4130.pt\n",
      "4131.pt\n",
      "4132.pt\n",
      "4133.pt\n",
      "4134.pt\n",
      "4135.pt\n",
      "4136.pt\n",
      "4137.pt\n",
      "4138.pt\n",
      "4139.pt\n",
      "4140.pt\n",
      "4141.pt\n",
      "4142.pt\n",
      "4143.pt\n",
      "4144.pt\n",
      "4145.pt\n",
      "4146.pt\n",
      "4147.pt\n",
      "4148.pt\n",
      "4149.pt\n",
      "4150.pt\n",
      "4151.pt\n",
      "4152.pt\n",
      "4153.pt\n",
      "4154.pt\n",
      "4155.pt\n",
      "4156.pt\n",
      "4157.pt\n",
      "4158.pt\n",
      "4159.pt\n",
      "4160.pt\n",
      "4161.pt\n",
      "4162.pt\n",
      "4163.pt\n",
      "4164.pt\n",
      "4165.pt\n",
      "4166.pt\n",
      "4167.pt\n",
      "4168.pt\n",
      "4169.pt\n",
      "4170.pt\n",
      "4171.pt\n",
      "4172.pt\n",
      "4173.pt\n",
      "4174.pt\n",
      "4175.pt\n",
      "4176.pt\n",
      "4177.pt\n",
      "4178.pt\n",
      "4179.pt\n",
      "4180.pt\n",
      "4181.pt\n",
      "4182.pt\n",
      "4183.pt\n",
      "4184.pt\n",
      "4185.pt\n",
      "4186.pt\n",
      "4187.pt\n",
      "4188.pt\n",
      "4189.pt\n",
      "4190.pt\n",
      "4191.pt\n",
      "4192.pt\n",
      "4193.pt\n",
      "4194.pt\n",
      "4195.pt\n",
      "4196.pt\n",
      "4197.pt\n",
      "4198.pt\n",
      "4199.pt\n",
      "4200.pt\n",
      "4201.pt\n",
      "4202.pt\n",
      "4203.pt\n",
      "4204.pt\n",
      "4205.pt\n",
      "4206.pt\n",
      "4207.pt\n",
      "4208.pt\n",
      "4209.pt\n",
      "4210.pt\n",
      "4211.pt\n",
      "4212.pt\n",
      "4213.pt\n",
      "4214.pt\n",
      "4215.pt\n",
      "4216.pt\n",
      "4217.pt\n",
      "4218.pt\n",
      "4219.pt\n",
      "4220.pt\n",
      "4221.pt\n",
      "4222.pt\n",
      "4223.pt\n",
      "4224.pt\n",
      "4225.pt\n",
      "4226.pt\n",
      "4227.pt\n",
      "4228.pt\n",
      "4229.pt\n",
      "4230.pt\n",
      "4231.pt\n",
      "4232.pt\n",
      "4233.pt\n",
      "4234.pt\n",
      "4235.pt\n",
      "4236.pt\n",
      "4237.pt\n",
      "4238.pt\n",
      "4239.pt\n",
      "4240.pt\n",
      "4241.pt\n",
      "4242.pt\n",
      "4243.pt\n",
      "4244.pt\n",
      "4245.pt\n",
      "4246.pt\n",
      "4247.pt\n",
      "4248.pt\n",
      "4249.pt\n",
      "4250.pt\n",
      "4251.pt\n",
      "4252.pt\n",
      "4253.pt\n",
      "4254.pt\n",
      "4255.pt\n",
      "4256.pt\n",
      "4257.pt\n",
      "4258.pt\n",
      "4259.pt\n",
      "4260.pt\n",
      "4261.pt\n",
      "4262.pt\n",
      "4263.pt\n",
      "4264.pt\n",
      "4265.pt\n",
      "4266.pt\n",
      "4267.pt\n",
      "4268.pt\n",
      "4269.pt\n",
      "4270.pt\n",
      "4271.pt\n",
      "4272.pt\n",
      "4273.pt\n",
      "4274.pt\n",
      "4275.pt\n",
      "4276.pt\n",
      "4277.pt\n",
      "4278.pt\n",
      "4279.pt\n",
      "4280.pt\n",
      "4281.pt\n",
      "4282.pt\n",
      "4283.pt\n",
      "4284.pt\n",
      "4285.pt\n",
      "4286.pt\n",
      "4287.pt\n",
      "4288.pt\n",
      "4289.pt\n",
      "4290.pt\n",
      "4291.pt\n",
      "4292.pt\n",
      "4293.pt\n",
      "4294.pt\n",
      "4295.pt\n",
      "4296.pt\n",
      "4297.pt\n",
      "4298.pt\n",
      "4299.pt\n",
      "4300.pt\n",
      "4301.pt\n",
      "4302.pt\n",
      "4303.pt\n",
      "4304.pt\n",
      "4305.pt\n",
      "4306.pt\n",
      "4307.pt\n",
      "4308.pt\n",
      "4309.pt\n",
      "4310.pt\n",
      "4311.pt\n",
      "4312.pt\n",
      "4313.pt\n",
      "4314.pt\n",
      "4315.pt\n",
      "4316.pt\n",
      "4317.pt\n",
      "4318.pt\n",
      "4319.pt\n",
      "4320.pt\n",
      "4321.pt\n",
      "4322.pt\n",
      "4323.pt\n",
      "4324.pt\n",
      "4325.pt\n",
      "4326.pt\n",
      "4327.pt\n",
      "4328.pt\n",
      "4329.pt\n",
      "4330.pt\n",
      "4331.pt\n",
      "4332.pt\n",
      "4333.pt\n",
      "4334.pt\n",
      "4335.pt\n",
      "4336.pt\n",
      "4337.pt\n",
      "4338.pt\n",
      "4339.pt\n",
      "4340.pt\n",
      "4341.pt\n",
      "4342.pt\n",
      "4343.pt\n",
      "4344.pt\n",
      "4345.pt\n",
      "4346.pt\n",
      "4347.pt\n",
      "4348.pt\n",
      "4349.pt\n",
      "4350.pt\n",
      "4351.pt\n",
      "4352.pt\n",
      "4353.pt\n",
      "4354.pt\n",
      "4355.pt\n",
      "4356.pt\n",
      "4357.pt\n",
      "4358.pt\n",
      "4359.pt\n",
      "4360.pt\n",
      "4361.pt\n",
      "4362.pt\n",
      "4363.pt\n",
      "4364.pt\n",
      "4365.pt\n",
      "4366.pt\n",
      "4367.pt\n",
      "4368.pt\n",
      "4369.pt\n",
      "4370.pt\n",
      "4371.pt\n",
      "4372.pt\n",
      "4373.pt\n",
      "4374.pt\n",
      "4375.pt\n",
      "4376.pt\n",
      "4377.pt\n",
      "4378.pt\n",
      "4379.pt\n",
      "4380.pt\n",
      "4381.pt\n",
      "4382.pt\n",
      "4383.pt\n",
      "4384.pt\n",
      "4385.pt\n",
      "4386.pt\n",
      "4387.pt\n",
      "4388.pt\n",
      "4389.pt\n",
      "4390.pt\n",
      "4391.pt\n",
      "4392.pt\n",
      "4393.pt\n",
      "4394.pt\n",
      "4395.pt\n",
      "4396.pt\n",
      "4397.pt\n",
      "4398.pt\n",
      "4399.pt\n",
      "4400.pt\n",
      "4401.pt\n",
      "4402.pt\n",
      "4403.pt\n",
      "4404.pt\n",
      "4405.pt\n",
      "4406.pt\n",
      "4407.pt\n",
      "4408.pt\n",
      "4409.pt\n",
      "4410.pt\n",
      "4411.pt\n",
      "4412.pt\n",
      "4413.pt\n",
      "4414.pt\n",
      "4415.pt\n",
      "4416.pt\n",
      "4417.pt\n",
      "4418.pt\n",
      "4419.pt\n",
      "4420.pt\n",
      "4421.pt\n",
      "4422.pt\n",
      "4423.pt\n",
      "4424.pt\n",
      "4425.pt\n",
      "4426.pt\n",
      "4427.pt\n",
      "4428.pt\n",
      "4429.pt\n",
      "4430.pt\n",
      "4431.pt\n",
      "4432.pt\n",
      "4433.pt\n",
      "4434.pt\n",
      "4435.pt\n",
      "4436.pt\n",
      "4437.pt\n",
      "4438.pt\n",
      "4439.pt\n",
      "4440.pt\n",
      "4441.pt\n",
      "4442.pt\n",
      "4443.pt\n",
      "4444.pt\n",
      "4445.pt\n",
      "4446.pt\n",
      "4447.pt\n",
      "4448.pt\n",
      "4449.pt\n",
      "4450.pt\n",
      "4451.pt\n",
      "4452.pt\n",
      "4453.pt\n",
      "4454.pt\n",
      "4455.pt\n",
      "4456.pt\n",
      "4457.pt\n",
      "4458.pt\n",
      "4459.pt\n",
      "4460.pt\n",
      "4461.pt\n",
      "4462.pt\n",
      "4463.pt\n",
      "4464.pt\n",
      "4465.pt\n",
      "4466.pt\n",
      "4467.pt\n",
      "4468.pt\n",
      "4469.pt\n",
      "4470.pt\n",
      "4471.pt\n",
      "4472.pt\n",
      "4473.pt\n",
      "4474.pt\n",
      "4475.pt\n",
      "4476.pt\n",
      "4477.pt\n",
      "4478.pt\n",
      "4479.pt\n",
      "4480.pt\n",
      "4481.pt\n",
      "4482.pt\n",
      "4483.pt\n",
      "4484.pt\n",
      "4485.pt\n",
      "4486.pt\n",
      "4487.pt\n",
      "4488.pt\n",
      "4489.pt\n",
      "4490.pt\n",
      "4491.pt\n",
      "4492.pt\n",
      "4493.pt\n",
      "4494.pt\n",
      "4495.pt\n",
      "4496.pt\n",
      "4497.pt\n",
      "4498.pt\n",
      "4499.pt\n",
      "4500.pt\n",
      "4501.pt\n",
      "4502.pt\n",
      "4503.pt\n",
      "4504.pt\n",
      "4505.pt\n",
      "4506.pt\n",
      "4507.pt\n",
      "4508.pt\n",
      "4509.pt\n",
      "4510.pt\n",
      "4511.pt\n",
      "4512.pt\n",
      "4513.pt\n",
      "4514.pt\n",
      "4515.pt\n",
      "4516.pt\n",
      "4517.pt\n",
      "4518.pt\n",
      "4519.pt\n",
      "4520.pt\n",
      "4521.pt\n",
      "4522.pt\n",
      "4523.pt\n",
      "4524.pt\n",
      "4525.pt\n",
      "4526.pt\n",
      "4527.pt\n",
      "4528.pt\n",
      "4529.pt\n",
      "4530.pt\n",
      "4531.pt\n",
      "4532.pt\n",
      "4533.pt\n",
      "4534.pt\n",
      "4535.pt\n",
      "4536.pt\n",
      "4537.pt\n",
      "4538.pt\n",
      "4539.pt\n",
      "4540.pt\n",
      "4541.pt\n",
      "4542.pt\n",
      "4543.pt\n",
      "4544.pt\n",
      "4545.pt\n",
      "4546.pt\n",
      "4547.pt\n",
      "4548.pt\n",
      "4549.pt\n",
      "4550.pt\n",
      "4551.pt\n",
      "4552.pt\n",
      "4553.pt\n",
      "4554.pt\n",
      "4555.pt\n",
      "4556.pt\n",
      "4557.pt\n",
      "4558.pt\n",
      "4559.pt\n",
      "4560.pt\n",
      "4561.pt\n",
      "4562.pt\n",
      "4563.pt\n",
      "4564.pt\n",
      "4565.pt\n",
      "4566.pt\n",
      "4567.pt\n",
      "4568.pt\n",
      "4569.pt\n",
      "4570.pt\n",
      "4571.pt\n",
      "4572.pt\n",
      "4573.pt\n",
      "4574.pt\n",
      "4575.pt\n",
      "4576.pt\n",
      "4577.pt\n",
      "4578.pt\n",
      "4579.pt\n",
      "4580.pt\n",
      "4581.pt\n",
      "4582.pt\n",
      "4583.pt\n",
      "4584.pt\n",
      "4585.pt\n",
      "4586.pt\n",
      "4587.pt\n",
      "4588.pt\n",
      "4589.pt\n",
      "4590.pt\n",
      "4591.pt\n",
      "4592.pt\n",
      "4593.pt\n",
      "4594.pt\n",
      "4595.pt\n",
      "4596.pt\n",
      "4597.pt\n",
      "4598.pt\n",
      "4599.pt\n",
      "4600.pt\n",
      "4601.pt\n",
      "4602.pt\n",
      "4603.pt\n",
      "4604.pt\n",
      "4605.pt\n",
      "4606.pt\n",
      "4607.pt\n",
      "4608.pt\n",
      "4609.pt\n",
      "4610.pt\n",
      "4611.pt\n",
      "4612.pt\n",
      "4613.pt\n",
      "4614.pt\n",
      "4615.pt\n",
      "4616.pt\n",
      "4617.pt\n",
      "4618.pt\n",
      "4619.pt\n",
      "4620.pt\n",
      "4621.pt\n",
      "4622.pt\n",
      "4623.pt\n",
      "4624.pt\n",
      "4625.pt\n",
      "4626.pt\n",
      "4627.pt\n",
      "4628.pt\n",
      "4629.pt\n",
      "4630.pt\n",
      "4631.pt\n",
      "4632.pt\n",
      "4633.pt\n",
      "4634.pt\n",
      "4635.pt\n",
      "4636.pt\n",
      "4637.pt\n",
      "4638.pt\n",
      "4639.pt\n",
      "4640.pt\n",
      "4641.pt\n",
      "4642.pt\n",
      "4643.pt\n",
      "4644.pt\n",
      "4645.pt\n",
      "4646.pt\n",
      "4647.pt\n",
      "4648.pt\n",
      "4649.pt\n",
      "4650.pt\n",
      "4651.pt\n",
      "4652.pt\n",
      "4653.pt\n",
      "4654.pt\n",
      "4655.pt\n",
      "4656.pt\n",
      "4657.pt\n",
      "4658.pt\n",
      "4659.pt\n",
      "4660.pt\n",
      "4661.pt\n",
      "4662.pt\n",
      "4663.pt\n",
      "4664.pt\n",
      "4665.pt\n",
      "4666.pt\n",
      "4667.pt\n",
      "4668.pt\n",
      "4669.pt\n",
      "4670.pt\n",
      "4671.pt\n",
      "4672.pt\n",
      "4673.pt\n",
      "4674.pt\n",
      "4675.pt\n",
      "4676.pt\n",
      "4677.pt\n",
      "4678.pt\n",
      "4679.pt\n",
      "4680.pt\n",
      "4681.pt\n",
      "4682.pt\n",
      "4683.pt\n",
      "4684.pt\n",
      "4685.pt\n",
      "4686.pt\n",
      "4687.pt\n",
      "4688.pt\n",
      "4689.pt\n",
      "4690.pt\n",
      "4691.pt\n",
      "4692.pt\n",
      "4693.pt\n",
      "4694.pt\n",
      "4695.pt\n",
      "4696.pt\n",
      "4697.pt\n",
      "4698.pt\n",
      "4699.pt\n",
      "4700.pt\n",
      "4701.pt\n",
      "4702.pt\n",
      "4703.pt\n",
      "4704.pt\n",
      "4705.pt\n",
      "4706.pt\n",
      "4707.pt\n",
      "4708.pt\n",
      "4709.pt\n",
      "4710.pt\n",
      "4711.pt\n",
      "4712.pt\n",
      "4713.pt\n",
      "4714.pt\n",
      "4715.pt\n",
      "4716.pt\n",
      "4717.pt\n",
      "4718.pt\n",
      "4719.pt\n",
      "4720.pt\n",
      "4721.pt\n",
      "4722.pt\n",
      "4723.pt\n",
      "4724.pt\n",
      "4725.pt\n",
      "4726.pt\n",
      "4727.pt\n",
      "4728.pt\n",
      "4729.pt\n",
      "4730.pt\n",
      "4731.pt\n",
      "4732.pt\n",
      "4733.pt\n",
      "4734.pt\n",
      "4735.pt\n",
      "4736.pt\n",
      "4737.pt\n",
      "4738.pt\n",
      "4739.pt\n",
      "4740.pt\n",
      "4741.pt\n",
      "4742.pt\n",
      "4743.pt\n",
      "4744.pt\n",
      "4745.pt\n",
      "4746.pt\n",
      "4747.pt\n",
      "4748.pt\n",
      "4749.pt\n",
      "4750.pt\n",
      "4751.pt\n",
      "4752.pt\n",
      "4753.pt\n",
      "4754.pt\n",
      "4755.pt\n",
      "4756.pt\n",
      "4757.pt\n",
      "4758.pt\n",
      "4759.pt\n",
      "4760.pt\n",
      "4761.pt\n",
      "4762.pt\n",
      "4763.pt\n",
      "4764.pt\n",
      "4765.pt\n",
      "4766.pt\n",
      "4767.pt\n",
      "4768.pt\n",
      "4769.pt\n",
      "4770.pt\n",
      "4771.pt\n",
      "4772.pt\n",
      "4773.pt\n",
      "4774.pt\n",
      "4775.pt\n",
      "4776.pt\n",
      "4777.pt\n",
      "4778.pt\n",
      "4779.pt\n",
      "4780.pt\n",
      "4781.pt\n",
      "4782.pt\n",
      "4783.pt\n",
      "4784.pt\n",
      "4785.pt\n",
      "4786.pt\n",
      "4787.pt\n",
      "4788.pt\n",
      "4789.pt\n",
      "4790.pt\n",
      "4791.pt\n",
      "4792.pt\n",
      "4793.pt\n",
      "4794.pt\n",
      "4795.pt\n",
      "4796.pt\n",
      "4797.pt\n",
      "4798.pt\n",
      "4799.pt\n",
      "4800.pt\n",
      "4801.pt\n",
      "4802.pt\n",
      "4803.pt\n",
      "4804.pt\n",
      "4805.pt\n",
      "4806.pt\n",
      "4807.pt\n",
      "4808.pt\n",
      "4809.pt\n",
      "4810.pt\n",
      "4811.pt\n",
      "4812.pt\n",
      "4813.pt\n",
      "4814.pt\n",
      "4815.pt\n",
      "4816.pt\n",
      "4817.pt\n",
      "4818.pt\n",
      "4819.pt\n",
      "4820.pt\n",
      "4821.pt\n",
      "4822.pt\n",
      "4823.pt\n",
      "4824.pt\n",
      "4825.pt\n",
      "4826.pt\n",
      "4827.pt\n",
      "4828.pt\n",
      "4829.pt\n",
      "4830.pt\n",
      "4831.pt\n",
      "4832.pt\n",
      "4833.pt\n",
      "4834.pt\n",
      "4835.pt\n",
      "4836.pt\n",
      "4837.pt\n",
      "4838.pt\n",
      "4839.pt\n",
      "4840.pt\n",
      "4841.pt\n",
      "4842.pt\n",
      "4843.pt\n",
      "4844.pt\n",
      "4845.pt\n",
      "4846.pt\n",
      "4847.pt\n",
      "4848.pt\n",
      "4849.pt\n",
      "4850.pt\n",
      "4851.pt\n",
      "4852.pt\n",
      "4853.pt\n",
      "4854.pt\n",
      "4855.pt\n",
      "4856.pt\n",
      "4857.pt\n",
      "4858.pt\n",
      "4859.pt\n",
      "4860.pt\n",
      "4861.pt\n",
      "4862.pt\n",
      "4863.pt\n",
      "4864.pt\n",
      "4865.pt\n",
      "4866.pt\n",
      "4867.pt\n",
      "4868.pt\n",
      "4869.pt\n",
      "4870.pt\n",
      "4871.pt\n",
      "4872.pt\n",
      "4873.pt\n",
      "4874.pt\n",
      "4875.pt\n",
      "4876.pt\n",
      "4877.pt\n",
      "4878.pt\n",
      "4879.pt\n",
      "4880.pt\n",
      "4881.pt\n",
      "4882.pt\n",
      "4883.pt\n",
      "4884.pt\n",
      "4885.pt\n",
      "4886.pt\n",
      "4887.pt\n",
      "4888.pt\n",
      "4889.pt\n",
      "4890.pt\n",
      "4891.pt\n",
      "4892.pt\n",
      "4893.pt\n",
      "4894.pt\n",
      "4895.pt\n",
      "4896.pt\n",
      "4897.pt\n",
      "4898.pt\n",
      "4899.pt\n",
      "4900.pt\n",
      "4901.pt\n",
      "4902.pt\n",
      "4903.pt\n",
      "4904.pt\n",
      "4905.pt\n",
      "4906.pt\n",
      "4907.pt\n",
      "4908.pt\n",
      "4909.pt\n",
      "4910.pt\n",
      "4911.pt\n",
      "4912.pt\n",
      "4913.pt\n",
      "4914.pt\n",
      "4915.pt\n",
      "4916.pt\n",
      "4917.pt\n",
      "4918.pt\n",
      "4919.pt\n",
      "4920.pt\n",
      "4921.pt\n",
      "4922.pt\n",
      "4923.pt\n",
      "4924.pt\n",
      "4925.pt\n",
      "4926.pt\n",
      "4927.pt\n",
      "4928.pt\n",
      "4929.pt\n",
      "4930.pt\n",
      "4931.pt\n",
      "4932.pt\n",
      "4933.pt\n",
      "4934.pt\n",
      "4935.pt\n",
      "4936.pt\n",
      "4937.pt\n",
      "4938.pt\n",
      "4939.pt\n",
      "4940.pt\n",
      "4941.pt\n",
      "4942.pt\n",
      "4943.pt\n",
      "4944.pt\n",
      "4945.pt\n",
      "4946.pt\n",
      "4947.pt\n",
      "4948.pt\n",
      "4949.pt\n",
      "4950.pt\n",
      "4951.pt\n",
      "4952.pt\n",
      "4953.pt\n",
      "4954.pt\n",
      "4955.pt\n",
      "4956.pt\n",
      "4957.pt\n",
      "4958.pt\n",
      "4959.pt\n",
      "4960.pt\n",
      "4961.pt\n",
      "4962.pt\n",
      "4963.pt\n",
      "4964.pt\n",
      "4965.pt\n",
      "4966.pt\n",
      "4967.pt\n",
      "4968.pt\n",
      "4969.pt\n",
      "4970.pt\n",
      "4971.pt\n",
      "4972.pt\n",
      "4973.pt\n",
      "4974.pt\n",
      "4975.pt\n",
      "4976.pt\n",
      "4977.pt\n",
      "4978.pt\n",
      "4979.pt\n",
      "4980.pt\n",
      "4981.pt\n",
      "4982.pt\n",
      "4983.pt\n",
      "4984.pt\n",
      "4985.pt\n",
      "4986.pt\n",
      "4987.pt\n",
      "4988.pt\n",
      "4989.pt\n",
      "4990.pt\n",
      "4991.pt\n",
      "4992.pt\n",
      "4993.pt\n",
      "4994.pt\n",
      "4995.pt\n",
      "4996.pt\n",
      "4997.pt\n",
      "4998.pt\n",
      "4999.pt\n",
      "5000.pt\n",
      "5001.pt\n",
      "5002.pt\n",
      "5003.pt\n",
      "5004.pt\n",
      "5005.pt\n",
      "5006.pt\n",
      "5007.pt\n",
      "5008.pt\n",
      "5009.pt\n",
      "5010.pt\n",
      "5011.pt\n",
      "5012.pt\n",
      "5013.pt\n",
      "5014.pt\n",
      "5015.pt\n",
      "5016.pt\n",
      "5017.pt\n",
      "5018.pt\n",
      "5019.pt\n",
      "5020.pt\n",
      "5021.pt\n",
      "5022.pt\n",
      "5023.pt\n",
      "5024.pt\n",
      "5025.pt\n",
      "5026.pt\n",
      "5027.pt\n",
      "5028.pt\n",
      "5029.pt\n",
      "5030.pt\n",
      "5031.pt\n",
      "5032.pt\n",
      "5033.pt\n",
      "5034.pt\n",
      "5035.pt\n",
      "5036.pt\n",
      "5037.pt\n",
      "5038.pt\n",
      "5039.pt\n",
      "5040.pt\n",
      "5041.pt\n",
      "5042.pt\n",
      "5043.pt\n",
      "5044.pt\n",
      "5045.pt\n",
      "5046.pt\n",
      "5047.pt\n",
      "5048.pt\n",
      "5049.pt\n",
      "5050.pt\n",
      "5051.pt\n",
      "5052.pt\n",
      "5053.pt\n",
      "5054.pt\n",
      "5055.pt\n",
      "5056.pt\n",
      "5057.pt\n",
      "5058.pt\n",
      "5059.pt\n",
      "5060.pt\n",
      "5061.pt\n",
      "5062.pt\n",
      "5063.pt\n",
      "5064.pt\n",
      "5065.pt\n",
      "5066.pt\n",
      "5067.pt\n",
      "5068.pt\n",
      "5069.pt\n",
      "5070.pt\n",
      "5071.pt\n",
      "5072.pt\n",
      "5073.pt\n",
      "5074.pt\n",
      "5075.pt\n",
      "5076.pt\n",
      "5077.pt\n",
      "5078.pt\n",
      "5079.pt\n",
      "5080.pt\n",
      "5081.pt\n",
      "5082.pt\n",
      "5083.pt\n",
      "5084.pt\n",
      "5085.pt\n",
      "5086.pt\n",
      "5087.pt\n",
      "5088.pt\n",
      "5089.pt\n",
      "5090.pt\n",
      "5091.pt\n",
      "5092.pt\n",
      "5093.pt\n",
      "5094.pt\n",
      "5095.pt\n",
      "5096.pt\n",
      "5097.pt\n",
      "5098.pt\n",
      "5099.pt\n",
      "5100.pt\n",
      "5101.pt\n",
      "5102.pt\n",
      "5103.pt\n",
      "5104.pt\n",
      "5105.pt\n",
      "5106.pt\n",
      "5107.pt\n",
      "5108.pt\n",
      "5109.pt\n",
      "5110.pt\n",
      "5111.pt\n",
      "5112.pt\n",
      "5113.pt\n",
      "5114.pt\n",
      "5115.pt\n",
      "5116.pt\n",
      "5117.pt\n",
      "5118.pt\n",
      "5119.pt\n",
      "5120.pt\n",
      "5121.pt\n",
      "5122.pt\n",
      "5123.pt\n",
      "5124.pt\n",
      "5125.pt\n",
      "5126.pt\n",
      "5127.pt\n",
      "5128.pt\n",
      "5129.pt\n",
      "5130.pt\n",
      "5131.pt\n",
      "5132.pt\n",
      "5133.pt\n",
      "5134.pt\n",
      "5135.pt\n",
      "5136.pt\n",
      "5137.pt\n",
      "5138.pt\n",
      "5139.pt\n",
      "5140.pt\n",
      "5141.pt\n",
      "5142.pt\n",
      "5143.pt\n",
      "5144.pt\n",
      "5145.pt\n",
      "5146.pt\n",
      "5147.pt\n",
      "5148.pt\n",
      "5149.pt\n",
      "5150.pt\n",
      "5151.pt\n",
      "5152.pt\n",
      "5153.pt\n",
      "5154.pt\n",
      "5155.pt\n",
      "5156.pt\n",
      "5157.pt\n",
      "5158.pt\n",
      "5159.pt\n",
      "5160.pt\n",
      "5161.pt\n",
      "5162.pt\n",
      "5163.pt\n",
      "5164.pt\n",
      "5165.pt\n",
      "5166.pt\n",
      "5167.pt\n",
      "5168.pt\n",
      "5169.pt\n",
      "5170.pt\n",
      "5171.pt\n",
      "5172.pt\n",
      "5173.pt\n",
      "5174.pt\n",
      "5175.pt\n",
      "5176.pt\n",
      "5177.pt\n",
      "5178.pt\n",
      "5179.pt\n",
      "5180.pt\n",
      "5181.pt\n",
      "5182.pt\n",
      "5183.pt\n",
      "5184.pt\n",
      "5185.pt\n",
      "5186.pt\n",
      "5187.pt\n",
      "5188.pt\n",
      "5189.pt\n",
      "5190.pt\n",
      "5191.pt\n",
      "5192.pt\n",
      "5193.pt\n",
      "5194.pt\n",
      "5195.pt\n",
      "5196.pt\n",
      "5197.pt\n",
      "5198.pt\n",
      "5199.pt\n",
      "5200.pt\n",
      "5201.pt\n",
      "5202.pt\n",
      "5203.pt\n",
      "5204.pt\n",
      "5205.pt\n",
      "5206.pt\n",
      "5207.pt\n",
      "5208.pt\n",
      "5209.pt\n",
      "5210.pt\n",
      "5211.pt\n",
      "5212.pt\n",
      "5213.pt\n",
      "5214.pt\n",
      "5215.pt\n",
      "5216.pt\n",
      "5217.pt\n",
      "5218.pt\n",
      "5219.pt\n",
      "5220.pt\n",
      "5221.pt\n",
      "5222.pt\n",
      "5223.pt\n",
      "5224.pt\n",
      "5225.pt\n",
      "5226.pt\n",
      "5227.pt\n",
      "5228.pt\n",
      "5229.pt\n",
      "5230.pt\n",
      "5231.pt\n",
      "5232.pt\n",
      "5233.pt\n",
      "5234.pt\n",
      "5235.pt\n",
      "5236.pt\n",
      "5237.pt\n",
      "5238.pt\n",
      "5239.pt\n",
      "5240.pt\n",
      "5241.pt\n",
      "5242.pt\n",
      "5243.pt\n",
      "5244.pt\n",
      "5245.pt\n",
      "5246.pt\n",
      "5247.pt\n",
      "5248.pt\n",
      "5249.pt\n",
      "5250.pt\n",
      "5251.pt\n",
      "5252.pt\n",
      "5253.pt\n",
      "5254.pt\n",
      "5255.pt\n",
      "5256.pt\n",
      "5257.pt\n",
      "5258.pt\n",
      "5259.pt\n",
      "5260.pt\n",
      "5261.pt\n",
      "5262.pt\n",
      "5263.pt\n",
      "5264.pt\n",
      "5265.pt\n",
      "5266.pt\n",
      "5267.pt\n",
      "5268.pt\n",
      "5269.pt\n",
      "5270.pt\n",
      "5271.pt\n",
      "5272.pt\n",
      "5273.pt\n",
      "5274.pt\n",
      "5275.pt\n",
      "5276.pt\n",
      "5277.pt\n",
      "5278.pt\n",
      "5279.pt\n",
      "5280.pt\n",
      "5281.pt\n",
      "5282.pt\n",
      "5283.pt\n",
      "5284.pt\n",
      "5285.pt\n",
      "5286.pt\n",
      "5287.pt\n",
      "5288.pt\n",
      "5289.pt\n",
      "5290.pt\n",
      "5291.pt\n",
      "5292.pt\n",
      "5293.pt\n",
      "5294.pt\n",
      "5295.pt\n",
      "5296.pt\n",
      "5297.pt\n",
      "5298.pt\n",
      "5299.pt\n",
      "5300.pt\n",
      "5301.pt\n",
      "5302.pt\n",
      "5303.pt\n",
      "5304.pt\n",
      "5305.pt\n",
      "5306.pt\n",
      "5307.pt\n",
      "5308.pt\n",
      "5309.pt\n",
      "5310.pt\n",
      "5311.pt\n",
      "5312.pt\n",
      "5313.pt\n",
      "5314.pt\n",
      "5315.pt\n",
      "5316.pt\n",
      "5317.pt\n",
      "5318.pt\n",
      "5319.pt\n",
      "5320.pt\n",
      "5321.pt\n",
      "5322.pt\n",
      "5323.pt\n",
      "5324.pt\n",
      "5325.pt\n",
      "5326.pt\n",
      "5327.pt\n",
      "5328.pt\n",
      "5329.pt\n",
      "5330.pt\n",
      "5331.pt\n",
      "5332.pt\n",
      "5333.pt\n",
      "5334.pt\n",
      "5335.pt\n",
      "5336.pt\n",
      "5337.pt\n",
      "5338.pt\n",
      "5339.pt\n",
      "5340.pt\n",
      "5341.pt\n",
      "5342.pt\n",
      "5343.pt\n",
      "5344.pt\n",
      "5345.pt\n",
      "5346.pt\n",
      "5347.pt\n",
      "5348.pt\n",
      "5349.pt\n",
      "5350.pt\n",
      "5351.pt\n",
      "5352.pt\n",
      "5353.pt\n",
      "5354.pt\n",
      "5355.pt\n",
      "5356.pt\n",
      "5357.pt\n",
      "5358.pt\n",
      "5359.pt\n",
      "5360.pt\n",
      "5361.pt\n",
      "5362.pt\n",
      "5363.pt\n",
      "5364.pt\n",
      "5365.pt\n",
      "5366.pt\n",
      "5367.pt\n",
      "5368.pt\n",
      "5369.pt\n",
      "5370.pt\n",
      "5371.pt\n",
      "5372.pt\n",
      "5373.pt\n",
      "5374.pt\n",
      "5375.pt\n",
      "5376.pt\n",
      "5377.pt\n",
      "5378.pt\n",
      "5379.pt\n",
      "5380.pt\n",
      "5381.pt\n",
      "5382.pt\n",
      "5383.pt\n",
      "5384.pt\n",
      "5385.pt\n",
      "5386.pt\n",
      "5387.pt\n",
      "5388.pt\n",
      "5389.pt\n",
      "5390.pt\n",
      "5391.pt\n",
      "5392.pt\n",
      "5393.pt\n",
      "5394.pt\n",
      "5395.pt\n",
      "5396.pt\n",
      "5397.pt\n",
      "5398.pt\n",
      "5399.pt\n",
      "5400.pt\n",
      "5401.pt\n",
      "5402.pt\n",
      "5403.pt\n",
      "5404.pt\n",
      "5405.pt\n",
      "5406.pt\n",
      "5407.pt\n",
      "5408.pt\n",
      "5409.pt\n",
      "5410.pt\n",
      "5411.pt\n",
      "5412.pt\n",
      "5413.pt\n",
      "5414.pt\n",
      "5415.pt\n",
      "5416.pt\n",
      "5417.pt\n",
      "5418.pt\n",
      "5419.pt\n",
      "5420.pt\n",
      "5421.pt\n",
      "5422.pt\n",
      "5423.pt\n",
      "5424.pt\n",
      "5425.pt\n",
      "5426.pt\n",
      "5427.pt\n",
      "5428.pt\n",
      "5429.pt\n",
      "5430.pt\n",
      "5431.pt\n",
      "5432.pt\n",
      "5433.pt\n",
      "5434.pt\n",
      "5435.pt\n",
      "5436.pt\n",
      "5437.pt\n",
      "5438.pt\n",
      "5439.pt\n",
      "5440.pt\n",
      "5441.pt\n",
      "5442.pt\n",
      "5443.pt\n",
      "5444.pt\n",
      "5445.pt\n",
      "5446.pt\n",
      "5447.pt\n",
      "5448.pt\n",
      "5449.pt\n",
      "5450.pt\n",
      "5451.pt\n",
      "5452.pt\n",
      "5453.pt\n",
      "5454.pt\n",
      "5455.pt\n",
      "5456.pt\n",
      "5457.pt\n",
      "5458.pt\n",
      "5459.pt\n",
      "5460.pt\n",
      "5461.pt\n",
      "5462.pt\n",
      "5463.pt\n",
      "5464.pt\n",
      "5465.pt\n",
      "5466.pt\n",
      "5467.pt\n",
      "5468.pt\n",
      "5469.pt\n",
      "5470.pt\n",
      "5471.pt\n",
      "5472.pt\n",
      "5473.pt\n",
      "5474.pt\n",
      "5475.pt\n",
      "5476.pt\n",
      "5477.pt\n",
      "5478.pt\n",
      "5479.pt\n",
      "5480.pt\n",
      "5481.pt\n",
      "5482.pt\n",
      "5483.pt\n",
      "5484.pt\n",
      "5485.pt\n",
      "5486.pt\n",
      "5487.pt\n",
      "5488.pt\n",
      "5489.pt\n",
      "5490.pt\n",
      "5491.pt\n",
      "5492.pt\n",
      "5493.pt\n",
      "5494.pt\n",
      "5495.pt\n",
      "5496.pt\n",
      "5497.pt\n",
      "5498.pt\n",
      "5499.pt\n",
      "5500.pt\n",
      "5501.pt\n",
      "5502.pt\n",
      "5503.pt\n",
      "5504.pt\n",
      "5505.pt\n",
      "5506.pt\n",
      "5507.pt\n",
      "5508.pt\n",
      "5509.pt\n",
      "5510.pt\n",
      "5511.pt\n",
      "5512.pt\n",
      "5513.pt\n",
      "5514.pt\n",
      "5515.pt\n",
      "5516.pt\n",
      "5517.pt\n",
      "5518.pt\n",
      "5519.pt\n",
      "5520.pt\n",
      "5521.pt\n",
      "5522.pt\n",
      "5523.pt\n",
      "5524.pt\n",
      "5525.pt\n",
      "5526.pt\n",
      "5527.pt\n",
      "5528.pt\n",
      "5529.pt\n",
      "5530.pt\n",
      "5531.pt\n",
      "5532.pt\n",
      "5533.pt\n",
      "5534.pt\n",
      "5535.pt\n",
      "5536.pt\n",
      "5537.pt\n",
      "5538.pt\n",
      "5539.pt\n",
      "5540.pt\n",
      "5541.pt\n",
      "5542.pt\n",
      "5543.pt\n",
      "5544.pt\n",
      "5545.pt\n",
      "5546.pt\n",
      "5547.pt\n",
      "5548.pt\n",
      "5549.pt\n",
      "5550.pt\n",
      "5551.pt\n",
      "5552.pt\n",
      "5553.pt\n",
      "5554.pt\n",
      "5555.pt\n",
      "5556.pt\n",
      "5557.pt\n",
      "5558.pt\n",
      "5559.pt\n",
      "5560.pt\n",
      "5561.pt\n",
      "5562.pt\n",
      "5563.pt\n",
      "5564.pt\n",
      "5565.pt\n",
      "5566.pt\n",
      "5567.pt\n",
      "5568.pt\n",
      "5569.pt\n",
      "5570.pt\n",
      "5571.pt\n",
      "5572.pt\n",
      "5573.pt\n",
      "5574.pt\n",
      "5575.pt\n",
      "5576.pt\n",
      "5577.pt\n",
      "5578.pt\n",
      "5579.pt\n",
      "5580.pt\n",
      "5581.pt\n",
      "5582.pt\n",
      "5583.pt\n",
      "5584.pt\n",
      "5585.pt\n",
      "5586.pt\n",
      "5587.pt\n",
      "5588.pt\n",
      "5589.pt\n",
      "5590.pt\n",
      "5591.pt\n",
      "5592.pt\n",
      "5593.pt\n",
      "5594.pt\n",
      "5595.pt\n",
      "5596.pt\n",
      "5597.pt\n",
      "5598.pt\n",
      "5599.pt\n",
      "5600.pt\n",
      "5601.pt\n",
      "5602.pt\n",
      "5603.pt\n",
      "5604.pt\n",
      "5605.pt\n",
      "5606.pt\n",
      "5607.pt\n",
      "5608.pt\n",
      "5609.pt\n",
      "5610.pt\n",
      "5611.pt\n",
      "5612.pt\n",
      "5613.pt\n",
      "5614.pt\n",
      "5615.pt\n",
      "5616.pt\n",
      "5617.pt\n",
      "5618.pt\n",
      "5619.pt\n",
      "5620.pt\n",
      "5621.pt\n",
      "5622.pt\n",
      "5623.pt\n",
      "5624.pt\n",
      "5625.pt\n",
      "5626.pt\n",
      "5627.pt\n",
      "5628.pt\n",
      "5629.pt\n",
      "5630.pt\n",
      "5631.pt\n",
      "5632.pt\n",
      "5633.pt\n",
      "5634.pt\n",
      "5635.pt\n",
      "5636.pt\n",
      "5637.pt\n",
      "5638.pt\n",
      "5639.pt\n",
      "5640.pt\n",
      "5641.pt\n",
      "5642.pt\n",
      "5643.pt\n",
      "5644.pt\n",
      "5645.pt\n",
      "5646.pt\n",
      "5647.pt\n",
      "5648.pt\n",
      "5649.pt\n",
      "5650.pt\n",
      "5651.pt\n",
      "5652.pt\n",
      "5653.pt\n",
      "5654.pt\n",
      "5655.pt\n",
      "5656.pt\n",
      "5657.pt\n",
      "5658.pt\n",
      "5659.pt\n",
      "5660.pt\n",
      "5661.pt\n",
      "5662.pt\n",
      "5663.pt\n",
      "5664.pt\n",
      "5665.pt\n",
      "5666.pt\n",
      "5667.pt\n",
      "5668.pt\n",
      "5669.pt\n",
      "5670.pt\n",
      "5671.pt\n",
      "5672.pt\n",
      "5673.pt\n",
      "5674.pt\n",
      "5675.pt\n",
      "5676.pt\n",
      "5677.pt\n",
      "5678.pt\n",
      "5679.pt\n",
      "5680.pt\n",
      "5681.pt\n",
      "5682.pt\n",
      "5683.pt\n",
      "5684.pt\n",
      "5685.pt\n",
      "5686.pt\n",
      "5687.pt\n",
      "5688.pt\n",
      "5689.pt\n",
      "5690.pt\n",
      "5691.pt\n",
      "5692.pt\n",
      "5693.pt\n",
      "5694.pt\n",
      "5695.pt\n",
      "5696.pt\n",
      "5697.pt\n",
      "5698.pt\n",
      "5699.pt\n",
      "5700.pt\n",
      "5701.pt\n",
      "5702.pt\n",
      "5703.pt\n",
      "5704.pt\n",
      "5705.pt\n",
      "5706.pt\n",
      "5707.pt\n",
      "5708.pt\n",
      "5709.pt\n",
      "5710.pt\n",
      "5711.pt\n",
      "5712.pt\n",
      "5713.pt\n",
      "5714.pt\n",
      "5715.pt\n",
      "5716.pt\n",
      "5717.pt\n",
      "5718.pt\n",
      "5719.pt\n",
      "5720.pt\n",
      "5721.pt\n",
      "5722.pt\n",
      "5723.pt\n",
      "5724.pt\n",
      "5725.pt\n",
      "5726.pt\n",
      "5727.pt\n",
      "5728.pt\n",
      "5729.pt\n",
      "5730.pt\n",
      "5731.pt\n",
      "5732.pt\n",
      "5733.pt\n",
      "5734.pt\n",
      "5735.pt\n",
      "5736.pt\n",
      "5737.pt\n",
      "5738.pt\n",
      "5739.pt\n",
      "5740.pt\n",
      "5741.pt\n",
      "5742.pt\n",
      "5743.pt\n",
      "5744.pt\n",
      "5745.pt\n",
      "5746.pt\n",
      "5747.pt\n",
      "5748.pt\n",
      "5749.pt\n",
      "5750.pt\n",
      "5751.pt\n",
      "5752.pt\n",
      "5753.pt\n",
      "5754.pt\n",
      "5755.pt\n",
      "5756.pt\n",
      "5757.pt\n",
      "5758.pt\n",
      "5759.pt\n",
      "5760.pt\n",
      "5761.pt\n",
      "5762.pt\n",
      "5763.pt\n",
      "5764.pt\n",
      "5765.pt\n",
      "5766.pt\n",
      "5767.pt\n",
      "5768.pt\n",
      "5769.pt\n",
      "5770.pt\n",
      "5771.pt\n",
      "5772.pt\n",
      "5773.pt\n",
      "5774.pt\n",
      "5775.pt\n",
      "5776.pt\n",
      "5777.pt\n",
      "5778.pt\n",
      "5779.pt\n",
      "5780.pt\n",
      "5781.pt\n",
      "5782.pt\n",
      "5783.pt\n",
      "5784.pt\n",
      "5785.pt\n",
      "5786.pt\n",
      "5787.pt\n",
      "5788.pt\n",
      "5789.pt\n",
      "5790.pt\n",
      "5791.pt\n",
      "5792.pt\n",
      "5793.pt\n",
      "5794.pt\n",
      "5795.pt\n",
      "5796.pt\n",
      "5797.pt\n",
      "5798.pt\n",
      "5799.pt\n",
      "5800.pt\n",
      "5801.pt\n",
      "5802.pt\n",
      "5803.pt\n",
      "5804.pt\n",
      "5805.pt\n",
      "5806.pt\n",
      "5807.pt\n",
      "5808.pt\n",
      "5809.pt\n",
      "5810.pt\n",
      "5811.pt\n",
      "5812.pt\n",
      "5813.pt\n",
      "5814.pt\n",
      "5815.pt\n",
      "5816.pt\n",
      "5817.pt\n",
      "5818.pt\n",
      "5819.pt\n",
      "5820.pt\n",
      "5821.pt\n",
      "5822.pt\n",
      "5823.pt\n",
      "5824.pt\n",
      "5825.pt\n",
      "5826.pt\n",
      "5827.pt\n",
      "5828.pt\n",
      "5829.pt\n",
      "5830.pt\n",
      "5831.pt\n",
      "5832.pt\n",
      "5833.pt\n",
      "5834.pt\n",
      "5835.pt\n",
      "5836.pt\n",
      "5837.pt\n",
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.12.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "                                              0.0/276.5 MB ? eta -:--:--\n",
      "                                              0.1/276.5 MB 4.3 MB/s eta 0:01:05\n",
      "                                              0.3/276.5 MB 3.5 MB/s eta 0:01:18\n",
      "                                              0.5/276.5 MB 3.5 MB/s eta 0:01:19\n",
      "                                              0.6/276.5 MB 4.1 MB/s eta 0:01:08\n",
      "                                              0.8/276.5 MB 4.1 MB/s eta 0:01:08\n",
      "                                              1.1/276.5 MB 4.2 MB/s eta 0:01:06\n",
      "                                              1.3/276.5 MB 4.2 MB/s eta 0:01:05\n",
      "                                              1.5/276.5 MB 4.4 MB/s eta 0:01:03\n",
      "                                              1.8/276.5 MB 4.6 MB/s eta 0:01:00\n",
      "                                              2.1/276.5 MB 4.6 MB/s eta 0:01:00\n",
      "                                              2.3/276.5 MB 4.8 MB/s eta 0:00:58\n",
      "                                              2.6/276.5 MB 5.0 MB/s eta 0:00:55\n",
      "                                              2.8/276.5 MB 5.0 MB/s eta 0:00:56\n",
      "                                              3.1/276.5 MB 5.0 MB/s eta 0:00:55\n",
      "                                              3.3/276.5 MB 5.0 MB/s eta 0:00:55\n",
      "                                              3.5/276.5 MB 4.8 MB/s eta 0:00:57\n",
      "                                              3.6/276.5 MB 4.8 MB/s eta 0:00:57\n",
      "                                              3.8/276.5 MB 4.8 MB/s eta 0:00:57\n",
      "                                              4.0/276.5 MB 4.8 MB/s eta 0:00:57\n",
      "                                              4.2/276.5 MB 4.7 MB/s eta 0:00:59\n",
      "                                              4.4/276.5 MB 4.6 MB/s eta 0:00:59\n",
      "                                              4.6/276.5 MB 4.7 MB/s eta 0:00:58\n",
      "                                              4.9/276.5 MB 4.8 MB/s eta 0:00:57\n",
      "                                              5.3/276.5 MB 5.0 MB/s eta 0:00:55\n",
      "                                              5.6/276.5 MB 5.1 MB/s eta 0:00:54\n",
      "                                              5.9/276.5 MB 5.1 MB/s eta 0:00:53\n",
      "                                              6.2/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "                                              6.6/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "                                              6.8/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        7.0/276.5 MB 5.3 MB/s eta 0:00:52\n",
      "     -                                        7.2/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        7.4/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        7.7/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        8.0/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        8.2/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        8.3/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        8.5/276.5 MB 5.1 MB/s eta 0:00:53\n",
      "     -                                        8.8/276.5 MB 5.1 MB/s eta 0:00:53\n",
      "     -                                        9.0/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        9.2/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        9.4/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        9.7/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                        9.9/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                       10.1/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                       10.3/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                       10.5/276.5 MB 5.2 MB/s eta 0:00:52\n",
      "     -                                       10.7/276.5 MB 5.2 MB/s eta 0:00:51\n",
      "     -                                       11.1/276.5 MB 5.3 MB/s eta 0:00:51\n",
      "     -                                       11.3/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       11.6/276.5 MB 5.4 MB/s eta 0:00:50\n",
      "     -                                       11.8/276.5 MB 5.4 MB/s eta 0:00:50\n",
      "     -                                       12.0/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       12.2/276.5 MB 5.3 MB/s eta 0:00:51\n",
      "     -                                       12.4/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       12.7/276.5 MB 5.2 MB/s eta 0:00:51\n",
      "     -                                       13.0/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       13.3/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       13.4/276.5 MB 5.2 MB/s eta 0:00:51\n",
      "     -                                       13.6/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     -                                       13.9/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     --                                      14.2/276.5 MB 5.4 MB/s eta 0:00:49\n",
      "     --                                      14.5/276.5 MB 5.5 MB/s eta 0:00:48\n",
      "     --                                      14.8/276.5 MB 5.6 MB/s eta 0:00:47\n",
      "     --                                      15.0/276.5 MB 5.5 MB/s eta 0:00:48\n",
      "     --                                      15.3/276.5 MB 5.5 MB/s eta 0:00:48\n",
      "     --                                      15.6/276.5 MB 5.5 MB/s eta 0:00:48\n",
      "     --                                      15.9/276.5 MB 5.4 MB/s eta 0:00:49\n",
      "     --                                      16.1/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      16.4/276.5 MB 5.3 MB/s eta 0:00:50\n",
      "     --                                      16.6/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      16.8/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      17.0/276.5 MB 5.2 MB/s eta 0:00:51\n",
      "     --                                      17.3/276.5 MB 5.2 MB/s eta 0:00:51\n",
      "     --                                      17.6/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      17.9/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      18.1/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      18.4/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      18.7/276.5 MB 5.4 MB/s eta 0:00:49\n",
      "     --                                      18.9/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      19.2/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      19.3/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      19.5/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      19.8/276.5 MB 5.2 MB/s eta 0:00:50\n",
      "     --                                      20.2/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      20.5/276.5 MB 5.3 MB/s eta 0:00:49\n",
      "     --                                      20.8/276.5 MB 5.5 MB/s eta 0:00:47\n",
      "     --                                      21.2/276.5 MB 5.5 MB/s eta 0:00:47\n",
      "     ---                                     21.4/276.5 MB 5.4 MB/s eta 0:00:48\n",
      "     ---                                     21.6/276.5 MB 5.4 MB/s eta 0:00:48\n",
      "     ---                                     21.9/276.5 MB 5.4 MB/s eta 0:00:48\n",
      "     ---                                     22.1/276.5 MB 5.4 MB/s eta 0:00:47\n",
      "     ---                                     22.3/276.5 MB 5.4 MB/s eta 0:00:48\n",
      "     ---                                     22.5/276.5 MB 5.4 MB/s eta 0:00:47\n",
      "     ---                                     22.8/276.5 MB 5.4 MB/s eta 0:00:47\n",
      "     ---                                     23.2/276.5 MB 5.5 MB/s eta 0:00:47\n",
      "     ---                                     23.6/276.5 MB 5.5 MB/s eta 0:00:46\n",
      "     ---                                     24.0/276.5 MB 5.6 MB/s eta 0:00:46\n",
      "     ---                                     24.4/276.5 MB 5.6 MB/s eta 0:00:45\n",
      "     ---                                     26.0/276.5 MB 5.5 MB/s eta 0:00:46\n",
      "     ---                                     26.2/276.5 MB 5.6 MB/s eta 0:00:45\n",
      "     ---                                     26.3/276.5 MB 5.5 MB/s eta 0:00:46\n",
      "     ---                                     26.7/276.5 MB 5.6 MB/s eta 0:00:45\n",
      "     ---                                     27.0/276.5 MB 5.7 MB/s eta 0:00:44\n",
      "     ---                                     27.4/276.5 MB 5.7 MB/s eta 0:00:44\n",
      "     ----                                    28.8/276.5 MB 5.6 MB/s eta 0:00:44\n",
      "     ----                                    29.2/276.5 MB 5.7 MB/s eta 0:00:44\n",
      "     ----                                    29.5/276.5 MB 5.8 MB/s eta 0:00:43\n",
      "     ----                                    29.8/276.5 MB 6.1 MB/s eta 0:00:41\n",
      "     ----                                    31.4/276.5 MB 5.8 MB/s eta 0:00:43\n",
      "     ----                                    31.8/276.5 MB 6.0 MB/s eta 0:00:42\n",
      "     ----                                    33.3/276.5 MB 5.9 MB/s eta 0:00:42\n",
      "     ----                                    33.6/276.5 MB 5.7 MB/s eta 0:00:43\n",
      "     ----                                    34.0/276.5 MB 5.7 MB/s eta 0:00:43\n",
      "     ----                                    35.1/276.5 MB 5.7 MB/s eta 0:00:43\n",
      "     ----                                    35.4/276.5 MB 5.8 MB/s eta 0:00:42\n",
      "     -----                                   35.7/276.5 MB 5.8 MB/s eta 0:00:42\n",
      "     -----                                   36.1/276.5 MB 5.9 MB/s eta 0:00:41\n",
      "     -----                                   36.4/276.5 MB 5.9 MB/s eta 0:00:41\n",
      "     -----                                   36.8/276.5 MB 6.1 MB/s eta 0:00:40\n",
      "     -----                                   37.0/276.5 MB 6.0 MB/s eta 0:00:40\n",
      "     -----                                   37.4/276.5 MB 6.0 MB/s eta 0:00:41\n",
      "     -----                                   37.7/276.5 MB 6.0 MB/s eta 0:00:41\n",
      "     -----                                   38.0/276.5 MB 6.0 MB/s eta 0:00:40\n",
      "     -----                                   39.7/276.5 MB 5.9 MB/s eta 0:00:41\n",
      "     -----                                   40.0/276.5 MB 5.9 MB/s eta 0:00:41\n",
      "     -----                                   41.6/276.5 MB 5.9 MB/s eta 0:00:40\n",
      "     -----                                   41.9/276.5 MB 5.8 MB/s eta 0:00:41\n",
      "     -----                                   42.1/276.5 MB 5.7 MB/s eta 0:00:41\n",
      "     -----                                   42.3/276.5 MB 5.7 MB/s eta 0:00:41\n",
      "     ------                                  42.6/276.5 MB 5.8 MB/s eta 0:00:40\n",
      "     ------                                  43.0/276.5 MB 5.9 MB/s eta 0:00:40\n",
      "     ------                                  43.4/276.5 MB 6.0 MB/s eta 0:00:39\n",
      "     ------                                  43.7/276.5 MB 6.1 MB/s eta 0:00:39\n",
      "     ------                                  44.0/276.5 MB 6.1 MB/s eta 0:00:39\n",
      "     ------                                  44.3/276.5 MB 6.2 MB/s eta 0:00:38\n",
      "     ------                                  44.6/276.5 MB 6.1 MB/s eta 0:00:38\n",
      "     ------                                  44.8/276.5 MB 6.2 MB/s eta 0:00:38\n",
      "     ------                                  45.2/276.5 MB 6.2 MB/s eta 0:00:38\n",
      "     ------                                  45.6/276.5 MB 6.2 MB/s eta 0:00:38\n",
      "     ------                                  45.9/276.5 MB 6.2 MB/s eta 0:00:37\n",
      "     ------                                  46.2/276.5 MB 6.2 MB/s eta 0:00:37\n",
      "     ------                                  47.8/276.5 MB 6.0 MB/s eta 0:00:39\n",
      "     ------                                  48.0/276.5 MB 6.0 MB/s eta 0:00:39\n",
      "     ------                                  48.3/276.5 MB 6.0 MB/s eta 0:00:38\n",
      "     ------                                  48.5/276.5 MB 6.0 MB/s eta 0:00:39\n",
      "     ------                                  48.9/276.5 MB 6.1 MB/s eta 0:00:38\n",
      "     -------                                 51.0/276.5 MB 5.9 MB/s eta 0:00:39\n",
      "     -------                                 51.3/276.5 MB 5.9 MB/s eta 0:00:39\n",
      "     -------                                 51.6/276.5 MB 5.9 MB/s eta 0:00:39\n",
      "     -------                                 51.9/276.5 MB 6.0 MB/s eta 0:00:38\n",
      "     -------                                 53.2/276.5 MB 5.9 MB/s eta 0:00:38\n",
      "     -------                                 53.4/276.5 MB 5.9 MB/s eta 0:00:38\n",
      "     -------                                 53.9/276.5 MB 5.8 MB/s eta 0:00:39\n",
      "     -------                                 54.2/276.5 MB 5.8 MB/s eta 0:00:39\n",
      "     -------                                 54.5/276.5 MB 5.8 MB/s eta 0:00:38\n",
      "     -------                                 54.8/276.5 MB 5.8 MB/s eta 0:00:39\n",
      "     -------                                 55.1/276.5 MB 5.8 MB/s eta 0:00:38\n",
      "     -------                                 56.3/276.5 MB 5.6 MB/s eta 0:00:40\n",
      "     --------                                56.9/276.5 MB 5.6 MB/s eta 0:00:40\n",
      "     --------                                57.4/276.5 MB 5.7 MB/s eta 0:00:39\n",
      "     --------                                57.7/276.5 MB 5.7 MB/s eta 0:00:39\n",
      "     --------                                58.0/276.5 MB 5.7 MB/s eta 0:00:39\n",
      "     --------                                58.3/276.5 MB 5.7 MB/s eta 0:00:38\n",
      "     --------                                59.8/276.5 MB 5.6 MB/s eta 0:00:40\n",
      "     --------                                60.1/276.5 MB 5.6 MB/s eta 0:00:39\n",
      "     --------                                60.5/276.5 MB 5.7 MB/s eta 0:00:38\n",
      "     --------                                60.9/276.5 MB 5.7 MB/s eta 0:00:38\n",
      "     --------                                61.2/276.5 MB 5.7 MB/s eta 0:00:38\n",
      "     --------                                61.5/276.5 MB 5.8 MB/s eta 0:00:38\n",
      "     --------                                62.3/276.5 MB 5.8 MB/s eta 0:00:37\n",
      "     --------                                62.6/276.5 MB 5.9 MB/s eta 0:00:37\n",
      "     --------                                62.9/276.5 MB 6.0 MB/s eta 0:00:36\n",
      "     --------                                63.3/276.5 MB 6.0 MB/s eta 0:00:36\n",
      "     --------                                63.7/276.5 MB 6.1 MB/s eta 0:00:36\n",
      "     ---------                               64.0/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               64.2/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               64.6/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               64.9/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               65.2/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               65.6/276.5 MB 6.1 MB/s eta 0:00:35\n",
      "     ---------                               66.2/276.5 MB 6.2 MB/s eta 0:00:34\n",
      "     ---------                               66.6/276.5 MB 6.4 MB/s eta 0:00:34\n",
      "     ---------                               66.9/276.5 MB 6.3 MB/s eta 0:00:34\n",
      "     ---------                               67.2/276.5 MB 6.4 MB/s eta 0:00:33\n",
      "     ---------                               68.7/276.5 MB 6.1 MB/s eta 0:00:34\n",
      "     ---------                               69.4/276.5 MB 6.4 MB/s eta 0:00:33\n",
      "     ---------                               70.2/276.5 MB 6.3 MB/s eta 0:00:33\n",
      "     ---------                               70.4/276.5 MB 6.2 MB/s eta 0:00:34\n",
      "     ---------                               70.6/276.5 MB 6.2 MB/s eta 0:00:34\n",
      "     ----------                              71.4/276.5 MB 6.0 MB/s eta 0:00:35\n",
      "     ----------                              71.6/276.5 MB 5.9 MB/s eta 0:00:35\n",
      "     ----------                              72.0/276.5 MB 5.9 MB/s eta 0:00:35\n",
      "     ----------                              72.4/276.5 MB 6.0 MB/s eta 0:00:35\n",
      "     ----------                              72.6/276.5 MB 6.0 MB/s eta 0:00:34\n",
      "     ----------                              72.9/276.5 MB 6.0 MB/s eta 0:00:35\n",
      "     ----------                              73.3/276.5 MB 6.0 MB/s eta 0:00:35\n",
      "     ----------                              74.7/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              75.0/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              75.3/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              75.6/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              76.0/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              76.3/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              76.6/276.5 MB 5.7 MB/s eta 0:00:36\n",
      "     ----------                              77.0/276.5 MB 5.7 MB/s eta 0:00:35\n",
      "     ----------                              77.3/276.5 MB 5.8 MB/s eta 0:00:35\n",
      "     ----------                              77.5/276.5 MB 5.7 MB/s eta 0:00:35\n",
      "     -----------                             79.0/276.5 MB 5.7 MB/s eta 0:00:35\n",
      "     -----------                             79.3/276.5 MB 5.8 MB/s eta 0:00:35\n",
      "     -----------                             79.8/276.5 MB 5.8 MB/s eta 0:00:34\n",
      "     -----------                             80.1/276.5 MB 5.9 MB/s eta 0:00:34\n",
      "     -----------                             80.5/276.5 MB 6.0 MB/s eta 0:00:33\n",
      "     -----------                             80.6/276.5 MB 6.0 MB/s eta 0:00:33\n",
      "     -----------                             81.1/276.5 MB 6.2 MB/s eta 0:00:32\n",
      "     -----------                             81.3/276.5 MB 6.2 MB/s eta 0:00:32\n",
      "     -----------                             81.7/276.5 MB 6.4 MB/s eta 0:00:31\n",
      "     -----------                             82.0/276.5 MB 6.4 MB/s eta 0:00:31\n",
      "     -----------                             82.4/276.5 MB 6.4 MB/s eta 0:00:31\n",
      "     -----------                             84.0/276.5 MB 6.2 MB/s eta 0:00:32\n",
      "     -----------                             84.4/276.5 MB 6.3 MB/s eta 0:00:31\n",
      "     -----------                             84.7/276.5 MB 6.4 MB/s eta 0:00:31\n",
      "     ------------                            86.2/276.5 MB 6.1 MB/s eta 0:00:32\n",
      "     ------------                            86.6/276.5 MB 6.2 MB/s eta 0:00:31\n",
      "     ------------                            86.9/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            87.3/276.5 MB 6.2 MB/s eta 0:00:31\n",
      "     ------------                            87.5/276.5 MB 6.1 MB/s eta 0:00:32\n",
      "     ------------                            87.9/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            88.1/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            88.4/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            88.7/276.5 MB 6.2 MB/s eta 0:00:31\n",
      "     ------------                            88.9/276.5 MB 6.2 MB/s eta 0:00:31\n",
      "     ------------                            89.2/276.5 MB 6.2 MB/s eta 0:00:31\n",
      "     ------------                            89.5/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     ------------                            89.8/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            90.1/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            90.4/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            90.7/276.5 MB 6.0 MB/s eta 0:00:31\n",
      "     ------------                            91.1/276.5 MB 6.1 MB/s eta 0:00:31\n",
      "     ------------                            91.5/276.5 MB 6.3 MB/s eta 0:00:30\n",
      "     ------------                            91.8/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     ------------                            92.1/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     -------------                           92.5/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     -------------                           92.7/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     -------------                           93.0/276.5 MB 6.2 MB/s eta 0:00:30\n",
      "     -------------                           94.5/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           95.3/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           96.5/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           96.8/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                           97.1/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           97.4/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                           97.6/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           97.9/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                           98.2/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                           98.5/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                           98.8/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     -------------                           99.1/276.5 MB 6.1 MB/s eta 0:00:30\n",
      "     --------------                          99.6/276.5 MB 6.2 MB/s eta 0:00:29\n",
      "     -------------                          100.4/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                          100.6/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                          100.7/276.5 MB 6.0 MB/s eta 0:00:30\n",
      "     -------------                          101.0/276.5 MB 5.7 MB/s eta 0:00:31\n",
      "     -------------                          101.2/276.5 MB 5.7 MB/s eta 0:00:31\n",
      "     -------------                          101.4/276.5 MB 5.5 MB/s eta 0:00:32\n",
      "     --------------                         102.8/276.5 MB 5.4 MB/s eta 0:00:33\n",
      "     --------------                         103.1/276.5 MB 5.3 MB/s eta 0:00:33\n",
      "     --------------                         104.7/276.5 MB 5.4 MB/s eta 0:00:33\n",
      "     --------------                         104.9/276.5 MB 5.3 MB/s eta 0:00:33\n",
      "     --------------                         105.2/276.5 MB 5.3 MB/s eta 0:00:33\n",
      "     --------------                         105.7/276.5 MB 5.4 MB/s eta 0:00:32\n",
      "     --------------                         106.1/276.5 MB 5.5 MB/s eta 0:00:32\n",
      "     --------------                         106.4/276.5 MB 5.5 MB/s eta 0:00:31\n",
      "     --------------                         108.0/276.5 MB 5.4 MB/s eta 0:00:32\n",
      "     --------------                         108.2/276.5 MB 5.4 MB/s eta 0:00:32\n",
      "     --------------                         108.5/276.5 MB 5.3 MB/s eta 0:00:32\n",
      "     --------------                         109.0/276.5 MB 5.4 MB/s eta 0:00:31\n",
      "     ---------------                        109.4/276.5 MB 5.5 MB/s eta 0:00:31\n",
      "     ---------------                        109.8/276.5 MB 5.5 MB/s eta 0:00:31\n",
      "     ---------------                        111.2/276.5 MB 5.6 MB/s eta 0:00:30\n",
      "     ---------------                        111.4/276.5 MB 5.6 MB/s eta 0:00:30\n",
      "     ---------------                        111.7/276.5 MB 5.7 MB/s eta 0:00:29\n",
      "     ---------------                        112.1/276.5 MB 5.8 MB/s eta 0:00:29\n",
      "     ---------------                        112.5/276.5 MB 5.9 MB/s eta 0:00:28\n",
      "     ---------------                        112.8/276.5 MB 6.0 MB/s eta 0:00:28\n",
      "     ---------------                        113.2/276.5 MB 6.0 MB/s eta 0:00:28\n",
      "     ---------------                        113.5/276.5 MB 6.0 MB/s eta 0:00:28\n",
      "     ---------------                        113.9/276.5 MB 6.0 MB/s eta 0:00:28\n",
      "     ---------------                        114.2/276.5 MB 6.1 MB/s eta 0:00:27\n",
      "     ---------------                        115.8/276.5 MB 6.0 MB/s eta 0:00:28\n",
      "     ---------------                        116.0/276.5 MB 5.8 MB/s eta 0:00:28\n",
      "     ---------------                        116.3/276.5 MB 5.9 MB/s eta 0:00:28\n",
      "     ----------------                       116.7/276.5 MB 6.0 MB/s eta 0:00:27\n",
      "     ----------------                       118.2/276.5 MB 6.0 MB/s eta 0:00:27\n",
      "     ----------------                       118.5/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       119.0/276.5 MB 6.2 MB/s eta 0:00:26\n",
      "     ----------------                       119.3/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       120.9/276.5 MB 6.0 MB/s eta 0:00:26\n",
      "     ----------------                       121.2/276.5 MB 6.0 MB/s eta 0:00:26\n",
      "     ----------------                       121.5/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       121.8/276.5 MB 6.2 MB/s eta 0:00:26\n",
      "     ----------------                       122.2/276.5 MB 6.2 MB/s eta 0:00:25\n",
      "     ----------------                       122.5/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       122.8/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       123.1/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     ----------------                       123.5/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     -----------------                      123.7/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     -----------------                      124.1/276.5 MB 6.1 MB/s eta 0:00:26\n",
      "     -----------------                      125.7/276.5 MB 6.1 MB/s eta 0:00:25\n",
      "     -----------------                      126.0/276.5 MB 6.2 MB/s eta 0:00:25\n",
      "     -----------------                      126.3/276.5 MB 6.3 MB/s eta 0:00:24\n",
      "     -----------------                      126.7/276.5 MB 6.2 MB/s eta 0:00:25\n",
      "     -----------------                      127.2/276.5 MB 6.3 MB/s eta 0:00:24\n",
      "     -----------------                      127.5/276.5 MB 6.4 MB/s eta 0:00:24\n",
      "     -----------------                      128.7/276.5 MB 6.2 MB/s eta 0:00:24\n",
      "     -----------------                      129.1/276.5 MB 6.2 MB/s eta 0:00:24\n",
      "     -----------------                      129.4/276.5 MB 6.1 MB/s eta 0:00:25\n",
      "     -----------------                      129.7/276.5 MB 6.2 MB/s eta 0:00:24\n",
      "     -----------------                      130.0/276.5 MB 6.2 MB/s eta 0:00:24\n",
      "     -----------------                      130.2/276.5 MB 6.2 MB/s eta 0:00:24\n",
      "     -----------------                      130.7/276.5 MB 6.4 MB/s eta 0:00:23\n",
      "     -----------------                      130.9/276.5 MB 6.3 MB/s eta 0:00:24\n",
      "     ------------------                     131.9/276.5 MB 6.0 MB/s eta 0:00:25\n",
      "     ------------------                     132.8/276.5 MB 6.0 MB/s eta 0:00:24\n",
      "     ------------------                     133.2/276.5 MB 6.0 MB/s eta 0:00:25\n",
      "     ------------------                     133.4/276.5 MB 6.0 MB/s eta 0:00:25\n",
      "     ------------------                     133.7/276.5 MB 6.0 MB/s eta 0:00:24\n",
      "     ------------------                     133.9/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     134.1/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     134.4/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     134.6/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     134.8/276.5 MB 5.7 MB/s eta 0:00:25\n",
      "     ------------------                     135.1/276.5 MB 5.7 MB/s eta 0:00:25\n",
      "     ------------------                     135.3/276.5 MB 5.7 MB/s eta 0:00:25\n",
      "     ------------------                     135.7/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     136.0/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     136.3/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     ------------------                     136.6/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     ------------------                     136.8/276.5 MB 5.8 MB/s eta 0:00:25\n",
      "     ------------------                     137.1/276.5 MB 5.7 MB/s eta 0:00:25\n",
      "     ------------------                     137.3/276.5 MB 5.6 MB/s eta 0:00:25\n",
      "     ------------------                     137.5/276.5 MB 5.6 MB/s eta 0:00:25\n",
      "     ------------------                     137.7/276.5 MB 5.6 MB/s eta 0:00:25\n",
      "     ------------------                     138.0/276.5 MB 5.6 MB/s eta 0:00:25\n",
      "     -------------------                    138.4/276.5 MB 5.7 MB/s eta 0:00:25\n",
      "     -------------------                    138.7/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    138.9/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    139.2/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    139.4/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    139.7/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    139.9/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    140.1/276.5 MB 5.6 MB/s eta 0:00:25\n",
      "     -------------------                    140.5/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    140.8/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    141.0/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    141.3/276.5 MB 5.9 MB/s eta 0:00:23\n",
      "     -------------------                    141.6/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    141.8/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    142.1/276.5 MB 6.0 MB/s eta 0:00:23\n",
      "     -------------------                    142.3/276.5 MB 6.0 MB/s eta 0:00:23\n",
      "     -------------------                    142.6/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     -------------------                    142.8/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    142.8/276.5 MB 5.8 MB/s eta 0:00:24\n",
      "     -------------------                    143.1/276.5 MB 5.6 MB/s eta 0:00:24\n",
      "     -------------------                    143.3/276.5 MB 5.6 MB/s eta 0:00:24\n",
      "     -------------------                    143.7/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    144.0/276.5 MB 5.7 MB/s eta 0:00:24\n",
      "     -------------------                    144.4/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     -------------------                    144.7/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     -------------------                    145.0/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     -------------------                    145.2/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     -------------------                    145.5/276.5 MB 6.0 MB/s eta 0:00:23\n",
      "     --------------------                   145.8/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     --------------------                   146.1/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   146.4/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   146.8/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   147.1/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     --------------------                   147.5/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     --------------------                   147.8/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     --------------------                   148.1/276.5 MB 6.0 MB/s eta 0:00:22\n",
      "     --------------------                   148.2/276.5 MB 6.0 MB/s eta 0:00:22\n",
      "     --------------------                   148.5/276.5 MB 5.8 MB/s eta 0:00:22\n",
      "     --------------------                   148.7/276.5 MB 5.8 MB/s eta 0:00:23\n",
      "     --------------------                   149.0/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   149.1/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   149.3/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   149.7/276.5 MB 5.7 MB/s eta 0:00:23\n",
      "     --------------------                   150.1/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     --------------------                   150.7/276.5 MB 6.0 MB/s eta 0:00:22\n",
      "     --------------------                   151.0/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     --------------------                   151.3/276.5 MB 6.0 MB/s eta 0:00:22\n",
      "     --------------------                   151.5/276.5 MB 5.8 MB/s eta 0:00:22\n",
      "     --------------------                   151.7/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     --------------------                   152.0/276.5 MB 5.8 MB/s eta 0:00:22\n",
      "     --------------------                   152.2/276.5 MB 5.8 MB/s eta 0:00:22\n",
      "     --------------------                   152.5/276.5 MB 5.9 MB/s eta 0:00:22\n",
      "     ---------------------                  153.0/276.5 MB 6.0 MB/s eta 0:00:21\n",
      "     ---------------------                  153.2/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  153.5/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  153.9/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  154.2/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  155.6/276.5 MB 6.1 MB/s eta 0:00:20\n",
      "     ---------------------                  155.9/276.5 MB 6.0 MB/s eta 0:00:21\n",
      "     ---------------------                  156.4/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  157.9/276.5 MB 5.9 MB/s eta 0:00:21\n",
      "     ---------------------                  158.2/276.5 MB 6.0 MB/s eta 0:00:20\n",
      "     ---------------------                  158.6/276.5 MB 6.1 MB/s eta 0:00:20\n",
      "     ---------------------                  159.0/276.5 MB 6.2 MB/s eta 0:00:20\n",
      "     ---------------------                  159.3/276.5 MB 6.2 MB/s eta 0:00:19\n",
      "     ----------------------                 160.3/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 160.8/276.5 MB 6.2 MB/s eta 0:00:19\n",
      "     ----------------------                 162.2/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 162.5/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 162.8/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 163.8/276.5 MB 6.0 MB/s eta 0:00:19\n",
      "     ----------------------                 164.2/276.5 MB 6.0 MB/s eta 0:00:19\n",
      "     ----------------------                 165.7/276.5 MB 6.0 MB/s eta 0:00:19\n",
      "     ----------------------                 166.1/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 166.3/276.5 MB 6.1 MB/s eta 0:00:19\n",
      "     ----------------------                 166.7/276.5 MB 6.1 MB/s eta 0:00:18\n",
      "     -----------------------                168.3/276.5 MB 6.0 MB/s eta 0:00:19\n",
      "     -----------------------                168.5/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                168.8/276.5 MB 5.9 MB/s eta 0:00:19\n",
      "     -----------------------                169.2/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                169.6/276.5 MB 6.0 MB/s eta 0:00:18\n",
      "     -----------------------                169.7/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                170.1/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                170.4/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                170.8/276.5 MB 5.8 MB/s eta 0:00:19\n",
      "     -----------------------                171.1/276.5 MB 5.7 MB/s eta 0:00:19\n",
      "     -----------------------                171.5/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     -----------------------                172.0/276.5 MB 6.0 MB/s eta 0:00:18\n",
      "     -----------------------                173.5/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     -----------------------                173.8/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     -----------------------                174.3/276.5 MB 6.0 MB/s eta 0:00:18\n",
      "     ------------------------               175.7/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     ------------------------               175.9/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     ------------------------               176.2/276.5 MB 5.8 MB/s eta 0:00:18\n",
      "     ------------------------               176.9/276.5 MB 5.5 MB/s eta 0:00:19\n",
      "     ------------------------               177.1/276.5 MB 5.4 MB/s eta 0:00:19\n",
      "     ------------------------               177.3/276.5 MB 5.4 MB/s eta 0:00:19\n",
      "     ------------------------               177.6/276.5 MB 5.5 MB/s eta 0:00:18\n",
      "     ------------------------               178.6/276.5 MB 5.6 MB/s eta 0:00:18\n",
      "     ------------------------               178.9/276.5 MB 5.6 MB/s eta 0:00:18\n",
      "     ------------------------               179.6/276.5 MB 5.6 MB/s eta 0:00:18\n",
      "     ------------------------               179.8/276.5 MB 5.7 MB/s eta 0:00:17\n",
      "     ------------------------               180.3/276.5 MB 5.8 MB/s eta 0:00:17\n",
      "     ------------------------               180.6/276.5 MB 5.8 MB/s eta 0:00:17\n",
      "     ------------------------               180.8/276.5 MB 5.7 MB/s eta 0:00:17\n",
      "     ------------------------               181.0/276.5 MB 5.7 MB/s eta 0:00:17\n",
      "     ------------------------               181.2/276.5 MB 5.6 MB/s eta 0:00:17\n",
      "     ------------------------               181.4/276.5 MB 5.6 MB/s eta 0:00:17\n",
      "     ------------------------               181.6/276.5 MB 5.5 MB/s eta 0:00:18\n",
      "     ------------------------               181.9/276.5 MB 5.5 MB/s eta 0:00:18\n",
      "     -------------------------              182.0/276.5 MB 5.4 MB/s eta 0:00:18\n",
      "     -------------------------              182.3/276.5 MB 5.3 MB/s eta 0:00:18\n",
      "     -------------------------              182.4/276.5 MB 5.3 MB/s eta 0:00:18\n",
      "     -------------------------              182.4/276.5 MB 5.2 MB/s eta 0:00:18\n",
      "     -------------------------              182.5/276.5 MB 5.1 MB/s eta 0:00:19\n",
      "     -------------------------              182.6/276.5 MB 5.0 MB/s eta 0:00:19\n",
      "     -------------------------              182.6/276.5 MB 4.8 MB/s eta 0:00:20\n",
      "     -------------------------              182.6/276.5 MB 4.8 MB/s eta 0:00:20\n",
      "     -------------------------              182.8/276.5 MB 4.7 MB/s eta 0:00:20\n",
      "     -------------------------              182.8/276.5 MB 4.6 MB/s eta 0:00:21\n",
      "     -------------------------              182.9/276.5 MB 4.5 MB/s eta 0:00:21\n",
      "     -------------------------              182.9/276.5 MB 4.5 MB/s eta 0:00:21\n",
      "     -------------------------              183.0/276.5 MB 4.4 MB/s eta 0:00:22\n",
      "     -------------------------              183.2/276.5 MB 4.4 MB/s eta 0:00:22\n",
      "     -------------------------              183.4/276.5 MB 4.4 MB/s eta 0:00:22\n",
      "     -------------------------              183.6/276.5 MB 4.4 MB/s eta 0:00:21\n",
      "     -------------------------              183.8/276.5 MB 4.4 MB/s eta 0:00:22\n",
      "     -------------------------              184.0/276.5 MB 4.4 MB/s eta 0:00:22\n",
      "     -------------------------              184.1/276.5 MB 4.3 MB/s eta 0:00:22\n",
      "     -------------------------              184.3/276.5 MB 4.3 MB/s eta 0:00:22\n",
      "     -------------------------              184.5/276.5 MB 4.2 MB/s eta 0:00:22\n",
      "     -------------------------              184.6/276.5 MB 4.2 MB/s eta 0:00:22\n",
      "     -------------------------              185.1/276.5 MB 4.2 MB/s eta 0:00:22\n",
      "     -------------------------              185.3/276.5 MB 4.1 MB/s eta 0:00:23\n",
      "     -------------------------              185.5/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              185.7/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              185.9/276.5 MB 4.2 MB/s eta 0:00:22\n",
      "     -------------------------              186.1/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              186.4/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              186.6/276.5 MB 4.2 MB/s eta 0:00:22\n",
      "     -------------------------              186.7/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              186.7/276.5 MB 4.1 MB/s eta 0:00:22\n",
      "     -------------------------              186.9/276.5 MB 4.0 MB/s eta 0:00:23\n",
      "     -------------------------              186.9/276.5 MB 4.0 MB/s eta 0:00:23\n",
      "     -------------------------              186.9/276.5 MB 3.9 MB/s eta 0:00:23\n",
      "     -------------------------              186.9/276.5 MB 3.9 MB/s eta 0:00:23\n",
      "     -------------------------              187.0/276.5 MB 3.9 MB/s eta 0:00:24\n",
      "     -------------------------              187.2/276.5 MB 3.8 MB/s eta 0:00:24\n",
      "     -------------------------              187.6/276.5 MB 3.9 MB/s eta 0:00:23\n",
      "     -------------------------              187.7/276.5 MB 3.8 MB/s eta 0:00:24\n",
      "     -------------------------              187.8/276.5 MB 3.7 MB/s eta 0:00:24\n",
      "     -------------------------              187.8/276.5 MB 3.7 MB/s eta 0:00:24\n",
      "     -------------------------              188.1/276.5 MB 3.7 MB/s eta 0:00:25\n",
      "     -------------------------              188.3/276.5 MB 3.7 MB/s eta 0:00:25\n",
      "     -------------------------              188.4/276.5 MB 3.6 MB/s eta 0:00:25\n",
      "     -------------------------              188.5/276.5 MB 3.6 MB/s eta 0:00:25\n",
      "     -------------------------              189.1/276.5 MB 3.5 MB/s eta 0:00:25\n",
      "     --------------------------             189.2/276.5 MB 3.5 MB/s eta 0:00:25\n",
      "     --------------------------             189.2/276.5 MB 3.5 MB/s eta 0:00:26\n",
      "     --------------------------             189.3/276.5 MB 3.4 MB/s eta 0:00:26\n",
      "     --------------------------             189.4/276.5 MB 3.4 MB/s eta 0:00:26\n",
      "     --------------------------             189.5/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "     --------------------------             189.7/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "     --------------------------             189.8/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             190.0/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "     --------------------------             190.0/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "     --------------------------             190.3/276.5 MB 3.2 MB/s eta 0:00:27\n",
      "     --------------------------             190.4/276.5 MB 3.2 MB/s eta 0:00:28\n",
      "     --------------------------             190.4/276.5 MB 3.1 MB/s eta 0:00:28\n",
      "     --------------------------             190.5/276.5 MB 3.1 MB/s eta 0:00:28\n",
      "     --------------------------             190.7/276.5 MB 3.1 MB/s eta 0:00:28\n",
      "     --------------------------             190.8/276.5 MB 3.1 MB/s eta 0:00:29\n",
      "     --------------------------             190.9/276.5 MB 3.0 MB/s eta 0:00:29\n",
      "     --------------------------             191.1/276.5 MB 3.0 MB/s eta 0:00:29\n",
      "     --------------------------             191.2/276.5 MB 3.0 MB/s eta 0:00:29\n",
      "     --------------------------             191.3/276.5 MB 3.0 MB/s eta 0:00:29\n",
      "     --------------------------             191.7/276.5 MB 3.0 MB/s eta 0:00:29\n",
      "     --------------------------             192.8/276.5 MB 3.2 MB/s eta 0:00:27\n",
      "     --------------------------             193.0/276.5 MB 3.2 MB/s eta 0:00:27\n",
      "     --------------------------             193.2/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             193.5/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             193.8/276.5 MB 3.4 MB/s eta 0:00:25\n",
      "     --------------------------             193.9/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             193.9/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             194.1/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             194.3/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             194.5/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "     --------------------------             194.7/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.0/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.2/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.5/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.7/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.8/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             195.9/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             196.2/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             196.3/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     --------------------------             196.3/276.5 MB 3.2 MB/s eta 0:00:25\n",
      "     ---------------------------            196.8/276.5 MB 3.3 MB/s eta 0:00:25\n",
      "     ---------------------------            197.2/276.5 MB 3.4 MB/s eta 0:00:24\n",
      "     ---------------------------            197.9/276.5 MB 3.5 MB/s eta 0:00:23\n",
      "     ---------------------------            198.2/276.5 MB 3.6 MB/s eta 0:00:22\n",
      "     ---------------------------            198.6/276.5 MB 3.7 MB/s eta 0:00:21\n",
      "     ---------------------------            199.0/276.5 MB 3.8 MB/s eta 0:00:21\n",
      "     ---------------------------            200.5/276.5 MB 4.2 MB/s eta 0:00:19\n",
      "     ---------------------------            200.9/276.5 MB 4.4 MB/s eta 0:00:18\n",
      "     ---------------------------            201.0/276.5 MB 4.5 MB/s eta 0:00:17\n",
      "     ---------------------------            201.3/276.5 MB 4.5 MB/s eta 0:00:17\n",
      "     ---------------------------            201.6/276.5 MB 4.8 MB/s eta 0:00:16\n",
      "     ---------------------------            201.9/276.5 MB 4.7 MB/s eta 0:00:16\n",
      "     ---------------------------            202.2/276.5 MB 4.8 MB/s eta 0:00:16\n",
      "     ---------------------------            202.4/276.5 MB 4.7 MB/s eta 0:00:16\n",
      "     ---------------------------            202.7/276.5 MB 4.8 MB/s eta 0:00:16\n",
      "     ---------------------------            203.0/276.5 MB 4.8 MB/s eta 0:00:16\n",
      "     ---------------------------            203.2/276.5 MB 4.9 MB/s eta 0:00:15\n",
      "     ---------------------------            203.5/276.5 MB 5.0 MB/s eta 0:00:15\n",
      "     ----------------------------           203.8/276.5 MB 5.0 MB/s eta 0:00:15\n",
      "     ----------------------------           204.2/276.5 MB 5.2 MB/s eta 0:00:14\n",
      "     ----------------------------           205.8/276.5 MB 5.4 MB/s eta 0:00:14\n",
      "     ----------------------------           206.1/276.5 MB 5.6 MB/s eta 0:00:13\n",
      "     ----------------------------           206.5/276.5 MB 5.7 MB/s eta 0:00:13\n",
      "     ----------------------------           206.7/276.5 MB 5.8 MB/s eta 0:00:12\n",
      "     ----------------------------           207.0/276.5 MB 5.8 MB/s eta 0:00:12\n",
      "     ----------------------------           207.2/276.5 MB 5.8 MB/s eta 0:00:12\n",
      "     ----------------------------           207.4/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           207.7/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           207.9/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           208.2/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           208.6/276.5 MB 5.8 MB/s eta 0:00:12\n",
      "     ----------------------------           208.9/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           209.2/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     ----------------------------           209.4/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     ----------------------------           209.6/276.5 MB 5.9 MB/s eta 0:00:12\n",
      "     ----------------------------           209.9/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     ----------------------------           210.1/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     ----------------------------           210.4/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     ----------------------------           210.6/276.5 MB 6.0 MB/s eta 0:00:11\n",
      "     ----------------------------           210.9/276.5 MB 6.0 MB/s eta 0:00:12\n",
      "     -----------------------------          211.4/276.5 MB 6.1 MB/s eta 0:00:11\n",
      "     -----------------------------          211.7/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          212.0/276.5 MB 6.1 MB/s eta 0:00:11\n",
      "     -----------------------------          212.2/276.5 MB 6.1 MB/s eta 0:00:11\n",
      "     -----------------------------          212.5/276.5 MB 6.1 MB/s eta 0:00:11\n",
      "     -----------------------------          212.9/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          213.2/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          213.6/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          213.8/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          214.1/276.5 MB 6.2 MB/s eta 0:00:11\n",
      "     -----------------------------          214.4/276.5 MB 6.1 MB/s eta 0:00:11\n",
      "     -----------------------------          214.7/276.5 MB 6.2 MB/s eta 0:00:10\n",
      "     -----------------------------          215.1/276.5 MB 6.2 MB/s eta 0:00:10\n",
      "     -----------------------------          215.3/276.5 MB 6.3 MB/s eta 0:00:10\n",
      "     -----------------------------          215.6/276.5 MB 6.3 MB/s eta 0:00:10\n",
      "     -----------------------------          215.9/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          216.2/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          216.5/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          216.8/276.5 MB 6.3 MB/s eta 0:00:10\n",
      "     -----------------------------          217.1/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          217.4/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          217.7/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     -----------------------------          218.0/276.5 MB 6.5 MB/s eta 0:00:10\n",
      "     ------------------------------         218.3/276.5 MB 6.5 MB/s eta 0:00:09\n",
      "     ------------------------------         218.6/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     ------------------------------         218.8/276.5 MB 6.4 MB/s eta 0:00:09\n",
      "     ------------------------------         219.1/276.5 MB 6.4 MB/s eta 0:00:10\n",
      "     ------------------------------         219.4/276.5 MB 6.2 MB/s eta 0:00:10\n",
      "     ------------------------------         219.8/276.5 MB 6.4 MB/s eta 0:00:09\n",
      "     ------------------------------         220.1/276.5 MB 6.5 MB/s eta 0:00:09\n",
      "     ------------------------------         220.4/276.5 MB 6.5 MB/s eta 0:00:09\n",
      "     ------------------------------         220.7/276.5 MB 6.5 MB/s eta 0:00:09\n",
      "     ------------------------------         222.1/276.5 MB 6.2 MB/s eta 0:00:09\n",
      "     ------------------------------         223.4/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         223.8/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         224.2/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         224.5/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         224.8/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         225.0/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     ------------------------------         225.4/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     -------------------------------        225.7/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     -------------------------------        225.9/276.5 MB 5.9 MB/s eta 0:00:09\n",
      "     -------------------------------        226.2/276.5 MB 6.0 MB/s eta 0:00:09\n",
      "     -------------------------------        227.8/276.5 MB 5.7 MB/s eta 0:00:09\n",
      "     -------------------------------        228.2/276.5 MB 5.7 MB/s eta 0:00:09\n",
      "     -------------------------------        228.5/276.5 MB 5.7 MB/s eta 0:00:09\n",
      "     -------------------------------        228.8/276.5 MB 5.8 MB/s eta 0:00:09\n",
      "     -------------------------------        229.0/276.5 MB 5.8 MB/s eta 0:00:09\n",
      "     -------------------------------        230.7/276.5 MB 5.5 MB/s eta 0:00:09\n",
      "     -------------------------------        231.1/276.5 MB 5.6 MB/s eta 0:00:09\n",
      "     -------------------------------        231.4/276.5 MB 5.6 MB/s eta 0:00:08\n",
      "     -------------------------------        231.8/276.5 MB 5.7 MB/s eta 0:00:08\n",
      "     -------------------------------        232.2/276.5 MB 5.8 MB/s eta 0:00:08\n",
      "     -------------------------------        232.4/276.5 MB 5.8 MB/s eta 0:00:08\n",
      "     -------------------------------        232.7/276.5 MB 5.8 MB/s eta 0:00:08\n",
      "     --------------------------------       233.7/276.5 MB 6.0 MB/s eta 0:00:08\n",
      "     --------------------------------       233.9/276.5 MB 5.9 MB/s eta 0:00:08\n",
      "     --------------------------------       234.3/276.5 MB 6.0 MB/s eta 0:00:08\n",
      "     --------------------------------       234.6/276.5 MB 5.9 MB/s eta 0:00:08\n",
      "     --------------------------------       234.9/276.5 MB 5.9 MB/s eta 0:00:08\n",
      "     --------------------------------       235.3/276.5 MB 5.9 MB/s eta 0:00:07\n",
      "     --------------------------------       235.6/276.5 MB 6.0 MB/s eta 0:00:07\n",
      "     --------------------------------       235.8/276.5 MB 5.9 MB/s eta 0:00:07\n",
      "     --------------------------------       237.5/276.5 MB 5.9 MB/s eta 0:00:07\n",
      "     --------------------------------       238.0/276.5 MB 6.0 MB/s eta 0:00:07\n",
      "     --------------------------------       239.6/276.5 MB 5.8 MB/s eta 0:00:07\n",
      "     --------------------------------       239.8/276.5 MB 5.8 MB/s eta 0:00:07\n",
      "     ---------------------------------      240.3/276.5 MB 5.8 MB/s eta 0:00:07\n",
      "     ---------------------------------      240.5/276.5 MB 5.9 MB/s eta 0:00:07\n",
      "     ---------------------------------      240.9/276.5 MB 6.0 MB/s eta 0:00:06\n",
      "     ---------------------------------      241.3/276.5 MB 6.0 MB/s eta 0:00:06\n",
      "     ---------------------------------      241.6/276.5 MB 5.9 MB/s eta 0:00:06\n",
      "     ---------------------------------      241.8/276.5 MB 5.8 MB/s eta 0:00:06\n",
      "     ---------------------------------      242.2/276.5 MB 5.8 MB/s eta 0:00:06\n",
      "     ---------------------------------      242.6/276.5 MB 5.8 MB/s eta 0:00:06\n",
      "     ---------------------------------      244.2/276.5 MB 5.7 MB/s eta 0:00:06\n",
      "     ---------------------------------      244.7/276.5 MB 5.8 MB/s eta 0:00:06\n",
      "     ---------------------------------      246.8/276.5 MB 5.7 MB/s eta 0:00:06\n",
      "     ---------------------------------      247.0/276.5 MB 5.7 MB/s eta 0:00:06\n",
      "     ----------------------------------     247.4/276.5 MB 5.8 MB/s eta 0:00:05\n",
      "     ----------------------------------     247.9/276.5 MB 5.9 MB/s eta 0:00:05\n",
      "     ----------------------------------     249.5/276.5 MB 5.9 MB/s eta 0:00:05\n",
      "     ----------------------------------     249.8/276.5 MB 5.9 MB/s eta 0:00:05\n",
      "     ----------------------------------     250.1/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     250.4/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     250.6/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     250.8/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     251.1/276.5 MB 5.9 MB/s eta 0:00:05\n",
      "     ----------------------------------     251.4/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     251.6/276.5 MB 5.9 MB/s eta 0:00:05\n",
      "     ----------------------------------     252.3/276.5 MB 6.0 MB/s eta 0:00:05\n",
      "     ----------------------------------     252.6/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     ----------------------------------     253.0/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     ----------------------------------     253.2/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     ----------------------------------     253.6/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     ----------------------------------     253.8/276.5 MB 6.1 MB/s eta 0:00:04\n",
      "     -----------------------------------    255.3/276.5 MB 5.9 MB/s eta 0:00:04\n",
      "     -----------------------------------    255.7/276.5 MB 5.8 MB/s eta 0:00:04\n",
      "     -----------------------------------    255.9/276.5 MB 5.8 MB/s eta 0:00:04\n",
      "     -----------------------------------    256.0/276.5 MB 5.8 MB/s eta 0:00:04\n",
      "     -----------------------------------    256.6/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     -----------------------------------    256.9/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     -----------------------------------    257.2/276.5 MB 6.1 MB/s eta 0:00:04\n",
      "     -----------------------------------    257.4/276.5 MB 6.0 MB/s eta 0:00:04\n",
      "     -----------------------------------    258.8/276.5 MB 5.8 MB/s eta 0:00:04\n",
      "     -----------------------------------    259.2/276.5 MB 5.7 MB/s eta 0:00:04\n",
      "     -----------------------------------    259.6/276.5 MB 5.8 MB/s eta 0:00:03\n",
      "     -----------------------------------    260.0/276.5 MB 5.9 MB/s eta 0:00:03\n",
      "     -----------------------------------    260.2/276.5 MB 5.8 MB/s eta 0:00:03\n",
      "     -----------------------------------    260.4/276.5 MB 5.8 MB/s eta 0:00:03\n",
      "     -----------------------------------    260.6/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    260.8/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    261.0/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    261.2/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    261.4/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     -----------------------------------    261.6/276.5 MB 5.6 MB/s eta 0:00:03\n",
      "     -----------------------------------    261.9/276.5 MB 5.7 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.2/276.5 MB 5.6 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.4/276.5 MB 5.6 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.6/276.5 MB 5.6 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.6/276.5 MB 5.5 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.7/276.5 MB 5.4 MB/s eta 0:00:03\n",
      "     ------------------------------------   262.9/276.5 MB 5.3 MB/s eta 0:00:03\n",
      "     ------------------------------------   263.2/276.5 MB 5.3 MB/s eta 0:00:03\n",
      "     ------------------------------------   263.2/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   263.5/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   263.7/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   264.0/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   264.2/276.5 MB 5.1 MB/s eta 0:00:03\n",
      "     ------------------------------------   264.5/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   264.8/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   265.0/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   265.2/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   265.5/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   265.8/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   265.9/276.5 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------------------------------   266.6/276.5 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------------   266.7/276.5 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------------   267.4/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------------------   267.8/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------------------   268.0/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------------------   269.1/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------------------  269.5/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------------------  269.6/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------------------  269.9/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------------------  270.2/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------------------  270.3/276.5 MB 4.7 MB/s eta 0:00:02\n",
      "     -------------------------------------  271.0/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------------------  271.2/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------------------  271.5/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------------------  271.8/276.5 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.0/276.5 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.3/276.5 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.6/276.5 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  272.9/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  274.3/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  274.6/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  274.8/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  275.1/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  275.4/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  275.8/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.0/276.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  276.5/276.5 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 276.5/276.5 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.54.2)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "                                              0.0/5.6 MB ? eta -:--:--\n",
      "                                              0.1/5.6 MB 2.4 MB/s eta 0:00:03\n",
      "     --                                       0.4/5.6 MB 3.5 MB/s eta 0:00:02\n",
      "     ----                                     0.6/5.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------                                   0.9/5.6 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------                                1.3/5.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------                               1.5/5.6 MB 4.1 MB/s eta 0:00:02\n",
      "     -----------------                        2.5/5.6 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------                      2.7/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------                    3.0/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "     -----------------------                  3.3/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "     --------------------------               3.7/5.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ---------------------------              3.8/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "     -----------------------------            4.1/5.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------           4.2/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "     --------------------------------         4.5/5.6 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        4.6/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      4.9/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      5.0/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    5.2/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.5/5.6 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 4.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "                                              0.0/440.8 kB ? eta -:--:--\n",
      "     --------------------                   235.5/440.8 kB 7.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  440.3/440.8 kB 4.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 440.8/440.8 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "     -----                                    0.2/1.7 MB 7.6 MB/s eta 0:00:01\n",
      "     ------------                             0.5/1.7 MB 5.7 MB/s eta 0:00:01\n",
      "     ------------------------------           1.3/1.7 MB 5.1 MB/s eta 0:00:01\n",
      "     -----------------------------------      1.5/1.7 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.12.0\n",
      "    Uninstalling tensorflow-intel-2.12.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.12.0\n",
      "5838.pt\n",
      "5839.pt\n",
      "5840.pt\n",
      "5841.pt\n",
      "5842.pt\n",
      "5843.pt\n",
      "5844.pt\n",
      "5845.pt\n",
      "5846.pt\n",
      "5847.pt\n",
      "5848.pt\n",
      "5849.pt\n",
      "5850.pt\n",
      "5851.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\Lib\\\\site-packages\\\\~ensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5852.pt\n",
      "5853.pt\n",
      "5854.pt\n",
      "5855.pt\n",
      "5856.pt\n",
      "5857.pt\n",
      "5858.pt\n",
      "5859.pt\n",
      "5860.pt\n",
      "5861.pt\n",
      "5862.pt\n",
      "5863.pt\n",
      "5864.pt\n",
      "5865.pt\n",
      "5866.pt\n",
      "5867.pt\n",
      "5868.pt\n",
      "5869.pt\n",
      "5870.pt\n",
      "5871.pt\n",
      "5872.pt\n",
      "5873.pt\n",
      "5874.pt\n",
      "5875.pt\n",
      "5876.pt\n",
      "5877.pt\n",
      "5878.pt\n",
      "5879.pt\n",
      "5880.pt\n",
      "5881.pt\n",
      "5882.pt\n",
      "5883.pt\n",
      "5884.pt\n",
      "5885.pt\n",
      "5886.pt\n",
      "5887.pt\n",
      "5888.pt\n",
      "5889.pt\n",
      "5890.pt\n",
      "5891.pt\n",
      "5892.pt\n",
      "5893.pt\n",
      "5894.pt\n",
      "5895.pt\n",
      "5896.pt\n",
      "5897.pt\n",
      "5898.pt\n",
      "5899.pt\n",
      "5900.pt\n",
      "5901.pt\n",
      "5902.pt\n",
      "5903.pt\n",
      "5904.pt\n",
      "5905.pt\n",
      "5906.pt\n",
      "5907.pt\n",
      "5908.pt\n",
      "5909.pt\n",
      "5910.pt\n",
      "5911.pt\n",
      "5912.pt\n",
      "5913.pt\n",
      "5914.pt\n",
      "5915.pt\n",
      "5916.pt\n",
      "5917.pt\n",
      "5918.pt\n",
      "5919.pt\n",
      "5920.pt\n",
      "5921.pt\n",
      "5922.pt\n",
      "5923.pt\n",
      "5924.pt\n",
      "5925.pt\n",
      "5926.pt\n",
      "5927.pt\n",
      "5928.pt\n",
      "5929.pt\n",
      "5930.pt\n",
      "5931.pt\n",
      "5932.pt\n",
      "5933.pt\n",
      "5934.pt\n",
      "5935.pt\n",
      "5936.pt\n",
      "5937.pt\n",
      "5938.pt\n",
      "5939.pt\n",
      "5940.pt\n",
      "5941.pt\n",
      "5942.pt\n",
      "5943.pt\n",
      "5944.pt\n",
      "5945.pt\n",
      "5946.pt\n",
      "5947.pt\n",
      "5948.pt\n",
      "5949.pt\n",
      "5950.pt\n",
      "5951.pt\n",
      "5952.pt\n",
      "5953.pt\n",
      "5954.pt\n",
      "5955.pt\n",
      "5956.pt\n",
      "5957.pt\n",
      "5958.pt\n",
      "5959.pt\n",
      "5960.pt\n",
      "5961.pt\n",
      "5962.pt\n",
      "5963.pt\n",
      "5964.pt\n",
      "5965.pt\n",
      "5966.pt\n",
      "5967.pt\n",
      "5968.pt\n",
      "5969.pt\n",
      "5970.pt\n",
      "5971.pt\n",
      "5972.pt\n",
      "5973.pt\n",
      "5974.pt\n",
      "5975.pt\n",
      "5976.pt\n",
      "5977.pt\n",
      "5978.pt\n",
      "5979.pt\n",
      "5980.pt\n",
      "5981.pt\n",
      "5982.pt\n",
      "5983.pt\n",
      "5984.pt\n",
      "5985.pt\n",
      "5986.pt\n",
      "5987.pt\n",
      "5988.pt\n",
      "5989.pt\n",
      "5990.pt\n",
      "5991.pt\n",
      "5992.pt\n",
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"attention\" (type Attention).\n\nAttention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: Tensor(\"Placeholder:0\", shape=(None, 64), dtype=float32).\n\nCall arguments received by layer \"attention\" (type Attention):\n   inputs=tf.Tensor(shape=(None, 64), dtype=float32)\n   mask=None\n   training=None\n   return_attention_scores=False\n   use_causal_mask=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> 41\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[0;32m     42\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n\u001b[0;32m     43\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[46], line 36\u001b[0m, in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     35\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> 36\u001b[0m model\u001b[39m.\u001b[39;49madd(Attention())\n\u001b[0;32m     37\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     38\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m try:\n\u001b[0;32m    204\u001b[0m   result = method(self, *args, **kwargs)\n\u001b[1;32m--> 205\u001b[0m finally:\n\u001b[0;32m    206\u001b[0m   self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n\u001b[0;32m    207\u001b[0m return result\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\attention\\base_dense_attention.py:215\u001b[0m, in \u001b[0;36m_validate_call_args\u001b[1;34m(self, inputs, mask)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"attention\" (type Attention).\n\nAttention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: Tensor(\"Placeholder:0\", shape=(None, 64), dtype=float32).\n\nCall arguments received by layer \"attention\" (type Attention):\n   inputs=tf.Tensor(shape=(None, 64), dtype=float32)\n   mask=None\n   training=None\n   return_attention_scores=False\n   use_causal_mask=False"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense, Attention, GlobalAveragePooling1D\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        print(filename)\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(GlobalAveragePooling1D(input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Attention())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pt\n",
      "1.pt\n",
      "2.pt\n",
      "3.pt\n",
      "4.pt\n",
      "5.pt\n",
      "6.pt\n",
      "7.pt\n",
      "8.pt\n",
      "9.pt\n",
      "10.pt\n",
      "11.pt\n",
      "12.pt\n",
      "13.pt\n",
      "14.pt\n",
      "15.pt\n",
      "16.pt\n",
      "17.pt\n",
      "18.pt\n",
      "19.pt\n",
      "20.pt\n",
      "21.pt\n",
      "22.pt\n",
      "23.pt\n",
      "24.pt\n",
      "25.pt\n",
      "26.pt\n",
      "27.pt\n",
      "28.pt\n",
      "29.pt\n",
      "30.pt\n",
      "31.pt\n",
      "32.pt\n",
      "33.pt\n",
      "34.pt\n",
      "35.pt\n",
      "36.pt\n",
      "37.pt\n",
      "38.pt\n",
      "39.pt\n",
      "40.pt\n",
      "41.pt\n",
      "42.pt\n",
      "43.pt\n",
      "44.pt\n",
      "45.pt\n",
      "46.pt\n",
      "47.pt\n",
      "48.pt\n",
      "49.pt\n",
      "50.pt\n",
      "51.pt\n",
      "52.pt\n",
      "53.pt\n",
      "54.pt\n",
      "55.pt\n",
      "56.pt\n",
      "57.pt\n",
      "58.pt\n",
      "59.pt\n",
      "60.pt\n",
      "61.pt\n",
      "62.pt\n",
      "63.pt\n",
      "64.pt\n",
      "65.pt\n",
      "66.pt\n",
      "67.pt\n",
      "68.pt\n",
      "69.pt\n",
      "70.pt\n",
      "71.pt\n",
      "72.pt\n",
      "73.pt\n",
      "74.pt\n",
      "75.pt\n",
      "76.pt\n",
      "77.pt\n",
      "78.pt\n",
      "79.pt\n",
      "80.pt\n",
      "81.pt\n",
      "82.pt\n",
      "83.pt\n",
      "84.pt\n",
      "85.pt\n",
      "86.pt\n",
      "87.pt\n",
      "88.pt\n",
      "89.pt\n",
      "90.pt\n",
      "91.pt\n",
      "92.pt\n",
      "93.pt\n",
      "94.pt\n",
      "95.pt\n",
      "96.pt\n",
      "97.pt\n",
      "98.pt\n",
      "99.pt\n",
      "100.pt\n",
      "101.pt\n",
      "102.pt\n",
      "103.pt\n",
      "104.pt\n",
      "105.pt\n",
      "106.pt\n",
      "107.pt\n",
      "108.pt\n",
      "109.pt\n",
      "110.pt\n",
      "111.pt\n",
      "112.pt\n",
      "113.pt\n",
      "114.pt\n",
      "115.pt\n",
      "116.pt\n",
      "117.pt\n",
      "118.pt\n",
      "119.pt\n",
      "120.pt\n",
      "121.pt\n",
      "122.pt\n",
      "123.pt\n",
      "124.pt\n",
      "125.pt\n",
      "126.pt\n",
      "127.pt\n",
      "128.pt\n",
      "129.pt\n",
      "130.pt\n",
      "131.pt\n",
      "132.pt\n",
      "133.pt\n",
      "134.pt\n",
      "135.pt\n",
      "136.pt\n",
      "137.pt\n",
      "138.pt\n",
      "139.pt\n",
      "140.pt\n",
      "141.pt\n",
      "142.pt\n",
      "143.pt\n",
      "144.pt\n",
      "145.pt\n",
      "146.pt\n",
      "147.pt\n",
      "148.pt\n",
      "149.pt\n",
      "150.pt\n",
      "151.pt\n",
      "152.pt\n",
      "153.pt\n",
      "154.pt\n",
      "155.pt\n",
      "156.pt\n",
      "157.pt\n",
      "158.pt\n",
      "159.pt\n",
      "160.pt\n",
      "161.pt\n",
      "162.pt\n",
      "163.pt\n",
      "164.pt\n",
      "165.pt\n",
      "166.pt\n",
      "167.pt\n",
      "168.pt\n",
      "169.pt\n",
      "170.pt\n",
      "171.pt\n",
      "172.pt\n",
      "173.pt\n",
      "174.pt\n",
      "175.pt\n",
      "176.pt\n",
      "177.pt\n",
      "178.pt\n",
      "179.pt\n",
      "180.pt\n",
      "181.pt\n",
      "182.pt\n",
      "183.pt\n",
      "184.pt\n",
      "185.pt\n",
      "186.pt\n",
      "187.pt\n",
      "188.pt\n",
      "189.pt\n",
      "190.pt\n",
      "191.pt\n",
      "192.pt\n",
      "193.pt\n",
      "194.pt\n",
      "195.pt\n",
      "196.pt\n",
      "197.pt\n",
      "198.pt\n",
      "199.pt\n",
      "200.pt\n",
      "201.pt\n",
      "202.pt\n",
      "203.pt\n",
      "204.pt\n",
      "205.pt\n",
      "206.pt\n",
      "207.pt\n",
      "208.pt\n",
      "209.pt\n",
      "210.pt\n",
      "211.pt\n",
      "212.pt\n",
      "213.pt\n",
      "214.pt\n",
      "215.pt\n",
      "216.pt\n",
      "217.pt\n",
      "218.pt\n",
      "219.pt\n",
      "220.pt\n",
      "221.pt\n",
      "222.pt\n",
      "223.pt\n",
      "224.pt\n",
      "225.pt\n",
      "226.pt\n",
      "227.pt\n",
      "228.pt\n",
      "229.pt\n",
      "230.pt\n",
      "231.pt\n",
      "232.pt\n",
      "233.pt\n",
      "234.pt\n",
      "235.pt\n",
      "236.pt\n",
      "237.pt\n",
      "238.pt\n",
      "239.pt\n",
      "240.pt\n",
      "241.pt\n",
      "242.pt\n",
      "243.pt\n",
      "244.pt\n",
      "245.pt\n",
      "246.pt\n",
      "247.pt\n",
      "248.pt\n",
      "249.pt\n",
      "250.pt\n",
      "251.pt\n",
      "252.pt\n",
      "253.pt\n",
      "254.pt\n",
      "255.pt\n",
      "256.pt\n",
      "257.pt\n",
      "258.pt\n",
      "259.pt\n",
      "260.pt\n",
      "261.pt\n",
      "262.pt\n",
      "263.pt\n",
      "264.pt\n",
      "265.pt\n",
      "266.pt\n",
      "267.pt\n",
      "268.pt\n",
      "269.pt\n",
      "270.pt\n",
      "271.pt\n",
      "272.pt\n",
      "273.pt\n",
      "274.pt\n",
      "275.pt\n",
      "276.pt\n",
      "277.pt\n",
      "278.pt\n",
      "279.pt\n",
      "280.pt\n",
      "281.pt\n",
      "282.pt\n",
      "283.pt\n",
      "284.pt\n",
      "285.pt\n",
      "286.pt\n",
      "287.pt\n",
      "288.pt\n",
      "289.pt\n",
      "290.pt\n",
      "291.pt\n",
      "292.pt\n",
      "293.pt\n",
      "294.pt\n",
      "295.pt\n",
      "296.pt\n",
      "297.pt\n",
      "298.pt\n",
      "299.pt\n",
      "300.pt\n",
      "301.pt\n",
      "302.pt\n",
      "303.pt\n",
      "304.pt\n",
      "305.pt\n",
      "306.pt\n",
      "307.pt\n",
      "308.pt\n",
      "309.pt\n",
      "310.pt\n",
      "311.pt\n",
      "312.pt\n",
      "313.pt\n",
      "314.pt\n",
      "315.pt\n",
      "316.pt\n",
      "317.pt\n",
      "318.pt\n",
      "319.pt\n",
      "320.pt\n",
      "321.pt\n",
      "322.pt\n",
      "323.pt\n",
      "324.pt\n",
      "325.pt\n",
      "326.pt\n",
      "327.pt\n",
      "328.pt\n",
      "329.pt\n",
      "330.pt\n",
      "331.pt\n",
      "332.pt\n",
      "333.pt\n",
      "334.pt\n",
      "335.pt\n",
      "336.pt\n",
      "337.pt\n",
      "338.pt\n",
      "339.pt\n",
      "340.pt\n",
      "341.pt\n",
      "342.pt\n",
      "343.pt\n",
      "344.pt\n",
      "345.pt\n",
      "346.pt\n",
      "347.pt\n",
      "348.pt\n",
      "349.pt\n",
      "350.pt\n",
      "351.pt\n",
      "352.pt\n",
      "353.pt\n",
      "354.pt\n",
      "355.pt\n",
      "356.pt\n",
      "357.pt\n",
      "358.pt\n",
      "359.pt\n",
      "360.pt\n",
      "361.pt\n",
      "362.pt\n",
      "363.pt\n",
      "364.pt\n",
      "365.pt\n",
      "366.pt\n",
      "367.pt\n",
      "368.pt\n",
      "369.pt\n",
      "370.pt\n",
      "371.pt\n",
      "372.pt\n",
      "373.pt\n",
      "374.pt\n",
      "375.pt\n",
      "376.pt\n",
      "377.pt\n",
      "378.pt\n",
      "379.pt\n",
      "380.pt\n",
      "381.pt\n",
      "382.pt\n",
      "383.pt\n",
      "384.pt\n",
      "385.pt\n",
      "386.pt\n",
      "387.pt\n",
      "388.pt\n",
      "389.pt\n",
      "390.pt\n",
      "391.pt\n",
      "392.pt\n",
      "393.pt\n",
      "394.pt\n",
      "395.pt\n",
      "396.pt\n",
      "397.pt\n",
      "398.pt\n",
      "399.pt\n",
      "400.pt\n",
      "401.pt\n",
      "402.pt\n",
      "403.pt\n",
      "404.pt\n",
      "405.pt\n",
      "406.pt\n",
      "407.pt\n",
      "408.pt\n",
      "409.pt\n",
      "410.pt\n",
      "411.pt\n",
      "412.pt\n",
      "413.pt\n",
      "414.pt\n",
      "415.pt\n",
      "416.pt\n",
      "417.pt\n",
      "418.pt\n",
      "419.pt\n",
      "420.pt\n",
      "421.pt\n",
      "422.pt\n",
      "423.pt\n",
      "424.pt\n",
      "425.pt\n",
      "426.pt\n",
      "427.pt\n",
      "428.pt\n",
      "429.pt\n",
      "430.pt\n",
      "431.pt\n",
      "432.pt\n",
      "433.pt\n",
      "434.pt\n",
      "435.pt\n",
      "436.pt\n",
      "437.pt\n",
      "438.pt\n",
      "439.pt\n",
      "440.pt\n",
      "441.pt\n",
      "442.pt\n",
      "443.pt\n",
      "444.pt\n",
      "445.pt\n",
      "446.pt\n",
      "447.pt\n",
      "448.pt\n",
      "449.pt\n",
      "450.pt\n",
      "451.pt\n",
      "452.pt\n",
      "453.pt\n",
      "454.pt\n",
      "455.pt\n",
      "456.pt\n",
      "457.pt\n",
      "458.pt\n",
      "459.pt\n",
      "460.pt\n",
      "461.pt\n",
      "462.pt\n",
      "463.pt\n",
      "464.pt\n",
      "465.pt\n",
      "466.pt\n",
      "467.pt\n",
      "468.pt\n",
      "469.pt\n",
      "470.pt\n",
      "471.pt\n",
      "472.pt\n",
      "473.pt\n",
      "474.pt\n",
      "475.pt\n",
      "476.pt\n",
      "477.pt\n",
      "478.pt\n",
      "479.pt\n",
      "480.pt\n",
      "481.pt\n",
      "482.pt\n",
      "483.pt\n",
      "484.pt\n",
      "485.pt\n",
      "486.pt\n",
      "487.pt\n",
      "488.pt\n",
      "489.pt\n",
      "490.pt\n",
      "491.pt\n",
      "492.pt\n",
      "493.pt\n",
      "494.pt\n",
      "495.pt\n",
      "496.pt\n",
      "497.pt\n",
      "498.pt\n",
      "499.pt\n",
      "500.pt\n",
      "501.pt\n",
      "502.pt\n",
      "503.pt\n",
      "504.pt\n",
      "505.pt\n",
      "506.pt\n",
      "507.pt\n",
      "508.pt\n",
      "509.pt\n",
      "510.pt\n",
      "511.pt\n",
      "512.pt\n",
      "513.pt\n",
      "514.pt\n",
      "515.pt\n",
      "516.pt\n",
      "517.pt\n",
      "518.pt\n",
      "519.pt\n",
      "520.pt\n",
      "521.pt\n",
      "522.pt\n",
      "523.pt\n",
      "524.pt\n",
      "525.pt\n",
      "526.pt\n",
      "527.pt\n",
      "528.pt\n",
      "529.pt\n",
      "530.pt\n",
      "531.pt\n",
      "532.pt\n",
      "533.pt\n",
      "534.pt\n",
      "535.pt\n",
      "536.pt\n",
      "537.pt\n",
      "538.pt\n",
      "539.pt\n",
      "540.pt\n",
      "541.pt\n",
      "542.pt\n",
      "543.pt\n",
      "544.pt\n",
      "545.pt\n",
      "546.pt\n",
      "547.pt\n",
      "548.pt\n",
      "549.pt\n",
      "550.pt\n",
      "551.pt\n",
      "552.pt\n",
      "553.pt\n",
      "554.pt\n",
      "555.pt\n",
      "556.pt\n",
      "557.pt\n",
      "558.pt\n",
      "559.pt\n",
      "560.pt\n",
      "561.pt\n",
      "562.pt\n",
      "563.pt\n",
      "564.pt\n",
      "565.pt\n",
      "566.pt\n",
      "567.pt\n",
      "568.pt\n",
      "569.pt\n",
      "570.pt\n",
      "571.pt\n",
      "572.pt\n",
      "573.pt\n",
      "574.pt\n",
      "575.pt\n",
      "576.pt\n",
      "577.pt\n",
      "578.pt\n",
      "579.pt\n",
      "580.pt\n",
      "581.pt\n",
      "582.pt\n",
      "583.pt\n",
      "584.pt\n",
      "585.pt\n",
      "586.pt\n",
      "587.pt\n",
      "588.pt\n",
      "589.pt\n",
      "590.pt\n",
      "591.pt\n",
      "592.pt\n",
      "593.pt\n",
      "594.pt\n",
      "595.pt\n",
      "596.pt\n",
      "597.pt\n",
      "598.pt\n",
      "599.pt\n",
      "600.pt\n",
      "601.pt\n",
      "602.pt\n",
      "603.pt\n",
      "604.pt\n",
      "605.pt\n",
      "606.pt\n",
      "607.pt\n",
      "608.pt\n",
      "609.pt\n",
      "610.pt\n",
      "611.pt\n",
      "612.pt\n",
      "613.pt\n",
      "614.pt\n",
      "615.pt\n",
      "616.pt\n",
      "617.pt\n",
      "618.pt\n",
      "619.pt\n",
      "620.pt\n",
      "621.pt\n",
      "622.pt\n",
      "623.pt\n",
      "624.pt\n",
      "625.pt\n",
      "626.pt\n",
      "627.pt\n",
      "628.pt\n",
      "629.pt\n",
      "630.pt\n",
      "631.pt\n",
      "632.pt\n",
      "633.pt\n",
      "634.pt\n",
      "635.pt\n",
      "636.pt\n",
      "637.pt\n",
      "638.pt\n",
      "639.pt\n",
      "640.pt\n",
      "641.pt\n",
      "642.pt\n",
      "643.pt\n",
      "644.pt\n",
      "645.pt\n",
      "646.pt\n",
      "647.pt\n",
      "648.pt\n",
      "649.pt\n",
      "650.pt\n",
      "651.pt\n",
      "652.pt\n",
      "653.pt\n",
      "654.pt\n",
      "655.pt\n",
      "656.pt\n",
      "657.pt\n",
      "658.pt\n",
      "659.pt\n",
      "660.pt\n",
      "661.pt\n",
      "662.pt\n",
      "663.pt\n",
      "664.pt\n",
      "665.pt\n",
      "666.pt\n",
      "667.pt\n",
      "668.pt\n",
      "669.pt\n",
      "670.pt\n",
      "671.pt\n",
      "672.pt\n",
      "673.pt\n",
      "674.pt\n",
      "675.pt\n",
      "676.pt\n",
      "677.pt\n",
      "678.pt\n",
      "679.pt\n",
      "680.pt\n",
      "681.pt\n",
      "682.pt\n",
      "683.pt\n",
      "684.pt\n",
      "685.pt\n",
      "686.pt\n",
      "687.pt\n",
      "688.pt\n",
      "689.pt\n",
      "690.pt\n",
      "691.pt\n",
      "692.pt\n",
      "693.pt\n",
      "694.pt\n",
      "695.pt\n",
      "696.pt\n",
      "697.pt\n",
      "698.pt\n",
      "699.pt\n",
      "700.pt\n",
      "701.pt\n",
      "702.pt\n",
      "703.pt\n",
      "704.pt\n",
      "705.pt\n",
      "706.pt\n",
      "707.pt\n",
      "708.pt\n",
      "709.pt\n",
      "710.pt\n",
      "711.pt\n",
      "712.pt\n",
      "713.pt\n",
      "714.pt\n",
      "715.pt\n",
      "716.pt\n",
      "717.pt\n",
      "718.pt\n",
      "719.pt\n",
      "720.pt\n",
      "721.pt\n",
      "722.pt\n",
      "723.pt\n",
      "724.pt\n",
      "725.pt\n",
      "726.pt\n",
      "727.pt\n",
      "728.pt\n",
      "729.pt\n",
      "730.pt\n",
      "731.pt\n",
      "732.pt\n",
      "733.pt\n",
      "734.pt\n",
      "735.pt\n",
      "736.pt\n",
      "737.pt\n",
      "738.pt\n",
      "739.pt\n",
      "740.pt\n",
      "741.pt\n",
      "742.pt\n",
      "743.pt\n",
      "744.pt\n",
      "745.pt\n",
      "746.pt\n",
      "747.pt\n",
      "748.pt\n",
      "749.pt\n",
      "750.pt\n",
      "751.pt\n",
      "752.pt\n",
      "753.pt\n",
      "754.pt\n",
      "755.pt\n",
      "756.pt\n",
      "757.pt\n",
      "758.pt\n",
      "759.pt\n",
      "760.pt\n",
      "761.pt\n",
      "762.pt\n",
      "763.pt\n",
      "764.pt\n",
      "765.pt\n",
      "766.pt\n",
      "767.pt\n",
      "768.pt\n",
      "769.pt\n",
      "770.pt\n",
      "771.pt\n",
      "772.pt\n",
      "773.pt\n",
      "774.pt\n",
      "775.pt\n",
      "776.pt\n",
      "777.pt\n",
      "778.pt\n",
      "779.pt\n",
      "780.pt\n",
      "781.pt\n",
      "782.pt\n",
      "783.pt\n",
      "784.pt\n",
      "785.pt\n",
      "786.pt\n",
      "787.pt\n",
      "788.pt\n",
      "789.pt\n",
      "790.pt\n",
      "791.pt\n",
      "792.pt\n",
      "793.pt\n",
      "794.pt\n",
      "795.pt\n",
      "796.pt\n",
      "797.pt\n",
      "798.pt\n",
      "799.pt\n",
      "800.pt\n",
      "801.pt\n",
      "802.pt\n",
      "803.pt\n",
      "804.pt\n",
      "805.pt\n",
      "806.pt\n",
      "807.pt\n",
      "808.pt\n",
      "809.pt\n",
      "810.pt\n",
      "811.pt\n",
      "812.pt\n",
      "813.pt\n",
      "814.pt\n",
      "815.pt\n",
      "816.pt\n",
      "817.pt\n",
      "818.pt\n",
      "819.pt\n",
      "820.pt\n",
      "821.pt\n",
      "822.pt\n",
      "823.pt\n",
      "824.pt\n",
      "825.pt\n",
      "826.pt\n",
      "827.pt\n",
      "828.pt\n",
      "829.pt\n",
      "830.pt\n",
      "831.pt\n",
      "832.pt\n",
      "833.pt\n",
      "834.pt\n",
      "835.pt\n",
      "836.pt\n",
      "837.pt\n",
      "838.pt\n",
      "839.pt\n",
      "840.pt\n",
      "841.pt\n",
      "842.pt\n",
      "843.pt\n",
      "844.pt\n",
      "845.pt\n",
      "846.pt\n",
      "847.pt\n",
      "848.pt\n",
      "849.pt\n",
      "850.pt\n",
      "851.pt\n",
      "852.pt\n",
      "853.pt\n",
      "854.pt\n",
      "855.pt\n",
      "856.pt\n",
      "857.pt\n",
      "858.pt\n",
      "859.pt\n",
      "860.pt\n",
      "861.pt\n",
      "862.pt\n",
      "863.pt\n",
      "864.pt\n",
      "865.pt\n",
      "866.pt\n",
      "867.pt\n",
      "868.pt\n",
      "869.pt\n",
      "870.pt\n",
      "871.pt\n",
      "872.pt\n",
      "873.pt\n",
      "874.pt\n",
      "875.pt\n",
      "876.pt\n",
      "877.pt\n",
      "878.pt\n",
      "879.pt\n",
      "880.pt\n",
      "881.pt\n",
      "882.pt\n",
      "883.pt\n",
      "884.pt\n",
      "885.pt\n",
      "886.pt\n",
      "887.pt\n",
      "888.pt\n",
      "889.pt\n",
      "890.pt\n",
      "891.pt\n",
      "892.pt\n",
      "893.pt\n",
      "894.pt\n",
      "895.pt\n",
      "896.pt\n",
      "897.pt\n",
      "898.pt\n",
      "899.pt\n",
      "900.pt\n",
      "901.pt\n",
      "902.pt\n",
      "903.pt\n",
      "904.pt\n",
      "905.pt\n",
      "906.pt\n",
      "907.pt\n",
      "908.pt\n",
      "909.pt\n",
      "910.pt\n",
      "911.pt\n",
      "912.pt\n",
      "913.pt\n",
      "914.pt\n",
      "915.pt\n",
      "916.pt\n",
      "917.pt\n",
      "918.pt\n",
      "919.pt\n",
      "920.pt\n",
      "921.pt\n",
      "922.pt\n",
      "923.pt\n",
      "924.pt\n",
      "925.pt\n",
      "926.pt\n",
      "927.pt\n",
      "928.pt\n",
      "929.pt\n",
      "930.pt\n",
      "931.pt\n",
      "932.pt\n",
      "933.pt\n",
      "934.pt\n",
      "935.pt\n",
      "936.pt\n",
      "937.pt\n",
      "938.pt\n",
      "939.pt\n",
      "940.pt\n",
      "941.pt\n",
      "942.pt\n",
      "943.pt\n",
      "944.pt\n",
      "945.pt\n",
      "946.pt\n",
      "947.pt\n",
      "948.pt\n",
      "949.pt\n",
      "950.pt\n",
      "951.pt\n",
      "952.pt\n",
      "953.pt\n",
      "954.pt\n",
      "955.pt\n",
      "956.pt\n",
      "957.pt\n",
      "958.pt\n",
      "959.pt\n",
      "960.pt\n",
      "961.pt\n",
      "962.pt\n",
      "963.pt\n",
      "964.pt\n",
      "965.pt\n",
      "966.pt\n",
      "967.pt\n",
      "968.pt\n",
      "969.pt\n",
      "970.pt\n",
      "971.pt\n",
      "972.pt\n",
      "973.pt\n",
      "974.pt\n",
      "975.pt\n",
      "976.pt\n",
      "977.pt\n",
      "978.pt\n",
      "979.pt\n",
      "980.pt\n",
      "981.pt\n",
      "982.pt\n",
      "983.pt\n",
      "984.pt\n",
      "985.pt\n",
      "986.pt\n",
      "987.pt\n",
      "988.pt\n",
      "989.pt\n",
      "990.pt\n",
      "991.pt\n",
      "992.pt\n",
      "993.pt\n",
      "994.pt\n",
      "995.pt\n",
      "996.pt\n",
      "997.pt\n",
      "998.pt\n",
      "999.pt\n",
      "1000.pt\n",
      "1001.pt\n",
      "1002.pt\n",
      "1003.pt\n",
      "1004.pt\n",
      "1005.pt\n",
      "1006.pt\n",
      "1007.pt\n",
      "1008.pt\n",
      "1009.pt\n",
      "1010.pt\n",
      "1011.pt\n",
      "1012.pt\n",
      "1013.pt\n",
      "1014.pt\n",
      "1015.pt\n",
      "1016.pt\n",
      "1017.pt\n",
      "1018.pt\n",
      "1019.pt\n",
      "1020.pt\n",
      "1021.pt\n",
      "1022.pt\n",
      "1023.pt\n",
      "1024.pt\n",
      "1025.pt\n",
      "1026.pt\n",
      "1027.pt\n",
      "1028.pt\n",
      "1029.pt\n",
      "1030.pt\n",
      "1031.pt\n",
      "1032.pt\n",
      "1033.pt\n",
      "1034.pt\n",
      "1035.pt\n",
      "1036.pt\n",
      "1037.pt\n",
      "1038.pt\n",
      "1039.pt\n",
      "1040.pt\n",
      "1041.pt\n",
      "1042.pt\n",
      "1043.pt\n",
      "1044.pt\n",
      "1045.pt\n",
      "1046.pt\n",
      "1047.pt\n",
      "1048.pt\n",
      "1049.pt\n",
      "1050.pt\n",
      "1051.pt\n",
      "1052.pt\n",
      "1053.pt\n",
      "1054.pt\n",
      "1055.pt\n",
      "1056.pt\n",
      "1057.pt\n",
      "1058.pt\n",
      "1059.pt\n",
      "1060.pt\n",
      "1061.pt\n",
      "1062.pt\n",
      "1063.pt\n",
      "1064.pt\n",
      "1065.pt\n",
      "1066.pt\n",
      "1067.pt\n",
      "1068.pt\n",
      "1069.pt\n",
      "1070.pt\n",
      "1071.pt\n",
      "1072.pt\n",
      "1073.pt\n",
      "1074.pt\n",
      "1075.pt\n",
      "1076.pt\n",
      "1077.pt\n",
      "1078.pt\n",
      "1079.pt\n",
      "1080.pt\n",
      "1081.pt\n",
      "1082.pt\n",
      "1083.pt\n",
      "1084.pt\n",
      "1085.pt\n",
      "1086.pt\n",
      "1087.pt\n",
      "1088.pt\n",
      "1089.pt\n",
      "1090.pt\n",
      "1091.pt\n",
      "1092.pt\n",
      "1093.pt\n",
      "1094.pt\n",
      "1095.pt\n",
      "1096.pt\n",
      "1097.pt\n",
      "1098.pt\n",
      "1099.pt\n",
      "1100.pt\n",
      "1101.pt\n",
      "1102.pt\n",
      "1103.pt\n",
      "1104.pt\n",
      "1105.pt\n",
      "1106.pt\n",
      "1107.pt\n",
      "1108.pt\n",
      "1109.pt\n",
      "1110.pt\n",
      "1111.pt\n",
      "1112.pt\n",
      "1113.pt\n",
      "1114.pt\n",
      "1115.pt\n",
      "1116.pt\n",
      "1117.pt\n",
      "1118.pt\n",
      "1119.pt\n",
      "1120.pt\n",
      "1121.pt\n",
      "1122.pt\n",
      "1123.pt\n",
      "1124.pt\n",
      "1125.pt\n",
      "1126.pt\n",
      "1127.pt\n",
      "1128.pt\n",
      "1129.pt\n",
      "1130.pt\n",
      "1131.pt\n",
      "1132.pt\n",
      "1133.pt\n",
      "1134.pt\n",
      "1135.pt\n",
      "1136.pt\n",
      "1137.pt\n",
      "1138.pt\n",
      "1139.pt\n",
      "1140.pt\n",
      "1141.pt\n",
      "1142.pt\n",
      "1143.pt\n",
      "1144.pt\n",
      "1145.pt\n",
      "1146.pt\n",
      "1147.pt\n",
      "1148.pt\n",
      "1149.pt\n",
      "1150.pt\n",
      "1151.pt\n",
      "1152.pt\n",
      "1153.pt\n",
      "1154.pt\n",
      "1155.pt\n",
      "1156.pt\n",
      "1157.pt\n",
      "1158.pt\n",
      "1159.pt\n",
      "1160.pt\n",
      "1161.pt\n",
      "1162.pt\n",
      "1163.pt\n",
      "1164.pt\n",
      "1165.pt\n",
      "1166.pt\n",
      "1167.pt\n",
      "1168.pt\n",
      "1169.pt\n",
      "1170.pt\n",
      "1171.pt\n",
      "1172.pt\n",
      "1173.pt\n",
      "1174.pt\n",
      "1175.pt\n",
      "1176.pt\n",
      "1177.pt\n",
      "1178.pt\n",
      "1179.pt\n",
      "1180.pt\n",
      "1181.pt\n",
      "1182.pt\n",
      "1183.pt\n",
      "1184.pt\n",
      "1185.pt\n",
      "1186.pt\n",
      "1187.pt\n",
      "1188.pt\n",
      "1189.pt\n",
      "1190.pt\n",
      "1191.pt\n",
      "1192.pt\n",
      "1193.pt\n",
      "1194.pt\n",
      "1195.pt\n",
      "1196.pt\n",
      "1197.pt\n",
      "1198.pt\n",
      "1199.pt\n",
      "1200.pt\n",
      "1201.pt\n",
      "1202.pt\n",
      "1203.pt\n",
      "1204.pt\n",
      "1205.pt\n",
      "1206.pt\n",
      "1207.pt\n",
      "1208.pt\n",
      "1209.pt\n",
      "1210.pt\n",
      "1211.pt\n",
      "1212.pt\n",
      "1213.pt\n",
      "1214.pt\n",
      "1215.pt\n",
      "1216.pt\n",
      "1217.pt\n",
      "1218.pt\n",
      "1219.pt\n",
      "1220.pt\n",
      "1221.pt\n",
      "1222.pt\n",
      "1223.pt\n",
      "1224.pt\n",
      "1225.pt\n",
      "1226.pt\n",
      "1227.pt\n",
      "1228.pt\n",
      "1229.pt\n",
      "1230.pt\n",
      "1231.pt\n",
      "1232.pt\n",
      "1233.pt\n",
      "1234.pt\n",
      "1235.pt\n",
      "1236.pt\n",
      "1237.pt\n",
      "1238.pt\n",
      "1239.pt\n",
      "1240.pt\n",
      "1241.pt\n",
      "1242.pt\n",
      "1243.pt\n",
      "1244.pt\n",
      "1245.pt\n",
      "1246.pt\n",
      "1247.pt\n",
      "1248.pt\n",
      "1249.pt\n",
      "1250.pt\n",
      "1251.pt\n",
      "1252.pt\n",
      "1253.pt\n",
      "1254.pt\n",
      "1255.pt\n",
      "1256.pt\n",
      "1257.pt\n",
      "1258.pt\n",
      "1259.pt\n",
      "1260.pt\n",
      "1261.pt\n",
      "1262.pt\n",
      "1263.pt\n",
      "1264.pt\n",
      "1265.pt\n",
      "1266.pt\n",
      "1267.pt\n",
      "1268.pt\n",
      "1269.pt\n",
      "1270.pt\n",
      "1271.pt\n",
      "1272.pt\n",
      "1273.pt\n",
      "1274.pt\n",
      "1275.pt\n",
      "1276.pt\n",
      "1277.pt\n",
      "1278.pt\n",
      "1279.pt\n",
      "1280.pt\n",
      "1281.pt\n",
      "1282.pt\n",
      "1283.pt\n",
      "1284.pt\n",
      "1285.pt\n",
      "1286.pt\n",
      "1287.pt\n",
      "1288.pt\n",
      "1289.pt\n",
      "1290.pt\n",
      "1291.pt\n",
      "1292.pt\n",
      "1293.pt\n",
      "1294.pt\n",
      "1295.pt\n",
      "1296.pt\n",
      "1297.pt\n",
      "1298.pt\n",
      "1299.pt\n",
      "1300.pt\n",
      "1301.pt\n",
      "1302.pt\n",
      "1303.pt\n",
      "1304.pt\n",
      "1305.pt\n",
      "1306.pt\n",
      "1307.pt\n",
      "1308.pt\n",
      "1309.pt\n",
      "1310.pt\n",
      "1311.pt\n",
      "1312.pt\n",
      "1313.pt\n",
      "1314.pt\n",
      "1315.pt\n",
      "1316.pt\n",
      "1317.pt\n",
      "1318.pt\n",
      "1319.pt\n",
      "1320.pt\n",
      "1321.pt\n",
      "1322.pt\n",
      "1323.pt\n",
      "1324.pt\n",
      "1325.pt\n",
      "1326.pt\n",
      "1327.pt\n",
      "1328.pt\n",
      "1329.pt\n",
      "1330.pt\n",
      "1331.pt\n",
      "1332.pt\n",
      "1333.pt\n",
      "1334.pt\n",
      "1335.pt\n",
      "1336.pt\n",
      "1337.pt\n",
      "1338.pt\n",
      "1339.pt\n",
      "1340.pt\n",
      "1341.pt\n",
      "1342.pt\n",
      "1343.pt\n",
      "1344.pt\n",
      "1345.pt\n",
      "1346.pt\n",
      "1347.pt\n",
      "1348.pt\n",
      "1349.pt\n",
      "1350.pt\n",
      "1351.pt\n",
      "1352.pt\n",
      "1353.pt\n",
      "1354.pt\n",
      "1355.pt\n",
      "1356.pt\n",
      "1357.pt\n",
      "1358.pt\n",
      "1359.pt\n",
      "1360.pt\n",
      "1361.pt\n",
      "1362.pt\n",
      "1363.pt\n",
      "1364.pt\n",
      "1365.pt\n",
      "1366.pt\n",
      "1367.pt\n",
      "1368.pt\n",
      "1369.pt\n",
      "1370.pt\n",
      "1371.pt\n",
      "1372.pt\n",
      "1373.pt\n",
      "1374.pt\n",
      "1375.pt\n",
      "1376.pt\n",
      "1377.pt\n",
      "1378.pt\n",
      "1379.pt\n",
      "1380.pt\n",
      "1381.pt\n",
      "1382.pt\n",
      "1383.pt\n",
      "1384.pt\n",
      "1385.pt\n",
      "1386.pt\n",
      "1387.pt\n",
      "1388.pt\n",
      "1389.pt\n",
      "1390.pt\n",
      "1391.pt\n",
      "1392.pt\n",
      "1393.pt\n",
      "1394.pt\n",
      "1395.pt\n",
      "1396.pt\n",
      "1397.pt\n",
      "1398.pt\n",
      "1399.pt\n",
      "1400.pt\n",
      "1401.pt\n",
      "1402.pt\n",
      "1403.pt\n",
      "1404.pt\n",
      "1405.pt\n",
      "1406.pt\n",
      "1407.pt\n",
      "1408.pt\n",
      "1409.pt\n",
      "1410.pt\n",
      "1411.pt\n",
      "1412.pt\n",
      "1413.pt\n",
      "1414.pt\n",
      "1415.pt\n",
      "1416.pt\n",
      "1417.pt\n",
      "1418.pt\n",
      "1419.pt\n",
      "1420.pt\n",
      "1421.pt\n",
      "1422.pt\n",
      "1423.pt\n",
      "1424.pt\n",
      "1425.pt\n",
      "1426.pt\n",
      "1427.pt\n",
      "1428.pt\n",
      "1429.pt\n",
      "1430.pt\n",
      "1431.pt\n",
      "1432.pt\n",
      "1433.pt\n",
      "1434.pt\n",
      "1435.pt\n",
      "1436.pt\n",
      "1437.pt\n",
      "1438.pt\n",
      "1439.pt\n",
      "1440.pt\n",
      "1441.pt\n",
      "1442.pt\n",
      "1443.pt\n",
      "1444.pt\n",
      "1445.pt\n",
      "1446.pt\n",
      "1447.pt\n",
      "1448.pt\n",
      "1449.pt\n",
      "1450.pt\n",
      "1451.pt\n",
      "1452.pt\n",
      "1453.pt\n",
      "1454.pt\n",
      "1455.pt\n",
      "1456.pt\n",
      "1457.pt\n",
      "1458.pt\n",
      "1459.pt\n",
      "1460.pt\n",
      "1461.pt\n",
      "1462.pt\n",
      "1463.pt\n",
      "1464.pt\n",
      "1465.pt\n",
      "1466.pt\n",
      "1467.pt\n",
      "1468.pt\n",
      "1469.pt\n",
      "1470.pt\n",
      "1471.pt\n",
      "1472.pt\n",
      "1473.pt\n",
      "1474.pt\n",
      "1475.pt\n",
      "1476.pt\n",
      "1477.pt\n",
      "1478.pt\n",
      "1479.pt\n",
      "1480.pt\n",
      "1481.pt\n",
      "1482.pt\n",
      "1483.pt\n",
      "1484.pt\n",
      "1485.pt\n",
      "1486.pt\n",
      "1487.pt\n",
      "1488.pt\n",
      "1489.pt\n",
      "1490.pt\n",
      "1491.pt\n",
      "1492.pt\n",
      "1493.pt\n",
      "1494.pt\n",
      "1495.pt\n",
      "1496.pt\n",
      "1497.pt\n",
      "1498.pt\n",
      "1499.pt\n",
      "1500.pt\n",
      "1501.pt\n",
      "1502.pt\n",
      "1503.pt\n",
      "1504.pt\n",
      "1505.pt\n",
      "1506.pt\n",
      "1507.pt\n",
      "1508.pt\n",
      "1509.pt\n",
      "1510.pt\n",
      "1511.pt\n",
      "1512.pt\n",
      "1513.pt\n",
      "1514.pt\n",
      "1515.pt\n",
      "1516.pt\n",
      "1517.pt\n",
      "1518.pt\n",
      "1519.pt\n",
      "1520.pt\n",
      "1521.pt\n",
      "1522.pt\n",
      "1523.pt\n",
      "1524.pt\n",
      "1525.pt\n",
      "1526.pt\n",
      "1527.pt\n",
      "1528.pt\n",
      "1529.pt\n",
      "1530.pt\n",
      "1531.pt\n",
      "1532.pt\n",
      "1533.pt\n",
      "1534.pt\n",
      "1535.pt\n",
      "1536.pt\n",
      "1537.pt\n",
      "1538.pt\n",
      "1539.pt\n",
      "1540.pt\n",
      "1541.pt\n",
      "1542.pt\n",
      "1543.pt\n",
      "1544.pt\n",
      "1545.pt\n",
      "1546.pt\n",
      "1547.pt\n",
      "1548.pt\n",
      "1549.pt\n",
      "1550.pt\n",
      "1551.pt\n",
      "1552.pt\n",
      "1553.pt\n",
      "1554.pt\n",
      "1555.pt\n",
      "1556.pt\n",
      "1557.pt\n",
      "1558.pt\n",
      "1559.pt\n",
      "1560.pt\n",
      "1561.pt\n",
      "1562.pt\n",
      "1563.pt\n",
      "1564.pt\n",
      "1565.pt\n",
      "1566.pt\n",
      "1567.pt\n",
      "1568.pt\n",
      "1569.pt\n",
      "1570.pt\n",
      "1571.pt\n",
      "1572.pt\n",
      "1573.pt\n",
      "1574.pt\n",
      "1575.pt\n",
      "1576.pt\n",
      "1577.pt\n",
      "1578.pt\n",
      "1579.pt\n",
      "1580.pt\n",
      "1581.pt\n",
      "1582.pt\n",
      "1583.pt\n",
      "1584.pt\n",
      "1585.pt\n",
      "1586.pt\n",
      "1587.pt\n",
      "1588.pt\n",
      "1589.pt\n",
      "1590.pt\n",
      "1591.pt\n",
      "1592.pt\n",
      "1593.pt\n",
      "1594.pt\n",
      "1595.pt\n",
      "1596.pt\n",
      "1597.pt\n",
      "1598.pt\n",
      "1599.pt\n",
      "1600.pt\n",
      "1601.pt\n",
      "1602.pt\n",
      "1603.pt\n",
      "1604.pt\n",
      "1605.pt\n",
      "1606.pt\n",
      "1607.pt\n",
      "1608.pt\n",
      "1609.pt\n",
      "1610.pt\n",
      "1611.pt\n",
      "1612.pt\n",
      "1613.pt\n",
      "1614.pt\n",
      "1615.pt\n",
      "1616.pt\n",
      "1617.pt\n",
      "1618.pt\n",
      "1619.pt\n",
      "1620.pt\n",
      "1621.pt\n",
      "1622.pt\n",
      "1623.pt\n",
      "1624.pt\n",
      "1625.pt\n",
      "1626.pt\n",
      "1627.pt\n",
      "1628.pt\n",
      "1629.pt\n",
      "1630.pt\n",
      "1631.pt\n",
      "1632.pt\n",
      "1633.pt\n",
      "1634.pt\n",
      "1635.pt\n",
      "1636.pt\n",
      "1637.pt\n",
      "1638.pt\n",
      "1639.pt\n",
      "1640.pt\n",
      "1641.pt\n",
      "1642.pt\n",
      "1643.pt\n",
      "1644.pt\n",
      "1645.pt\n",
      "1646.pt\n",
      "1647.pt\n",
      "1648.pt\n",
      "1649.pt\n",
      "1650.pt\n",
      "1651.pt\n",
      "1652.pt\n",
      "1653.pt\n",
      "1654.pt\n",
      "1655.pt\n",
      "1656.pt\n",
      "1657.pt\n",
      "1658.pt\n",
      "1659.pt\n",
      "1660.pt\n",
      "1661.pt\n",
      "1662.pt\n",
      "1663.pt\n",
      "1664.pt\n",
      "1665.pt\n",
      "1666.pt\n",
      "1667.pt\n",
      "1668.pt\n",
      "1669.pt\n",
      "1670.pt\n",
      "1671.pt\n",
      "1672.pt\n",
      "1673.pt\n",
      "1674.pt\n",
      "1675.pt\n",
      "1676.pt\n",
      "1677.pt\n",
      "1678.pt\n",
      "1679.pt\n",
      "1680.pt\n",
      "1681.pt\n",
      "1682.pt\n",
      "1683.pt\n",
      "1684.pt\n",
      "1685.pt\n",
      "1686.pt\n",
      "1687.pt\n",
      "1688.pt\n",
      "1689.pt\n",
      "1690.pt\n",
      "1691.pt\n",
      "1692.pt\n",
      "1693.pt\n",
      "1694.pt\n",
      "1695.pt\n",
      "1696.pt\n",
      "1697.pt\n",
      "1698.pt\n",
      "1699.pt\n",
      "1700.pt\n",
      "1701.pt\n",
      "1702.pt\n",
      "1703.pt\n",
      "1704.pt\n",
      "1705.pt\n",
      "1706.pt\n",
      "1707.pt\n",
      "1708.pt\n",
      "1709.pt\n",
      "1710.pt\n",
      "1711.pt\n",
      "1712.pt\n",
      "1713.pt\n",
      "1714.pt\n",
      "1715.pt\n",
      "1716.pt\n",
      "1717.pt\n",
      "1718.pt\n",
      "1719.pt\n",
      "1720.pt\n",
      "1721.pt\n",
      "1722.pt\n",
      "1723.pt\n",
      "1724.pt\n",
      "1725.pt\n",
      "1726.pt\n",
      "1727.pt\n",
      "1728.pt\n",
      "1729.pt\n",
      "1730.pt\n",
      "1731.pt\n",
      "1732.pt\n",
      "1733.pt\n",
      "1734.pt\n",
      "1735.pt\n",
      "1736.pt\n",
      "1737.pt\n",
      "1738.pt\n",
      "1739.pt\n",
      "1740.pt\n",
      "1741.pt\n",
      "1742.pt\n",
      "1743.pt\n",
      "1744.pt\n",
      "1745.pt\n",
      "1746.pt\n",
      "1747.pt\n",
      "1748.pt\n",
      "1749.pt\n",
      "1750.pt\n",
      "1751.pt\n",
      "1752.pt\n",
      "1753.pt\n",
      "1754.pt\n",
      "1755.pt\n",
      "1756.pt\n",
      "1757.pt\n",
      "1758.pt\n",
      "1759.pt\n",
      "1760.pt\n",
      "1761.pt\n",
      "1762.pt\n",
      "1763.pt\n",
      "1764.pt\n",
      "1765.pt\n",
      "1766.pt\n",
      "1767.pt\n",
      "1768.pt\n",
      "1769.pt\n",
      "1770.pt\n",
      "1771.pt\n",
      "1772.pt\n",
      "1773.pt\n",
      "1774.pt\n",
      "1775.pt\n",
      "1776.pt\n",
      "1777.pt\n",
      "1778.pt\n",
      "1779.pt\n",
      "1780.pt\n",
      "1781.pt\n",
      "1782.pt\n",
      "1783.pt\n",
      "1784.pt\n",
      "1785.pt\n",
      "1786.pt\n",
      "1787.pt\n",
      "1788.pt\n",
      "1789.pt\n",
      "1790.pt\n",
      "1791.pt\n",
      "1792.pt\n",
      "1793.pt\n",
      "1794.pt\n",
      "1795.pt\n",
      "1796.pt\n",
      "1797.pt\n",
      "1798.pt\n",
      "1799.pt\n",
      "1800.pt\n",
      "1801.pt\n",
      "1802.pt\n",
      "1803.pt\n",
      "1804.pt\n",
      "1805.pt\n",
      "1806.pt\n",
      "1807.pt\n",
      "1808.pt\n",
      "1809.pt\n",
      "1810.pt\n",
      "1811.pt\n",
      "1812.pt\n",
      "1813.pt\n",
      "1814.pt\n",
      "1815.pt\n",
      "1816.pt\n",
      "1817.pt\n",
      "1818.pt\n",
      "1819.pt\n",
      "1820.pt\n",
      "1821.pt\n",
      "1822.pt\n",
      "1823.pt\n",
      "1824.pt\n",
      "1825.pt\n",
      "1826.pt\n",
      "1827.pt\n",
      "1828.pt\n",
      "1829.pt\n",
      "1830.pt\n",
      "1831.pt\n",
      "1832.pt\n",
      "1833.pt\n",
      "1834.pt\n",
      "1835.pt\n",
      "1836.pt\n",
      "1837.pt\n",
      "1838.pt\n",
      "1839.pt\n",
      "1840.pt\n",
      "1841.pt\n",
      "1842.pt\n",
      "1843.pt\n",
      "1844.pt\n",
      "1845.pt\n",
      "1846.pt\n",
      "1847.pt\n",
      "1848.pt\n",
      "1849.pt\n",
      "1850.pt\n",
      "1851.pt\n",
      "1852.pt\n",
      "1853.pt\n",
      "1854.pt\n",
      "1855.pt\n",
      "1856.pt\n",
      "1857.pt\n",
      "1858.pt\n",
      "1859.pt\n",
      "1860.pt\n",
      "1861.pt\n",
      "1862.pt\n",
      "1863.pt\n",
      "1864.pt\n",
      "1865.pt\n",
      "1866.pt\n",
      "1867.pt\n",
      "1868.pt\n",
      "1869.pt\n",
      "1870.pt\n",
      "1871.pt\n",
      "1872.pt\n",
      "1873.pt\n",
      "1874.pt\n",
      "1875.pt\n",
      "1876.pt\n",
      "1877.pt\n",
      "1878.pt\n",
      "1879.pt\n",
      "1880.pt\n",
      "1881.pt\n",
      "1882.pt\n",
      "1883.pt\n",
      "1884.pt\n",
      "1885.pt\n",
      "1886.pt\n",
      "1887.pt\n",
      "1888.pt\n",
      "1889.pt\n",
      "1890.pt\n",
      "1891.pt\n",
      "1892.pt\n",
      "1893.pt\n",
      "1894.pt\n",
      "1895.pt\n",
      "1896.pt\n",
      "1897.pt\n",
      "1898.pt\n",
      "1899.pt\n",
      "1900.pt\n",
      "1901.pt\n",
      "1902.pt\n",
      "1903.pt\n",
      "1904.pt\n",
      "1905.pt\n",
      "1906.pt\n",
      "1907.pt\n",
      "1908.pt\n",
      "1909.pt\n",
      "1910.pt\n",
      "1911.pt\n",
      "1912.pt\n",
      "1913.pt\n",
      "1914.pt\n",
      "1915.pt\n",
      "1916.pt\n",
      "1917.pt\n",
      "1918.pt\n",
      "1919.pt\n",
      "1920.pt\n",
      "1921.pt\n",
      "1922.pt\n",
      "1923.pt\n",
      "1924.pt\n",
      "1925.pt\n",
      "1926.pt\n",
      "1927.pt\n",
      "1928.pt\n",
      "1929.pt\n",
      "1930.pt\n",
      "1931.pt\n",
      "1932.pt\n",
      "1933.pt\n",
      "1934.pt\n",
      "1935.pt\n",
      "1936.pt\n",
      "1937.pt\n",
      "1938.pt\n",
      "1939.pt\n",
      "1940.pt\n",
      "1941.pt\n",
      "1942.pt\n",
      "1943.pt\n",
      "1944.pt\n",
      "1945.pt\n",
      "1946.pt\n",
      "1947.pt\n",
      "1948.pt\n",
      "1949.pt\n",
      "1950.pt\n",
      "1951.pt\n",
      "1952.pt\n",
      "1953.pt\n",
      "1954.pt\n",
      "1955.pt\n",
      "1956.pt\n",
      "1957.pt\n",
      "1958.pt\n",
      "1959.pt\n",
      "1960.pt\n",
      "1961.pt\n",
      "1962.pt\n",
      "1963.pt\n",
      "1964.pt\n",
      "1965.pt\n",
      "1966.pt\n",
      "1967.pt\n",
      "1968.pt\n",
      "1969.pt\n",
      "1970.pt\n",
      "1971.pt\n",
      "1972.pt\n",
      "1973.pt\n",
      "1974.pt\n",
      "1975.pt\n",
      "1976.pt\n",
      "1977.pt\n",
      "1978.pt\n",
      "1979.pt\n",
      "1980.pt\n",
      "1981.pt\n",
      "1982.pt\n",
      "1983.pt\n",
      "1984.pt\n",
      "1985.pt\n",
      "1986.pt\n",
      "1987.pt\n",
      "1988.pt\n",
      "1989.pt\n",
      "1990.pt\n",
      "1991.pt\n",
      "1992.pt\n",
      "1993.pt\n",
      "1994.pt\n",
      "1995.pt\n",
      "1996.pt\n",
      "1997.pt\n",
      "1998.pt\n",
      "1999.pt\n",
      "2000.pt\n",
      "2001.pt\n",
      "2002.pt\n",
      "2003.pt\n",
      "2004.pt\n",
      "2005.pt\n",
      "2006.pt\n",
      "2007.pt\n",
      "2008.pt\n",
      "2009.pt\n",
      "2010.pt\n",
      "2011.pt\n",
      "2012.pt\n",
      "2013.pt\n",
      "2014.pt\n",
      "2015.pt\n",
      "2016.pt\n",
      "2017.pt\n",
      "2018.pt\n",
      "2019.pt\n",
      "2020.pt\n",
      "2021.pt\n",
      "2022.pt\n",
      "2023.pt\n",
      "2024.pt\n",
      "2025.pt\n",
      "2026.pt\n",
      "2027.pt\n",
      "2028.pt\n",
      "2029.pt\n",
      "2030.pt\n",
      "2031.pt\n",
      "2032.pt\n",
      "2033.pt\n",
      "2034.pt\n",
      "2035.pt\n",
      "2036.pt\n",
      "2037.pt\n",
      "2038.pt\n",
      "2039.pt\n",
      "2040.pt\n",
      "2041.pt\n",
      "2042.pt\n",
      "2043.pt\n",
      "2044.pt\n",
      "2045.pt\n",
      "2046.pt\n",
      "2047.pt\n",
      "2048.pt\n",
      "2049.pt\n",
      "2050.pt\n",
      "2051.pt\n",
      "2052.pt\n",
      "2053.pt\n",
      "2054.pt\n",
      "2055.pt\n",
      "2056.pt\n",
      "2057.pt\n",
      "2058.pt\n",
      "2059.pt\n",
      "2060.pt\n",
      "2061.pt\n",
      "2062.pt\n",
      "2063.pt\n",
      "2064.pt\n",
      "2065.pt\n",
      "2066.pt\n",
      "2067.pt\n",
      "2068.pt\n",
      "2069.pt\n",
      "2070.pt\n",
      "2071.pt\n",
      "2072.pt\n",
      "2073.pt\n",
      "2074.pt\n",
      "2075.pt\n",
      "2076.pt\n",
      "2077.pt\n",
      "2078.pt\n",
      "2079.pt\n",
      "2080.pt\n",
      "2081.pt\n",
      "2082.pt\n",
      "2083.pt\n",
      "2084.pt\n",
      "2085.pt\n",
      "2086.pt\n",
      "2087.pt\n",
      "2088.pt\n",
      "2089.pt\n",
      "2090.pt\n",
      "2091.pt\n",
      "2092.pt\n",
      "2093.pt\n",
      "2094.pt\n",
      "2095.pt\n",
      "2096.pt\n",
      "2097.pt\n",
      "2098.pt\n",
      "2099.pt\n",
      "2100.pt\n",
      "2101.pt\n",
      "2102.pt\n",
      "2103.pt\n",
      "2104.pt\n",
      "2105.pt\n",
      "2106.pt\n",
      "2107.pt\n",
      "2108.pt\n",
      "2109.pt\n",
      "2110.pt\n",
      "2111.pt\n",
      "2112.pt\n",
      "2113.pt\n",
      "2114.pt\n",
      "2115.pt\n",
      "2116.pt\n",
      "2117.pt\n",
      "2118.pt\n",
      "2119.pt\n",
      "2120.pt\n",
      "2121.pt\n",
      "2122.pt\n",
      "2123.pt\n",
      "2124.pt\n",
      "2125.pt\n",
      "2126.pt\n",
      "2127.pt\n",
      "2128.pt\n",
      "2129.pt\n",
      "2130.pt\n",
      "2131.pt\n",
      "2132.pt\n",
      "2133.pt\n",
      "2134.pt\n",
      "2135.pt\n",
      "2136.pt\n",
      "2137.pt\n",
      "2138.pt\n",
      "2139.pt\n",
      "2140.pt\n",
      "2141.pt\n",
      "2142.pt\n",
      "2143.pt\n",
      "2144.pt\n",
      "2145.pt\n",
      "2146.pt\n",
      "2147.pt\n",
      "2148.pt\n",
      "2149.pt\n",
      "2150.pt\n",
      "2151.pt\n",
      "2152.pt\n",
      "2153.pt\n",
      "2154.pt\n",
      "2155.pt\n",
      "2156.pt\n",
      "2157.pt\n",
      "2158.pt\n",
      "2159.pt\n",
      "2160.pt\n",
      "2161.pt\n",
      "2162.pt\n",
      "2163.pt\n",
      "2164.pt\n",
      "2165.pt\n",
      "2166.pt\n",
      "2167.pt\n",
      "2168.pt\n",
      "2169.pt\n",
      "2170.pt\n",
      "2171.pt\n",
      "2172.pt\n",
      "2173.pt\n",
      "2174.pt\n",
      "2175.pt\n",
      "2176.pt\n",
      "2177.pt\n",
      "2178.pt\n",
      "2179.pt\n",
      "2180.pt\n",
      "2181.pt\n",
      "2182.pt\n",
      "2183.pt\n",
      "2184.pt\n",
      "2185.pt\n",
      "2186.pt\n",
      "2187.pt\n",
      "2188.pt\n",
      "2189.pt\n",
      "2190.pt\n",
      "2191.pt\n",
      "2192.pt\n",
      "2193.pt\n",
      "2194.pt\n",
      "2195.pt\n",
      "2196.pt\n",
      "2197.pt\n",
      "2198.pt\n",
      "2199.pt\n",
      "2200.pt\n",
      "2201.pt\n",
      "2202.pt\n",
      "2203.pt\n",
      "2204.pt\n",
      "2205.pt\n",
      "2206.pt\n",
      "2207.pt\n",
      "2208.pt\n",
      "2209.pt\n",
      "2210.pt\n",
      "2211.pt\n",
      "2212.pt\n",
      "2213.pt\n",
      "2214.pt\n",
      "2215.pt\n",
      "2216.pt\n",
      "2217.pt\n",
      "2218.pt\n",
      "2219.pt\n",
      "2220.pt\n",
      "2221.pt\n",
      "2222.pt\n",
      "2223.pt\n",
      "2224.pt\n",
      "2225.pt\n",
      "2226.pt\n",
      "2227.pt\n",
      "2228.pt\n",
      "2229.pt\n",
      "2230.pt\n",
      "2231.pt\n",
      "2232.pt\n",
      "2233.pt\n",
      "2234.pt\n",
      "2235.pt\n",
      "2236.pt\n",
      "2237.pt\n",
      "2238.pt\n",
      "2239.pt\n",
      "2240.pt\n",
      "2241.pt\n",
      "2242.pt\n",
      "2243.pt\n",
      "2244.pt\n",
      "2245.pt\n",
      "2246.pt\n",
      "2247.pt\n",
      "2248.pt\n",
      "2249.pt\n",
      "2250.pt\n",
      "2251.pt\n",
      "2252.pt\n",
      "2253.pt\n",
      "2254.pt\n",
      "2255.pt\n",
      "2256.pt\n",
      "2257.pt\n",
      "2258.pt\n",
      "2259.pt\n",
      "2260.pt\n",
      "2261.pt\n",
      "2262.pt\n",
      "2263.pt\n",
      "2264.pt\n",
      "2265.pt\n",
      "2266.pt\n",
      "2267.pt\n",
      "2268.pt\n",
      "2269.pt\n",
      "2270.pt\n",
      "2271.pt\n",
      "2272.pt\n",
      "2273.pt\n",
      "2274.pt\n",
      "2275.pt\n",
      "2276.pt\n",
      "2277.pt\n",
      "2278.pt\n",
      "2279.pt\n",
      "2280.pt\n",
      "2281.pt\n",
      "2282.pt\n",
      "2283.pt\n",
      "2284.pt\n",
      "2285.pt\n",
      "2286.pt\n",
      "2287.pt\n",
      "2288.pt\n",
      "2289.pt\n",
      "2290.pt\n",
      "2291.pt\n",
      "2292.pt\n",
      "2293.pt\n",
      "2294.pt\n",
      "2295.pt\n",
      "2296.pt\n",
      "2297.pt\n",
      "2298.pt\n",
      "2299.pt\n",
      "2300.pt\n",
      "2301.pt\n",
      "2302.pt\n",
      "2303.pt\n",
      "2304.pt\n",
      "2305.pt\n",
      "2306.pt\n",
      "2307.pt\n",
      "2308.pt\n",
      "2309.pt\n",
      "2310.pt\n",
      "2311.pt\n",
      "2312.pt\n",
      "2313.pt\n",
      "2314.pt\n",
      "2315.pt\n",
      "2316.pt\n",
      "2317.pt\n",
      "2318.pt\n",
      "2319.pt\n",
      "2320.pt\n",
      "2321.pt\n",
      "2322.pt\n",
      "2323.pt\n",
      "2324.pt\n",
      "2325.pt\n",
      "2326.pt\n",
      "2327.pt\n",
      "2328.pt\n",
      "2329.pt\n",
      "2330.pt\n",
      "2331.pt\n",
      "2332.pt\n",
      "2333.pt\n",
      "2334.pt\n",
      "2335.pt\n",
      "2336.pt\n",
      "2337.pt\n",
      "2338.pt\n",
      "2339.pt\n",
      "2340.pt\n",
      "2341.pt\n",
      "2342.pt\n",
      "2343.pt\n",
      "2344.pt\n",
      "2345.pt\n",
      "2346.pt\n",
      "2347.pt\n",
      "2348.pt\n",
      "2349.pt\n",
      "2350.pt\n",
      "2351.pt\n",
      "2352.pt\n",
      "2353.pt\n",
      "2354.pt\n",
      "2355.pt\n",
      "2356.pt\n",
      "2357.pt\n",
      "2358.pt\n",
      "2359.pt\n",
      "2360.pt\n",
      "2361.pt\n",
      "2362.pt\n",
      "2363.pt\n",
      "2364.pt\n",
      "2365.pt\n",
      "2366.pt\n",
      "2367.pt\n",
      "2368.pt\n",
      "2369.pt\n",
      "2370.pt\n",
      "2371.pt\n",
      "2372.pt\n",
      "2373.pt\n",
      "2374.pt\n",
      "2375.pt\n",
      "2376.pt\n",
      "2377.pt\n",
      "2378.pt\n",
      "2379.pt\n",
      "2380.pt\n",
      "2381.pt\n",
      "2382.pt\n",
      "2383.pt\n",
      "2384.pt\n",
      "2385.pt\n",
      "2386.pt\n",
      "2387.pt\n",
      "2388.pt\n",
      "2389.pt\n",
      "2390.pt\n",
      "2391.pt\n",
      "2392.pt\n",
      "2393.pt\n",
      "2394.pt\n",
      "2395.pt\n",
      "2396.pt\n",
      "2397.pt\n",
      "2398.pt\n",
      "2399.pt\n",
      "2400.pt\n",
      "2401.pt\n",
      "2402.pt\n",
      "2403.pt\n",
      "2404.pt\n",
      "2405.pt\n",
      "2406.pt\n",
      "2407.pt\n",
      "2408.pt\n",
      "2409.pt\n",
      "2410.pt\n",
      "2411.pt\n",
      "2412.pt\n",
      "2413.pt\n",
      "2414.pt\n",
      "2415.pt\n",
      "2416.pt\n",
      "2417.pt\n",
      "2418.pt\n",
      "2419.pt\n",
      "2420.pt\n",
      "2421.pt\n",
      "2422.pt\n",
      "2423.pt\n",
      "2424.pt\n",
      "2425.pt\n",
      "2426.pt\n",
      "2427.pt\n",
      "2428.pt\n",
      "2429.pt\n",
      "2430.pt\n",
      "2431.pt\n",
      "2432.pt\n",
      "2433.pt\n",
      "2434.pt\n",
      "2435.pt\n",
      "2436.pt\n",
      "2437.pt\n",
      "2438.pt\n",
      "2439.pt\n",
      "2440.pt\n",
      "2441.pt\n",
      "2442.pt\n",
      "2443.pt\n",
      "2444.pt\n",
      "2445.pt\n",
      "2446.pt\n",
      "2447.pt\n",
      "2448.pt\n",
      "2449.pt\n",
      "2450.pt\n",
      "2451.pt\n",
      "2452.pt\n",
      "2453.pt\n",
      "2454.pt\n",
      "2455.pt\n",
      "2456.pt\n",
      "2457.pt\n",
      "2458.pt\n",
      "2459.pt\n",
      "2460.pt\n",
      "2461.pt\n",
      "2462.pt\n",
      "2463.pt\n",
      "2464.pt\n",
      "2465.pt\n",
      "2466.pt\n",
      "2467.pt\n",
      "2468.pt\n",
      "2469.pt\n",
      "2470.pt\n",
      "2471.pt\n",
      "2472.pt\n",
      "2473.pt\n",
      "2474.pt\n",
      "2475.pt\n",
      "2476.pt\n",
      "2477.pt\n",
      "2478.pt\n",
      "2479.pt\n",
      "2480.pt\n",
      "2481.pt\n",
      "2482.pt\n",
      "2483.pt\n",
      "2484.pt\n",
      "2485.pt\n",
      "2486.pt\n",
      "2487.pt\n",
      "2488.pt\n",
      "2489.pt\n",
      "2490.pt\n",
      "2491.pt\n",
      "2492.pt\n",
      "2493.pt\n",
      "2494.pt\n",
      "2495.pt\n",
      "2496.pt\n",
      "2497.pt\n",
      "2498.pt\n",
      "2499.pt\n",
      "2500.pt\n",
      "2501.pt\n",
      "2502.pt\n",
      "2503.pt\n",
      "2504.pt\n",
      "2505.pt\n",
      "2506.pt\n",
      "2507.pt\n",
      "2508.pt\n",
      "2509.pt\n",
      "2510.pt\n",
      "2511.pt\n",
      "2512.pt\n",
      "2513.pt\n",
      "2514.pt\n",
      "2515.pt\n",
      "2516.pt\n",
      "2517.pt\n",
      "2518.pt\n",
      "2519.pt\n",
      "2520.pt\n",
      "2521.pt\n",
      "2522.pt\n",
      "2523.pt\n",
      "2524.pt\n",
      "2525.pt\n",
      "2526.pt\n",
      "2527.pt\n",
      "2528.pt\n",
      "2529.pt\n",
      "2530.pt\n",
      "2531.pt\n",
      "2532.pt\n",
      "2533.pt\n",
      "2534.pt\n",
      "2535.pt\n",
      "2536.pt\n",
      "2537.pt\n",
      "2538.pt\n",
      "2539.pt\n",
      "2540.pt\n",
      "2541.pt\n",
      "2542.pt\n",
      "2543.pt\n",
      "2544.pt\n",
      "2545.pt\n",
      "2546.pt\n",
      "2547.pt\n",
      "2548.pt\n",
      "2549.pt\n",
      "2550.pt\n",
      "2551.pt\n",
      "2552.pt\n",
      "2553.pt\n",
      "2554.pt\n",
      "2555.pt\n",
      "2556.pt\n",
      "2557.pt\n",
      "2558.pt\n",
      "2559.pt\n",
      "2560.pt\n",
      "2561.pt\n",
      "2562.pt\n",
      "2563.pt\n",
      "2564.pt\n",
      "2565.pt\n",
      "2566.pt\n",
      "2567.pt\n",
      "2568.pt\n",
      "2569.pt\n",
      "2570.pt\n",
      "2571.pt\n",
      "2572.pt\n",
      "2573.pt\n",
      "2574.pt\n",
      "2575.pt\n",
      "2576.pt\n",
      "2577.pt\n",
      "2578.pt\n",
      "2579.pt\n",
      "2580.pt\n",
      "2581.pt\n",
      "2582.pt\n",
      "2583.pt\n",
      "2584.pt\n",
      "2585.pt\n",
      "2586.pt\n",
      "2587.pt\n",
      "2588.pt\n",
      "2589.pt\n",
      "2590.pt\n",
      "2591.pt\n",
      "2592.pt\n",
      "2593.pt\n",
      "2594.pt\n",
      "2595.pt\n",
      "2596.pt\n",
      "2597.pt\n",
      "2598.pt\n",
      "2599.pt\n",
      "2600.pt\n",
      "2601.pt\n",
      "2602.pt\n",
      "2603.pt\n",
      "2604.pt\n",
      "2605.pt\n",
      "2606.pt\n",
      "2607.pt\n",
      "2608.pt\n",
      "2609.pt\n",
      "2610.pt\n",
      "2611.pt\n",
      "2612.pt\n",
      "2613.pt\n",
      "2614.pt\n",
      "2615.pt\n",
      "2616.pt\n",
      "2617.pt\n",
      "2618.pt\n",
      "2619.pt\n",
      "2620.pt\n",
      "2621.pt\n",
      "2622.pt\n",
      "2623.pt\n",
      "2624.pt\n",
      "2625.pt\n",
      "2626.pt\n",
      "2627.pt\n",
      "2628.pt\n",
      "2629.pt\n",
      "2630.pt\n",
      "2631.pt\n",
      "2632.pt\n",
      "2633.pt\n",
      "2634.pt\n",
      "2635.pt\n",
      "2636.pt\n",
      "2637.pt\n",
      "2638.pt\n",
      "2639.pt\n",
      "2640.pt\n",
      "2641.pt\n",
      "2642.pt\n",
      "2643.pt\n",
      "2644.pt\n",
      "2645.pt\n",
      "2646.pt\n",
      "2647.pt\n",
      "2648.pt\n",
      "2649.pt\n",
      "2650.pt\n",
      "2651.pt\n",
      "2652.pt\n",
      "2653.pt\n",
      "2654.pt\n",
      "2655.pt\n",
      "2656.pt\n",
      "2657.pt\n",
      "2658.pt\n",
      "2659.pt\n",
      "2660.pt\n",
      "2661.pt\n",
      "2662.pt\n",
      "2663.pt\n",
      "2664.pt\n",
      "2665.pt\n",
      "2666.pt\n",
      "2667.pt\n",
      "2668.pt\n",
      "2669.pt\n",
      "2670.pt\n",
      "2671.pt\n",
      "2672.pt\n",
      "2673.pt\n",
      "2674.pt\n",
      "2675.pt\n",
      "2676.pt\n",
      "2677.pt\n",
      "2678.pt\n",
      "2679.pt\n",
      "2680.pt\n",
      "2681.pt\n",
      "2682.pt\n",
      "2683.pt\n",
      "2684.pt\n",
      "2685.pt\n",
      "2686.pt\n",
      "2687.pt\n",
      "2688.pt\n",
      "2689.pt\n",
      "2690.pt\n",
      "2691.pt\n",
      "2692.pt\n",
      "2693.pt\n",
      "2694.pt\n",
      "2695.pt\n",
      "2696.pt\n",
      "2697.pt\n",
      "2698.pt\n",
      "2699.pt\n",
      "2700.pt\n",
      "2701.pt\n",
      "2702.pt\n",
      "2703.pt\n",
      "2704.pt\n",
      "2705.pt\n",
      "2706.pt\n",
      "2707.pt\n",
      "2708.pt\n",
      "2709.pt\n",
      "2710.pt\n",
      "2711.pt\n",
      "2712.pt\n",
      "2713.pt\n",
      "2714.pt\n",
      "2715.pt\n",
      "2716.pt\n",
      "2717.pt\n",
      "2718.pt\n",
      "2719.pt\n",
      "2720.pt\n",
      "2721.pt\n",
      "2722.pt\n",
      "2723.pt\n",
      "2724.pt\n",
      "2725.pt\n",
      "2726.pt\n",
      "2727.pt\n",
      "2728.pt\n",
      "2729.pt\n",
      "2730.pt\n",
      "2731.pt\n",
      "2732.pt\n",
      "2733.pt\n",
      "2734.pt\n",
      "2735.pt\n",
      "2736.pt\n",
      "2737.pt\n",
      "2738.pt\n",
      "2739.pt\n",
      "2740.pt\n",
      "2741.pt\n",
      "2742.pt\n",
      "2743.pt\n",
      "2744.pt\n",
      "2745.pt\n",
      "2746.pt\n",
      "2747.pt\n",
      "2748.pt\n",
      "2749.pt\n",
      "2750.pt\n",
      "2751.pt\n",
      "2752.pt\n",
      "2753.pt\n",
      "2754.pt\n",
      "2755.pt\n",
      "2756.pt\n",
      "2757.pt\n",
      "2758.pt\n",
      "2759.pt\n",
      "2760.pt\n",
      "2761.pt\n",
      "2762.pt\n",
      "2763.pt\n",
      "2764.pt\n",
      "2765.pt\n",
      "2766.pt\n",
      "2767.pt\n",
      "2768.pt\n",
      "2769.pt\n",
      "2770.pt\n",
      "2771.pt\n",
      "2772.pt\n",
      "2773.pt\n",
      "2774.pt\n",
      "2775.pt\n",
      "2776.pt\n",
      "2777.pt\n",
      "2778.pt\n",
      "2779.pt\n",
      "2780.pt\n",
      "2781.pt\n",
      "2782.pt\n",
      "2783.pt\n",
      "2784.pt\n",
      "2785.pt\n",
      "2786.pt\n",
      "2787.pt\n",
      "2788.pt\n",
      "2789.pt\n",
      "2790.pt\n",
      "2791.pt\n",
      "2792.pt\n",
      "2793.pt\n",
      "2794.pt\n",
      "2795.pt\n",
      "2796.pt\n",
      "2797.pt\n",
      "2798.pt\n",
      "2799.pt\n",
      "2800.pt\n",
      "2801.pt\n",
      "2802.pt\n",
      "2803.pt\n",
      "2804.pt\n",
      "2805.pt\n",
      "2806.pt\n",
      "2807.pt\n",
      "2808.pt\n",
      "2809.pt\n",
      "2810.pt\n",
      "2811.pt\n",
      "2812.pt\n",
      "2813.pt\n",
      "2814.pt\n",
      "2815.pt\n",
      "2816.pt\n",
      "2817.pt\n",
      "2818.pt\n",
      "2819.pt\n",
      "2820.pt\n",
      "2821.pt\n",
      "2822.pt\n",
      "2823.pt\n",
      "2824.pt\n",
      "2825.pt\n",
      "2826.pt\n",
      "2827.pt\n",
      "2828.pt\n",
      "2829.pt\n",
      "2830.pt\n",
      "2831.pt\n",
      "2832.pt\n",
      "2833.pt\n",
      "2834.pt\n",
      "2835.pt\n",
      "2836.pt\n",
      "2837.pt\n",
      "2838.pt\n",
      "2839.pt\n",
      "2840.pt\n",
      "2841.pt\n",
      "2842.pt\n",
      "2843.pt\n",
      "2844.pt\n",
      "2845.pt\n",
      "2846.pt\n",
      "2847.pt\n",
      "2848.pt\n",
      "2849.pt\n",
      "2850.pt\n",
      "2851.pt\n",
      "2852.pt\n",
      "2853.pt\n",
      "2854.pt\n",
      "2855.pt\n",
      "2856.pt\n",
      "2857.pt\n",
      "2858.pt\n",
      "2859.pt\n",
      "2860.pt\n",
      "2861.pt\n",
      "2862.pt\n",
      "2863.pt\n",
      "2864.pt\n",
      "2865.pt\n",
      "2866.pt\n",
      "2867.pt\n",
      "2868.pt\n",
      "2869.pt\n",
      "2870.pt\n",
      "2871.pt\n",
      "2872.pt\n",
      "2873.pt\n",
      "2874.pt\n",
      "2875.pt\n",
      "2876.pt\n",
      "2877.pt\n",
      "2878.pt\n",
      "2879.pt\n",
      "2880.pt\n",
      "2881.pt\n",
      "2882.pt\n",
      "2883.pt\n",
      "2884.pt\n",
      "2885.pt\n",
      "2886.pt\n",
      "2887.pt\n",
      "2888.pt\n",
      "2889.pt\n",
      "2890.pt\n",
      "2891.pt\n",
      "2892.pt\n",
      "2893.pt\n",
      "2894.pt\n",
      "2895.pt\n",
      "2896.pt\n",
      "2897.pt\n",
      "2898.pt\n",
      "2899.pt\n",
      "2900.pt\n",
      "2901.pt\n",
      "2902.pt\n",
      "2903.pt\n",
      "2904.pt\n",
      "2905.pt\n",
      "2906.pt\n",
      "2907.pt\n",
      "2908.pt\n",
      "2909.pt\n",
      "2910.pt\n",
      "2911.pt\n",
      "2912.pt\n",
      "2913.pt\n",
      "2914.pt\n",
      "2915.pt\n",
      "2916.pt\n",
      "2917.pt\n",
      "2918.pt\n",
      "2919.pt\n",
      "2920.pt\n",
      "2921.pt\n",
      "2922.pt\n",
      "2923.pt\n",
      "2924.pt\n",
      "2925.pt\n",
      "2926.pt\n",
      "2927.pt\n",
      "2928.pt\n",
      "2929.pt\n",
      "2930.pt\n",
      "2931.pt\n",
      "2932.pt\n",
      "2933.pt\n",
      "2934.pt\n",
      "2935.pt\n",
      "2936.pt\n",
      "2937.pt\n",
      "2938.pt\n",
      "2939.pt\n",
      "2940.pt\n",
      "2941.pt\n",
      "2942.pt\n",
      "2943.pt\n",
      "2944.pt\n",
      "2945.pt\n",
      "2946.pt\n",
      "2947.pt\n",
      "2948.pt\n",
      "2949.pt\n",
      "2950.pt\n",
      "2951.pt\n",
      "2952.pt\n",
      "2953.pt\n",
      "2954.pt\n",
      "2955.pt\n",
      "2956.pt\n",
      "2957.pt\n",
      "2958.pt\n",
      "2959.pt\n",
      "2960.pt\n",
      "2961.pt\n",
      "2962.pt\n",
      "2963.pt\n",
      "2964.pt\n",
      "2965.pt\n",
      "2966.pt\n",
      "2967.pt\n",
      "2968.pt\n",
      "2969.pt\n",
      "2970.pt\n",
      "2971.pt\n",
      "2972.pt\n",
      "2973.pt\n",
      "2974.pt\n",
      "2975.pt\n",
      "2976.pt\n",
      "2977.pt\n",
      "2978.pt\n",
      "2979.pt\n",
      "2980.pt\n",
      "2981.pt\n",
      "2982.pt\n",
      "2983.pt\n",
      "2984.pt\n",
      "2985.pt\n",
      "2986.pt\n",
      "2987.pt\n",
      "2988.pt\n",
      "2989.pt\n",
      "2990.pt\n",
      "2991.pt\n",
      "2992.pt\n",
      "2993.pt\n",
      "2994.pt\n",
      "2995.pt\n",
      "2996.pt\n",
      "2997.pt\n",
      "2998.pt\n",
      "2999.pt\n",
      "3000.pt\n",
      "3001.pt\n",
      "3002.pt\n",
      "3003.pt\n",
      "3004.pt\n",
      "3005.pt\n",
      "3006.pt\n",
      "3007.pt\n",
      "3008.pt\n",
      "3009.pt\n",
      "3010.pt\n",
      "3011.pt\n",
      "3012.pt\n",
      "3013.pt\n",
      "3014.pt\n",
      "3015.pt\n",
      "3016.pt\n",
      "3017.pt\n",
      "3018.pt\n",
      "3019.pt\n",
      "3020.pt\n",
      "3021.pt\n",
      "3022.pt\n",
      "3023.pt\n",
      "3024.pt\n",
      "3025.pt\n",
      "3026.pt\n",
      "3027.pt\n",
      "3028.pt\n",
      "3029.pt\n",
      "3030.pt\n",
      "3031.pt\n",
      "3032.pt\n",
      "3033.pt\n",
      "3034.pt\n",
      "3035.pt\n",
      "3036.pt\n",
      "3037.pt\n",
      "3038.pt\n",
      "3039.pt\n",
      "3040.pt\n",
      "3041.pt\n",
      "3042.pt\n",
      "3043.pt\n",
      "3044.pt\n",
      "3045.pt\n",
      "3046.pt\n",
      "3047.pt\n",
      "3048.pt\n",
      "3049.pt\n",
      "3050.pt\n",
      "3051.pt\n",
      "3052.pt\n",
      "3053.pt\n",
      "3054.pt\n",
      "3055.pt\n",
      "3056.pt\n",
      "3057.pt\n",
      "3058.pt\n",
      "3059.pt\n",
      "3060.pt\n",
      "3061.pt\n",
      "3062.pt\n",
      "3063.pt\n",
      "3064.pt\n",
      "3065.pt\n",
      "3066.pt\n",
      "3067.pt\n",
      "3068.pt\n",
      "3069.pt\n",
      "3070.pt\n",
      "3071.pt\n",
      "3072.pt\n",
      "3073.pt\n",
      "3074.pt\n",
      "3075.pt\n",
      "3076.pt\n",
      "3077.pt\n",
      "3078.pt\n",
      "3079.pt\n",
      "3080.pt\n",
      "3081.pt\n",
      "3082.pt\n",
      "3083.pt\n",
      "3084.pt\n",
      "3085.pt\n",
      "3086.pt\n",
      "3087.pt\n",
      "3088.pt\n",
      "3089.pt\n",
      "3090.pt\n",
      "3091.pt\n",
      "3092.pt\n",
      "3093.pt\n",
      "3094.pt\n",
      "3095.pt\n",
      "3096.pt\n",
      "3097.pt\n",
      "3098.pt\n",
      "3099.pt\n",
      "3100.pt\n",
      "3101.pt\n",
      "3102.pt\n",
      "3103.pt\n",
      "3104.pt\n",
      "3105.pt\n",
      "3106.pt\n",
      "3107.pt\n",
      "3108.pt\n",
      "3109.pt\n",
      "3110.pt\n",
      "3111.pt\n",
      "3112.pt\n",
      "3113.pt\n",
      "3114.pt\n",
      "3115.pt\n",
      "3116.pt\n",
      "3117.pt\n",
      "3118.pt\n",
      "3119.pt\n",
      "3120.pt\n",
      "3121.pt\n",
      "3122.pt\n",
      "3123.pt\n",
      "3124.pt\n",
      "3125.pt\n",
      "3126.pt\n",
      "3127.pt\n",
      "3128.pt\n",
      "3129.pt\n",
      "3130.pt\n",
      "3131.pt\n",
      "3132.pt\n",
      "3133.pt\n",
      "3134.pt\n",
      "3135.pt\n",
      "3136.pt\n",
      "3137.pt\n",
      "3138.pt\n",
      "3139.pt\n",
      "3140.pt\n",
      "3141.pt\n",
      "3142.pt\n",
      "3143.pt\n",
      "3144.pt\n",
      "3145.pt\n",
      "3146.pt\n",
      "3147.pt\n",
      "3148.pt\n",
      "3149.pt\n",
      "3150.pt\n",
      "3151.pt\n",
      "3152.pt\n",
      "3153.pt\n",
      "3154.pt\n",
      "3155.pt\n",
      "3156.pt\n",
      "3157.pt\n",
      "3158.pt\n",
      "3159.pt\n",
      "3160.pt\n",
      "3161.pt\n",
      "3162.pt\n",
      "3163.pt\n",
      "3164.pt\n",
      "3165.pt\n",
      "3166.pt\n",
      "3167.pt\n",
      "3168.pt\n",
      "3169.pt\n",
      "3170.pt\n",
      "3171.pt\n",
      "3172.pt\n",
      "3173.pt\n",
      "3174.pt\n",
      "3175.pt\n",
      "3176.pt\n",
      "3177.pt\n",
      "3178.pt\n",
      "3179.pt\n",
      "3180.pt\n",
      "3181.pt\n",
      "3182.pt\n",
      "3183.pt\n",
      "3184.pt\n",
      "3185.pt\n",
      "3186.pt\n",
      "3187.pt\n",
      "3188.pt\n",
      "3189.pt\n",
      "3190.pt\n",
      "3191.pt\n",
      "3192.pt\n",
      "3193.pt\n",
      "3194.pt\n",
      "3195.pt\n",
      "3196.pt\n",
      "3197.pt\n",
      "3198.pt\n",
      "3199.pt\n",
      "3200.pt\n",
      "3201.pt\n",
      "3202.pt\n",
      "3203.pt\n",
      "3204.pt\n",
      "3205.pt\n",
      "3206.pt\n",
      "3207.pt\n",
      "3208.pt\n",
      "3209.pt\n",
      "3210.pt\n",
      "3211.pt\n",
      "3212.pt\n",
      "3213.pt\n",
      "3214.pt\n",
      "3215.pt\n",
      "3216.pt\n",
      "3217.pt\n",
      "3218.pt\n",
      "3219.pt\n",
      "3220.pt\n",
      "3221.pt\n",
      "3222.pt\n",
      "3223.pt\n",
      "3224.pt\n",
      "3225.pt\n",
      "3226.pt\n",
      "3227.pt\n",
      "3228.pt\n",
      "3229.pt\n",
      "3230.pt\n",
      "3231.pt\n",
      "3232.pt\n",
      "3233.pt\n",
      "3234.pt\n",
      "3235.pt\n",
      "3236.pt\n",
      "3237.pt\n",
      "3238.pt\n",
      "3239.pt\n",
      "3240.pt\n",
      "3241.pt\n",
      "3242.pt\n",
      "3243.pt\n",
      "3244.pt\n",
      "3245.pt\n",
      "3246.pt\n",
      "3247.pt\n",
      "3248.pt\n",
      "3249.pt\n",
      "3250.pt\n",
      "3251.pt\n",
      "3252.pt\n",
      "3253.pt\n",
      "3254.pt\n",
      "3255.pt\n",
      "3256.pt\n",
      "3257.pt\n",
      "3258.pt\n",
      "3259.pt\n",
      "3260.pt\n",
      "3261.pt\n",
      "3262.pt\n",
      "3263.pt\n",
      "3264.pt\n",
      "3265.pt\n",
      "3266.pt\n",
      "3267.pt\n",
      "3268.pt\n",
      "3269.pt\n",
      "3270.pt\n",
      "3271.pt\n",
      "3272.pt\n",
      "3273.pt\n",
      "3274.pt\n",
      "3275.pt\n",
      "3276.pt\n",
      "3277.pt\n",
      "3278.pt\n",
      "3279.pt\n",
      "3280.pt\n",
      "3281.pt\n",
      "3282.pt\n",
      "3283.pt\n",
      "3284.pt\n",
      "3285.pt\n",
      "3286.pt\n",
      "3287.pt\n",
      "3288.pt\n",
      "3289.pt\n",
      "3290.pt\n",
      "3291.pt\n",
      "3292.pt\n",
      "3293.pt\n",
      "3294.pt\n",
      "3295.pt\n",
      "3296.pt\n",
      "3297.pt\n",
      "3298.pt\n",
      "3299.pt\n",
      "3300.pt\n",
      "3301.pt\n",
      "3302.pt\n",
      "3303.pt\n",
      "3304.pt\n",
      "3305.pt\n",
      "3306.pt\n",
      "3307.pt\n",
      "3308.pt\n",
      "3309.pt\n",
      "3310.pt\n",
      "3311.pt\n",
      "3312.pt\n",
      "3313.pt\n",
      "3314.pt\n",
      "3315.pt\n",
      "3316.pt\n",
      "3317.pt\n",
      "3318.pt\n",
      "3319.pt\n",
      "3320.pt\n",
      "3321.pt\n",
      "3322.pt\n",
      "3323.pt\n",
      "3324.pt\n",
      "3325.pt\n",
      "3326.pt\n",
      "3327.pt\n",
      "3328.pt\n",
      "3329.pt\n",
      "3330.pt\n",
      "3331.pt\n",
      "3332.pt\n",
      "3333.pt\n",
      "3334.pt\n",
      "3335.pt\n",
      "3336.pt\n",
      "3337.pt\n",
      "3338.pt\n",
      "3339.pt\n",
      "3340.pt\n",
      "3341.pt\n",
      "3342.pt\n",
      "3343.pt\n",
      "3344.pt\n",
      "3345.pt\n",
      "3346.pt\n",
      "3347.pt\n",
      "3348.pt\n",
      "3349.pt\n",
      "3350.pt\n",
      "3351.pt\n",
      "3352.pt\n",
      "3353.pt\n",
      "3354.pt\n",
      "3355.pt\n",
      "3356.pt\n",
      "3357.pt\n",
      "3358.pt\n",
      "3359.pt\n",
      "3360.pt\n",
      "3361.pt\n",
      "3362.pt\n",
      "3363.pt\n",
      "3364.pt\n",
      "3365.pt\n",
      "3366.pt\n",
      "3367.pt\n",
      "3368.pt\n",
      "3369.pt\n",
      "3370.pt\n",
      "3371.pt\n",
      "3372.pt\n",
      "3373.pt\n",
      "3374.pt\n",
      "3375.pt\n",
      "3376.pt\n",
      "3377.pt\n",
      "3378.pt\n",
      "3379.pt\n",
      "3380.pt\n",
      "3381.pt\n",
      "3382.pt\n",
      "3383.pt\n",
      "3384.pt\n",
      "3385.pt\n",
      "3386.pt\n",
      "3387.pt\n",
      "3388.pt\n",
      "3389.pt\n",
      "3390.pt\n",
      "3391.pt\n",
      "3392.pt\n",
      "3393.pt\n",
      "3394.pt\n",
      "3395.pt\n",
      "3396.pt\n",
      "3397.pt\n",
      "3398.pt\n",
      "3399.pt\n",
      "3400.pt\n",
      "3401.pt\n",
      "3402.pt\n",
      "3403.pt\n",
      "3404.pt\n",
      "3405.pt\n",
      "3406.pt\n",
      "3407.pt\n",
      "3408.pt\n",
      "3409.pt\n",
      "3410.pt\n",
      "3411.pt\n",
      "3412.pt\n",
      "3413.pt\n",
      "3414.pt\n",
      "3415.pt\n",
      "3416.pt\n",
      "3417.pt\n",
      "3418.pt\n",
      "3419.pt\n",
      "3420.pt\n",
      "3421.pt\n",
      "3422.pt\n",
      "3423.pt\n",
      "3424.pt\n",
      "3425.pt\n",
      "3426.pt\n",
      "3427.pt\n",
      "3428.pt\n",
      "3429.pt\n",
      "3430.pt\n",
      "3431.pt\n",
      "3432.pt\n",
      "3433.pt\n",
      "3434.pt\n",
      "3435.pt\n",
      "3436.pt\n",
      "3437.pt\n",
      "3438.pt\n",
      "3439.pt\n",
      "3440.pt\n",
      "3441.pt\n",
      "3442.pt\n",
      "3443.pt\n",
      "3444.pt\n",
      "3445.pt\n",
      "3446.pt\n",
      "3447.pt\n",
      "3448.pt\n",
      "3449.pt\n",
      "3450.pt\n",
      "3451.pt\n",
      "3452.pt\n",
      "3453.pt\n",
      "3454.pt\n",
      "3455.pt\n",
      "3456.pt\n",
      "3457.pt\n",
      "3458.pt\n",
      "3459.pt\n",
      "3460.pt\n",
      "3461.pt\n",
      "3462.pt\n",
      "3463.pt\n",
      "3464.pt\n",
      "3465.pt\n",
      "3466.pt\n",
      "3467.pt\n",
      "3468.pt\n",
      "3469.pt\n",
      "3470.pt\n",
      "3471.pt\n",
      "3472.pt\n",
      "3473.pt\n",
      "3474.pt\n",
      "3475.pt\n",
      "3476.pt\n",
      "3477.pt\n",
      "3478.pt\n",
      "3479.pt\n",
      "3480.pt\n",
      "3481.pt\n",
      "3482.pt\n",
      "3483.pt\n",
      "3484.pt\n",
      "3485.pt\n",
      "3486.pt\n",
      "3487.pt\n",
      "3488.pt\n",
      "3489.pt\n",
      "3490.pt\n",
      "3491.pt\n",
      "3492.pt\n",
      "3493.pt\n",
      "3494.pt\n",
      "3495.pt\n",
      "3496.pt\n",
      "3497.pt\n",
      "3498.pt\n",
      "3499.pt\n",
      "3500.pt\n",
      "3501.pt\n",
      "3502.pt\n",
      "3503.pt\n",
      "3504.pt\n",
      "3505.pt\n",
      "3506.pt\n",
      "3507.pt\n",
      "3508.pt\n",
      "3509.pt\n",
      "3510.pt\n",
      "3511.pt\n",
      "3512.pt\n",
      "3513.pt\n",
      "3514.pt\n",
      "3515.pt\n",
      "3516.pt\n",
      "3517.pt\n",
      "3518.pt\n",
      "3519.pt\n",
      "3520.pt\n",
      "3521.pt\n",
      "3522.pt\n",
      "3523.pt\n",
      "3524.pt\n",
      "3525.pt\n",
      "3526.pt\n",
      "3527.pt\n",
      "3528.pt\n",
      "3529.pt\n",
      "3530.pt\n",
      "3531.pt\n",
      "3532.pt\n",
      "3533.pt\n",
      "3534.pt\n",
      "3535.pt\n",
      "3536.pt\n",
      "3537.pt\n",
      "3538.pt\n",
      "3539.pt\n",
      "3540.pt\n",
      "3541.pt\n",
      "3542.pt\n",
      "3543.pt\n",
      "3544.pt\n",
      "3545.pt\n",
      "3546.pt\n",
      "3547.pt\n",
      "3548.pt\n",
      "3549.pt\n",
      "3550.pt\n",
      "3551.pt\n",
      "3552.pt\n",
      "3553.pt\n",
      "3554.pt\n",
      "3555.pt\n",
      "3556.pt\n",
      "3557.pt\n",
      "3558.pt\n",
      "3559.pt\n",
      "3560.pt\n",
      "3561.pt\n",
      "3562.pt\n",
      "3563.pt\n",
      "3564.pt\n",
      "3565.pt\n",
      "3566.pt\n",
      "3567.pt\n",
      "3568.pt\n",
      "3569.pt\n",
      "3570.pt\n",
      "3571.pt\n",
      "3572.pt\n",
      "3573.pt\n",
      "3574.pt\n",
      "3575.pt\n",
      "3576.pt\n",
      "3577.pt\n",
      "3578.pt\n",
      "3579.pt\n",
      "3580.pt\n",
      "3581.pt\n",
      "3582.pt\n",
      "3583.pt\n",
      "3584.pt\n",
      "3585.pt\n",
      "3586.pt\n",
      "3587.pt\n",
      "3588.pt\n",
      "3589.pt\n",
      "3590.pt\n",
      "3591.pt\n",
      "3592.pt\n",
      "3593.pt\n",
      "3594.pt\n",
      "3595.pt\n",
      "3596.pt\n",
      "3597.pt\n",
      "3598.pt\n",
      "3599.pt\n",
      "3600.pt\n",
      "3601.pt\n",
      "3602.pt\n",
      "3603.pt\n",
      "3604.pt\n",
      "3605.pt\n",
      "3606.pt\n",
      "3607.pt\n",
      "3608.pt\n",
      "3609.pt\n",
      "3610.pt\n",
      "3611.pt\n",
      "3612.pt\n",
      "3613.pt\n",
      "3614.pt\n",
      "3615.pt\n",
      "3616.pt\n",
      "3617.pt\n",
      "3618.pt\n",
      "3619.pt\n",
      "3620.pt\n",
      "3621.pt\n",
      "3622.pt\n",
      "3623.pt\n",
      "3624.pt\n",
      "3625.pt\n",
      "3626.pt\n",
      "3627.pt\n",
      "3628.pt\n",
      "3629.pt\n",
      "3630.pt\n",
      "3631.pt\n",
      "3632.pt\n",
      "3633.pt\n",
      "3634.pt\n",
      "3635.pt\n",
      "3636.pt\n",
      "3637.pt\n",
      "3638.pt\n",
      "3639.pt\n",
      "3640.pt\n",
      "3641.pt\n",
      "3642.pt\n",
      "3643.pt\n",
      "3644.pt\n",
      "3645.pt\n",
      "3646.pt\n",
      "3647.pt\n",
      "3648.pt\n",
      "3649.pt\n",
      "3650.pt\n",
      "3651.pt\n",
      "3652.pt\n",
      "3653.pt\n",
      "3654.pt\n",
      "3655.pt\n",
      "3656.pt\n",
      "3657.pt\n",
      "3658.pt\n",
      "3659.pt\n",
      "3660.pt\n",
      "3661.pt\n",
      "3662.pt\n",
      "3663.pt\n",
      "3664.pt\n",
      "3665.pt\n",
      "3666.pt\n",
      "3667.pt\n",
      "3668.pt\n",
      "3669.pt\n",
      "3670.pt\n",
      "3671.pt\n",
      "3672.pt\n",
      "3673.pt\n",
      "3674.pt\n",
      "3675.pt\n",
      "3676.pt\n",
      "3677.pt\n",
      "3678.pt\n",
      "3679.pt\n",
      "3680.pt\n",
      "3681.pt\n",
      "3682.pt\n",
      "3683.pt\n",
      "3684.pt\n",
      "3685.pt\n",
      "3686.pt\n",
      "3687.pt\n",
      "3688.pt\n",
      "3689.pt\n",
      "3690.pt\n",
      "3691.pt\n",
      "3692.pt\n",
      "3693.pt\n",
      "3694.pt\n",
      "3695.pt\n",
      "3696.pt\n",
      "3697.pt\n",
      "3698.pt\n",
      "3699.pt\n",
      "3700.pt\n",
      "3701.pt\n",
      "3702.pt\n",
      "3703.pt\n",
      "3704.pt\n",
      "3705.pt\n",
      "3706.pt\n",
      "3707.pt\n",
      "3708.pt\n",
      "3709.pt\n",
      "3710.pt\n",
      "3711.pt\n",
      "3712.pt\n",
      "3713.pt\n",
      "3714.pt\n",
      "3715.pt\n",
      "3716.pt\n",
      "3717.pt\n",
      "3718.pt\n",
      "3719.pt\n",
      "3720.pt\n",
      "3721.pt\n",
      "3722.pt\n",
      "3723.pt\n",
      "3724.pt\n",
      "3725.pt\n",
      "3726.pt\n",
      "3727.pt\n",
      "3728.pt\n",
      "3729.pt\n",
      "3730.pt\n",
      "3731.pt\n",
      "3732.pt\n",
      "3733.pt\n",
      "3734.pt\n",
      "3735.pt\n",
      "3736.pt\n",
      "3737.pt\n",
      "3738.pt\n",
      "3739.pt\n",
      "3740.pt\n",
      "3741.pt\n",
      "3742.pt\n",
      "3743.pt\n",
      "3744.pt\n",
      "3745.pt\n",
      "3746.pt\n",
      "3747.pt\n",
      "3748.pt\n",
      "3749.pt\n",
      "3750.pt\n",
      "3751.pt\n",
      "3752.pt\n",
      "3753.pt\n",
      "3754.pt\n",
      "3755.pt\n",
      "3756.pt\n",
      "3757.pt\n",
      "3758.pt\n",
      "3759.pt\n",
      "3760.pt\n",
      "3761.pt\n",
      "3762.pt\n",
      "3763.pt\n",
      "3764.pt\n",
      "3765.pt\n",
      "3766.pt\n",
      "3767.pt\n",
      "3768.pt\n",
      "3769.pt\n",
      "3770.pt\n",
      "3771.pt\n",
      "3772.pt\n",
      "3773.pt\n",
      "3774.pt\n",
      "3775.pt\n",
      "3776.pt\n",
      "3777.pt\n",
      "3778.pt\n",
      "3779.pt\n",
      "3780.pt\n",
      "3781.pt\n",
      "3782.pt\n",
      "3783.pt\n",
      "3784.pt\n",
      "3785.pt\n",
      "3786.pt\n",
      "3787.pt\n",
      "3788.pt\n",
      "3789.pt\n",
      "3790.pt\n",
      "3791.pt\n",
      "3792.pt\n",
      "3793.pt\n",
      "3794.pt\n",
      "3795.pt\n",
      "3796.pt\n",
      "3797.pt\n",
      "3798.pt\n",
      "3799.pt\n",
      "3800.pt\n",
      "3801.pt\n",
      "3802.pt\n",
      "3803.pt\n",
      "3804.pt\n",
      "3805.pt\n",
      "3806.pt\n",
      "3807.pt\n",
      "3808.pt\n",
      "3809.pt\n",
      "3810.pt\n",
      "3811.pt\n",
      "3812.pt\n",
      "3813.pt\n",
      "3814.pt\n",
      "3815.pt\n",
      "3816.pt\n",
      "3817.pt\n",
      "3818.pt\n",
      "3819.pt\n",
      "3820.pt\n",
      "3821.pt\n",
      "3822.pt\n",
      "3823.pt\n",
      "3824.pt\n",
      "3825.pt\n",
      "3826.pt\n",
      "3827.pt\n",
      "3828.pt\n",
      "3829.pt\n",
      "3830.pt\n",
      "3831.pt\n",
      "3832.pt\n",
      "3833.pt\n",
      "3834.pt\n",
      "3835.pt\n",
      "3836.pt\n",
      "3837.pt\n",
      "3838.pt\n",
      "3839.pt\n",
      "3840.pt\n",
      "3841.pt\n",
      "3842.pt\n",
      "3843.pt\n",
      "3844.pt\n",
      "3845.pt\n",
      "3846.pt\n",
      "3847.pt\n",
      "3848.pt\n",
      "3849.pt\n",
      "3850.pt\n",
      "3851.pt\n",
      "3852.pt\n",
      "3853.pt\n",
      "3854.pt\n",
      "3855.pt\n",
      "3856.pt\n",
      "3857.pt\n",
      "3858.pt\n",
      "3859.pt\n",
      "3860.pt\n",
      "3861.pt\n",
      "3862.pt\n",
      "3863.pt\n",
      "3864.pt\n",
      "3865.pt\n",
      "3866.pt\n",
      "3867.pt\n",
      "3868.pt\n",
      "3869.pt\n",
      "3870.pt\n",
      "3871.pt\n",
      "3872.pt\n",
      "3873.pt\n",
      "3874.pt\n",
      "3875.pt\n",
      "3876.pt\n",
      "3877.pt\n",
      "3878.pt\n",
      "3879.pt\n",
      "3880.pt\n",
      "3881.pt\n",
      "3882.pt\n",
      "3883.pt\n",
      "3884.pt\n",
      "3885.pt\n",
      "3886.pt\n",
      "3887.pt\n",
      "3888.pt\n",
      "3889.pt\n",
      "3890.pt\n",
      "3891.pt\n",
      "3892.pt\n",
      "3893.pt\n",
      "3894.pt\n",
      "3895.pt\n",
      "3896.pt\n",
      "3897.pt\n",
      "3898.pt\n",
      "3899.pt\n",
      "3900.pt\n",
      "3901.pt\n",
      "3902.pt\n",
      "3903.pt\n",
      "3904.pt\n",
      "3905.pt\n",
      "3906.pt\n",
      "3907.pt\n",
      "3908.pt\n",
      "3909.pt\n",
      "3910.pt\n",
      "3911.pt\n",
      "3912.pt\n",
      "3913.pt\n",
      "3914.pt\n",
      "3915.pt\n",
      "3916.pt\n",
      "3917.pt\n",
      "3918.pt\n",
      "3919.pt\n",
      "3920.pt\n",
      "3921.pt\n",
      "3922.pt\n",
      "3923.pt\n",
      "3924.pt\n",
      "3925.pt\n",
      "3926.pt\n",
      "3927.pt\n",
      "3928.pt\n",
      "3929.pt\n",
      "3930.pt\n",
      "3931.pt\n",
      "3932.pt\n",
      "3933.pt\n",
      "3934.pt\n",
      "3935.pt\n",
      "3936.pt\n",
      "3937.pt\n",
      "3938.pt\n",
      "3939.pt\n",
      "3940.pt\n",
      "3941.pt\n",
      "3942.pt\n",
      "3943.pt\n",
      "3944.pt\n",
      "3945.pt\n",
      "3946.pt\n",
      "3947.pt\n",
      "3948.pt\n",
      "3949.pt\n",
      "3950.pt\n",
      "3951.pt\n",
      "3952.pt\n",
      "3953.pt\n",
      "3954.pt\n",
      "3955.pt\n",
      "3956.pt\n",
      "3957.pt\n",
      "3958.pt\n",
      "3959.pt\n",
      "3960.pt\n",
      "3961.pt\n",
      "3962.pt\n",
      "3963.pt\n",
      "3964.pt\n",
      "3965.pt\n",
      "3966.pt\n",
      "3967.pt\n",
      "3968.pt\n",
      "3969.pt\n",
      "3970.pt\n",
      "3971.pt\n",
      "3972.pt\n",
      "3973.pt\n",
      "3974.pt\n",
      "3975.pt\n",
      "3976.pt\n",
      "3977.pt\n",
      "3978.pt\n",
      "3979.pt\n",
      "3980.pt\n",
      "3981.pt\n",
      "3982.pt\n",
      "3983.pt\n",
      "3984.pt\n",
      "3985.pt\n",
      "3986.pt\n",
      "3987.pt\n",
      "3988.pt\n",
      "3989.pt\n",
      "3990.pt\n",
      "3991.pt\n",
      "3992.pt\n",
      "3993.pt\n",
      "3994.pt\n",
      "3995.pt\n",
      "3996.pt\n",
      "3997.pt\n",
      "3998.pt\n",
      "3999.pt\n",
      "4000.pt\n",
      "4001.pt\n",
      "4002.pt\n",
      "4003.pt\n",
      "4004.pt\n",
      "4005.pt\n",
      "4006.pt\n",
      "4007.pt\n",
      "4008.pt\n",
      "4009.pt\n",
      "4010.pt\n",
      "4011.pt\n",
      "4012.pt\n",
      "4013.pt\n",
      "4014.pt\n",
      "4015.pt\n",
      "4016.pt\n",
      "4017.pt\n",
      "4018.pt\n",
      "4019.pt\n",
      "4020.pt\n",
      "4021.pt\n",
      "4022.pt\n",
      "4023.pt\n",
      "4024.pt\n",
      "4025.pt\n",
      "4026.pt\n",
      "4027.pt\n",
      "4028.pt\n",
      "4029.pt\n",
      "4030.pt\n",
      "4031.pt\n",
      "4032.pt\n",
      "4033.pt\n",
      "4034.pt\n",
      "4035.pt\n",
      "4036.pt\n",
      "4037.pt\n",
      "4038.pt\n",
      "4039.pt\n",
      "4040.pt\n",
      "4041.pt\n",
      "4042.pt\n",
      "4043.pt\n",
      "4044.pt\n",
      "4045.pt\n",
      "4046.pt\n",
      "4047.pt\n",
      "4048.pt\n",
      "4049.pt\n",
      "4050.pt\n",
      "4051.pt\n",
      "4052.pt\n",
      "4053.pt\n",
      "4054.pt\n",
      "4055.pt\n",
      "4056.pt\n",
      "4057.pt\n",
      "4058.pt\n",
      "4059.pt\n",
      "4060.pt\n",
      "4061.pt\n",
      "4062.pt\n",
      "4063.pt\n",
      "4064.pt\n",
      "4065.pt\n",
      "4066.pt\n",
      "4067.pt\n",
      "4068.pt\n",
      "4069.pt\n",
      "4070.pt\n",
      "4071.pt\n",
      "4072.pt\n",
      "4073.pt\n",
      "4074.pt\n",
      "4075.pt\n",
      "4076.pt\n",
      "4077.pt\n",
      "4078.pt\n",
      "4079.pt\n",
      "4080.pt\n",
      "4081.pt\n",
      "4082.pt\n",
      "4083.pt\n",
      "4084.pt\n",
      "4085.pt\n",
      "4086.pt\n",
      "4087.pt\n",
      "4088.pt\n",
      "4089.pt\n",
      "4090.pt\n",
      "4091.pt\n",
      "4092.pt\n",
      "4093.pt\n",
      "4094.pt\n",
      "4095.pt\n",
      "4096.pt\n",
      "4097.pt\n",
      "4098.pt\n",
      "4099.pt\n",
      "4100.pt\n",
      "4101.pt\n",
      "4102.pt\n",
      "4103.pt\n",
      "4104.pt\n",
      "4105.pt\n",
      "4106.pt\n",
      "4107.pt\n",
      "4108.pt\n",
      "4109.pt\n",
      "4110.pt\n",
      "4111.pt\n",
      "4112.pt\n",
      "4113.pt\n",
      "4114.pt\n",
      "4115.pt\n",
      "4116.pt\n",
      "4117.pt\n",
      "4118.pt\n",
      "4119.pt\n",
      "4120.pt\n",
      "4121.pt\n",
      "4122.pt\n",
      "4123.pt\n",
      "4124.pt\n",
      "4125.pt\n",
      "4126.pt\n",
      "4127.pt\n",
      "4128.pt\n",
      "4129.pt\n",
      "4130.pt\n",
      "4131.pt\n",
      "4132.pt\n",
      "4133.pt\n",
      "4134.pt\n",
      "4135.pt\n",
      "4136.pt\n",
      "4137.pt\n",
      "4138.pt\n",
      "4139.pt\n",
      "4140.pt\n",
      "4141.pt\n",
      "4142.pt\n",
      "4143.pt\n",
      "4144.pt\n",
      "4145.pt\n",
      "4146.pt\n",
      "4147.pt\n",
      "4148.pt\n",
      "4149.pt\n",
      "4150.pt\n",
      "4151.pt\n",
      "4152.pt\n",
      "4153.pt\n",
      "4154.pt\n",
      "4155.pt\n",
      "4156.pt\n",
      "4157.pt\n",
      "4158.pt\n",
      "4159.pt\n",
      "4160.pt\n",
      "4161.pt\n",
      "4162.pt\n",
      "4163.pt\n",
      "4164.pt\n",
      "4165.pt\n",
      "4166.pt\n",
      "4167.pt\n",
      "4168.pt\n",
      "4169.pt\n",
      "4170.pt\n",
      "4171.pt\n",
      "4172.pt\n",
      "4173.pt\n",
      "4174.pt\n",
      "4175.pt\n",
      "4176.pt\n",
      "4177.pt\n",
      "4178.pt\n",
      "4179.pt\n",
      "4180.pt\n",
      "4181.pt\n",
      "4182.pt\n",
      "4183.pt\n",
      "4184.pt\n",
      "4185.pt\n",
      "4186.pt\n",
      "4187.pt\n",
      "4188.pt\n",
      "4189.pt\n",
      "4190.pt\n",
      "4191.pt\n",
      "4192.pt\n",
      "4193.pt\n",
      "4194.pt\n",
      "4195.pt\n",
      "4196.pt\n",
      "4197.pt\n",
      "4198.pt\n",
      "4199.pt\n",
      "4200.pt\n",
      "4201.pt\n",
      "4202.pt\n",
      "4203.pt\n",
      "4204.pt\n",
      "4205.pt\n",
      "4206.pt\n",
      "4207.pt\n",
      "4208.pt\n",
      "4209.pt\n",
      "4210.pt\n",
      "4211.pt\n",
      "4212.pt\n",
      "4213.pt\n",
      "4214.pt\n",
      "4215.pt\n",
      "4216.pt\n",
      "4217.pt\n",
      "4218.pt\n",
      "4219.pt\n",
      "4220.pt\n",
      "4221.pt\n",
      "4222.pt\n",
      "4223.pt\n",
      "4224.pt\n",
      "4225.pt\n",
      "4226.pt\n",
      "4227.pt\n",
      "4228.pt\n",
      "4229.pt\n",
      "4230.pt\n",
      "4231.pt\n",
      "4232.pt\n",
      "4233.pt\n",
      "4234.pt\n",
      "4235.pt\n",
      "4236.pt\n",
      "4237.pt\n",
      "4238.pt\n",
      "4239.pt\n",
      "4240.pt\n",
      "4241.pt\n",
      "4242.pt\n",
      "4243.pt\n",
      "4244.pt\n",
      "4245.pt\n",
      "4246.pt\n",
      "4247.pt\n",
      "4248.pt\n",
      "4249.pt\n",
      "4250.pt\n",
      "4251.pt\n",
      "4252.pt\n",
      "4253.pt\n",
      "4254.pt\n",
      "4255.pt\n",
      "4256.pt\n",
      "4257.pt\n",
      "4258.pt\n",
      "4259.pt\n",
      "4260.pt\n",
      "4261.pt\n",
      "4262.pt\n",
      "4263.pt\n",
      "4264.pt\n",
      "4265.pt\n",
      "4266.pt\n",
      "4267.pt\n",
      "4268.pt\n",
      "4269.pt\n",
      "4270.pt\n",
      "4271.pt\n",
      "4272.pt\n",
      "4273.pt\n",
      "4274.pt\n",
      "4275.pt\n",
      "4276.pt\n",
      "4277.pt\n",
      "4278.pt\n",
      "4279.pt\n",
      "4280.pt\n",
      "4281.pt\n",
      "4282.pt\n",
      "4283.pt\n",
      "4284.pt\n",
      "4285.pt\n",
      "4286.pt\n",
      "4287.pt\n",
      "4288.pt\n",
      "4289.pt\n",
      "4290.pt\n",
      "4291.pt\n",
      "4292.pt\n",
      "4293.pt\n",
      "4294.pt\n",
      "4295.pt\n",
      "4296.pt\n",
      "4297.pt\n",
      "4298.pt\n",
      "4299.pt\n",
      "4300.pt\n",
      "4301.pt\n",
      "4302.pt\n",
      "4303.pt\n",
      "4304.pt\n",
      "4305.pt\n",
      "4306.pt\n",
      "4307.pt\n",
      "4308.pt\n",
      "4309.pt\n",
      "4310.pt\n",
      "4311.pt\n",
      "4312.pt\n",
      "4313.pt\n",
      "4314.pt\n",
      "4315.pt\n",
      "4316.pt\n",
      "4317.pt\n",
      "4318.pt\n",
      "4319.pt\n",
      "4320.pt\n",
      "4321.pt\n",
      "4322.pt\n",
      "4323.pt\n",
      "4324.pt\n",
      "4325.pt\n",
      "4326.pt\n",
      "4327.pt\n",
      "4328.pt\n",
      "4329.pt\n",
      "4330.pt\n",
      "4331.pt\n",
      "4332.pt\n",
      "4333.pt\n",
      "4334.pt\n",
      "4335.pt\n",
      "4336.pt\n",
      "4337.pt\n",
      "4338.pt\n",
      "4339.pt\n",
      "4340.pt\n",
      "4341.pt\n",
      "4342.pt\n",
      "4343.pt\n",
      "4344.pt\n",
      "4345.pt\n",
      "4346.pt\n",
      "4347.pt\n",
      "4348.pt\n",
      "4349.pt\n",
      "4350.pt\n",
      "4351.pt\n",
      "4352.pt\n",
      "4353.pt\n",
      "4354.pt\n",
      "4355.pt\n",
      "4356.pt\n",
      "4357.pt\n",
      "4358.pt\n",
      "4359.pt\n",
      "4360.pt\n",
      "4361.pt\n",
      "4362.pt\n",
      "4363.pt\n",
      "4364.pt\n",
      "4365.pt\n",
      "4366.pt\n",
      "4367.pt\n",
      "4368.pt\n",
      "4369.pt\n",
      "4370.pt\n",
      "4371.pt\n",
      "4372.pt\n",
      "4373.pt\n",
      "4374.pt\n",
      "4375.pt\n",
      "4376.pt\n",
      "4377.pt\n",
      "4378.pt\n",
      "4379.pt\n",
      "4380.pt\n",
      "4381.pt\n",
      "4382.pt\n",
      "4383.pt\n",
      "4384.pt\n",
      "4385.pt\n",
      "4386.pt\n",
      "4387.pt\n",
      "4388.pt\n",
      "4389.pt\n",
      "4390.pt\n",
      "4391.pt\n",
      "4392.pt\n",
      "4393.pt\n",
      "4394.pt\n",
      "4395.pt\n",
      "4396.pt\n",
      "4397.pt\n",
      "4398.pt\n",
      "4399.pt\n",
      "4400.pt\n",
      "4401.pt\n",
      "4402.pt\n",
      "4403.pt\n",
      "4404.pt\n",
      "4405.pt\n",
      "4406.pt\n",
      "4407.pt\n",
      "4408.pt\n",
      "4409.pt\n",
      "4410.pt\n",
      "4411.pt\n",
      "4412.pt\n",
      "4413.pt\n",
      "4414.pt\n",
      "4415.pt\n",
      "4416.pt\n",
      "4417.pt\n",
      "4418.pt\n",
      "4419.pt\n",
      "4420.pt\n",
      "4421.pt\n",
      "4422.pt\n",
      "4423.pt\n",
      "4424.pt\n",
      "4425.pt\n",
      "4426.pt\n",
      "4427.pt\n",
      "4428.pt\n",
      "4429.pt\n",
      "4430.pt\n",
      "4431.pt\n",
      "4432.pt\n",
      "4433.pt\n",
      "4434.pt\n",
      "4435.pt\n",
      "4436.pt\n",
      "4437.pt\n",
      "4438.pt\n",
      "4439.pt\n",
      "4440.pt\n",
      "4441.pt\n",
      "4442.pt\n",
      "4443.pt\n",
      "4444.pt\n",
      "4445.pt\n",
      "4446.pt\n",
      "4447.pt\n",
      "4448.pt\n",
      "4449.pt\n",
      "4450.pt\n",
      "4451.pt\n",
      "4452.pt\n",
      "4453.pt\n",
      "4454.pt\n",
      "4455.pt\n",
      "4456.pt\n",
      "4457.pt\n",
      "4458.pt\n",
      "4459.pt\n",
      "4460.pt\n",
      "4461.pt\n",
      "4462.pt\n",
      "4463.pt\n",
      "4464.pt\n",
      "4465.pt\n",
      "4466.pt\n",
      "4467.pt\n",
      "4468.pt\n",
      "4469.pt\n",
      "4470.pt\n",
      "4471.pt\n",
      "4472.pt\n",
      "4473.pt\n",
      "4474.pt\n",
      "4475.pt\n",
      "4476.pt\n",
      "4477.pt\n",
      "4478.pt\n",
      "4479.pt\n",
      "4480.pt\n",
      "4481.pt\n",
      "4482.pt\n",
      "4483.pt\n",
      "4484.pt\n",
      "4485.pt\n",
      "4486.pt\n",
      "4487.pt\n",
      "4488.pt\n",
      "4489.pt\n",
      "4490.pt\n",
      "4491.pt\n",
      "4492.pt\n",
      "4493.pt\n",
      "4494.pt\n",
      "4495.pt\n",
      "4496.pt\n",
      "4497.pt\n",
      "4498.pt\n",
      "4499.pt\n",
      "4500.pt\n",
      "4501.pt\n",
      "4502.pt\n",
      "4503.pt\n",
      "4504.pt\n",
      "4505.pt\n",
      "4506.pt\n",
      "4507.pt\n",
      "4508.pt\n",
      "4509.pt\n",
      "4510.pt\n",
      "4511.pt\n",
      "4512.pt\n",
      "4513.pt\n",
      "4514.pt\n",
      "4515.pt\n",
      "4516.pt\n",
      "4517.pt\n",
      "4518.pt\n",
      "4519.pt\n",
      "4520.pt\n",
      "4521.pt\n",
      "4522.pt\n",
      "4523.pt\n",
      "4524.pt\n",
      "4525.pt\n",
      "4526.pt\n",
      "4527.pt\n",
      "4528.pt\n",
      "4529.pt\n",
      "4530.pt\n",
      "4531.pt\n",
      "4532.pt\n",
      "4533.pt\n",
      "4534.pt\n",
      "4535.pt\n",
      "4536.pt\n",
      "4537.pt\n",
      "4538.pt\n",
      "4539.pt\n",
      "4540.pt\n",
      "4541.pt\n",
      "4542.pt\n",
      "4543.pt\n",
      "4544.pt\n",
      "4545.pt\n",
      "4546.pt\n",
      "4547.pt\n",
      "4548.pt\n",
      "4549.pt\n",
      "4550.pt\n",
      "4551.pt\n",
      "4552.pt\n",
      "4553.pt\n",
      "4554.pt\n",
      "4555.pt\n",
      "4556.pt\n",
      "4557.pt\n",
      "4558.pt\n",
      "4559.pt\n",
      "4560.pt\n",
      "4561.pt\n",
      "4562.pt\n",
      "4563.pt\n",
      "4564.pt\n",
      "4565.pt\n",
      "4566.pt\n",
      "4567.pt\n",
      "4568.pt\n",
      "4569.pt\n",
      "4570.pt\n",
      "4571.pt\n",
      "4572.pt\n",
      "4573.pt\n",
      "4574.pt\n",
      "4575.pt\n",
      "4576.pt\n",
      "4577.pt\n",
      "4578.pt\n",
      "4579.pt\n",
      "4580.pt\n",
      "4581.pt\n",
      "4582.pt\n",
      "4583.pt\n",
      "4584.pt\n",
      "4585.pt\n",
      "4586.pt\n",
      "4587.pt\n",
      "4588.pt\n",
      "4589.pt\n",
      "4590.pt\n",
      "4591.pt\n",
      "4592.pt\n",
      "4593.pt\n",
      "4594.pt\n",
      "4595.pt\n",
      "4596.pt\n",
      "4597.pt\n",
      "4598.pt\n",
      "4599.pt\n",
      "4600.pt\n",
      "4601.pt\n",
      "4602.pt\n",
      "4603.pt\n",
      "4604.pt\n",
      "4605.pt\n",
      "4606.pt\n",
      "4607.pt\n",
      "4608.pt\n",
      "4609.pt\n",
      "4610.pt\n",
      "4611.pt\n",
      "4612.pt\n",
      "4613.pt\n",
      "4614.pt\n",
      "4615.pt\n",
      "4616.pt\n",
      "4617.pt\n",
      "4618.pt\n",
      "4619.pt\n",
      "4620.pt\n",
      "4621.pt\n",
      "4622.pt\n",
      "4623.pt\n",
      "4624.pt\n",
      "4625.pt\n",
      "4626.pt\n",
      "4627.pt\n",
      "4628.pt\n",
      "4629.pt\n",
      "4630.pt\n",
      "4631.pt\n",
      "4632.pt\n",
      "4633.pt\n",
      "4634.pt\n",
      "4635.pt\n",
      "4636.pt\n",
      "4637.pt\n",
      "4638.pt\n",
      "4639.pt\n",
      "4640.pt\n",
      "4641.pt\n",
      "4642.pt\n",
      "4643.pt\n",
      "4644.pt\n",
      "4645.pt\n",
      "4646.pt\n",
      "4647.pt\n",
      "4648.pt\n",
      "4649.pt\n",
      "4650.pt\n",
      "4651.pt\n",
      "4652.pt\n",
      "4653.pt\n",
      "4654.pt\n",
      "4655.pt\n",
      "4656.pt\n",
      "4657.pt\n",
      "4658.pt\n",
      "4659.pt\n",
      "4660.pt\n",
      "4661.pt\n",
      "4662.pt\n",
      "4663.pt\n",
      "4664.pt\n",
      "4665.pt\n",
      "4666.pt\n",
      "4667.pt\n",
      "4668.pt\n",
      "4669.pt\n",
      "4670.pt\n",
      "4671.pt\n",
      "4672.pt\n",
      "4673.pt\n",
      "4674.pt\n",
      "4675.pt\n",
      "4676.pt\n",
      "4677.pt\n",
      "4678.pt\n",
      "4679.pt\n",
      "4680.pt\n",
      "4681.pt\n",
      "4682.pt\n",
      "4683.pt\n",
      "4684.pt\n",
      "4685.pt\n",
      "4686.pt\n",
      "4687.pt\n",
      "4688.pt\n",
      "4689.pt\n",
      "4690.pt\n",
      "4691.pt\n",
      "4692.pt\n",
      "4693.pt\n",
      "4694.pt\n",
      "4695.pt\n",
      "4696.pt\n",
      "4697.pt\n",
      "4698.pt\n",
      "4699.pt\n",
      "4700.pt\n",
      "4701.pt\n",
      "4702.pt\n",
      "4703.pt\n",
      "4704.pt\n",
      "4705.pt\n",
      "4706.pt\n",
      "4707.pt\n",
      "4708.pt\n",
      "4709.pt\n",
      "4710.pt\n",
      "4711.pt\n",
      "4712.pt\n",
      "4713.pt\n",
      "4714.pt\n",
      "4715.pt\n",
      "4716.pt\n",
      "4717.pt\n",
      "4718.pt\n",
      "4719.pt\n",
      "4720.pt\n",
      "4721.pt\n",
      "4722.pt\n",
      "4723.pt\n",
      "4724.pt\n",
      "4725.pt\n",
      "4726.pt\n",
      "4727.pt\n",
      "4728.pt\n",
      "4729.pt\n",
      "4730.pt\n",
      "4731.pt\n",
      "4732.pt\n",
      "4733.pt\n",
      "4734.pt\n",
      "4735.pt\n",
      "4736.pt\n",
      "4737.pt\n",
      "4738.pt\n",
      "4739.pt\n",
      "4740.pt\n",
      "4741.pt\n",
      "4742.pt\n",
      "4743.pt\n",
      "4744.pt\n",
      "4745.pt\n",
      "4746.pt\n",
      "4747.pt\n",
      "4748.pt\n",
      "4749.pt\n",
      "4750.pt\n",
      "4751.pt\n",
      "4752.pt\n",
      "4753.pt\n",
      "4754.pt\n",
      "4755.pt\n",
      "4756.pt\n",
      "4757.pt\n",
      "4758.pt\n",
      "4759.pt\n",
      "4760.pt\n",
      "4761.pt\n",
      "4762.pt\n",
      "4763.pt\n",
      "4764.pt\n",
      "4765.pt\n",
      "4766.pt\n",
      "4767.pt\n",
      "4768.pt\n",
      "4769.pt\n",
      "4770.pt\n",
      "4771.pt\n",
      "4772.pt\n",
      "4773.pt\n",
      "4774.pt\n",
      "4775.pt\n",
      "4776.pt\n",
      "4777.pt\n",
      "4778.pt\n",
      "4779.pt\n",
      "4780.pt\n",
      "4781.pt\n",
      "4782.pt\n",
      "4783.pt\n",
      "4784.pt\n",
      "4785.pt\n",
      "4786.pt\n",
      "4787.pt\n",
      "4788.pt\n",
      "4789.pt\n",
      "4790.pt\n",
      "4791.pt\n",
      "4792.pt\n",
      "4793.pt\n",
      "4794.pt\n",
      "4795.pt\n",
      "4796.pt\n",
      "4797.pt\n",
      "4798.pt\n",
      "4799.pt\n",
      "4800.pt\n",
      "4801.pt\n",
      "4802.pt\n",
      "4803.pt\n",
      "4804.pt\n",
      "4805.pt\n",
      "4806.pt\n",
      "4807.pt\n",
      "4808.pt\n",
      "4809.pt\n",
      "4810.pt\n",
      "4811.pt\n",
      "4812.pt\n",
      "4813.pt\n",
      "4814.pt\n",
      "4815.pt\n",
      "4816.pt\n",
      "4817.pt\n",
      "4818.pt\n",
      "4819.pt\n",
      "4820.pt\n",
      "4821.pt\n",
      "4822.pt\n",
      "4823.pt\n",
      "4824.pt\n",
      "4825.pt\n",
      "4826.pt\n",
      "4827.pt\n",
      "4828.pt\n",
      "4829.pt\n",
      "4830.pt\n",
      "4831.pt\n",
      "4832.pt\n",
      "4833.pt\n",
      "4834.pt\n",
      "4835.pt\n",
      "4836.pt\n",
      "4837.pt\n",
      "4838.pt\n",
      "4839.pt\n",
      "4840.pt\n",
      "4841.pt\n",
      "4842.pt\n",
      "4843.pt\n",
      "4844.pt\n",
      "4845.pt\n",
      "4846.pt\n",
      "4847.pt\n",
      "4848.pt\n",
      "4849.pt\n",
      "4850.pt\n",
      "4851.pt\n",
      "4852.pt\n",
      "4853.pt\n",
      "4854.pt\n",
      "4855.pt\n",
      "4856.pt\n",
      "4857.pt\n",
      "4858.pt\n",
      "4859.pt\n",
      "4860.pt\n",
      "4861.pt\n",
      "4862.pt\n",
      "4863.pt\n",
      "4864.pt\n",
      "4865.pt\n",
      "4866.pt\n",
      "4867.pt\n",
      "4868.pt\n",
      "4869.pt\n",
      "4870.pt\n",
      "4871.pt\n",
      "4872.pt\n",
      "4873.pt\n",
      "4874.pt\n",
      "4875.pt\n",
      "4876.pt\n",
      "4877.pt\n",
      "4878.pt\n",
      "4879.pt\n",
      "4880.pt\n",
      "4881.pt\n",
      "4882.pt\n",
      "4883.pt\n",
      "4884.pt\n",
      "4885.pt\n",
      "4886.pt\n",
      "4887.pt\n",
      "4888.pt\n",
      "4889.pt\n",
      "4890.pt\n",
      "4891.pt\n",
      "4892.pt\n",
      "4893.pt\n",
      "4894.pt\n",
      "4895.pt\n",
      "4896.pt\n",
      "4897.pt\n",
      "4898.pt\n",
      "4899.pt\n",
      "4900.pt\n",
      "4901.pt\n",
      "4902.pt\n",
      "4903.pt\n",
      "4904.pt\n",
      "4905.pt\n",
      "4906.pt\n",
      "4907.pt\n",
      "4908.pt\n",
      "4909.pt\n",
      "4910.pt\n",
      "4911.pt\n",
      "4912.pt\n",
      "4913.pt\n",
      "4914.pt\n",
      "4915.pt\n",
      "4916.pt\n",
      "4917.pt\n",
      "4918.pt\n",
      "4919.pt\n",
      "4920.pt\n",
      "4921.pt\n",
      "4922.pt\n",
      "4923.pt\n",
      "4924.pt\n",
      "4925.pt\n",
      "4926.pt\n",
      "4927.pt\n",
      "4928.pt\n",
      "4929.pt\n",
      "4930.pt\n",
      "4931.pt\n",
      "4932.pt\n",
      "4933.pt\n",
      "4934.pt\n",
      "4935.pt\n",
      "4936.pt\n",
      "4937.pt\n",
      "4938.pt\n",
      "4939.pt\n",
      "4940.pt\n",
      "4941.pt\n",
      "4942.pt\n",
      "4943.pt\n",
      "4944.pt\n",
      "4945.pt\n",
      "4946.pt\n",
      "4947.pt\n",
      "4948.pt\n",
      "4949.pt\n",
      "4950.pt\n",
      "4951.pt\n",
      "4952.pt\n",
      "4953.pt\n",
      "4954.pt\n",
      "4955.pt\n",
      "4956.pt\n",
      "4957.pt\n",
      "4958.pt\n",
      "4959.pt\n",
      "4960.pt\n",
      "4961.pt\n",
      "4962.pt\n",
      "4963.pt\n",
      "4964.pt\n",
      "4965.pt\n",
      "4966.pt\n",
      "4967.pt\n",
      "4968.pt\n",
      "4969.pt\n",
      "4970.pt\n",
      "4971.pt\n",
      "4972.pt\n",
      "4973.pt\n",
      "4974.pt\n",
      "4975.pt\n",
      "4976.pt\n",
      "4977.pt\n",
      "4978.pt\n",
      "4979.pt\n",
      "4980.pt\n",
      "4981.pt\n",
      "4982.pt\n",
      "4983.pt\n",
      "4984.pt\n",
      "4985.pt\n",
      "4986.pt\n",
      "4987.pt\n",
      "4988.pt\n",
      "4989.pt\n",
      "4990.pt\n",
      "4991.pt\n",
      "4992.pt\n",
      "4993.pt\n",
      "4994.pt\n",
      "4995.pt\n",
      "4996.pt\n",
      "4997.pt\n",
      "4998.pt\n",
      "4999.pt\n",
      "5000.pt\n",
      "5001.pt\n",
      "5002.pt\n",
      "5003.pt\n",
      "5004.pt\n",
      "5005.pt\n",
      "5006.pt\n",
      "5007.pt\n",
      "5008.pt\n",
      "5009.pt\n",
      "5010.pt\n",
      "5011.pt\n",
      "5012.pt\n",
      "5013.pt\n",
      "5014.pt\n",
      "5015.pt\n",
      "5016.pt\n",
      "5017.pt\n",
      "5018.pt\n",
      "5019.pt\n",
      "5020.pt\n",
      "5021.pt\n",
      "5022.pt\n",
      "5023.pt\n",
      "5024.pt\n",
      "5025.pt\n",
      "5026.pt\n",
      "5027.pt\n",
      "5028.pt\n",
      "5029.pt\n",
      "5030.pt\n",
      "5031.pt\n",
      "5032.pt\n",
      "5033.pt\n",
      "5034.pt\n",
      "5035.pt\n",
      "5036.pt\n",
      "5037.pt\n",
      "5038.pt\n",
      "5039.pt\n",
      "5040.pt\n",
      "5041.pt\n",
      "5042.pt\n",
      "5043.pt\n",
      "5044.pt\n",
      "5045.pt\n",
      "5046.pt\n",
      "5047.pt\n",
      "5048.pt\n",
      "5049.pt\n",
      "5050.pt\n",
      "5051.pt\n",
      "5052.pt\n",
      "5053.pt\n",
      "5054.pt\n",
      "5055.pt\n",
      "5056.pt\n",
      "5057.pt\n",
      "5058.pt\n",
      "5059.pt\n",
      "5060.pt\n",
      "5061.pt\n",
      "5062.pt\n",
      "5063.pt\n",
      "5064.pt\n",
      "5065.pt\n",
      "5066.pt\n",
      "5067.pt\n",
      "5068.pt\n",
      "5069.pt\n",
      "5070.pt\n",
      "5071.pt\n",
      "5072.pt\n",
      "5073.pt\n",
      "5074.pt\n",
      "5075.pt\n",
      "5076.pt\n",
      "5077.pt\n",
      "5078.pt\n",
      "5079.pt\n",
      "5080.pt\n",
      "5081.pt\n",
      "5082.pt\n",
      "5083.pt\n",
      "5084.pt\n",
      "5085.pt\n",
      "5086.pt\n",
      "5087.pt\n",
      "5088.pt\n",
      "5089.pt\n",
      "5090.pt\n",
      "5091.pt\n",
      "5092.pt\n",
      "5093.pt\n",
      "5094.pt\n",
      "5095.pt\n",
      "5096.pt\n",
      "5097.pt\n",
      "5098.pt\n",
      "5099.pt\n",
      "5100.pt\n",
      "5101.pt\n",
      "5102.pt\n",
      "5103.pt\n",
      "5104.pt\n",
      "5105.pt\n",
      "5106.pt\n",
      "5107.pt\n",
      "5108.pt\n",
      "5109.pt\n",
      "5110.pt\n",
      "5111.pt\n",
      "5112.pt\n",
      "5113.pt\n",
      "5114.pt\n",
      "5115.pt\n",
      "5116.pt\n",
      "5117.pt\n",
      "5118.pt\n",
      "5119.pt\n",
      "5120.pt\n",
      "5121.pt\n",
      "5122.pt\n",
      "5123.pt\n",
      "5124.pt\n",
      "5125.pt\n",
      "5126.pt\n",
      "5127.pt\n",
      "5128.pt\n",
      "5129.pt\n",
      "5130.pt\n",
      "5131.pt\n",
      "5132.pt\n",
      "5133.pt\n",
      "5134.pt\n",
      "5135.pt\n",
      "5136.pt\n",
      "5137.pt\n",
      "5138.pt\n",
      "5139.pt\n",
      "5140.pt\n",
      "5141.pt\n",
      "5142.pt\n",
      "5143.pt\n",
      "5144.pt\n",
      "5145.pt\n",
      "5146.pt\n",
      "5147.pt\n",
      "5148.pt\n",
      "5149.pt\n",
      "5150.pt\n",
      "5151.pt\n",
      "5152.pt\n",
      "5153.pt\n",
      "5154.pt\n",
      "5155.pt\n",
      "5156.pt\n",
      "5157.pt\n",
      "5158.pt\n",
      "5159.pt\n",
      "5160.pt\n",
      "5161.pt\n",
      "5162.pt\n",
      "5163.pt\n",
      "5164.pt\n",
      "5165.pt\n",
      "5166.pt\n",
      "5167.pt\n",
      "5168.pt\n",
      "5169.pt\n",
      "5170.pt\n",
      "5171.pt\n",
      "5172.pt\n",
      "5173.pt\n",
      "5174.pt\n",
      "5175.pt\n",
      "5176.pt\n",
      "5177.pt\n",
      "5178.pt\n",
      "5179.pt\n",
      "5180.pt\n",
      "5181.pt\n",
      "5182.pt\n",
      "5183.pt\n",
      "5184.pt\n",
      "5185.pt\n",
      "5186.pt\n",
      "5187.pt\n",
      "5188.pt\n",
      "5189.pt\n",
      "5190.pt\n",
      "5191.pt\n",
      "5192.pt\n",
      "5193.pt\n",
      "5194.pt\n",
      "5195.pt\n",
      "5196.pt\n",
      "5197.pt\n",
      "5198.pt\n",
      "5199.pt\n",
      "5200.pt\n",
      "5201.pt\n",
      "5202.pt\n",
      "5203.pt\n",
      "5204.pt\n",
      "5205.pt\n",
      "5206.pt\n",
      "5207.pt\n",
      "5208.pt\n",
      "5209.pt\n",
      "5210.pt\n",
      "5211.pt\n",
      "5212.pt\n",
      "5213.pt\n",
      "5214.pt\n",
      "5215.pt\n",
      "5216.pt\n",
      "5217.pt\n",
      "5218.pt\n",
      "5219.pt\n",
      "5220.pt\n",
      "5221.pt\n",
      "5222.pt\n",
      "5223.pt\n",
      "5224.pt\n",
      "5225.pt\n",
      "5226.pt\n",
      "5227.pt\n",
      "5228.pt\n",
      "5229.pt\n",
      "5230.pt\n",
      "5231.pt\n",
      "5232.pt\n",
      "5233.pt\n",
      "5234.pt\n",
      "5235.pt\n",
      "5236.pt\n",
      "5237.pt\n",
      "5238.pt\n",
      "5239.pt\n",
      "5240.pt\n",
      "5241.pt\n",
      "5242.pt\n",
      "5243.pt\n",
      "5244.pt\n",
      "5245.pt\n",
      "5246.pt\n",
      "5247.pt\n",
      "5248.pt\n",
      "5249.pt\n",
      "5250.pt\n",
      "5251.pt\n",
      "5252.pt\n",
      "5253.pt\n",
      "5254.pt\n",
      "5255.pt\n",
      "5256.pt\n",
      "5257.pt\n",
      "5258.pt\n",
      "5259.pt\n",
      "5260.pt\n",
      "5261.pt\n",
      "5262.pt\n",
      "5263.pt\n",
      "5264.pt\n",
      "5265.pt\n",
      "5266.pt\n",
      "5267.pt\n",
      "5268.pt\n",
      "5269.pt\n",
      "5270.pt\n",
      "5271.pt\n",
      "5272.pt\n",
      "5273.pt\n",
      "5274.pt\n",
      "5275.pt\n",
      "5276.pt\n",
      "5277.pt\n",
      "5278.pt\n",
      "5279.pt\n",
      "5280.pt\n",
      "5281.pt\n",
      "5282.pt\n",
      "5283.pt\n",
      "5284.pt\n",
      "5285.pt\n",
      "5286.pt\n",
      "5287.pt\n",
      "5288.pt\n",
      "5289.pt\n",
      "5290.pt\n",
      "5291.pt\n",
      "5292.pt\n",
      "5293.pt\n",
      "5294.pt\n",
      "5295.pt\n",
      "5296.pt\n",
      "5297.pt\n",
      "5298.pt\n",
      "5299.pt\n",
      "5300.pt\n",
      "5301.pt\n",
      "5302.pt\n",
      "5303.pt\n",
      "5304.pt\n",
      "5305.pt\n",
      "5306.pt\n",
      "5307.pt\n",
      "5308.pt\n",
      "5309.pt\n",
      "5310.pt\n",
      "5311.pt\n",
      "5312.pt\n",
      "5313.pt\n",
      "5314.pt\n",
      "5315.pt\n",
      "5316.pt\n",
      "5317.pt\n",
      "5318.pt\n",
      "5319.pt\n",
      "5320.pt\n",
      "5321.pt\n",
      "5322.pt\n",
      "5323.pt\n",
      "5324.pt\n",
      "5325.pt\n",
      "5326.pt\n",
      "5327.pt\n",
      "5328.pt\n",
      "5329.pt\n",
      "5330.pt\n",
      "5331.pt\n",
      "5332.pt\n",
      "5333.pt\n",
      "5334.pt\n",
      "5335.pt\n",
      "5336.pt\n",
      "5337.pt\n",
      "5338.pt\n",
      "5339.pt\n",
      "5340.pt\n",
      "5341.pt\n",
      "5342.pt\n",
      "5343.pt\n",
      "5344.pt\n",
      "5345.pt\n",
      "5346.pt\n",
      "5347.pt\n",
      "5348.pt\n",
      "5349.pt\n",
      "5350.pt\n",
      "5351.pt\n",
      "5352.pt\n",
      "5353.pt\n",
      "5354.pt\n",
      "5355.pt\n",
      "5356.pt\n",
      "5357.pt\n",
      "5358.pt\n",
      "5359.pt\n",
      "5360.pt\n",
      "5361.pt\n",
      "5362.pt\n",
      "5363.pt\n",
      "5364.pt\n",
      "5365.pt\n",
      "5366.pt\n",
      "5367.pt\n",
      "5368.pt\n",
      "5369.pt\n",
      "5370.pt\n",
      "5371.pt\n",
      "5372.pt\n",
      "5373.pt\n",
      "5374.pt\n",
      "5375.pt\n",
      "5376.pt\n",
      "5377.pt\n",
      "5378.pt\n",
      "5379.pt\n",
      "5380.pt\n",
      "5381.pt\n",
      "5382.pt\n",
      "5383.pt\n",
      "5384.pt\n",
      "5385.pt\n",
      "5386.pt\n",
      "5387.pt\n",
      "5388.pt\n",
      "5389.pt\n",
      "5390.pt\n",
      "5391.pt\n",
      "5392.pt\n",
      "5393.pt\n",
      "5394.pt\n",
      "5395.pt\n",
      "5396.pt\n",
      "5397.pt\n",
      "5398.pt\n",
      "5399.pt\n",
      "5400.pt\n",
      "5401.pt\n",
      "5402.pt\n",
      "5403.pt\n",
      "5404.pt\n",
      "5405.pt\n",
      "5406.pt\n",
      "5407.pt\n",
      "5408.pt\n",
      "5409.pt\n",
      "5410.pt\n",
      "5411.pt\n",
      "5412.pt\n",
      "5413.pt\n",
      "5414.pt\n",
      "5415.pt\n",
      "5416.pt\n",
      "5417.pt\n",
      "5418.pt\n",
      "5419.pt\n",
      "5420.pt\n",
      "5421.pt\n",
      "5422.pt\n",
      "5423.pt\n",
      "5424.pt\n",
      "5425.pt\n",
      "5426.pt\n",
      "5427.pt\n",
      "5428.pt\n",
      "5429.pt\n",
      "5430.pt\n",
      "5431.pt\n",
      "5432.pt\n",
      "5433.pt\n",
      "5434.pt\n",
      "5435.pt\n",
      "5436.pt\n",
      "5437.pt\n",
      "5438.pt\n",
      "5439.pt\n",
      "5440.pt\n",
      "5441.pt\n",
      "5442.pt\n",
      "5443.pt\n",
      "5444.pt\n",
      "5445.pt\n",
      "5446.pt\n",
      "5447.pt\n",
      "5448.pt\n",
      "5449.pt\n",
      "5450.pt\n",
      "5451.pt\n",
      "5452.pt\n",
      "5453.pt\n",
      "5454.pt\n",
      "5455.pt\n",
      "5456.pt\n",
      "5457.pt\n",
      "5458.pt\n",
      "5459.pt\n",
      "5460.pt\n",
      "5461.pt\n",
      "5462.pt\n",
      "5463.pt\n",
      "5464.pt\n",
      "5465.pt\n",
      "5466.pt\n",
      "5467.pt\n",
      "5468.pt\n",
      "5469.pt\n",
      "5470.pt\n",
      "5471.pt\n",
      "5472.pt\n",
      "5473.pt\n",
      "5474.pt\n",
      "5475.pt\n",
      "5476.pt\n",
      "5477.pt\n",
      "5478.pt\n",
      "5479.pt\n",
      "5480.pt\n",
      "5481.pt\n",
      "5482.pt\n",
      "5483.pt\n",
      "5484.pt\n",
      "5485.pt\n",
      "5486.pt\n",
      "5487.pt\n",
      "5488.pt\n",
      "5489.pt\n",
      "5490.pt\n",
      "5491.pt\n",
      "5492.pt\n",
      "5493.pt\n",
      "5494.pt\n",
      "5495.pt\n",
      "5496.pt\n",
      "5497.pt\n",
      "5498.pt\n",
      "5499.pt\n",
      "5500.pt\n",
      "5501.pt\n",
      "5502.pt\n",
      "5503.pt\n",
      "5504.pt\n",
      "5505.pt\n",
      "5506.pt\n",
      "5507.pt\n",
      "5508.pt\n",
      "5509.pt\n",
      "5510.pt\n",
      "5511.pt\n",
      "5512.pt\n",
      "5513.pt\n",
      "5514.pt\n",
      "5515.pt\n",
      "5516.pt\n",
      "5517.pt\n",
      "5518.pt\n",
      "5519.pt\n",
      "5520.pt\n",
      "5521.pt\n",
      "5522.pt\n",
      "5523.pt\n",
      "5524.pt\n",
      "5525.pt\n",
      "5526.pt\n",
      "5527.pt\n",
      "5528.pt\n",
      "5529.pt\n",
      "5530.pt\n",
      "5531.pt\n",
      "5532.pt\n",
      "5533.pt\n",
      "5534.pt\n",
      "5535.pt\n",
      "5536.pt\n",
      "5537.pt\n",
      "5538.pt\n",
      "5539.pt\n",
      "5540.pt\n",
      "5541.pt\n",
      "5542.pt\n",
      "5543.pt\n",
      "5544.pt\n",
      "5545.pt\n",
      "5546.pt\n",
      "5547.pt\n",
      "5548.pt\n",
      "5549.pt\n",
      "5550.pt\n",
      "5551.pt\n",
      "5552.pt\n",
      "5553.pt\n",
      "5554.pt\n",
      "5555.pt\n",
      "5556.pt\n",
      "5557.pt\n",
      "5558.pt\n",
      "5559.pt\n",
      "5560.pt\n",
      "5561.pt\n",
      "5562.pt\n",
      "5563.pt\n",
      "5564.pt\n",
      "5565.pt\n",
      "5566.pt\n",
      "5567.pt\n",
      "5568.pt\n",
      "5569.pt\n",
      "5570.pt\n",
      "5571.pt\n",
      "5572.pt\n",
      "5573.pt\n",
      "5574.pt\n",
      "5575.pt\n",
      "5576.pt\n",
      "5577.pt\n",
      "5578.pt\n",
      "5579.pt\n",
      "5580.pt\n",
      "5581.pt\n",
      "5582.pt\n",
      "5583.pt\n",
      "5584.pt\n",
      "5585.pt\n",
      "5586.pt\n",
      "5587.pt\n",
      "5588.pt\n",
      "5589.pt\n",
      "5590.pt\n",
      "5591.pt\n",
      "5592.pt\n",
      "5593.pt\n",
      "5594.pt\n",
      "5595.pt\n",
      "5596.pt\n",
      "5597.pt\n",
      "5598.pt\n",
      "5599.pt\n",
      "5600.pt\n",
      "5601.pt\n",
      "5602.pt\n",
      "5603.pt\n",
      "5604.pt\n",
      "5605.pt\n",
      "5606.pt\n",
      "5607.pt\n",
      "5608.pt\n",
      "5609.pt\n",
      "5610.pt\n",
      "5611.pt\n",
      "5612.pt\n",
      "5613.pt\n",
      "5614.pt\n",
      "5615.pt\n",
      "5616.pt\n",
      "5617.pt\n",
      "5618.pt\n",
      "5619.pt\n",
      "5620.pt\n",
      "5621.pt\n",
      "5622.pt\n",
      "5623.pt\n",
      "5624.pt\n",
      "5625.pt\n",
      "5626.pt\n",
      "5627.pt\n",
      "5628.pt\n",
      "5629.pt\n",
      "5630.pt\n",
      "5631.pt\n",
      "5632.pt\n",
      "5633.pt\n",
      "5634.pt\n",
      "5635.pt\n",
      "5636.pt\n",
      "5637.pt\n",
      "5638.pt\n",
      "5639.pt\n",
      "5640.pt\n",
      "5641.pt\n",
      "5642.pt\n",
      "5643.pt\n",
      "5644.pt\n",
      "5645.pt\n",
      "5646.pt\n",
      "5647.pt\n",
      "5648.pt\n",
      "5649.pt\n",
      "5650.pt\n",
      "5651.pt\n",
      "5652.pt\n",
      "5653.pt\n",
      "5654.pt\n",
      "5655.pt\n",
      "5656.pt\n",
      "5657.pt\n",
      "5658.pt\n",
      "5659.pt\n",
      "5660.pt\n",
      "5661.pt\n",
      "5662.pt\n",
      "5663.pt\n",
      "5664.pt\n",
      "5665.pt\n",
      "5666.pt\n",
      "5667.pt\n",
      "5668.pt\n",
      "5669.pt\n",
      "5670.pt\n",
      "5671.pt\n",
      "5672.pt\n",
      "5673.pt\n",
      "5674.pt\n",
      "5675.pt\n",
      "5676.pt\n",
      "5677.pt\n",
      "5678.pt\n",
      "5679.pt\n",
      "5680.pt\n",
      "5681.pt\n",
      "5682.pt\n",
      "5683.pt\n",
      "5684.pt\n",
      "5685.pt\n",
      "5686.pt\n",
      "5687.pt\n",
      "5688.pt\n",
      "5689.pt\n",
      "5690.pt\n",
      "5691.pt\n",
      "5692.pt\n",
      "5693.pt\n",
      "5694.pt\n",
      "5695.pt\n",
      "5696.pt\n",
      "5697.pt\n",
      "5698.pt\n",
      "5699.pt\n",
      "5700.pt\n",
      "5701.pt\n",
      "5702.pt\n",
      "5703.pt\n",
      "5704.pt\n",
      "5705.pt\n",
      "5706.pt\n",
      "5707.pt\n",
      "5708.pt\n",
      "5709.pt\n",
      "5710.pt\n",
      "5711.pt\n",
      "5712.pt\n",
      "5713.pt\n",
      "5714.pt\n",
      "5715.pt\n",
      "5716.pt\n",
      "5717.pt\n",
      "5718.pt\n",
      "5719.pt\n",
      "5720.pt\n",
      "5721.pt\n",
      "5722.pt\n",
      "5723.pt\n",
      "5724.pt\n",
      "5725.pt\n",
      "5726.pt\n",
      "5727.pt\n",
      "5728.pt\n",
      "5729.pt\n",
      "5730.pt\n",
      "5731.pt\n",
      "5732.pt\n",
      "5733.pt\n",
      "5734.pt\n",
      "5735.pt\n",
      "5736.pt\n",
      "5737.pt\n",
      "5738.pt\n",
      "5739.pt\n",
      "5740.pt\n",
      "5741.pt\n",
      "5742.pt\n",
      "5743.pt\n",
      "5744.pt\n",
      "5745.pt\n",
      "5746.pt\n",
      "5747.pt\n",
      "5748.pt\n",
      "5749.pt\n",
      "5750.pt\n",
      "5751.pt\n",
      "5752.pt\n",
      "5753.pt\n",
      "5754.pt\n",
      "5755.pt\n",
      "5756.pt\n",
      "5757.pt\n",
      "5758.pt\n",
      "5759.pt\n",
      "5760.pt\n",
      "5761.pt\n",
      "5762.pt\n",
      "5763.pt\n",
      "5764.pt\n",
      "5765.pt\n",
      "5766.pt\n",
      "5767.pt\n",
      "5768.pt\n",
      "5769.pt\n",
      "5770.pt\n",
      "5771.pt\n",
      "5772.pt\n",
      "5773.pt\n",
      "5774.pt\n",
      "5775.pt\n",
      "5776.pt\n",
      "5777.pt\n",
      "5778.pt\n",
      "5779.pt\n",
      "5780.pt\n",
      "5781.pt\n",
      "5782.pt\n",
      "5783.pt\n",
      "5784.pt\n",
      "5785.pt\n",
      "5786.pt\n",
      "5787.pt\n",
      "5788.pt\n",
      "5789.pt\n",
      "5790.pt\n",
      "5791.pt\n",
      "5792.pt\n",
      "5793.pt\n",
      "5794.pt\n",
      "5795.pt\n",
      "5796.pt\n",
      "5797.pt\n",
      "5798.pt\n",
      "5799.pt\n",
      "5800.pt\n",
      "5801.pt\n",
      "5802.pt\n",
      "5803.pt\n",
      "5804.pt\n",
      "5805.pt\n",
      "5806.pt\n",
      "5807.pt\n",
      "5808.pt\n",
      "5809.pt\n",
      "5810.pt\n",
      "5811.pt\n",
      "5812.pt\n",
      "5813.pt\n",
      "5814.pt\n",
      "5815.pt\n",
      "5816.pt\n",
      "5817.pt\n",
      "5818.pt\n",
      "5819.pt\n",
      "5820.pt\n",
      "5821.pt\n",
      "5822.pt\n",
      "5823.pt\n",
      "5824.pt\n",
      "5825.pt\n",
      "5826.pt\n",
      "5827.pt\n",
      "5828.pt\n",
      "5829.pt\n",
      "5830.pt\n",
      "5831.pt\n",
      "5832.pt\n",
      "5833.pt\n",
      "5834.pt\n",
      "5835.pt\n",
      "5836.pt\n",
      "5837.pt\n",
      "5838.pt\n",
      "5839.pt\n",
      "5840.pt\n",
      "5841.pt\n",
      "5842.pt\n",
      "5843.pt\n",
      "5844.pt\n",
      "5845.pt\n",
      "5846.pt\n",
      "5847.pt\n",
      "5848.pt\n",
      "5849.pt\n",
      "5850.pt\n",
      "5851.pt\n",
      "5852.pt\n",
      "5853.pt\n",
      "5854.pt\n",
      "5855.pt\n",
      "5856.pt\n",
      "5857.pt\n",
      "5858.pt\n",
      "5859.pt\n",
      "5860.pt\n",
      "5861.pt\n",
      "5862.pt\n",
      "5863.pt\n",
      "5864.pt\n",
      "5865.pt\n",
      "5866.pt\n",
      "5867.pt\n",
      "5868.pt\n",
      "5869.pt\n",
      "5870.pt\n",
      "5871.pt\n",
      "5872.pt\n",
      "5873.pt\n",
      "5874.pt\n",
      "5875.pt\n",
      "5876.pt\n",
      "5877.pt\n",
      "5878.pt\n",
      "5879.pt\n",
      "5880.pt\n",
      "5881.pt\n",
      "5882.pt\n",
      "5883.pt\n",
      "5884.pt\n",
      "5885.pt\n",
      "5886.pt\n",
      "5887.pt\n",
      "5888.pt\n",
      "5889.pt\n",
      "5890.pt\n",
      "5891.pt\n",
      "5892.pt\n",
      "5893.pt\n",
      "5894.pt\n",
      "5895.pt\n",
      "5896.pt\n",
      "5897.pt\n",
      "5898.pt\n",
      "5899.pt\n",
      "5900.pt\n",
      "5901.pt\n",
      "5902.pt\n",
      "5903.pt\n",
      "5904.pt\n",
      "5905.pt\n",
      "5906.pt\n",
      "5907.pt\n",
      "5908.pt\n",
      "5909.pt\n",
      "5910.pt\n",
      "5911.pt\n",
      "5912.pt\n",
      "5913.pt\n",
      "5914.pt\n",
      "5915.pt\n",
      "5916.pt\n",
      "5917.pt\n",
      "5918.pt\n",
      "5919.pt\n",
      "5920.pt\n",
      "5921.pt\n",
      "5922.pt\n",
      "5923.pt\n",
      "5924.pt\n",
      "5925.pt\n",
      "5926.pt\n",
      "5927.pt\n",
      "5928.pt\n",
      "5929.pt\n",
      "5930.pt\n",
      "5931.pt\n",
      "5932.pt\n",
      "5933.pt\n",
      "5934.pt\n",
      "5935.pt\n",
      "5936.pt\n",
      "5937.pt\n",
      "5938.pt\n",
      "5939.pt\n",
      "5940.pt\n",
      "5941.pt\n",
      "5942.pt\n",
      "5943.pt\n",
      "5944.pt\n",
      "5945.pt\n",
      "5946.pt\n",
      "5947.pt\n",
      "5948.pt\n",
      "5949.pt\n",
      "5950.pt\n",
      "5951.pt\n",
      "5952.pt\n",
      "5953.pt\n",
      "5954.pt\n",
      "5955.pt\n",
      "5956.pt\n",
      "5957.pt\n",
      "5958.pt\n",
      "5959.pt\n",
      "5960.pt\n",
      "5961.pt\n",
      "5962.pt\n",
      "5963.pt\n",
      "5964.pt\n",
      "5965.pt\n",
      "5966.pt\n",
      "5967.pt\n",
      "5968.pt\n",
      "5969.pt\n",
      "5970.pt\n",
      "5971.pt\n",
      "5972.pt\n",
      "5973.pt\n",
      "5974.pt\n",
      "5975.pt\n",
      "5976.pt\n",
      "5977.pt\n",
      "5978.pt\n",
      "5979.pt\n",
      "5980.pt\n",
      "5981.pt\n",
      "5982.pt\n",
      "5983.pt\n",
      "5984.pt\n",
      "5985.pt\n",
      "5986.pt\n",
      "5987.pt\n",
      "5988.pt\n",
      "5989.pt\n",
      "5990.pt\n",
      "5991.pt\n",
      "5992.pt\n",
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 2s 6ms/step - loss: 0.6738 - accuracy: 0.6110 - val_loss: 0.6757 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6671 - accuracy: 0.6197 - val_loss: 0.6773 - val_accuracy: 0.5930\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.6197 - val_loss: 0.6795 - val_accuracy: 0.5930\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6661 - accuracy: 0.6197 - val_loss: 0.6860 - val_accuracy: 0.5930\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6669 - accuracy: 0.6179 - val_loss: 0.6758 - val_accuracy: 0.5930\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6648 - accuracy: 0.6189 - val_loss: 0.6889 - val_accuracy: 0.5930\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.6197 - val_loss: 0.6754 - val_accuracy: 0.5930\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.6195 - val_loss: 0.6756 - val_accuracy: 0.5938\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6669 - accuracy: 0.6195 - val_loss: 0.6781 - val_accuracy: 0.5930\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.6662 - accuracy: 0.6191 - val_loss: 0.6769 - val_accuracy: 0.5938\n",
      "Test loss: 0.6768988966941833\n",
      "Test accuracy: 0.5938282012939453\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Attention, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        print(filename)\n",
    "        data.append(feature.view(-1, 1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)\n",
    "\n",
    "input_layer = Input(shape=(data[0].shape[0], 1))\n",
    "x = GlobalAveragePooling1D()(input_layer)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Apply self-attention\n",
    "attention = Attention()([x, x])\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(attention)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pt\n",
      "1.pt\n",
      "2.pt\n",
      "3.pt\n",
      "4.pt\n",
      "5.pt\n",
      "6.pt\n",
      "7.pt\n",
      "8.pt\n",
      "9.pt\n",
      "10.pt\n",
      "11.pt\n",
      "12.pt\n",
      "13.pt\n",
      "14.pt\n",
      "15.pt\n",
      "16.pt\n",
      "17.pt\n",
      "18.pt\n",
      "19.pt\n",
      "20.pt\n",
      "21.pt\n",
      "22.pt\n",
      "23.pt\n",
      "24.pt\n",
      "25.pt\n",
      "26.pt\n",
      "27.pt\n",
      "28.pt\n",
      "29.pt\n",
      "30.pt\n",
      "31.pt\n",
      "32.pt\n",
      "33.pt\n",
      "34.pt\n",
      "35.pt\n",
      "36.pt\n",
      "37.pt\n",
      "38.pt\n",
      "39.pt\n",
      "40.pt\n",
      "41.pt\n",
      "42.pt\n",
      "43.pt\n",
      "44.pt\n",
      "45.pt\n",
      "46.pt\n",
      "47.pt\n",
      "48.pt\n",
      "49.pt\n",
      "50.pt\n",
      "51.pt\n",
      "52.pt\n",
      "53.pt\n",
      "54.pt\n",
      "55.pt\n",
      "56.pt\n",
      "57.pt\n",
      "58.pt\n",
      "59.pt\n",
      "60.pt\n",
      "61.pt\n",
      "62.pt\n",
      "63.pt\n",
      "64.pt\n",
      "65.pt\n",
      "66.pt\n",
      "67.pt\n",
      "68.pt\n",
      "69.pt\n",
      "70.pt\n",
      "71.pt\n",
      "72.pt\n",
      "73.pt\n",
      "74.pt\n",
      "75.pt\n",
      "76.pt\n",
      "77.pt\n",
      "78.pt\n",
      "79.pt\n",
      "80.pt\n",
      "81.pt\n",
      "82.pt\n",
      "83.pt\n",
      "84.pt\n",
      "85.pt\n",
      "86.pt\n",
      "87.pt\n",
      "88.pt\n",
      "89.pt\n",
      "90.pt\n",
      "91.pt\n",
      "92.pt\n",
      "93.pt\n",
      "94.pt\n",
      "95.pt\n",
      "96.pt\n",
      "97.pt\n",
      "98.pt\n",
      "99.pt\n",
      "100.pt\n",
      "101.pt\n",
      "102.pt\n",
      "103.pt\n",
      "104.pt\n",
      "105.pt\n",
      "106.pt\n",
      "107.pt\n",
      "108.pt\n",
      "109.pt\n",
      "110.pt\n",
      "111.pt\n",
      "112.pt\n",
      "113.pt\n",
      "114.pt\n",
      "115.pt\n",
      "116.pt\n",
      "117.pt\n",
      "118.pt\n",
      "119.pt\n",
      "120.pt\n",
      "121.pt\n",
      "122.pt\n",
      "123.pt\n",
      "124.pt\n",
      "125.pt\n",
      "126.pt\n",
      "127.pt\n",
      "128.pt\n",
      "129.pt\n",
      "130.pt\n",
      "131.pt\n",
      "132.pt\n",
      "133.pt\n",
      "134.pt\n",
      "135.pt\n",
      "136.pt\n",
      "137.pt\n",
      "138.pt\n",
      "139.pt\n",
      "140.pt\n",
      "141.pt\n",
      "142.pt\n",
      "143.pt\n",
      "144.pt\n",
      "145.pt\n",
      "146.pt\n",
      "147.pt\n",
      "148.pt\n",
      "149.pt\n",
      "150.pt\n",
      "151.pt\n",
      "152.pt\n",
      "153.pt\n",
      "154.pt\n",
      "155.pt\n",
      "156.pt\n",
      "157.pt\n",
      "158.pt\n",
      "159.pt\n",
      "160.pt\n",
      "161.pt\n",
      "162.pt\n",
      "163.pt\n",
      "164.pt\n",
      "165.pt\n",
      "166.pt\n",
      "167.pt\n",
      "168.pt\n",
      "169.pt\n",
      "170.pt\n",
      "171.pt\n",
      "172.pt\n",
      "173.pt\n",
      "174.pt\n",
      "175.pt\n",
      "176.pt\n",
      "177.pt\n",
      "178.pt\n",
      "179.pt\n",
      "180.pt\n",
      "181.pt\n",
      "182.pt\n",
      "183.pt\n",
      "184.pt\n",
      "185.pt\n",
      "186.pt\n",
      "187.pt\n",
      "188.pt\n",
      "189.pt\n",
      "190.pt\n",
      "191.pt\n",
      "192.pt\n",
      "193.pt\n",
      "194.pt\n",
      "195.pt\n",
      "196.pt\n",
      "197.pt\n",
      "198.pt\n",
      "199.pt\n",
      "200.pt\n",
      "201.pt\n",
      "202.pt\n",
      "203.pt\n",
      "204.pt\n",
      "205.pt\n",
      "206.pt\n",
      "207.pt\n",
      "208.pt\n",
      "209.pt\n",
      "210.pt\n",
      "211.pt\n",
      "212.pt\n",
      "213.pt\n",
      "214.pt\n",
      "215.pt\n",
      "216.pt\n",
      "217.pt\n",
      "218.pt\n",
      "219.pt\n",
      "220.pt\n",
      "221.pt\n",
      "222.pt\n",
      "223.pt\n",
      "224.pt\n",
      "225.pt\n",
      "226.pt\n",
      "227.pt\n",
      "228.pt\n",
      "229.pt\n",
      "230.pt\n",
      "231.pt\n",
      "232.pt\n",
      "233.pt\n",
      "234.pt\n",
      "235.pt\n",
      "236.pt\n",
      "237.pt\n",
      "238.pt\n",
      "239.pt\n",
      "240.pt\n",
      "241.pt\n",
      "242.pt\n",
      "243.pt\n",
      "244.pt\n",
      "245.pt\n",
      "246.pt\n",
      "247.pt\n",
      "248.pt\n",
      "249.pt\n",
      "250.pt\n",
      "251.pt\n",
      "252.pt\n",
      "253.pt\n",
      "254.pt\n",
      "255.pt\n",
      "256.pt\n",
      "257.pt\n",
      "258.pt\n",
      "259.pt\n",
      "260.pt\n",
      "261.pt\n",
      "262.pt\n",
      "263.pt\n",
      "264.pt\n",
      "265.pt\n",
      "266.pt\n",
      "267.pt\n",
      "268.pt\n",
      "269.pt\n",
      "270.pt\n",
      "271.pt\n",
      "272.pt\n",
      "273.pt\n",
      "274.pt\n",
      "275.pt\n",
      "276.pt\n",
      "277.pt\n",
      "278.pt\n",
      "279.pt\n",
      "280.pt\n",
      "281.pt\n",
      "282.pt\n",
      "283.pt\n",
      "284.pt\n",
      "285.pt\n",
      "286.pt\n",
      "287.pt\n",
      "288.pt\n",
      "289.pt\n",
      "290.pt\n",
      "291.pt\n",
      "292.pt\n",
      "293.pt\n",
      "294.pt\n",
      "295.pt\n",
      "296.pt\n",
      "297.pt\n",
      "298.pt\n",
      "299.pt\n",
      "300.pt\n",
      "301.pt\n",
      "302.pt\n",
      "303.pt\n",
      "304.pt\n",
      "305.pt\n",
      "306.pt\n",
      "307.pt\n",
      "308.pt\n",
      "309.pt\n",
      "310.pt\n",
      "311.pt\n",
      "312.pt\n",
      "313.pt\n",
      "314.pt\n",
      "315.pt\n",
      "316.pt\n",
      "317.pt\n",
      "318.pt\n",
      "319.pt\n",
      "320.pt\n",
      "321.pt\n",
      "322.pt\n",
      "323.pt\n",
      "324.pt\n",
      "325.pt\n",
      "326.pt\n",
      "327.pt\n",
      "328.pt\n",
      "329.pt\n",
      "330.pt\n",
      "331.pt\n",
      "332.pt\n",
      "333.pt\n",
      "334.pt\n",
      "335.pt\n",
      "336.pt\n",
      "337.pt\n",
      "338.pt\n",
      "339.pt\n",
      "340.pt\n",
      "341.pt\n",
      "342.pt\n",
      "343.pt\n",
      "344.pt\n",
      "345.pt\n",
      "346.pt\n",
      "347.pt\n",
      "348.pt\n",
      "349.pt\n",
      "350.pt\n",
      "351.pt\n",
      "352.pt\n",
      "353.pt\n",
      "354.pt\n",
      "355.pt\n",
      "356.pt\n",
      "357.pt\n",
      "358.pt\n",
      "359.pt\n",
      "360.pt\n",
      "361.pt\n",
      "362.pt\n",
      "363.pt\n",
      "364.pt\n",
      "365.pt\n",
      "366.pt\n",
      "367.pt\n",
      "368.pt\n",
      "369.pt\n",
      "370.pt\n",
      "371.pt\n",
      "372.pt\n",
      "373.pt\n",
      "374.pt\n",
      "375.pt\n",
      "376.pt\n",
      "377.pt\n",
      "378.pt\n",
      "379.pt\n",
      "380.pt\n",
      "381.pt\n",
      "382.pt\n",
      "383.pt\n",
      "384.pt\n",
      "385.pt\n",
      "386.pt\n",
      "387.pt\n",
      "388.pt\n",
      "389.pt\n",
      "390.pt\n",
      "391.pt\n",
      "392.pt\n",
      "393.pt\n",
      "394.pt\n",
      "395.pt\n",
      "396.pt\n",
      "397.pt\n",
      "398.pt\n",
      "399.pt\n",
      "400.pt\n",
      "401.pt\n",
      "402.pt\n",
      "403.pt\n",
      "404.pt\n",
      "405.pt\n",
      "406.pt\n",
      "407.pt\n",
      "408.pt\n",
      "409.pt\n",
      "410.pt\n",
      "411.pt\n",
      "412.pt\n",
      "413.pt\n",
      "414.pt\n",
      "415.pt\n",
      "416.pt\n",
      "417.pt\n",
      "418.pt\n",
      "419.pt\n",
      "420.pt\n",
      "421.pt\n",
      "422.pt\n",
      "423.pt\n",
      "424.pt\n",
      "425.pt\n",
      "426.pt\n",
      "427.pt\n",
      "428.pt\n",
      "429.pt\n",
      "430.pt\n",
      "431.pt\n",
      "432.pt\n",
      "433.pt\n",
      "434.pt\n",
      "435.pt\n",
      "436.pt\n",
      "437.pt\n",
      "438.pt\n",
      "439.pt\n",
      "440.pt\n",
      "441.pt\n",
      "442.pt\n",
      "443.pt\n",
      "444.pt\n",
      "445.pt\n",
      "446.pt\n",
      "447.pt\n",
      "448.pt\n",
      "449.pt\n",
      "450.pt\n",
      "451.pt\n",
      "452.pt\n",
      "453.pt\n",
      "454.pt\n",
      "455.pt\n",
      "456.pt\n",
      "457.pt\n",
      "458.pt\n",
      "459.pt\n",
      "460.pt\n",
      "461.pt\n",
      "462.pt\n",
      "463.pt\n",
      "464.pt\n",
      "465.pt\n",
      "466.pt\n",
      "467.pt\n",
      "468.pt\n",
      "469.pt\n",
      "470.pt\n",
      "471.pt\n",
      "472.pt\n",
      "473.pt\n",
      "474.pt\n",
      "475.pt\n",
      "476.pt\n",
      "477.pt\n",
      "478.pt\n",
      "479.pt\n",
      "480.pt\n",
      "481.pt\n",
      "482.pt\n",
      "483.pt\n",
      "484.pt\n",
      "485.pt\n",
      "486.pt\n",
      "487.pt\n",
      "488.pt\n",
      "489.pt\n",
      "490.pt\n",
      "491.pt\n",
      "492.pt\n",
      "493.pt\n",
      "494.pt\n",
      "495.pt\n",
      "496.pt\n",
      "497.pt\n",
      "498.pt\n",
      "499.pt\n",
      "500.pt\n",
      "501.pt\n",
      "502.pt\n",
      "503.pt\n",
      "504.pt\n",
      "505.pt\n",
      "506.pt\n",
      "507.pt\n",
      "508.pt\n",
      "509.pt\n",
      "510.pt\n",
      "511.pt\n",
      "512.pt\n",
      "513.pt\n",
      "514.pt\n",
      "515.pt\n",
      "516.pt\n",
      "517.pt\n",
      "518.pt\n",
      "519.pt\n",
      "520.pt\n",
      "521.pt\n",
      "522.pt\n",
      "523.pt\n",
      "524.pt\n",
      "525.pt\n",
      "526.pt\n",
      "527.pt\n",
      "528.pt\n",
      "529.pt\n",
      "530.pt\n",
      "531.pt\n",
      "532.pt\n",
      "533.pt\n",
      "534.pt\n",
      "535.pt\n",
      "536.pt\n",
      "537.pt\n",
      "538.pt\n",
      "539.pt\n",
      "540.pt\n",
      "541.pt\n",
      "542.pt\n",
      "543.pt\n",
      "544.pt\n",
      "545.pt\n",
      "546.pt\n",
      "547.pt\n",
      "548.pt\n",
      "549.pt\n",
      "550.pt\n",
      "551.pt\n",
      "552.pt\n",
      "553.pt\n",
      "554.pt\n",
      "555.pt\n",
      "556.pt\n",
      "557.pt\n",
      "558.pt\n",
      "559.pt\n",
      "560.pt\n",
      "561.pt\n",
      "562.pt\n",
      "563.pt\n",
      "564.pt\n",
      "565.pt\n",
      "566.pt\n",
      "567.pt\n",
      "568.pt\n",
      "569.pt\n",
      "570.pt\n",
      "571.pt\n",
      "572.pt\n",
      "573.pt\n",
      "574.pt\n",
      "575.pt\n",
      "576.pt\n",
      "577.pt\n",
      "578.pt\n",
      "579.pt\n",
      "580.pt\n",
      "581.pt\n",
      "582.pt\n",
      "583.pt\n",
      "584.pt\n",
      "585.pt\n",
      "586.pt\n",
      "587.pt\n",
      "588.pt\n",
      "589.pt\n",
      "590.pt\n",
      "591.pt\n",
      "592.pt\n",
      "593.pt\n",
      "594.pt\n",
      "595.pt\n",
      "596.pt\n",
      "597.pt\n",
      "598.pt\n",
      "599.pt\n",
      "600.pt\n",
      "601.pt\n",
      "602.pt\n",
      "603.pt\n",
      "604.pt\n",
      "605.pt\n",
      "606.pt\n",
      "607.pt\n",
      "608.pt\n",
      "609.pt\n",
      "610.pt\n",
      "611.pt\n",
      "612.pt\n",
      "613.pt\n",
      "614.pt\n",
      "615.pt\n",
      "616.pt\n",
      "617.pt\n",
      "618.pt\n",
      "619.pt\n",
      "620.pt\n",
      "621.pt\n",
      "622.pt\n",
      "623.pt\n",
      "624.pt\n",
      "625.pt\n",
      "626.pt\n",
      "627.pt\n",
      "628.pt\n",
      "629.pt\n",
      "630.pt\n",
      "631.pt\n",
      "632.pt\n",
      "633.pt\n",
      "634.pt\n",
      "635.pt\n",
      "636.pt\n",
      "637.pt\n",
      "638.pt\n",
      "639.pt\n",
      "640.pt\n",
      "641.pt\n",
      "642.pt\n",
      "643.pt\n",
      "644.pt\n",
      "645.pt\n",
      "646.pt\n",
      "647.pt\n",
      "648.pt\n",
      "649.pt\n",
      "650.pt\n",
      "651.pt\n",
      "652.pt\n",
      "653.pt\n",
      "654.pt\n",
      "655.pt\n",
      "656.pt\n",
      "657.pt\n",
      "658.pt\n",
      "659.pt\n",
      "660.pt\n",
      "661.pt\n",
      "662.pt\n",
      "663.pt\n",
      "664.pt\n",
      "665.pt\n",
      "666.pt\n",
      "667.pt\n",
      "668.pt\n",
      "669.pt\n",
      "670.pt\n",
      "671.pt\n",
      "672.pt\n",
      "673.pt\n",
      "674.pt\n",
      "675.pt\n",
      "676.pt\n",
      "677.pt\n",
      "678.pt\n",
      "679.pt\n",
      "680.pt\n",
      "681.pt\n",
      "682.pt\n",
      "683.pt\n",
      "684.pt\n",
      "685.pt\n",
      "686.pt\n",
      "687.pt\n",
      "688.pt\n",
      "689.pt\n",
      "690.pt\n",
      "691.pt\n",
      "692.pt\n",
      "693.pt\n",
      "694.pt\n",
      "695.pt\n",
      "696.pt\n",
      "697.pt\n",
      "698.pt\n",
      "699.pt\n",
      "700.pt\n",
      "701.pt\n",
      "702.pt\n",
      "703.pt\n",
      "704.pt\n",
      "705.pt\n",
      "706.pt\n",
      "707.pt\n",
      "708.pt\n",
      "709.pt\n",
      "710.pt\n",
      "711.pt\n",
      "712.pt\n",
      "713.pt\n",
      "714.pt\n",
      "715.pt\n",
      "716.pt\n",
      "717.pt\n",
      "718.pt\n",
      "719.pt\n",
      "720.pt\n",
      "721.pt\n",
      "722.pt\n",
      "723.pt\n",
      "724.pt\n",
      "725.pt\n",
      "726.pt\n",
      "727.pt\n",
      "728.pt\n",
      "729.pt\n",
      "730.pt\n",
      "731.pt\n",
      "732.pt\n",
      "733.pt\n",
      "734.pt\n",
      "735.pt\n",
      "736.pt\n",
      "737.pt\n",
      "738.pt\n",
      "739.pt\n",
      "740.pt\n",
      "741.pt\n",
      "742.pt\n",
      "743.pt\n",
      "744.pt\n",
      "745.pt\n",
      "746.pt\n",
      "747.pt\n",
      "748.pt\n",
      "749.pt\n",
      "750.pt\n",
      "751.pt\n",
      "752.pt\n",
      "753.pt\n",
      "754.pt\n",
      "755.pt\n",
      "756.pt\n",
      "757.pt\n",
      "758.pt\n",
      "759.pt\n",
      "760.pt\n",
      "761.pt\n",
      "762.pt\n",
      "763.pt\n",
      "764.pt\n",
      "765.pt\n",
      "766.pt\n",
      "767.pt\n",
      "768.pt\n",
      "769.pt\n",
      "770.pt\n",
      "771.pt\n",
      "772.pt\n",
      "773.pt\n",
      "774.pt\n",
      "775.pt\n",
      "776.pt\n",
      "777.pt\n",
      "778.pt\n",
      "779.pt\n",
      "780.pt\n",
      "781.pt\n",
      "782.pt\n",
      "783.pt\n",
      "784.pt\n",
      "785.pt\n",
      "786.pt\n",
      "787.pt\n",
      "788.pt\n",
      "789.pt\n",
      "790.pt\n",
      "791.pt\n",
      "792.pt\n",
      "793.pt\n",
      "794.pt\n",
      "795.pt\n",
      "796.pt\n",
      "797.pt\n",
      "798.pt\n",
      "799.pt\n",
      "800.pt\n",
      "801.pt\n",
      "802.pt\n",
      "803.pt\n",
      "804.pt\n",
      "805.pt\n",
      "806.pt\n",
      "807.pt\n",
      "808.pt\n",
      "809.pt\n",
      "810.pt\n",
      "811.pt\n",
      "812.pt\n",
      "813.pt\n",
      "814.pt\n",
      "815.pt\n",
      "816.pt\n",
      "817.pt\n",
      "818.pt\n",
      "819.pt\n",
      "820.pt\n",
      "821.pt\n",
      "822.pt\n",
      "823.pt\n",
      "824.pt\n",
      "825.pt\n",
      "826.pt\n",
      "827.pt\n",
      "828.pt\n",
      "829.pt\n",
      "830.pt\n",
      "831.pt\n",
      "832.pt\n",
      "833.pt\n",
      "834.pt\n",
      "835.pt\n",
      "836.pt\n",
      "837.pt\n",
      "838.pt\n",
      "839.pt\n",
      "840.pt\n",
      "841.pt\n",
      "842.pt\n",
      "843.pt\n",
      "844.pt\n",
      "845.pt\n",
      "846.pt\n",
      "847.pt\n",
      "848.pt\n",
      "849.pt\n",
      "850.pt\n",
      "851.pt\n",
      "852.pt\n",
      "853.pt\n",
      "854.pt\n",
      "855.pt\n",
      "856.pt\n",
      "857.pt\n",
      "858.pt\n",
      "859.pt\n",
      "860.pt\n",
      "861.pt\n",
      "862.pt\n",
      "863.pt\n",
      "864.pt\n",
      "865.pt\n",
      "866.pt\n",
      "867.pt\n",
      "868.pt\n",
      "869.pt\n",
      "870.pt\n",
      "871.pt\n",
      "872.pt\n",
      "873.pt\n",
      "874.pt\n",
      "875.pt\n",
      "876.pt\n",
      "877.pt\n",
      "878.pt\n",
      "879.pt\n",
      "880.pt\n",
      "881.pt\n",
      "882.pt\n",
      "883.pt\n",
      "884.pt\n",
      "885.pt\n",
      "886.pt\n",
      "887.pt\n",
      "888.pt\n",
      "889.pt\n",
      "890.pt\n",
      "891.pt\n",
      "892.pt\n",
      "893.pt\n",
      "894.pt\n",
      "895.pt\n",
      "896.pt\n",
      "897.pt\n",
      "898.pt\n",
      "899.pt\n",
      "900.pt\n",
      "901.pt\n",
      "902.pt\n",
      "903.pt\n",
      "904.pt\n",
      "905.pt\n",
      "906.pt\n",
      "907.pt\n",
      "908.pt\n",
      "909.pt\n",
      "910.pt\n",
      "911.pt\n",
      "912.pt\n",
      "913.pt\n",
      "914.pt\n",
      "915.pt\n",
      "916.pt\n",
      "917.pt\n",
      "918.pt\n",
      "919.pt\n",
      "920.pt\n",
      "921.pt\n",
      "922.pt\n",
      "923.pt\n",
      "924.pt\n",
      "925.pt\n",
      "926.pt\n",
      "927.pt\n",
      "928.pt\n",
      "929.pt\n",
      "930.pt\n",
      "931.pt\n",
      "932.pt\n",
      "933.pt\n",
      "934.pt\n",
      "935.pt\n",
      "936.pt\n",
      "937.pt\n",
      "938.pt\n",
      "939.pt\n",
      "940.pt\n",
      "941.pt\n",
      "942.pt\n",
      "943.pt\n",
      "944.pt\n",
      "945.pt\n",
      "946.pt\n",
      "947.pt\n",
      "948.pt\n",
      "949.pt\n",
      "950.pt\n",
      "951.pt\n",
      "952.pt\n",
      "953.pt\n",
      "954.pt\n",
      "955.pt\n",
      "956.pt\n",
      "957.pt\n",
      "958.pt\n",
      "959.pt\n",
      "960.pt\n",
      "961.pt\n",
      "962.pt\n",
      "963.pt\n",
      "964.pt\n",
      "965.pt\n",
      "966.pt\n",
      "967.pt\n",
      "968.pt\n",
      "969.pt\n",
      "970.pt\n",
      "971.pt\n",
      "972.pt\n",
      "973.pt\n",
      "974.pt\n",
      "975.pt\n",
      "976.pt\n",
      "977.pt\n",
      "978.pt\n",
      "979.pt\n",
      "980.pt\n",
      "981.pt\n",
      "982.pt\n",
      "983.pt\n",
      "984.pt\n",
      "985.pt\n",
      "986.pt\n",
      "987.pt\n",
      "988.pt\n",
      "989.pt\n",
      "990.pt\n",
      "991.pt\n",
      "992.pt\n",
      "993.pt\n",
      "994.pt\n",
      "995.pt\n",
      "996.pt\n",
      "997.pt\n",
      "998.pt\n",
      "999.pt\n",
      "1000.pt\n",
      "1001.pt\n",
      "1002.pt\n",
      "1003.pt\n",
      "1004.pt\n",
      "1005.pt\n",
      "1006.pt\n",
      "1007.pt\n",
      "1008.pt\n",
      "1009.pt\n",
      "1010.pt\n",
      "1011.pt\n",
      "1012.pt\n",
      "1013.pt\n",
      "1014.pt\n",
      "1015.pt\n",
      "1016.pt\n",
      "1017.pt\n",
      "1018.pt\n",
      "1019.pt\n",
      "1020.pt\n",
      "1021.pt\n",
      "1022.pt\n",
      "1023.pt\n",
      "1024.pt\n",
      "1025.pt\n",
      "1026.pt\n",
      "1027.pt\n",
      "1028.pt\n",
      "1029.pt\n",
      "1030.pt\n",
      "1031.pt\n",
      "1032.pt\n",
      "1033.pt\n",
      "1034.pt\n",
      "1035.pt\n",
      "1036.pt\n",
      "1037.pt\n",
      "1038.pt\n",
      "1039.pt\n",
      "1040.pt\n",
      "1041.pt\n",
      "1042.pt\n",
      "1043.pt\n",
      "1044.pt\n",
      "1045.pt\n",
      "1046.pt\n",
      "1047.pt\n",
      "1048.pt\n",
      "1049.pt\n",
      "1050.pt\n",
      "1051.pt\n",
      "1052.pt\n",
      "1053.pt\n",
      "1054.pt\n",
      "1055.pt\n",
      "1056.pt\n",
      "1057.pt\n",
      "1058.pt\n",
      "1059.pt\n",
      "1060.pt\n",
      "1061.pt\n",
      "1062.pt\n",
      "1063.pt\n",
      "1064.pt\n",
      "1065.pt\n",
      "1066.pt\n",
      "1067.pt\n",
      "1068.pt\n",
      "1069.pt\n",
      "1070.pt\n",
      "1071.pt\n",
      "1072.pt\n",
      "1073.pt\n",
      "1074.pt\n",
      "1075.pt\n",
      "1076.pt\n",
      "1077.pt\n",
      "1078.pt\n",
      "1079.pt\n",
      "1080.pt\n",
      "1081.pt\n",
      "1082.pt\n",
      "1083.pt\n",
      "1084.pt\n",
      "1085.pt\n",
      "1086.pt\n",
      "1087.pt\n",
      "1088.pt\n",
      "1089.pt\n",
      "1090.pt\n",
      "1091.pt\n",
      "1092.pt\n",
      "1093.pt\n",
      "1094.pt\n",
      "1095.pt\n",
      "1096.pt\n",
      "1097.pt\n",
      "1098.pt\n",
      "1099.pt\n",
      "1100.pt\n",
      "1101.pt\n",
      "1102.pt\n",
      "1103.pt\n",
      "1104.pt\n",
      "1105.pt\n",
      "1106.pt\n",
      "1107.pt\n",
      "1108.pt\n",
      "1109.pt\n",
      "1110.pt\n",
      "1111.pt\n",
      "1112.pt\n",
      "1113.pt\n",
      "1114.pt\n",
      "1115.pt\n",
      "1116.pt\n",
      "1117.pt\n",
      "1118.pt\n",
      "1119.pt\n",
      "1120.pt\n",
      "1121.pt\n",
      "1122.pt\n",
      "1123.pt\n",
      "1124.pt\n",
      "1125.pt\n",
      "1126.pt\n",
      "1127.pt\n",
      "1128.pt\n",
      "1129.pt\n",
      "1130.pt\n",
      "1131.pt\n",
      "1132.pt\n",
      "1133.pt\n",
      "1134.pt\n",
      "1135.pt\n",
      "1136.pt\n",
      "1137.pt\n",
      "1138.pt\n",
      "1139.pt\n",
      "1140.pt\n",
      "1141.pt\n",
      "1142.pt\n",
      "1143.pt\n",
      "1144.pt\n",
      "1145.pt\n",
      "1146.pt\n",
      "1147.pt\n",
      "1148.pt\n",
      "1149.pt\n",
      "1150.pt\n",
      "1151.pt\n",
      "1152.pt\n",
      "1153.pt\n",
      "1154.pt\n",
      "1155.pt\n",
      "1156.pt\n",
      "1157.pt\n",
      "1158.pt\n",
      "1159.pt\n",
      "1160.pt\n",
      "1161.pt\n",
      "1162.pt\n",
      "1163.pt\n",
      "1164.pt\n",
      "1165.pt\n",
      "1166.pt\n",
      "1167.pt\n",
      "1168.pt\n",
      "1169.pt\n",
      "1170.pt\n",
      "1171.pt\n",
      "1172.pt\n",
      "1173.pt\n",
      "1174.pt\n",
      "1175.pt\n",
      "1176.pt\n",
      "1177.pt\n",
      "1178.pt\n",
      "1179.pt\n",
      "1180.pt\n",
      "1181.pt\n",
      "1182.pt\n",
      "1183.pt\n",
      "1184.pt\n",
      "1185.pt\n",
      "1186.pt\n",
      "1187.pt\n",
      "1188.pt\n",
      "1189.pt\n",
      "1190.pt\n",
      "1191.pt\n",
      "1192.pt\n",
      "1193.pt\n",
      "1194.pt\n",
      "1195.pt\n",
      "1196.pt\n",
      "1197.pt\n",
      "1198.pt\n",
      "1199.pt\n",
      "1200.pt\n",
      "1201.pt\n",
      "1202.pt\n",
      "1203.pt\n",
      "1204.pt\n",
      "1205.pt\n",
      "1206.pt\n",
      "1207.pt\n",
      "1208.pt\n",
      "1209.pt\n",
      "1210.pt\n",
      "1211.pt\n",
      "1212.pt\n",
      "1213.pt\n",
      "1214.pt\n",
      "1215.pt\n",
      "1216.pt\n",
      "1217.pt\n",
      "1218.pt\n",
      "1219.pt\n",
      "1220.pt\n",
      "1221.pt\n",
      "1222.pt\n",
      "1223.pt\n",
      "1224.pt\n",
      "1225.pt\n",
      "1226.pt\n",
      "1227.pt\n",
      "1228.pt\n",
      "1229.pt\n",
      "1230.pt\n",
      "1231.pt\n",
      "1232.pt\n",
      "1233.pt\n",
      "1234.pt\n",
      "1235.pt\n",
      "1236.pt\n",
      "1237.pt\n",
      "1238.pt\n",
      "1239.pt\n",
      "1240.pt\n",
      "1241.pt\n",
      "1242.pt\n",
      "1243.pt\n",
      "1244.pt\n",
      "1245.pt\n",
      "1246.pt\n",
      "1247.pt\n",
      "1248.pt\n",
      "1249.pt\n",
      "1250.pt\n",
      "1251.pt\n",
      "1252.pt\n",
      "1253.pt\n",
      "1254.pt\n",
      "1255.pt\n",
      "1256.pt\n",
      "1257.pt\n",
      "1258.pt\n",
      "1259.pt\n",
      "1260.pt\n",
      "1261.pt\n",
      "1262.pt\n",
      "1263.pt\n",
      "1264.pt\n",
      "1265.pt\n",
      "1266.pt\n",
      "1267.pt\n",
      "1268.pt\n",
      "1269.pt\n",
      "1270.pt\n",
      "1271.pt\n",
      "1272.pt\n",
      "1273.pt\n",
      "1274.pt\n",
      "1275.pt\n",
      "1276.pt\n",
      "1277.pt\n",
      "1278.pt\n",
      "1279.pt\n",
      "1280.pt\n",
      "1281.pt\n",
      "1282.pt\n",
      "1283.pt\n",
      "1284.pt\n",
      "1285.pt\n",
      "1286.pt\n",
      "1287.pt\n",
      "1288.pt\n",
      "1289.pt\n",
      "1290.pt\n",
      "1291.pt\n",
      "1292.pt\n",
      "1293.pt\n",
      "1294.pt\n",
      "1295.pt\n",
      "1296.pt\n",
      "1297.pt\n",
      "1298.pt\n",
      "1299.pt\n",
      "1300.pt\n",
      "1301.pt\n",
      "1302.pt\n",
      "1303.pt\n",
      "1304.pt\n",
      "1305.pt\n",
      "1306.pt\n",
      "1307.pt\n",
      "1308.pt\n",
      "1309.pt\n",
      "1310.pt\n",
      "1311.pt\n",
      "1312.pt\n",
      "1313.pt\n",
      "1314.pt\n",
      "1315.pt\n",
      "1316.pt\n",
      "1317.pt\n",
      "1318.pt\n",
      "1319.pt\n",
      "1320.pt\n",
      "1321.pt\n",
      "1322.pt\n",
      "1323.pt\n",
      "1324.pt\n",
      "1325.pt\n",
      "1326.pt\n",
      "1327.pt\n",
      "1328.pt\n",
      "1329.pt\n",
      "1330.pt\n",
      "1331.pt\n",
      "1332.pt\n",
      "1333.pt\n",
      "1334.pt\n",
      "1335.pt\n",
      "1336.pt\n",
      "1337.pt\n",
      "1338.pt\n",
      "1339.pt\n",
      "1340.pt\n",
      "1341.pt\n",
      "1342.pt\n",
      "1343.pt\n",
      "1344.pt\n",
      "1345.pt\n",
      "1346.pt\n",
      "1347.pt\n",
      "1348.pt\n",
      "1349.pt\n",
      "1350.pt\n",
      "1351.pt\n",
      "1352.pt\n",
      "1353.pt\n",
      "1354.pt\n",
      "1355.pt\n",
      "1356.pt\n",
      "1357.pt\n",
      "1358.pt\n",
      "1359.pt\n",
      "1360.pt\n",
      "1361.pt\n",
      "1362.pt\n",
      "1363.pt\n",
      "1364.pt\n",
      "1365.pt\n",
      "1366.pt\n",
      "1367.pt\n",
      "1368.pt\n",
      "1369.pt\n",
      "1370.pt\n",
      "1371.pt\n",
      "1372.pt\n",
      "1373.pt\n",
      "1374.pt\n",
      "1375.pt\n",
      "1376.pt\n",
      "1377.pt\n",
      "1378.pt\n",
      "1379.pt\n",
      "1380.pt\n",
      "1381.pt\n",
      "1382.pt\n",
      "1383.pt\n",
      "1384.pt\n",
      "1385.pt\n",
      "1386.pt\n",
      "1387.pt\n",
      "1388.pt\n",
      "1389.pt\n",
      "1390.pt\n",
      "1391.pt\n",
      "1392.pt\n",
      "1393.pt\n",
      "1394.pt\n",
      "1395.pt\n",
      "1396.pt\n",
      "1397.pt\n",
      "1398.pt\n",
      "1399.pt\n",
      "1400.pt\n",
      "1401.pt\n",
      "1402.pt\n",
      "1403.pt\n",
      "1404.pt\n",
      "1405.pt\n",
      "1406.pt\n",
      "1407.pt\n",
      "1408.pt\n",
      "1409.pt\n",
      "1410.pt\n",
      "1411.pt\n",
      "1412.pt\n",
      "1413.pt\n",
      "1414.pt\n",
      "1415.pt\n",
      "1416.pt\n",
      "1417.pt\n",
      "1418.pt\n",
      "1419.pt\n",
      "1420.pt\n",
      "1421.pt\n",
      "1422.pt\n",
      "1423.pt\n",
      "1424.pt\n",
      "1425.pt\n",
      "1426.pt\n",
      "1427.pt\n",
      "1428.pt\n",
      "1429.pt\n",
      "1430.pt\n",
      "1431.pt\n",
      "1432.pt\n",
      "1433.pt\n",
      "1434.pt\n",
      "1435.pt\n",
      "1436.pt\n",
      "1437.pt\n",
      "1438.pt\n",
      "1439.pt\n",
      "1440.pt\n",
      "1441.pt\n",
      "1442.pt\n",
      "1443.pt\n",
      "1444.pt\n",
      "1445.pt\n",
      "1446.pt\n",
      "1447.pt\n",
      "1448.pt\n",
      "1449.pt\n",
      "1450.pt\n",
      "1451.pt\n",
      "1452.pt\n",
      "1453.pt\n",
      "1454.pt\n",
      "1455.pt\n",
      "1456.pt\n",
      "1457.pt\n",
      "1458.pt\n",
      "1459.pt\n",
      "1460.pt\n",
      "1461.pt\n",
      "1462.pt\n",
      "1463.pt\n",
      "1464.pt\n",
      "1465.pt\n",
      "1466.pt\n",
      "1467.pt\n",
      "1468.pt\n",
      "1469.pt\n",
      "1470.pt\n",
      "1471.pt\n",
      "1472.pt\n",
      "1473.pt\n",
      "1474.pt\n",
      "1475.pt\n",
      "1476.pt\n",
      "1477.pt\n",
      "1478.pt\n",
      "1479.pt\n",
      "1480.pt\n",
      "1481.pt\n",
      "1482.pt\n",
      "1483.pt\n",
      "1484.pt\n",
      "1485.pt\n",
      "1486.pt\n",
      "1487.pt\n",
      "1488.pt\n",
      "1489.pt\n",
      "1490.pt\n",
      "1491.pt\n",
      "1492.pt\n",
      "1493.pt\n",
      "1494.pt\n",
      "1495.pt\n",
      "1496.pt\n",
      "1497.pt\n",
      "1498.pt\n",
      "1499.pt\n",
      "1500.pt\n",
      "1501.pt\n",
      "1502.pt\n",
      "1503.pt\n",
      "1504.pt\n",
      "1505.pt\n",
      "1506.pt\n",
      "1507.pt\n",
      "1508.pt\n",
      "1509.pt\n",
      "1510.pt\n",
      "1511.pt\n",
      "1512.pt\n",
      "1513.pt\n",
      "1514.pt\n",
      "1515.pt\n",
      "1516.pt\n",
      "1517.pt\n",
      "1518.pt\n",
      "1519.pt\n",
      "1520.pt\n",
      "1521.pt\n",
      "1522.pt\n",
      "1523.pt\n",
      "1524.pt\n",
      "1525.pt\n",
      "1526.pt\n",
      "1527.pt\n",
      "1528.pt\n",
      "1529.pt\n",
      "1530.pt\n",
      "1531.pt\n",
      "1532.pt\n",
      "1533.pt\n",
      "1534.pt\n",
      "1535.pt\n",
      "1536.pt\n",
      "1537.pt\n",
      "1538.pt\n",
      "1539.pt\n",
      "1540.pt\n",
      "1541.pt\n",
      "1542.pt\n",
      "1543.pt\n",
      "1544.pt\n",
      "1545.pt\n",
      "1546.pt\n",
      "1547.pt\n",
      "1548.pt\n",
      "1549.pt\n",
      "1550.pt\n",
      "1551.pt\n",
      "1552.pt\n",
      "1553.pt\n",
      "1554.pt\n",
      "1555.pt\n",
      "1556.pt\n",
      "1557.pt\n",
      "1558.pt\n",
      "1559.pt\n",
      "1560.pt\n",
      "1561.pt\n",
      "1562.pt\n",
      "1563.pt\n",
      "1564.pt\n",
      "1565.pt\n",
      "1566.pt\n",
      "1567.pt\n",
      "1568.pt\n",
      "1569.pt\n",
      "1570.pt\n",
      "1571.pt\n",
      "1572.pt\n",
      "1573.pt\n",
      "1574.pt\n",
      "1575.pt\n",
      "1576.pt\n",
      "1577.pt\n",
      "1578.pt\n",
      "1579.pt\n",
      "1580.pt\n",
      "1581.pt\n",
      "1582.pt\n",
      "1583.pt\n",
      "1584.pt\n",
      "1585.pt\n",
      "1586.pt\n",
      "1587.pt\n",
      "1588.pt\n",
      "1589.pt\n",
      "1590.pt\n",
      "1591.pt\n",
      "1592.pt\n",
      "1593.pt\n",
      "1594.pt\n",
      "1595.pt\n",
      "1596.pt\n",
      "1597.pt\n",
      "1598.pt\n",
      "1599.pt\n",
      "1600.pt\n",
      "1601.pt\n",
      "1602.pt\n",
      "1603.pt\n",
      "1604.pt\n",
      "1605.pt\n",
      "1606.pt\n",
      "1607.pt\n",
      "1608.pt\n",
      "1609.pt\n",
      "1610.pt\n",
      "1611.pt\n",
      "1612.pt\n",
      "1613.pt\n",
      "1614.pt\n",
      "1615.pt\n",
      "1616.pt\n",
      "1617.pt\n",
      "1618.pt\n",
      "1619.pt\n",
      "1620.pt\n",
      "1621.pt\n",
      "1622.pt\n",
      "1623.pt\n",
      "1624.pt\n",
      "1625.pt\n",
      "1626.pt\n",
      "1627.pt\n",
      "1628.pt\n",
      "1629.pt\n",
      "1630.pt\n",
      "1631.pt\n",
      "1632.pt\n",
      "1633.pt\n",
      "1634.pt\n",
      "1635.pt\n",
      "1636.pt\n",
      "1637.pt\n",
      "1638.pt\n",
      "1639.pt\n",
      "1640.pt\n",
      "1641.pt\n",
      "1642.pt\n",
      "1643.pt\n",
      "1644.pt\n",
      "1645.pt\n",
      "1646.pt\n",
      "1647.pt\n",
      "1648.pt\n",
      "1649.pt\n",
      "1650.pt\n",
      "1651.pt\n",
      "1652.pt\n",
      "1653.pt\n",
      "1654.pt\n",
      "1655.pt\n",
      "1656.pt\n",
      "1657.pt\n",
      "1658.pt\n",
      "1659.pt\n",
      "1660.pt\n",
      "1661.pt\n",
      "1662.pt\n",
      "1663.pt\n",
      "1664.pt\n",
      "1665.pt\n",
      "1666.pt\n",
      "1667.pt\n",
      "1668.pt\n",
      "1669.pt\n",
      "1670.pt\n",
      "1671.pt\n",
      "1672.pt\n",
      "1673.pt\n",
      "1674.pt\n",
      "1675.pt\n",
      "1676.pt\n",
      "1677.pt\n",
      "1678.pt\n",
      "1679.pt\n",
      "1680.pt\n",
      "1681.pt\n",
      "1682.pt\n",
      "1683.pt\n",
      "1684.pt\n",
      "1685.pt\n",
      "1686.pt\n",
      "1687.pt\n",
      "1688.pt\n",
      "1689.pt\n",
      "1690.pt\n",
      "1691.pt\n",
      "1692.pt\n",
      "1693.pt\n",
      "1694.pt\n",
      "1695.pt\n",
      "1696.pt\n",
      "1697.pt\n",
      "1698.pt\n",
      "1699.pt\n",
      "1700.pt\n",
      "1701.pt\n",
      "1702.pt\n",
      "1703.pt\n",
      "1704.pt\n",
      "1705.pt\n",
      "1706.pt\n",
      "1707.pt\n",
      "1708.pt\n",
      "1709.pt\n",
      "1710.pt\n",
      "1711.pt\n",
      "1712.pt\n",
      "1713.pt\n",
      "1714.pt\n",
      "1715.pt\n",
      "1716.pt\n",
      "1717.pt\n",
      "1718.pt\n",
      "1719.pt\n",
      "1720.pt\n",
      "1721.pt\n",
      "1722.pt\n",
      "1723.pt\n",
      "1724.pt\n",
      "1725.pt\n",
      "1726.pt\n",
      "1727.pt\n",
      "1728.pt\n",
      "1729.pt\n",
      "1730.pt\n",
      "1731.pt\n",
      "1732.pt\n",
      "1733.pt\n",
      "1734.pt\n",
      "1735.pt\n",
      "1736.pt\n",
      "1737.pt\n",
      "1738.pt\n",
      "1739.pt\n",
      "1740.pt\n",
      "1741.pt\n",
      "1742.pt\n",
      "1743.pt\n",
      "1744.pt\n",
      "1745.pt\n",
      "1746.pt\n",
      "1747.pt\n",
      "1748.pt\n",
      "1749.pt\n",
      "1750.pt\n",
      "1751.pt\n",
      "1752.pt\n",
      "1753.pt\n",
      "1754.pt\n",
      "1755.pt\n",
      "1756.pt\n",
      "1757.pt\n",
      "1758.pt\n",
      "1759.pt\n",
      "1760.pt\n",
      "1761.pt\n",
      "1762.pt\n",
      "1763.pt\n",
      "1764.pt\n",
      "1765.pt\n",
      "1766.pt\n",
      "1767.pt\n",
      "1768.pt\n",
      "1769.pt\n",
      "1770.pt\n",
      "1771.pt\n",
      "1772.pt\n",
      "1773.pt\n",
      "1774.pt\n",
      "1775.pt\n",
      "1776.pt\n",
      "1777.pt\n",
      "1778.pt\n",
      "1779.pt\n",
      "1780.pt\n",
      "1781.pt\n",
      "1782.pt\n",
      "1783.pt\n",
      "1784.pt\n",
      "1785.pt\n",
      "1786.pt\n",
      "1787.pt\n",
      "1788.pt\n",
      "1789.pt\n",
      "1790.pt\n",
      "1791.pt\n",
      "1792.pt\n",
      "1793.pt\n",
      "1794.pt\n",
      "1795.pt\n",
      "1796.pt\n",
      "1797.pt\n",
      "1798.pt\n",
      "1799.pt\n",
      "1800.pt\n",
      "1801.pt\n",
      "1802.pt\n",
      "1803.pt\n",
      "1804.pt\n",
      "1805.pt\n",
      "1806.pt\n",
      "1807.pt\n",
      "1808.pt\n",
      "1809.pt\n",
      "1810.pt\n",
      "1811.pt\n",
      "1812.pt\n",
      "1813.pt\n",
      "1814.pt\n",
      "1815.pt\n",
      "1816.pt\n",
      "1817.pt\n",
      "1818.pt\n",
      "1819.pt\n",
      "1820.pt\n",
      "1821.pt\n",
      "1822.pt\n",
      "1823.pt\n",
      "1824.pt\n",
      "1825.pt\n",
      "1826.pt\n",
      "1827.pt\n",
      "1828.pt\n",
      "1829.pt\n",
      "1830.pt\n",
      "1831.pt\n",
      "1832.pt\n",
      "1833.pt\n",
      "1834.pt\n",
      "1835.pt\n",
      "1836.pt\n",
      "1837.pt\n",
      "1838.pt\n",
      "1839.pt\n",
      "1840.pt\n",
      "1841.pt\n",
      "1842.pt\n",
      "1843.pt\n",
      "1844.pt\n",
      "1845.pt\n",
      "1846.pt\n",
      "1847.pt\n",
      "1848.pt\n",
      "1849.pt\n",
      "1850.pt\n",
      "1851.pt\n",
      "1852.pt\n",
      "1853.pt\n",
      "1854.pt\n",
      "1855.pt\n",
      "1856.pt\n",
      "1857.pt\n",
      "1858.pt\n",
      "1859.pt\n",
      "1860.pt\n",
      "1861.pt\n",
      "1862.pt\n",
      "1863.pt\n",
      "1864.pt\n",
      "1865.pt\n",
      "1866.pt\n",
      "1867.pt\n",
      "1868.pt\n",
      "1869.pt\n",
      "1870.pt\n",
      "1871.pt\n",
      "1872.pt\n",
      "1873.pt\n",
      "1874.pt\n",
      "1875.pt\n",
      "1876.pt\n",
      "1877.pt\n",
      "1878.pt\n",
      "1879.pt\n",
      "1880.pt\n",
      "1881.pt\n",
      "1882.pt\n",
      "1883.pt\n",
      "1884.pt\n",
      "1885.pt\n",
      "1886.pt\n",
      "1887.pt\n",
      "1888.pt\n",
      "1889.pt\n",
      "1890.pt\n",
      "1891.pt\n",
      "1892.pt\n",
      "1893.pt\n",
      "1894.pt\n",
      "1895.pt\n",
      "1896.pt\n",
      "1897.pt\n",
      "1898.pt\n",
      "1899.pt\n",
      "1900.pt\n",
      "1901.pt\n",
      "1902.pt\n",
      "1903.pt\n",
      "1904.pt\n",
      "1905.pt\n",
      "1906.pt\n",
      "1907.pt\n",
      "1908.pt\n",
      "1909.pt\n",
      "1910.pt\n",
      "1911.pt\n",
      "1912.pt\n",
      "1913.pt\n",
      "1914.pt\n",
      "1915.pt\n",
      "1916.pt\n",
      "1917.pt\n",
      "1918.pt\n",
      "1919.pt\n",
      "1920.pt\n",
      "1921.pt\n",
      "1922.pt\n",
      "1923.pt\n",
      "1924.pt\n",
      "1925.pt\n",
      "1926.pt\n",
      "1927.pt\n",
      "1928.pt\n",
      "1929.pt\n",
      "1930.pt\n",
      "1931.pt\n",
      "1932.pt\n",
      "1933.pt\n",
      "1934.pt\n",
      "1935.pt\n",
      "1936.pt\n",
      "1937.pt\n",
      "1938.pt\n",
      "1939.pt\n",
      "1940.pt\n",
      "1941.pt\n",
      "1942.pt\n",
      "1943.pt\n",
      "1944.pt\n",
      "1945.pt\n",
      "1946.pt\n",
      "1947.pt\n",
      "1948.pt\n",
      "1949.pt\n",
      "1950.pt\n",
      "1951.pt\n",
      "1952.pt\n",
      "1953.pt\n",
      "1954.pt\n",
      "1955.pt\n",
      "1956.pt\n",
      "1957.pt\n",
      "1958.pt\n",
      "1959.pt\n",
      "1960.pt\n",
      "1961.pt\n",
      "1962.pt\n",
      "1963.pt\n",
      "1964.pt\n",
      "1965.pt\n",
      "1966.pt\n",
      "1967.pt\n",
      "1968.pt\n",
      "1969.pt\n",
      "1970.pt\n",
      "1971.pt\n",
      "1972.pt\n",
      "1973.pt\n",
      "1974.pt\n",
      "1975.pt\n",
      "1976.pt\n",
      "1977.pt\n",
      "1978.pt\n",
      "1979.pt\n",
      "1980.pt\n",
      "1981.pt\n",
      "1982.pt\n",
      "1983.pt\n",
      "1984.pt\n",
      "1985.pt\n",
      "1986.pt\n",
      "1987.pt\n",
      "1988.pt\n",
      "1989.pt\n",
      "1990.pt\n",
      "1991.pt\n",
      "1992.pt\n",
      "1993.pt\n",
      "1994.pt\n",
      "1995.pt\n",
      "1996.pt\n",
      "1997.pt\n",
      "1998.pt\n",
      "1999.pt\n",
      "2000.pt\n",
      "2001.pt\n",
      "2002.pt\n",
      "2003.pt\n",
      "2004.pt\n",
      "2005.pt\n",
      "2006.pt\n",
      "2007.pt\n",
      "2008.pt\n",
      "2009.pt\n",
      "2010.pt\n",
      "2011.pt\n",
      "2012.pt\n",
      "2013.pt\n",
      "2014.pt\n",
      "2015.pt\n",
      "2016.pt\n",
      "2017.pt\n",
      "2018.pt\n",
      "2019.pt\n",
      "2020.pt\n",
      "2021.pt\n",
      "2022.pt\n",
      "2023.pt\n",
      "2024.pt\n",
      "2025.pt\n",
      "2026.pt\n",
      "2027.pt\n",
      "2028.pt\n",
      "2029.pt\n",
      "2030.pt\n",
      "2031.pt\n",
      "2032.pt\n",
      "2033.pt\n",
      "2034.pt\n",
      "2035.pt\n",
      "2036.pt\n",
      "2037.pt\n",
      "2038.pt\n",
      "2039.pt\n",
      "2040.pt\n",
      "2041.pt\n",
      "2042.pt\n",
      "2043.pt\n",
      "2044.pt\n",
      "2045.pt\n",
      "2046.pt\n",
      "2047.pt\n",
      "2048.pt\n",
      "2049.pt\n",
      "2050.pt\n",
      "2051.pt\n",
      "2052.pt\n",
      "2053.pt\n",
      "2054.pt\n",
      "2055.pt\n",
      "2056.pt\n",
      "2057.pt\n",
      "2058.pt\n",
      "2059.pt\n",
      "2060.pt\n",
      "2061.pt\n",
      "2062.pt\n",
      "2063.pt\n",
      "2064.pt\n",
      "2065.pt\n",
      "2066.pt\n",
      "2067.pt\n",
      "2068.pt\n",
      "2069.pt\n",
      "2070.pt\n",
      "2071.pt\n",
      "2072.pt\n",
      "2073.pt\n",
      "2074.pt\n",
      "2075.pt\n",
      "2076.pt\n",
      "2077.pt\n",
      "2078.pt\n",
      "2079.pt\n",
      "2080.pt\n",
      "2081.pt\n",
      "2082.pt\n",
      "2083.pt\n",
      "2084.pt\n",
      "2085.pt\n",
      "2086.pt\n",
      "2087.pt\n",
      "2088.pt\n",
      "2089.pt\n",
      "2090.pt\n",
      "2091.pt\n",
      "2092.pt\n",
      "2093.pt\n",
      "2094.pt\n",
      "2095.pt\n",
      "2096.pt\n",
      "2097.pt\n",
      "2098.pt\n",
      "2099.pt\n",
      "2100.pt\n",
      "2101.pt\n",
      "2102.pt\n",
      "2103.pt\n",
      "2104.pt\n",
      "2105.pt\n",
      "2106.pt\n",
      "2107.pt\n",
      "2108.pt\n",
      "2109.pt\n",
      "2110.pt\n",
      "2111.pt\n",
      "2112.pt\n",
      "2113.pt\n",
      "2114.pt\n",
      "2115.pt\n",
      "2116.pt\n",
      "2117.pt\n",
      "2118.pt\n",
      "2119.pt\n",
      "2120.pt\n",
      "2121.pt\n",
      "2122.pt\n",
      "2123.pt\n",
      "2124.pt\n",
      "2125.pt\n",
      "2126.pt\n",
      "2127.pt\n",
      "2128.pt\n",
      "2129.pt\n",
      "2130.pt\n",
      "2131.pt\n",
      "2132.pt\n",
      "2133.pt\n",
      "2134.pt\n",
      "2135.pt\n",
      "2136.pt\n",
      "2137.pt\n",
      "2138.pt\n",
      "2139.pt\n",
      "2140.pt\n",
      "2141.pt\n",
      "2142.pt\n",
      "2143.pt\n",
      "2144.pt\n",
      "2145.pt\n",
      "2146.pt\n",
      "2147.pt\n",
      "2148.pt\n",
      "2149.pt\n",
      "2150.pt\n",
      "2151.pt\n",
      "2152.pt\n",
      "2153.pt\n",
      "2154.pt\n",
      "2155.pt\n",
      "2156.pt\n",
      "2157.pt\n",
      "2158.pt\n",
      "2159.pt\n",
      "2160.pt\n",
      "2161.pt\n",
      "2162.pt\n",
      "2163.pt\n",
      "2164.pt\n",
      "2165.pt\n",
      "2166.pt\n",
      "2167.pt\n",
      "2168.pt\n",
      "2169.pt\n",
      "2170.pt\n",
      "2171.pt\n",
      "2172.pt\n",
      "2173.pt\n",
      "2174.pt\n",
      "2175.pt\n",
      "2176.pt\n",
      "2177.pt\n",
      "2178.pt\n",
      "2179.pt\n",
      "2180.pt\n",
      "2181.pt\n",
      "2182.pt\n",
      "2183.pt\n",
      "2184.pt\n",
      "2185.pt\n",
      "2186.pt\n",
      "2187.pt\n",
      "2188.pt\n",
      "2189.pt\n",
      "2190.pt\n",
      "2191.pt\n",
      "2192.pt\n",
      "2193.pt\n",
      "2194.pt\n",
      "2195.pt\n",
      "2196.pt\n",
      "2197.pt\n",
      "2198.pt\n",
      "2199.pt\n",
      "2200.pt\n",
      "2201.pt\n",
      "2202.pt\n",
      "2203.pt\n",
      "2204.pt\n",
      "2205.pt\n",
      "2206.pt\n",
      "2207.pt\n",
      "2208.pt\n",
      "2209.pt\n",
      "2210.pt\n",
      "2211.pt\n",
      "2212.pt\n",
      "2213.pt\n",
      "2214.pt\n",
      "2215.pt\n",
      "2216.pt\n",
      "2217.pt\n",
      "2218.pt\n",
      "2219.pt\n",
      "2220.pt\n",
      "2221.pt\n",
      "2222.pt\n",
      "2223.pt\n",
      "2224.pt\n",
      "2225.pt\n",
      "2226.pt\n",
      "2227.pt\n",
      "2228.pt\n",
      "2229.pt\n",
      "2230.pt\n",
      "2231.pt\n",
      "2232.pt\n",
      "2233.pt\n",
      "2234.pt\n",
      "2235.pt\n",
      "2236.pt\n",
      "2237.pt\n",
      "2238.pt\n",
      "2239.pt\n",
      "2240.pt\n",
      "2241.pt\n",
      "2242.pt\n",
      "2243.pt\n",
      "2244.pt\n",
      "2245.pt\n",
      "2246.pt\n",
      "2247.pt\n",
      "2248.pt\n",
      "2249.pt\n",
      "2250.pt\n",
      "2251.pt\n",
      "2252.pt\n",
      "2253.pt\n",
      "2254.pt\n",
      "2255.pt\n",
      "2256.pt\n",
      "2257.pt\n",
      "2258.pt\n",
      "2259.pt\n",
      "2260.pt\n",
      "2261.pt\n",
      "2262.pt\n",
      "2263.pt\n",
      "2264.pt\n",
      "2265.pt\n",
      "2266.pt\n",
      "2267.pt\n",
      "2268.pt\n",
      "2269.pt\n",
      "2270.pt\n",
      "2271.pt\n",
      "2272.pt\n",
      "2273.pt\n",
      "2274.pt\n",
      "2275.pt\n",
      "2276.pt\n",
      "2277.pt\n",
      "2278.pt\n",
      "2279.pt\n",
      "2280.pt\n",
      "2281.pt\n",
      "2282.pt\n",
      "2283.pt\n",
      "2284.pt\n",
      "2285.pt\n",
      "2286.pt\n",
      "2287.pt\n",
      "2288.pt\n",
      "2289.pt\n",
      "2290.pt\n",
      "2291.pt\n",
      "2292.pt\n",
      "2293.pt\n",
      "2294.pt\n",
      "2295.pt\n",
      "2296.pt\n",
      "2297.pt\n",
      "2298.pt\n",
      "2299.pt\n",
      "2300.pt\n",
      "2301.pt\n",
      "2302.pt\n",
      "2303.pt\n",
      "2304.pt\n",
      "2305.pt\n",
      "2306.pt\n",
      "2307.pt\n",
      "2308.pt\n",
      "2309.pt\n",
      "2310.pt\n",
      "2311.pt\n",
      "2312.pt\n",
      "2313.pt\n",
      "2314.pt\n",
      "2315.pt\n",
      "2316.pt\n",
      "2317.pt\n",
      "2318.pt\n",
      "2319.pt\n",
      "2320.pt\n",
      "2321.pt\n",
      "2322.pt\n",
      "2323.pt\n",
      "2324.pt\n",
      "2325.pt\n",
      "2326.pt\n",
      "2327.pt\n",
      "2328.pt\n",
      "2329.pt\n",
      "2330.pt\n",
      "2331.pt\n",
      "2332.pt\n",
      "2333.pt\n",
      "2334.pt\n",
      "2335.pt\n",
      "2336.pt\n",
      "2337.pt\n",
      "2338.pt\n",
      "2339.pt\n",
      "2340.pt\n",
      "2341.pt\n",
      "2342.pt\n",
      "2343.pt\n",
      "2344.pt\n",
      "2345.pt\n",
      "2346.pt\n",
      "2347.pt\n",
      "2348.pt\n",
      "2349.pt\n",
      "2350.pt\n",
      "2351.pt\n",
      "2352.pt\n",
      "2353.pt\n",
      "2354.pt\n",
      "2355.pt\n",
      "2356.pt\n",
      "2357.pt\n",
      "2358.pt\n",
      "2359.pt\n",
      "2360.pt\n",
      "2361.pt\n",
      "2362.pt\n",
      "2363.pt\n",
      "2364.pt\n",
      "2365.pt\n",
      "2366.pt\n",
      "2367.pt\n",
      "2368.pt\n",
      "2369.pt\n",
      "2370.pt\n",
      "2371.pt\n",
      "2372.pt\n",
      "2373.pt\n",
      "2374.pt\n",
      "2375.pt\n",
      "2376.pt\n",
      "2377.pt\n",
      "2378.pt\n",
      "2379.pt\n",
      "2380.pt\n",
      "2381.pt\n",
      "2382.pt\n",
      "2383.pt\n",
      "2384.pt\n",
      "2385.pt\n",
      "2386.pt\n",
      "2387.pt\n",
      "2388.pt\n",
      "2389.pt\n",
      "2390.pt\n",
      "2391.pt\n",
      "2392.pt\n",
      "2393.pt\n",
      "2394.pt\n",
      "2395.pt\n",
      "2396.pt\n",
      "2397.pt\n",
      "2398.pt\n",
      "2399.pt\n",
      "2400.pt\n",
      "2401.pt\n",
      "2402.pt\n",
      "2403.pt\n",
      "2404.pt\n",
      "2405.pt\n",
      "2406.pt\n",
      "2407.pt\n",
      "2408.pt\n",
      "2409.pt\n",
      "2410.pt\n",
      "2411.pt\n",
      "2412.pt\n",
      "2413.pt\n",
      "2414.pt\n",
      "2415.pt\n",
      "2416.pt\n",
      "2417.pt\n",
      "2418.pt\n",
      "2419.pt\n",
      "2420.pt\n",
      "2421.pt\n",
      "2422.pt\n",
      "2423.pt\n",
      "2424.pt\n",
      "2425.pt\n",
      "2426.pt\n",
      "2427.pt\n",
      "2428.pt\n",
      "2429.pt\n",
      "2430.pt\n",
      "2431.pt\n",
      "2432.pt\n",
      "2433.pt\n",
      "2434.pt\n",
      "2435.pt\n",
      "2436.pt\n",
      "2437.pt\n",
      "2438.pt\n",
      "2439.pt\n",
      "2440.pt\n",
      "2441.pt\n",
      "2442.pt\n",
      "2443.pt\n",
      "2444.pt\n",
      "2445.pt\n",
      "2446.pt\n",
      "2447.pt\n",
      "2448.pt\n",
      "2449.pt\n",
      "2450.pt\n",
      "2451.pt\n",
      "2452.pt\n",
      "2453.pt\n",
      "2454.pt\n",
      "2455.pt\n",
      "2456.pt\n",
      "2457.pt\n",
      "2458.pt\n",
      "2459.pt\n",
      "2460.pt\n",
      "2461.pt\n",
      "2462.pt\n",
      "2463.pt\n",
      "2464.pt\n",
      "2465.pt\n",
      "2466.pt\n",
      "2467.pt\n",
      "2468.pt\n",
      "2469.pt\n",
      "2470.pt\n",
      "2471.pt\n",
      "2472.pt\n",
      "2473.pt\n",
      "2474.pt\n",
      "2475.pt\n",
      "2476.pt\n",
      "2477.pt\n",
      "2478.pt\n",
      "2479.pt\n",
      "2480.pt\n",
      "2481.pt\n",
      "2482.pt\n",
      "2483.pt\n",
      "2484.pt\n",
      "2485.pt\n",
      "2486.pt\n",
      "2487.pt\n",
      "2488.pt\n",
      "2489.pt\n",
      "2490.pt\n",
      "2491.pt\n",
      "2492.pt\n",
      "2493.pt\n",
      "2494.pt\n",
      "2495.pt\n",
      "2496.pt\n",
      "2497.pt\n",
      "2498.pt\n",
      "2499.pt\n",
      "2500.pt\n",
      "2501.pt\n",
      "2502.pt\n",
      "2503.pt\n",
      "2504.pt\n",
      "2505.pt\n",
      "2506.pt\n",
      "2507.pt\n",
      "2508.pt\n",
      "2509.pt\n",
      "2510.pt\n",
      "2511.pt\n",
      "2512.pt\n",
      "2513.pt\n",
      "2514.pt\n",
      "2515.pt\n",
      "2516.pt\n",
      "2517.pt\n",
      "2518.pt\n",
      "2519.pt\n",
      "2520.pt\n",
      "2521.pt\n",
      "2522.pt\n",
      "2523.pt\n",
      "2524.pt\n",
      "2525.pt\n",
      "2526.pt\n",
      "2527.pt\n",
      "2528.pt\n",
      "2529.pt\n",
      "2530.pt\n",
      "2531.pt\n",
      "2532.pt\n",
      "2533.pt\n",
      "2534.pt\n",
      "2535.pt\n",
      "2536.pt\n",
      "2537.pt\n",
      "2538.pt\n",
      "2539.pt\n",
      "2540.pt\n",
      "2541.pt\n",
      "2542.pt\n",
      "2543.pt\n",
      "2544.pt\n",
      "2545.pt\n",
      "2546.pt\n",
      "2547.pt\n",
      "2548.pt\n",
      "2549.pt\n",
      "2550.pt\n",
      "2551.pt\n",
      "2552.pt\n",
      "2553.pt\n",
      "2554.pt\n",
      "2555.pt\n",
      "2556.pt\n",
      "2557.pt\n",
      "2558.pt\n",
      "2559.pt\n",
      "2560.pt\n",
      "2561.pt\n",
      "2562.pt\n",
      "2563.pt\n",
      "2564.pt\n",
      "2565.pt\n",
      "2566.pt\n",
      "2567.pt\n",
      "2568.pt\n",
      "2569.pt\n",
      "2570.pt\n",
      "2571.pt\n",
      "2572.pt\n",
      "2573.pt\n",
      "2574.pt\n",
      "2575.pt\n",
      "2576.pt\n",
      "2577.pt\n",
      "2578.pt\n",
      "2579.pt\n",
      "2580.pt\n",
      "2581.pt\n",
      "2582.pt\n",
      "2583.pt\n",
      "2584.pt\n",
      "2585.pt\n",
      "2586.pt\n",
      "2587.pt\n",
      "2588.pt\n",
      "2589.pt\n",
      "2590.pt\n",
      "2591.pt\n",
      "2592.pt\n",
      "2593.pt\n",
      "2594.pt\n",
      "2595.pt\n",
      "2596.pt\n",
      "2597.pt\n",
      "2598.pt\n",
      "2599.pt\n",
      "2600.pt\n",
      "2601.pt\n",
      "2602.pt\n",
      "2603.pt\n",
      "2604.pt\n",
      "2605.pt\n",
      "2606.pt\n",
      "2607.pt\n",
      "2608.pt\n",
      "2609.pt\n",
      "2610.pt\n",
      "2611.pt\n",
      "2612.pt\n",
      "2613.pt\n",
      "2614.pt\n",
      "2615.pt\n",
      "2616.pt\n",
      "2617.pt\n",
      "2618.pt\n",
      "2619.pt\n",
      "2620.pt\n",
      "2621.pt\n",
      "2622.pt\n",
      "2623.pt\n",
      "2624.pt\n",
      "2625.pt\n",
      "2626.pt\n",
      "2627.pt\n",
      "2628.pt\n",
      "2629.pt\n",
      "2630.pt\n",
      "2631.pt\n",
      "2632.pt\n",
      "2633.pt\n",
      "2634.pt\n",
      "2635.pt\n",
      "2636.pt\n",
      "2637.pt\n",
      "2638.pt\n",
      "2639.pt\n",
      "2640.pt\n",
      "2641.pt\n",
      "2642.pt\n",
      "2643.pt\n",
      "2644.pt\n",
      "2645.pt\n",
      "2646.pt\n",
      "2647.pt\n",
      "2648.pt\n",
      "2649.pt\n",
      "2650.pt\n",
      "2651.pt\n",
      "2652.pt\n",
      "2653.pt\n",
      "2654.pt\n",
      "2655.pt\n",
      "2656.pt\n",
      "2657.pt\n",
      "2658.pt\n",
      "2659.pt\n",
      "2660.pt\n",
      "2661.pt\n",
      "2662.pt\n",
      "2663.pt\n",
      "2664.pt\n",
      "2665.pt\n",
      "2666.pt\n",
      "2667.pt\n",
      "2668.pt\n",
      "2669.pt\n",
      "2670.pt\n",
      "2671.pt\n",
      "2672.pt\n",
      "2673.pt\n",
      "2674.pt\n",
      "2675.pt\n",
      "2676.pt\n",
      "2677.pt\n",
      "2678.pt\n",
      "2679.pt\n",
      "2680.pt\n",
      "2681.pt\n",
      "2682.pt\n",
      "2683.pt\n",
      "2684.pt\n",
      "2685.pt\n",
      "2686.pt\n",
      "2687.pt\n",
      "2688.pt\n",
      "2689.pt\n",
      "2690.pt\n",
      "2691.pt\n",
      "2692.pt\n",
      "2693.pt\n",
      "2694.pt\n",
      "2695.pt\n",
      "2696.pt\n",
      "2697.pt\n",
      "2698.pt\n",
      "2699.pt\n",
      "2700.pt\n",
      "2701.pt\n",
      "2702.pt\n",
      "2703.pt\n",
      "2704.pt\n",
      "2705.pt\n",
      "2706.pt\n",
      "2707.pt\n",
      "2708.pt\n",
      "2709.pt\n",
      "2710.pt\n",
      "2711.pt\n",
      "2712.pt\n",
      "2713.pt\n",
      "2714.pt\n",
      "2715.pt\n",
      "2716.pt\n",
      "2717.pt\n",
      "2718.pt\n",
      "2719.pt\n",
      "2720.pt\n",
      "2721.pt\n",
      "2722.pt\n",
      "2723.pt\n",
      "2724.pt\n",
      "2725.pt\n",
      "2726.pt\n",
      "2727.pt\n",
      "2728.pt\n",
      "2729.pt\n",
      "2730.pt\n",
      "2731.pt\n",
      "2732.pt\n",
      "2733.pt\n",
      "2734.pt\n",
      "2735.pt\n",
      "2736.pt\n",
      "2737.pt\n",
      "2738.pt\n",
      "2739.pt\n",
      "2740.pt\n",
      "2741.pt\n",
      "2742.pt\n",
      "2743.pt\n",
      "2744.pt\n",
      "2745.pt\n",
      "2746.pt\n",
      "2747.pt\n",
      "2748.pt\n",
      "2749.pt\n",
      "2750.pt\n",
      "2751.pt\n",
      "2752.pt\n",
      "2753.pt\n",
      "2754.pt\n",
      "2755.pt\n",
      "2756.pt\n",
      "2757.pt\n",
      "2758.pt\n",
      "2759.pt\n",
      "2760.pt\n",
      "2761.pt\n",
      "2762.pt\n",
      "2763.pt\n",
      "2764.pt\n",
      "2765.pt\n",
      "2766.pt\n",
      "2767.pt\n",
      "2768.pt\n",
      "2769.pt\n",
      "2770.pt\n",
      "2771.pt\n",
      "2772.pt\n",
      "2773.pt\n",
      "2774.pt\n",
      "2775.pt\n",
      "2776.pt\n",
      "2777.pt\n",
      "2778.pt\n",
      "2779.pt\n",
      "2780.pt\n",
      "2781.pt\n",
      "2782.pt\n",
      "2783.pt\n",
      "2784.pt\n",
      "2785.pt\n",
      "2786.pt\n",
      "2787.pt\n",
      "2788.pt\n",
      "2789.pt\n",
      "2790.pt\n",
      "2791.pt\n",
      "2792.pt\n",
      "2793.pt\n",
      "2794.pt\n",
      "2795.pt\n",
      "2796.pt\n",
      "2797.pt\n",
      "2798.pt\n",
      "2799.pt\n",
      "2800.pt\n",
      "2801.pt\n",
      "2802.pt\n",
      "2803.pt\n",
      "2804.pt\n",
      "2805.pt\n",
      "2806.pt\n",
      "2807.pt\n",
      "2808.pt\n",
      "2809.pt\n",
      "2810.pt\n",
      "2811.pt\n",
      "2812.pt\n",
      "2813.pt\n",
      "2814.pt\n",
      "2815.pt\n",
      "2816.pt\n",
      "2817.pt\n",
      "2818.pt\n",
      "2819.pt\n",
      "2820.pt\n",
      "2821.pt\n",
      "2822.pt\n",
      "2823.pt\n",
      "2824.pt\n",
      "2825.pt\n",
      "2826.pt\n",
      "2827.pt\n",
      "2828.pt\n",
      "2829.pt\n",
      "2830.pt\n",
      "2831.pt\n",
      "2832.pt\n",
      "2833.pt\n",
      "2834.pt\n",
      "2835.pt\n",
      "2836.pt\n",
      "2837.pt\n",
      "2838.pt\n",
      "2839.pt\n",
      "2840.pt\n",
      "2841.pt\n",
      "2842.pt\n",
      "2843.pt\n",
      "2844.pt\n",
      "2845.pt\n",
      "2846.pt\n",
      "2847.pt\n",
      "2848.pt\n",
      "2849.pt\n",
      "2850.pt\n",
      "2851.pt\n",
      "2852.pt\n",
      "2853.pt\n",
      "2854.pt\n",
      "2855.pt\n",
      "2856.pt\n",
      "2857.pt\n",
      "2858.pt\n",
      "2859.pt\n",
      "2860.pt\n",
      "2861.pt\n",
      "2862.pt\n",
      "2863.pt\n",
      "2864.pt\n",
      "2865.pt\n",
      "2866.pt\n",
      "2867.pt\n",
      "2868.pt\n",
      "2869.pt\n",
      "2870.pt\n",
      "2871.pt\n",
      "2872.pt\n",
      "2873.pt\n",
      "2874.pt\n",
      "2875.pt\n",
      "2876.pt\n",
      "2877.pt\n",
      "2878.pt\n",
      "2879.pt\n",
      "2880.pt\n",
      "2881.pt\n",
      "2882.pt\n",
      "2883.pt\n",
      "2884.pt\n",
      "2885.pt\n",
      "2886.pt\n",
      "2887.pt\n",
      "2888.pt\n",
      "2889.pt\n",
      "2890.pt\n",
      "2891.pt\n",
      "2892.pt\n",
      "2893.pt\n",
      "2894.pt\n",
      "2895.pt\n",
      "2896.pt\n",
      "2897.pt\n",
      "2898.pt\n",
      "2899.pt\n",
      "2900.pt\n",
      "2901.pt\n",
      "2902.pt\n",
      "2903.pt\n",
      "2904.pt\n",
      "2905.pt\n",
      "2906.pt\n",
      "2907.pt\n",
      "2908.pt\n",
      "2909.pt\n",
      "2910.pt\n",
      "2911.pt\n",
      "2912.pt\n",
      "2913.pt\n",
      "2914.pt\n",
      "2915.pt\n",
      "2916.pt\n",
      "2917.pt\n",
      "2918.pt\n",
      "2919.pt\n",
      "2920.pt\n",
      "2921.pt\n",
      "2922.pt\n",
      "2923.pt\n",
      "2924.pt\n",
      "2925.pt\n",
      "2926.pt\n",
      "2927.pt\n",
      "2928.pt\n",
      "2929.pt\n",
      "2930.pt\n",
      "2931.pt\n",
      "2932.pt\n",
      "2933.pt\n",
      "2934.pt\n",
      "2935.pt\n",
      "2936.pt\n",
      "2937.pt\n",
      "2938.pt\n",
      "2939.pt\n",
      "2940.pt\n",
      "2941.pt\n",
      "2942.pt\n",
      "2943.pt\n",
      "2944.pt\n",
      "2945.pt\n",
      "2946.pt\n",
      "2947.pt\n",
      "2948.pt\n",
      "2949.pt\n",
      "2950.pt\n",
      "2951.pt\n",
      "2952.pt\n",
      "2953.pt\n",
      "2954.pt\n",
      "2955.pt\n",
      "2956.pt\n",
      "2957.pt\n",
      "2958.pt\n",
      "2959.pt\n",
      "2960.pt\n",
      "2961.pt\n",
      "2962.pt\n",
      "2963.pt\n",
      "2964.pt\n",
      "2965.pt\n",
      "2966.pt\n",
      "2967.pt\n",
      "2968.pt\n",
      "2969.pt\n",
      "2970.pt\n",
      "2971.pt\n",
      "2972.pt\n",
      "2973.pt\n",
      "2974.pt\n",
      "2975.pt\n",
      "2976.pt\n",
      "2977.pt\n",
      "2978.pt\n",
      "2979.pt\n",
      "2980.pt\n",
      "2981.pt\n",
      "2982.pt\n",
      "2983.pt\n",
      "2984.pt\n",
      "2985.pt\n",
      "2986.pt\n",
      "2987.pt\n",
      "2988.pt\n",
      "2989.pt\n",
      "2990.pt\n",
      "2991.pt\n",
      "2992.pt\n",
      "2993.pt\n",
      "2994.pt\n",
      "2995.pt\n",
      "2996.pt\n",
      "2997.pt\n",
      "2998.pt\n",
      "2999.pt\n",
      "3000.pt\n",
      "3001.pt\n",
      "3002.pt\n",
      "3003.pt\n",
      "3004.pt\n",
      "3005.pt\n",
      "3006.pt\n",
      "3007.pt\n",
      "3008.pt\n",
      "3009.pt\n",
      "3010.pt\n",
      "3011.pt\n",
      "3012.pt\n",
      "3013.pt\n",
      "3014.pt\n",
      "3015.pt\n",
      "3016.pt\n",
      "3017.pt\n",
      "3018.pt\n",
      "3019.pt\n",
      "3020.pt\n",
      "3021.pt\n",
      "3022.pt\n",
      "3023.pt\n",
      "3024.pt\n",
      "3025.pt\n",
      "3026.pt\n",
      "3027.pt\n",
      "3028.pt\n",
      "3029.pt\n",
      "3030.pt\n",
      "3031.pt\n",
      "3032.pt\n",
      "3033.pt\n",
      "3034.pt\n",
      "3035.pt\n",
      "3036.pt\n",
      "3037.pt\n",
      "3038.pt\n",
      "3039.pt\n",
      "3040.pt\n",
      "3041.pt\n",
      "3042.pt\n",
      "3043.pt\n",
      "3044.pt\n",
      "3045.pt\n",
      "3046.pt\n",
      "3047.pt\n",
      "3048.pt\n",
      "3049.pt\n",
      "3050.pt\n",
      "3051.pt\n",
      "3052.pt\n",
      "3053.pt\n",
      "3054.pt\n",
      "3055.pt\n",
      "3056.pt\n",
      "3057.pt\n",
      "3058.pt\n",
      "3059.pt\n",
      "3060.pt\n",
      "3061.pt\n",
      "3062.pt\n",
      "3063.pt\n",
      "3064.pt\n",
      "3065.pt\n",
      "3066.pt\n",
      "3067.pt\n",
      "3068.pt\n",
      "3069.pt\n",
      "3070.pt\n",
      "3071.pt\n",
      "3072.pt\n",
      "3073.pt\n",
      "3074.pt\n",
      "3075.pt\n",
      "3076.pt\n",
      "3077.pt\n",
      "3078.pt\n",
      "3079.pt\n",
      "3080.pt\n",
      "3081.pt\n",
      "3082.pt\n",
      "3083.pt\n",
      "3084.pt\n",
      "3085.pt\n",
      "3086.pt\n",
      "3087.pt\n",
      "3088.pt\n",
      "3089.pt\n",
      "3090.pt\n",
      "3091.pt\n",
      "3092.pt\n",
      "3093.pt\n",
      "3094.pt\n",
      "3095.pt\n",
      "3096.pt\n",
      "3097.pt\n",
      "3098.pt\n",
      "3099.pt\n",
      "3100.pt\n",
      "3101.pt\n",
      "3102.pt\n",
      "3103.pt\n",
      "3104.pt\n",
      "3105.pt\n",
      "3106.pt\n",
      "3107.pt\n",
      "3108.pt\n",
      "3109.pt\n",
      "3110.pt\n",
      "3111.pt\n",
      "3112.pt\n",
      "3113.pt\n",
      "3114.pt\n",
      "3115.pt\n",
      "3116.pt\n",
      "3117.pt\n",
      "3118.pt\n",
      "3119.pt\n",
      "3120.pt\n",
      "3121.pt\n",
      "3122.pt\n",
      "3123.pt\n",
      "3124.pt\n",
      "3125.pt\n",
      "3126.pt\n",
      "3127.pt\n",
      "3128.pt\n",
      "3129.pt\n",
      "3130.pt\n",
      "3131.pt\n",
      "3132.pt\n",
      "3133.pt\n",
      "3134.pt\n",
      "3135.pt\n",
      "3136.pt\n",
      "3137.pt\n",
      "3138.pt\n",
      "3139.pt\n",
      "3140.pt\n",
      "3141.pt\n",
      "3142.pt\n",
      "3143.pt\n",
      "3144.pt\n",
      "3145.pt\n",
      "3146.pt\n",
      "3147.pt\n",
      "3148.pt\n",
      "3149.pt\n",
      "3150.pt\n",
      "3151.pt\n",
      "3152.pt\n",
      "3153.pt\n",
      "3154.pt\n",
      "3155.pt\n",
      "3156.pt\n",
      "3157.pt\n",
      "3158.pt\n",
      "3159.pt\n",
      "3160.pt\n",
      "3161.pt\n",
      "3162.pt\n",
      "3163.pt\n",
      "3164.pt\n",
      "3165.pt\n",
      "3166.pt\n",
      "3167.pt\n",
      "3168.pt\n",
      "3169.pt\n",
      "3170.pt\n",
      "3171.pt\n",
      "3172.pt\n",
      "3173.pt\n",
      "3174.pt\n",
      "3175.pt\n",
      "3176.pt\n",
      "3177.pt\n",
      "3178.pt\n",
      "3179.pt\n",
      "3180.pt\n",
      "3181.pt\n",
      "3182.pt\n",
      "3183.pt\n",
      "3184.pt\n",
      "3185.pt\n",
      "3186.pt\n",
      "3187.pt\n",
      "3188.pt\n",
      "3189.pt\n",
      "3190.pt\n",
      "3191.pt\n",
      "3192.pt\n",
      "3193.pt\n",
      "3194.pt\n",
      "3195.pt\n",
      "3196.pt\n",
      "3197.pt\n",
      "3198.pt\n",
      "3199.pt\n",
      "3200.pt\n",
      "3201.pt\n",
      "3202.pt\n",
      "3203.pt\n",
      "3204.pt\n",
      "3205.pt\n",
      "3206.pt\n",
      "3207.pt\n",
      "3208.pt\n",
      "3209.pt\n",
      "3210.pt\n",
      "3211.pt\n",
      "3212.pt\n",
      "3213.pt\n",
      "3214.pt\n",
      "3215.pt\n",
      "3216.pt\n",
      "3217.pt\n",
      "3218.pt\n",
      "3219.pt\n",
      "3220.pt\n",
      "3221.pt\n",
      "3222.pt\n",
      "3223.pt\n",
      "3224.pt\n",
      "3225.pt\n",
      "3226.pt\n",
      "3227.pt\n",
      "3228.pt\n",
      "3229.pt\n",
      "3230.pt\n",
      "3231.pt\n",
      "3232.pt\n",
      "3233.pt\n",
      "3234.pt\n",
      "3235.pt\n",
      "3236.pt\n",
      "3237.pt\n",
      "3238.pt\n",
      "3239.pt\n",
      "3240.pt\n",
      "3241.pt\n",
      "3242.pt\n",
      "3243.pt\n",
      "3244.pt\n",
      "3245.pt\n",
      "3246.pt\n",
      "3247.pt\n",
      "3248.pt\n",
      "3249.pt\n",
      "3250.pt\n",
      "3251.pt\n",
      "3252.pt\n",
      "3253.pt\n",
      "3254.pt\n",
      "3255.pt\n",
      "3256.pt\n",
      "3257.pt\n",
      "3258.pt\n",
      "3259.pt\n",
      "3260.pt\n",
      "3261.pt\n",
      "3262.pt\n",
      "3263.pt\n",
      "3264.pt\n",
      "3265.pt\n",
      "3266.pt\n",
      "3267.pt\n",
      "3268.pt\n",
      "3269.pt\n",
      "3270.pt\n",
      "3271.pt\n",
      "3272.pt\n",
      "3273.pt\n",
      "3274.pt\n",
      "3275.pt\n",
      "3276.pt\n",
      "3277.pt\n",
      "3278.pt\n",
      "3279.pt\n",
      "3280.pt\n",
      "3281.pt\n",
      "3282.pt\n",
      "3283.pt\n",
      "3284.pt\n",
      "3285.pt\n",
      "3286.pt\n",
      "3287.pt\n",
      "3288.pt\n",
      "3289.pt\n",
      "3290.pt\n",
      "3291.pt\n",
      "3292.pt\n",
      "3293.pt\n",
      "3294.pt\n",
      "3295.pt\n",
      "3296.pt\n",
      "3297.pt\n",
      "3298.pt\n",
      "3299.pt\n",
      "3300.pt\n",
      "3301.pt\n",
      "3302.pt\n",
      "3303.pt\n",
      "3304.pt\n",
      "3305.pt\n",
      "3306.pt\n",
      "3307.pt\n",
      "3308.pt\n",
      "3309.pt\n",
      "3310.pt\n",
      "3311.pt\n",
      "3312.pt\n",
      "3313.pt\n",
      "3314.pt\n",
      "3315.pt\n",
      "3316.pt\n",
      "3317.pt\n",
      "3318.pt\n",
      "3319.pt\n",
      "3320.pt\n",
      "3321.pt\n",
      "3322.pt\n",
      "3323.pt\n",
      "3324.pt\n",
      "3325.pt\n",
      "3326.pt\n",
      "3327.pt\n",
      "3328.pt\n",
      "3329.pt\n",
      "3330.pt\n",
      "3331.pt\n",
      "3332.pt\n",
      "3333.pt\n",
      "3334.pt\n",
      "3335.pt\n",
      "3336.pt\n",
      "3337.pt\n",
      "3338.pt\n",
      "3339.pt\n",
      "3340.pt\n",
      "3341.pt\n",
      "3342.pt\n",
      "3343.pt\n",
      "3344.pt\n",
      "3345.pt\n",
      "3346.pt\n",
      "3347.pt\n",
      "3348.pt\n",
      "3349.pt\n",
      "3350.pt\n",
      "3351.pt\n",
      "3352.pt\n",
      "3353.pt\n",
      "3354.pt\n",
      "3355.pt\n",
      "3356.pt\n",
      "3357.pt\n",
      "3358.pt\n",
      "3359.pt\n",
      "3360.pt\n",
      "3361.pt\n",
      "3362.pt\n",
      "3363.pt\n",
      "3364.pt\n",
      "3365.pt\n",
      "3366.pt\n",
      "3367.pt\n",
      "3368.pt\n",
      "3369.pt\n",
      "3370.pt\n",
      "3371.pt\n",
      "3372.pt\n",
      "3373.pt\n",
      "3374.pt\n",
      "3375.pt\n",
      "3376.pt\n",
      "3377.pt\n",
      "3378.pt\n",
      "3379.pt\n",
      "3380.pt\n",
      "3381.pt\n",
      "3382.pt\n",
      "3383.pt\n",
      "3384.pt\n",
      "3385.pt\n",
      "3386.pt\n",
      "3387.pt\n",
      "3388.pt\n",
      "3389.pt\n",
      "3390.pt\n",
      "3391.pt\n",
      "3392.pt\n",
      "3393.pt\n",
      "3394.pt\n",
      "3395.pt\n",
      "3396.pt\n",
      "3397.pt\n",
      "3398.pt\n",
      "3399.pt\n",
      "3400.pt\n",
      "3401.pt\n",
      "3402.pt\n",
      "3403.pt\n",
      "3404.pt\n",
      "3405.pt\n",
      "3406.pt\n",
      "3407.pt\n",
      "3408.pt\n",
      "3409.pt\n",
      "3410.pt\n",
      "3411.pt\n",
      "3412.pt\n",
      "3413.pt\n",
      "3414.pt\n",
      "3415.pt\n",
      "3416.pt\n",
      "3417.pt\n",
      "3418.pt\n",
      "3419.pt\n",
      "3420.pt\n",
      "3421.pt\n",
      "3422.pt\n",
      "3423.pt\n",
      "3424.pt\n",
      "3425.pt\n",
      "3426.pt\n",
      "3427.pt\n",
      "3428.pt\n",
      "3429.pt\n",
      "3430.pt\n",
      "3431.pt\n",
      "3432.pt\n",
      "3433.pt\n",
      "3434.pt\n",
      "3435.pt\n",
      "3436.pt\n",
      "3437.pt\n",
      "3438.pt\n",
      "3439.pt\n",
      "3440.pt\n",
      "3441.pt\n",
      "3442.pt\n",
      "3443.pt\n",
      "3444.pt\n",
      "3445.pt\n",
      "3446.pt\n",
      "3447.pt\n",
      "3448.pt\n",
      "3449.pt\n",
      "3450.pt\n",
      "3451.pt\n",
      "3452.pt\n",
      "3453.pt\n",
      "3454.pt\n",
      "3455.pt\n",
      "3456.pt\n",
      "3457.pt\n",
      "3458.pt\n",
      "3459.pt\n",
      "3460.pt\n",
      "3461.pt\n",
      "3462.pt\n",
      "3463.pt\n",
      "3464.pt\n",
      "3465.pt\n",
      "3466.pt\n",
      "3467.pt\n",
      "3468.pt\n",
      "3469.pt\n",
      "3470.pt\n",
      "3471.pt\n",
      "3472.pt\n",
      "3473.pt\n",
      "3474.pt\n",
      "3475.pt\n",
      "3476.pt\n",
      "3477.pt\n",
      "3478.pt\n",
      "3479.pt\n",
      "3480.pt\n",
      "3481.pt\n",
      "3482.pt\n",
      "3483.pt\n",
      "3484.pt\n",
      "3485.pt\n",
      "3486.pt\n",
      "3487.pt\n",
      "3488.pt\n",
      "3489.pt\n",
      "3490.pt\n",
      "3491.pt\n",
      "3492.pt\n",
      "3493.pt\n",
      "3494.pt\n",
      "3495.pt\n",
      "3496.pt\n",
      "3497.pt\n",
      "3498.pt\n",
      "3499.pt\n",
      "3500.pt\n",
      "3501.pt\n",
      "3502.pt\n",
      "3503.pt\n",
      "3504.pt\n",
      "3505.pt\n",
      "3506.pt\n",
      "3507.pt\n",
      "3508.pt\n",
      "3509.pt\n",
      "3510.pt\n",
      "3511.pt\n",
      "3512.pt\n",
      "3513.pt\n",
      "3514.pt\n",
      "3515.pt\n",
      "3516.pt\n",
      "3517.pt\n",
      "3518.pt\n",
      "3519.pt\n",
      "3520.pt\n",
      "3521.pt\n",
      "3522.pt\n",
      "3523.pt\n",
      "3524.pt\n",
      "3525.pt\n",
      "3526.pt\n",
      "3527.pt\n",
      "3528.pt\n",
      "3529.pt\n",
      "3530.pt\n",
      "3531.pt\n",
      "3532.pt\n",
      "3533.pt\n",
      "3534.pt\n",
      "3535.pt\n",
      "3536.pt\n",
      "3537.pt\n",
      "3538.pt\n",
      "3539.pt\n",
      "3540.pt\n",
      "3541.pt\n",
      "3542.pt\n",
      "3543.pt\n",
      "3544.pt\n",
      "3545.pt\n",
      "3546.pt\n",
      "3547.pt\n",
      "3548.pt\n",
      "3549.pt\n",
      "3550.pt\n",
      "3551.pt\n",
      "3552.pt\n",
      "3553.pt\n",
      "3554.pt\n",
      "3555.pt\n",
      "3556.pt\n",
      "3557.pt\n",
      "3558.pt\n",
      "3559.pt\n",
      "3560.pt\n",
      "3561.pt\n",
      "3562.pt\n",
      "3563.pt\n",
      "3564.pt\n",
      "3565.pt\n",
      "3566.pt\n",
      "3567.pt\n",
      "3568.pt\n",
      "3569.pt\n",
      "3570.pt\n",
      "3571.pt\n",
      "3572.pt\n",
      "3573.pt\n",
      "3574.pt\n",
      "3575.pt\n",
      "3576.pt\n",
      "3577.pt\n",
      "3578.pt\n",
      "3579.pt\n",
      "3580.pt\n",
      "3581.pt\n",
      "3582.pt\n",
      "3583.pt\n",
      "3584.pt\n",
      "3585.pt\n",
      "3586.pt\n",
      "3587.pt\n",
      "3588.pt\n",
      "3589.pt\n",
      "3590.pt\n",
      "3591.pt\n",
      "3592.pt\n",
      "3593.pt\n",
      "3594.pt\n",
      "3595.pt\n",
      "3596.pt\n",
      "3597.pt\n",
      "3598.pt\n",
      "3599.pt\n",
      "3600.pt\n",
      "3601.pt\n",
      "3602.pt\n",
      "3603.pt\n",
      "3604.pt\n",
      "3605.pt\n",
      "3606.pt\n",
      "3607.pt\n",
      "3608.pt\n",
      "3609.pt\n",
      "3610.pt\n",
      "3611.pt\n",
      "3612.pt\n",
      "3613.pt\n",
      "3614.pt\n",
      "3615.pt\n",
      "3616.pt\n",
      "3617.pt\n",
      "3618.pt\n",
      "3619.pt\n",
      "3620.pt\n",
      "3621.pt\n",
      "3622.pt\n",
      "3623.pt\n",
      "3624.pt\n",
      "3625.pt\n",
      "3626.pt\n",
      "3627.pt\n",
      "3628.pt\n",
      "3629.pt\n",
      "3630.pt\n",
      "3631.pt\n",
      "3632.pt\n",
      "3633.pt\n",
      "3634.pt\n",
      "3635.pt\n",
      "3636.pt\n",
      "3637.pt\n",
      "3638.pt\n",
      "3639.pt\n",
      "3640.pt\n",
      "3641.pt\n",
      "3642.pt\n",
      "3643.pt\n",
      "3644.pt\n",
      "3645.pt\n",
      "3646.pt\n",
      "3647.pt\n",
      "3648.pt\n",
      "3649.pt\n",
      "3650.pt\n",
      "3651.pt\n",
      "3652.pt\n",
      "3653.pt\n",
      "3654.pt\n",
      "3655.pt\n",
      "3656.pt\n",
      "3657.pt\n",
      "3658.pt\n",
      "3659.pt\n",
      "3660.pt\n",
      "3661.pt\n",
      "3662.pt\n",
      "3663.pt\n",
      "3664.pt\n",
      "3665.pt\n",
      "3666.pt\n",
      "3667.pt\n",
      "3668.pt\n",
      "3669.pt\n",
      "3670.pt\n",
      "3671.pt\n",
      "3672.pt\n",
      "3673.pt\n",
      "3674.pt\n",
      "3675.pt\n",
      "3676.pt\n",
      "3677.pt\n",
      "3678.pt\n",
      "3679.pt\n",
      "3680.pt\n",
      "3681.pt\n",
      "3682.pt\n",
      "3683.pt\n",
      "3684.pt\n",
      "3685.pt\n",
      "3686.pt\n",
      "3687.pt\n",
      "3688.pt\n",
      "3689.pt\n",
      "3690.pt\n",
      "3691.pt\n",
      "3692.pt\n",
      "3693.pt\n",
      "3694.pt\n",
      "3695.pt\n",
      "3696.pt\n",
      "3697.pt\n",
      "3698.pt\n",
      "3699.pt\n",
      "3700.pt\n",
      "3701.pt\n",
      "3702.pt\n",
      "3703.pt\n",
      "3704.pt\n",
      "3705.pt\n",
      "3706.pt\n",
      "3707.pt\n",
      "3708.pt\n",
      "3709.pt\n",
      "3710.pt\n",
      "3711.pt\n",
      "3712.pt\n",
      "3713.pt\n",
      "3714.pt\n",
      "3715.pt\n",
      "3716.pt\n",
      "3717.pt\n",
      "3718.pt\n",
      "3719.pt\n",
      "3720.pt\n",
      "3721.pt\n",
      "3722.pt\n",
      "3723.pt\n",
      "3724.pt\n",
      "3725.pt\n",
      "3726.pt\n",
      "3727.pt\n",
      "3728.pt\n",
      "3729.pt\n",
      "3730.pt\n",
      "3731.pt\n",
      "3732.pt\n",
      "3733.pt\n",
      "3734.pt\n",
      "3735.pt\n",
      "3736.pt\n",
      "3737.pt\n",
      "3738.pt\n",
      "3739.pt\n",
      "3740.pt\n",
      "3741.pt\n",
      "3742.pt\n",
      "3743.pt\n",
      "3744.pt\n",
      "3745.pt\n",
      "3746.pt\n",
      "3747.pt\n",
      "3748.pt\n",
      "3749.pt\n",
      "3750.pt\n",
      "3751.pt\n",
      "3752.pt\n",
      "3753.pt\n",
      "3754.pt\n",
      "3755.pt\n",
      "3756.pt\n",
      "3757.pt\n",
      "3758.pt\n",
      "3759.pt\n",
      "3760.pt\n",
      "3761.pt\n",
      "3762.pt\n",
      "3763.pt\n",
      "3764.pt\n",
      "3765.pt\n",
      "3766.pt\n",
      "3767.pt\n",
      "3768.pt\n",
      "3769.pt\n",
      "3770.pt\n",
      "3771.pt\n",
      "3772.pt\n",
      "3773.pt\n",
      "3774.pt\n",
      "3775.pt\n",
      "3776.pt\n",
      "3777.pt\n",
      "3778.pt\n",
      "3779.pt\n",
      "3780.pt\n",
      "3781.pt\n",
      "3782.pt\n",
      "3783.pt\n",
      "3784.pt\n",
      "3785.pt\n",
      "3786.pt\n",
      "3787.pt\n",
      "3788.pt\n",
      "3789.pt\n",
      "3790.pt\n",
      "3791.pt\n",
      "3792.pt\n",
      "3793.pt\n",
      "3794.pt\n",
      "3795.pt\n",
      "3796.pt\n",
      "3797.pt\n",
      "3798.pt\n",
      "3799.pt\n",
      "3800.pt\n",
      "3801.pt\n",
      "3802.pt\n",
      "3803.pt\n",
      "3804.pt\n",
      "3805.pt\n",
      "3806.pt\n",
      "3807.pt\n",
      "3808.pt\n",
      "3809.pt\n",
      "3810.pt\n",
      "3811.pt\n",
      "3812.pt\n",
      "3813.pt\n",
      "3814.pt\n",
      "3815.pt\n",
      "3816.pt\n",
      "3817.pt\n",
      "3818.pt\n",
      "3819.pt\n",
      "3820.pt\n",
      "3821.pt\n",
      "3822.pt\n",
      "3823.pt\n",
      "3824.pt\n",
      "3825.pt\n",
      "3826.pt\n",
      "3827.pt\n",
      "3828.pt\n",
      "3829.pt\n",
      "3830.pt\n",
      "3831.pt\n",
      "3832.pt\n",
      "3833.pt\n",
      "3834.pt\n",
      "3835.pt\n",
      "3836.pt\n",
      "3837.pt\n",
      "3838.pt\n",
      "3839.pt\n",
      "3840.pt\n",
      "3841.pt\n",
      "3842.pt\n",
      "3843.pt\n",
      "3844.pt\n",
      "3845.pt\n",
      "3846.pt\n",
      "3847.pt\n",
      "3848.pt\n",
      "3849.pt\n",
      "3850.pt\n",
      "3851.pt\n",
      "3852.pt\n",
      "3853.pt\n",
      "3854.pt\n",
      "3855.pt\n",
      "3856.pt\n",
      "3857.pt\n",
      "3858.pt\n",
      "3859.pt\n",
      "3860.pt\n",
      "3861.pt\n",
      "3862.pt\n",
      "3863.pt\n",
      "3864.pt\n",
      "3865.pt\n",
      "3866.pt\n",
      "3867.pt\n",
      "3868.pt\n",
      "3869.pt\n",
      "3870.pt\n",
      "3871.pt\n",
      "3872.pt\n",
      "3873.pt\n",
      "3874.pt\n",
      "3875.pt\n",
      "3876.pt\n",
      "3877.pt\n",
      "3878.pt\n",
      "3879.pt\n",
      "3880.pt\n",
      "3881.pt\n",
      "3882.pt\n",
      "3883.pt\n",
      "3884.pt\n",
      "3885.pt\n",
      "3886.pt\n",
      "3887.pt\n",
      "3888.pt\n",
      "3889.pt\n",
      "3890.pt\n",
      "3891.pt\n",
      "3892.pt\n",
      "3893.pt\n",
      "3894.pt\n",
      "3895.pt\n",
      "3896.pt\n",
      "3897.pt\n",
      "3898.pt\n",
      "3899.pt\n",
      "3900.pt\n",
      "3901.pt\n",
      "3902.pt\n",
      "3903.pt\n",
      "3904.pt\n",
      "3905.pt\n",
      "3906.pt\n",
      "3907.pt\n",
      "3908.pt\n",
      "3909.pt\n",
      "3910.pt\n",
      "3911.pt\n",
      "3912.pt\n",
      "3913.pt\n",
      "3914.pt\n",
      "3915.pt\n",
      "3916.pt\n",
      "3917.pt\n",
      "3918.pt\n",
      "3919.pt\n",
      "3920.pt\n",
      "3921.pt\n",
      "3922.pt\n",
      "3923.pt\n",
      "3924.pt\n",
      "3925.pt\n",
      "3926.pt\n",
      "3927.pt\n",
      "3928.pt\n",
      "3929.pt\n",
      "3930.pt\n",
      "3931.pt\n",
      "3932.pt\n",
      "3933.pt\n",
      "3934.pt\n",
      "3935.pt\n",
      "3936.pt\n",
      "3937.pt\n",
      "3938.pt\n",
      "3939.pt\n",
      "3940.pt\n",
      "3941.pt\n",
      "3942.pt\n",
      "3943.pt\n",
      "3944.pt\n",
      "3945.pt\n",
      "3946.pt\n",
      "3947.pt\n",
      "3948.pt\n",
      "3949.pt\n",
      "3950.pt\n",
      "3951.pt\n",
      "3952.pt\n",
      "3953.pt\n",
      "3954.pt\n",
      "3955.pt\n",
      "3956.pt\n",
      "3957.pt\n",
      "3958.pt\n",
      "3959.pt\n",
      "3960.pt\n",
      "3961.pt\n",
      "3962.pt\n",
      "3963.pt\n",
      "3964.pt\n",
      "3965.pt\n",
      "3966.pt\n",
      "3967.pt\n",
      "3968.pt\n",
      "3969.pt\n",
      "3970.pt\n",
      "3971.pt\n",
      "3972.pt\n",
      "3973.pt\n",
      "3974.pt\n",
      "3975.pt\n",
      "3976.pt\n",
      "3977.pt\n",
      "3978.pt\n",
      "3979.pt\n",
      "3980.pt\n",
      "3981.pt\n",
      "3982.pt\n",
      "3983.pt\n",
      "3984.pt\n",
      "3985.pt\n",
      "3986.pt\n",
      "3987.pt\n",
      "3988.pt\n",
      "3989.pt\n",
      "3990.pt\n",
      "3991.pt\n",
      "3992.pt\n",
      "3993.pt\n",
      "3994.pt\n",
      "3995.pt\n",
      "3996.pt\n",
      "3997.pt\n",
      "3998.pt\n",
      "3999.pt\n",
      "4000.pt\n",
      "4001.pt\n",
      "4002.pt\n",
      "4003.pt\n",
      "4004.pt\n",
      "4005.pt\n",
      "4006.pt\n",
      "4007.pt\n",
      "4008.pt\n",
      "4009.pt\n",
      "4010.pt\n",
      "4011.pt\n",
      "4012.pt\n",
      "4013.pt\n",
      "4014.pt\n",
      "4015.pt\n",
      "4016.pt\n",
      "4017.pt\n",
      "4018.pt\n",
      "4019.pt\n",
      "4020.pt\n",
      "4021.pt\n",
      "4022.pt\n",
      "4023.pt\n",
      "4024.pt\n",
      "4025.pt\n",
      "4026.pt\n",
      "4027.pt\n",
      "4028.pt\n",
      "4029.pt\n",
      "4030.pt\n",
      "4031.pt\n",
      "4032.pt\n",
      "4033.pt\n",
      "4034.pt\n",
      "4035.pt\n",
      "4036.pt\n",
      "4037.pt\n",
      "4038.pt\n",
      "4039.pt\n",
      "4040.pt\n",
      "4041.pt\n",
      "4042.pt\n",
      "4043.pt\n",
      "4044.pt\n",
      "4045.pt\n",
      "4046.pt\n",
      "4047.pt\n",
      "4048.pt\n",
      "4049.pt\n",
      "4050.pt\n",
      "4051.pt\n",
      "4052.pt\n",
      "4053.pt\n",
      "4054.pt\n",
      "4055.pt\n",
      "4056.pt\n",
      "4057.pt\n",
      "4058.pt\n",
      "4059.pt\n",
      "4060.pt\n",
      "4061.pt\n",
      "4062.pt\n",
      "4063.pt\n",
      "4064.pt\n",
      "4065.pt\n",
      "4066.pt\n",
      "4067.pt\n",
      "4068.pt\n",
      "4069.pt\n",
      "4070.pt\n",
      "4071.pt\n",
      "4072.pt\n",
      "4073.pt\n",
      "4074.pt\n",
      "4075.pt\n",
      "4076.pt\n",
      "4077.pt\n",
      "4078.pt\n",
      "4079.pt\n",
      "4080.pt\n",
      "4081.pt\n",
      "4082.pt\n",
      "4083.pt\n",
      "4084.pt\n",
      "4085.pt\n",
      "4086.pt\n",
      "4087.pt\n",
      "4088.pt\n",
      "4089.pt\n",
      "4090.pt\n",
      "4091.pt\n",
      "4092.pt\n",
      "4093.pt\n",
      "4094.pt\n",
      "4095.pt\n",
      "4096.pt\n",
      "4097.pt\n",
      "4098.pt\n",
      "4099.pt\n",
      "4100.pt\n",
      "4101.pt\n",
      "4102.pt\n",
      "4103.pt\n",
      "4104.pt\n",
      "4105.pt\n",
      "4106.pt\n",
      "4107.pt\n",
      "4108.pt\n",
      "4109.pt\n",
      "4110.pt\n",
      "4111.pt\n",
      "4112.pt\n",
      "4113.pt\n",
      "4114.pt\n",
      "4115.pt\n",
      "4116.pt\n",
      "4117.pt\n",
      "4118.pt\n",
      "4119.pt\n",
      "4120.pt\n",
      "4121.pt\n",
      "4122.pt\n",
      "4123.pt\n",
      "4124.pt\n",
      "4125.pt\n",
      "4126.pt\n",
      "4127.pt\n",
      "4128.pt\n",
      "4129.pt\n",
      "4130.pt\n",
      "4131.pt\n",
      "4132.pt\n",
      "4133.pt\n",
      "4134.pt\n",
      "4135.pt\n",
      "4136.pt\n",
      "4137.pt\n",
      "4138.pt\n",
      "4139.pt\n",
      "4140.pt\n",
      "4141.pt\n",
      "4142.pt\n",
      "4143.pt\n",
      "4144.pt\n",
      "4145.pt\n",
      "4146.pt\n",
      "4147.pt\n",
      "4148.pt\n",
      "4149.pt\n",
      "4150.pt\n",
      "4151.pt\n",
      "4152.pt\n",
      "4153.pt\n",
      "4154.pt\n",
      "4155.pt\n",
      "4156.pt\n",
      "4157.pt\n",
      "4158.pt\n",
      "4159.pt\n",
      "4160.pt\n",
      "4161.pt\n",
      "4162.pt\n",
      "4163.pt\n",
      "4164.pt\n",
      "4165.pt\n",
      "4166.pt\n",
      "4167.pt\n",
      "4168.pt\n",
      "4169.pt\n",
      "4170.pt\n",
      "4171.pt\n",
      "4172.pt\n",
      "4173.pt\n",
      "4174.pt\n",
      "4175.pt\n",
      "4176.pt\n",
      "4177.pt\n",
      "4178.pt\n",
      "4179.pt\n",
      "4180.pt\n",
      "4181.pt\n",
      "4182.pt\n",
      "4183.pt\n",
      "4184.pt\n",
      "4185.pt\n",
      "4186.pt\n",
      "4187.pt\n",
      "4188.pt\n",
      "4189.pt\n",
      "4190.pt\n",
      "4191.pt\n",
      "4192.pt\n",
      "4193.pt\n",
      "4194.pt\n",
      "4195.pt\n",
      "4196.pt\n",
      "4197.pt\n",
      "4198.pt\n",
      "4199.pt\n",
      "4200.pt\n",
      "4201.pt\n",
      "4202.pt\n",
      "4203.pt\n",
      "4204.pt\n",
      "4205.pt\n",
      "4206.pt\n",
      "4207.pt\n",
      "4208.pt\n",
      "4209.pt\n",
      "4210.pt\n",
      "4211.pt\n",
      "4212.pt\n",
      "4213.pt\n",
      "4214.pt\n",
      "4215.pt\n",
      "4216.pt\n",
      "4217.pt\n",
      "4218.pt\n",
      "4219.pt\n",
      "4220.pt\n",
      "4221.pt\n",
      "4222.pt\n",
      "4223.pt\n",
      "4224.pt\n",
      "4225.pt\n",
      "4226.pt\n",
      "4227.pt\n",
      "4228.pt\n",
      "4229.pt\n",
      "4230.pt\n",
      "4231.pt\n",
      "4232.pt\n",
      "4233.pt\n",
      "4234.pt\n",
      "4235.pt\n",
      "4236.pt\n",
      "4237.pt\n",
      "4238.pt\n",
      "4239.pt\n",
      "4240.pt\n",
      "4241.pt\n",
      "4242.pt\n",
      "4243.pt\n",
      "4244.pt\n",
      "4245.pt\n",
      "4246.pt\n",
      "4247.pt\n",
      "4248.pt\n",
      "4249.pt\n",
      "4250.pt\n",
      "4251.pt\n",
      "4252.pt\n",
      "4253.pt\n",
      "4254.pt\n",
      "4255.pt\n",
      "4256.pt\n",
      "4257.pt\n",
      "4258.pt\n",
      "4259.pt\n",
      "4260.pt\n",
      "4261.pt\n",
      "4262.pt\n",
      "4263.pt\n",
      "4264.pt\n",
      "4265.pt\n",
      "4266.pt\n",
      "4267.pt\n",
      "4268.pt\n",
      "4269.pt\n",
      "4270.pt\n",
      "4271.pt\n",
      "4272.pt\n",
      "4273.pt\n",
      "4274.pt\n",
      "4275.pt\n",
      "4276.pt\n",
      "4277.pt\n",
      "4278.pt\n",
      "4279.pt\n",
      "4280.pt\n",
      "4281.pt\n",
      "4282.pt\n",
      "4283.pt\n",
      "4284.pt\n",
      "4285.pt\n",
      "4286.pt\n",
      "4287.pt\n",
      "4288.pt\n",
      "4289.pt\n",
      "4290.pt\n",
      "4291.pt\n",
      "4292.pt\n",
      "4293.pt\n",
      "4294.pt\n",
      "4295.pt\n",
      "4296.pt\n",
      "4297.pt\n",
      "4298.pt\n",
      "4299.pt\n",
      "4300.pt\n",
      "4301.pt\n",
      "4302.pt\n",
      "4303.pt\n",
      "4304.pt\n",
      "4305.pt\n",
      "4306.pt\n",
      "4307.pt\n",
      "4308.pt\n",
      "4309.pt\n",
      "4310.pt\n",
      "4311.pt\n",
      "4312.pt\n",
      "4313.pt\n",
      "4314.pt\n",
      "4315.pt\n",
      "4316.pt\n",
      "4317.pt\n",
      "4318.pt\n",
      "4319.pt\n",
      "4320.pt\n",
      "4321.pt\n",
      "4322.pt\n",
      "4323.pt\n",
      "4324.pt\n",
      "4325.pt\n",
      "4326.pt\n",
      "4327.pt\n",
      "4328.pt\n",
      "4329.pt\n",
      "4330.pt\n",
      "4331.pt\n",
      "4332.pt\n",
      "4333.pt\n",
      "4334.pt\n",
      "4335.pt\n",
      "4336.pt\n",
      "4337.pt\n",
      "4338.pt\n",
      "4339.pt\n",
      "4340.pt\n",
      "4341.pt\n",
      "4342.pt\n",
      "4343.pt\n",
      "4344.pt\n",
      "4345.pt\n",
      "4346.pt\n",
      "4347.pt\n",
      "4348.pt\n",
      "4349.pt\n",
      "4350.pt\n",
      "4351.pt\n",
      "4352.pt\n",
      "4353.pt\n",
      "4354.pt\n",
      "4355.pt\n",
      "4356.pt\n",
      "4357.pt\n",
      "4358.pt\n",
      "4359.pt\n",
      "4360.pt\n",
      "4361.pt\n",
      "4362.pt\n",
      "4363.pt\n",
      "4364.pt\n",
      "4365.pt\n",
      "4366.pt\n",
      "4367.pt\n",
      "4368.pt\n",
      "4369.pt\n",
      "4370.pt\n",
      "4371.pt\n",
      "4372.pt\n",
      "4373.pt\n",
      "4374.pt\n",
      "4375.pt\n",
      "4376.pt\n",
      "4377.pt\n",
      "4378.pt\n",
      "4379.pt\n",
      "4380.pt\n",
      "4381.pt\n",
      "4382.pt\n",
      "4383.pt\n",
      "4384.pt\n",
      "4385.pt\n",
      "4386.pt\n",
      "4387.pt\n",
      "4388.pt\n",
      "4389.pt\n",
      "4390.pt\n",
      "4391.pt\n",
      "4392.pt\n",
      "4393.pt\n",
      "4394.pt\n",
      "4395.pt\n",
      "4396.pt\n",
      "4397.pt\n",
      "4398.pt\n",
      "4399.pt\n",
      "4400.pt\n",
      "4401.pt\n",
      "4402.pt\n",
      "4403.pt\n",
      "4404.pt\n",
      "4405.pt\n",
      "4406.pt\n",
      "4407.pt\n",
      "4408.pt\n",
      "4409.pt\n",
      "4410.pt\n",
      "4411.pt\n",
      "4412.pt\n",
      "4413.pt\n",
      "4414.pt\n",
      "4415.pt\n",
      "4416.pt\n",
      "4417.pt\n",
      "4418.pt\n",
      "4419.pt\n",
      "4420.pt\n",
      "4421.pt\n",
      "4422.pt\n",
      "4423.pt\n",
      "4424.pt\n",
      "4425.pt\n",
      "4426.pt\n",
      "4427.pt\n",
      "4428.pt\n",
      "4429.pt\n",
      "4430.pt\n",
      "4431.pt\n",
      "4432.pt\n",
      "4433.pt\n",
      "4434.pt\n",
      "4435.pt\n",
      "4436.pt\n",
      "4437.pt\n",
      "4438.pt\n",
      "4439.pt\n",
      "4440.pt\n",
      "4441.pt\n",
      "4442.pt\n",
      "4443.pt\n",
      "4444.pt\n",
      "4445.pt\n",
      "4446.pt\n",
      "4447.pt\n",
      "4448.pt\n",
      "4449.pt\n",
      "4450.pt\n",
      "4451.pt\n",
      "4452.pt\n",
      "4453.pt\n",
      "4454.pt\n",
      "4455.pt\n",
      "4456.pt\n",
      "4457.pt\n",
      "4458.pt\n",
      "4459.pt\n",
      "4460.pt\n",
      "4461.pt\n",
      "4462.pt\n",
      "4463.pt\n",
      "4464.pt\n",
      "4465.pt\n",
      "4466.pt\n",
      "4467.pt\n",
      "4468.pt\n",
      "4469.pt\n",
      "4470.pt\n",
      "4471.pt\n",
      "4472.pt\n",
      "4473.pt\n",
      "4474.pt\n",
      "4475.pt\n",
      "4476.pt\n",
      "4477.pt\n",
      "4478.pt\n",
      "4479.pt\n",
      "4480.pt\n",
      "4481.pt\n",
      "4482.pt\n",
      "4483.pt\n",
      "4484.pt\n",
      "4485.pt\n",
      "4486.pt\n",
      "4487.pt\n",
      "4488.pt\n",
      "4489.pt\n",
      "4490.pt\n",
      "4491.pt\n",
      "4492.pt\n",
      "4493.pt\n",
      "4494.pt\n",
      "4495.pt\n",
      "4496.pt\n",
      "4497.pt\n",
      "4498.pt\n",
      "4499.pt\n",
      "4500.pt\n",
      "4501.pt\n",
      "4502.pt\n",
      "4503.pt\n",
      "4504.pt\n",
      "4505.pt\n",
      "4506.pt\n",
      "4507.pt\n",
      "4508.pt\n",
      "4509.pt\n",
      "4510.pt\n",
      "4511.pt\n",
      "4512.pt\n",
      "4513.pt\n",
      "4514.pt\n",
      "4515.pt\n",
      "4516.pt\n",
      "4517.pt\n",
      "4518.pt\n",
      "4519.pt\n",
      "4520.pt\n",
      "4521.pt\n",
      "4522.pt\n",
      "4523.pt\n",
      "4524.pt\n",
      "4525.pt\n",
      "4526.pt\n",
      "4527.pt\n",
      "4528.pt\n",
      "4529.pt\n",
      "4530.pt\n",
      "4531.pt\n",
      "4532.pt\n",
      "4533.pt\n",
      "4534.pt\n",
      "4535.pt\n",
      "4536.pt\n",
      "4537.pt\n",
      "4538.pt\n",
      "4539.pt\n",
      "4540.pt\n",
      "4541.pt\n",
      "4542.pt\n",
      "4543.pt\n",
      "4544.pt\n",
      "4545.pt\n",
      "4546.pt\n",
      "4547.pt\n",
      "4548.pt\n",
      "4549.pt\n",
      "4550.pt\n",
      "4551.pt\n",
      "4552.pt\n",
      "4553.pt\n",
      "4554.pt\n",
      "4555.pt\n",
      "4556.pt\n",
      "4557.pt\n",
      "4558.pt\n",
      "4559.pt\n",
      "4560.pt\n",
      "4561.pt\n",
      "4562.pt\n",
      "4563.pt\n",
      "4564.pt\n",
      "4565.pt\n",
      "4566.pt\n",
      "4567.pt\n",
      "4568.pt\n",
      "4569.pt\n",
      "4570.pt\n",
      "4571.pt\n",
      "4572.pt\n",
      "4573.pt\n",
      "4574.pt\n",
      "4575.pt\n",
      "4576.pt\n",
      "4577.pt\n",
      "4578.pt\n",
      "4579.pt\n",
      "4580.pt\n",
      "4581.pt\n",
      "4582.pt\n",
      "4583.pt\n",
      "4584.pt\n",
      "4585.pt\n",
      "4586.pt\n",
      "4587.pt\n",
      "4588.pt\n",
      "4589.pt\n",
      "4590.pt\n",
      "4591.pt\n",
      "4592.pt\n",
      "4593.pt\n",
      "4594.pt\n",
      "4595.pt\n",
      "4596.pt\n",
      "4597.pt\n",
      "4598.pt\n",
      "4599.pt\n",
      "4600.pt\n",
      "4601.pt\n",
      "4602.pt\n",
      "4603.pt\n",
      "4604.pt\n",
      "4605.pt\n",
      "4606.pt\n",
      "4607.pt\n",
      "4608.pt\n",
      "4609.pt\n",
      "4610.pt\n",
      "4611.pt\n",
      "4612.pt\n",
      "4613.pt\n",
      "4614.pt\n",
      "4615.pt\n",
      "4616.pt\n",
      "4617.pt\n",
      "4618.pt\n",
      "4619.pt\n",
      "4620.pt\n",
      "4621.pt\n",
      "4622.pt\n",
      "4623.pt\n",
      "4624.pt\n",
      "4625.pt\n",
      "4626.pt\n",
      "4627.pt\n",
      "4628.pt\n",
      "4629.pt\n",
      "4630.pt\n",
      "4631.pt\n",
      "4632.pt\n",
      "4633.pt\n",
      "4634.pt\n",
      "4635.pt\n",
      "4636.pt\n",
      "4637.pt\n",
      "4638.pt\n",
      "4639.pt\n",
      "4640.pt\n",
      "4641.pt\n",
      "4642.pt\n",
      "4643.pt\n",
      "4644.pt\n",
      "4645.pt\n",
      "4646.pt\n",
      "4647.pt\n",
      "4648.pt\n",
      "4649.pt\n",
      "4650.pt\n",
      "4651.pt\n",
      "4652.pt\n",
      "4653.pt\n",
      "4654.pt\n",
      "4655.pt\n",
      "4656.pt\n",
      "4657.pt\n",
      "4658.pt\n",
      "4659.pt\n",
      "4660.pt\n",
      "4661.pt\n",
      "4662.pt\n",
      "4663.pt\n",
      "4664.pt\n",
      "4665.pt\n",
      "4666.pt\n",
      "4667.pt\n",
      "4668.pt\n",
      "4669.pt\n",
      "4670.pt\n",
      "4671.pt\n",
      "4672.pt\n",
      "4673.pt\n",
      "4674.pt\n",
      "4675.pt\n",
      "4676.pt\n",
      "4677.pt\n",
      "4678.pt\n",
      "4679.pt\n",
      "4680.pt\n",
      "4681.pt\n",
      "4682.pt\n",
      "4683.pt\n",
      "4684.pt\n",
      "4685.pt\n",
      "4686.pt\n",
      "4687.pt\n",
      "4688.pt\n",
      "4689.pt\n",
      "4690.pt\n",
      "4691.pt\n",
      "4692.pt\n",
      "4693.pt\n",
      "4694.pt\n",
      "4695.pt\n",
      "4696.pt\n",
      "4697.pt\n",
      "4698.pt\n",
      "4699.pt\n",
      "4700.pt\n",
      "4701.pt\n",
      "4702.pt\n",
      "4703.pt\n",
      "4704.pt\n",
      "4705.pt\n",
      "4706.pt\n",
      "4707.pt\n",
      "4708.pt\n",
      "4709.pt\n",
      "4710.pt\n",
      "4711.pt\n",
      "4712.pt\n",
      "4713.pt\n",
      "4714.pt\n",
      "4715.pt\n",
      "4716.pt\n",
      "4717.pt\n",
      "4718.pt\n",
      "4719.pt\n",
      "4720.pt\n",
      "4721.pt\n",
      "4722.pt\n",
      "4723.pt\n",
      "4724.pt\n",
      "4725.pt\n",
      "4726.pt\n",
      "4727.pt\n",
      "4728.pt\n",
      "4729.pt\n",
      "4730.pt\n",
      "4731.pt\n",
      "4732.pt\n",
      "4733.pt\n",
      "4734.pt\n",
      "4735.pt\n",
      "4736.pt\n",
      "4737.pt\n",
      "4738.pt\n",
      "4739.pt\n",
      "4740.pt\n",
      "4741.pt\n",
      "4742.pt\n",
      "4743.pt\n",
      "4744.pt\n",
      "4745.pt\n",
      "4746.pt\n",
      "4747.pt\n",
      "4748.pt\n",
      "4749.pt\n",
      "4750.pt\n",
      "4751.pt\n",
      "4752.pt\n",
      "4753.pt\n",
      "4754.pt\n",
      "4755.pt\n",
      "4756.pt\n",
      "4757.pt\n",
      "4758.pt\n",
      "4759.pt\n",
      "4760.pt\n",
      "4761.pt\n",
      "4762.pt\n",
      "4763.pt\n",
      "4764.pt\n",
      "4765.pt\n",
      "4766.pt\n",
      "4767.pt\n",
      "4768.pt\n",
      "4769.pt\n",
      "4770.pt\n",
      "4771.pt\n",
      "4772.pt\n",
      "4773.pt\n",
      "4774.pt\n",
      "4775.pt\n",
      "4776.pt\n",
      "4777.pt\n",
      "4778.pt\n",
      "4779.pt\n",
      "4780.pt\n",
      "4781.pt\n",
      "4782.pt\n",
      "4783.pt\n",
      "4784.pt\n",
      "4785.pt\n",
      "4786.pt\n",
      "4787.pt\n",
      "4788.pt\n",
      "4789.pt\n",
      "4790.pt\n",
      "4791.pt\n",
      "4792.pt\n",
      "4793.pt\n",
      "4794.pt\n",
      "4795.pt\n",
      "4796.pt\n",
      "4797.pt\n",
      "4798.pt\n",
      "4799.pt\n",
      "4800.pt\n",
      "4801.pt\n",
      "4802.pt\n",
      "4803.pt\n",
      "4804.pt\n",
      "4805.pt\n",
      "4806.pt\n",
      "4807.pt\n",
      "4808.pt\n",
      "4809.pt\n",
      "4810.pt\n",
      "4811.pt\n",
      "4812.pt\n",
      "4813.pt\n",
      "4814.pt\n",
      "4815.pt\n",
      "4816.pt\n",
      "4817.pt\n",
      "4818.pt\n",
      "4819.pt\n",
      "4820.pt\n",
      "4821.pt\n",
      "4822.pt\n",
      "4823.pt\n",
      "4824.pt\n",
      "4825.pt\n",
      "4826.pt\n",
      "4827.pt\n",
      "4828.pt\n",
      "4829.pt\n",
      "4830.pt\n",
      "4831.pt\n",
      "4832.pt\n",
      "4833.pt\n",
      "4834.pt\n",
      "4835.pt\n",
      "4836.pt\n",
      "4837.pt\n",
      "4838.pt\n",
      "4839.pt\n",
      "4840.pt\n",
      "4841.pt\n",
      "4842.pt\n",
      "4843.pt\n",
      "4844.pt\n",
      "4845.pt\n",
      "4846.pt\n",
      "4847.pt\n",
      "4848.pt\n",
      "4849.pt\n",
      "4850.pt\n",
      "4851.pt\n",
      "4852.pt\n",
      "4853.pt\n",
      "4854.pt\n",
      "4855.pt\n",
      "4856.pt\n",
      "4857.pt\n",
      "4858.pt\n",
      "4859.pt\n",
      "4860.pt\n",
      "4861.pt\n",
      "4862.pt\n",
      "4863.pt\n",
      "4864.pt\n",
      "4865.pt\n",
      "4866.pt\n",
      "4867.pt\n",
      "4868.pt\n",
      "4869.pt\n",
      "4870.pt\n",
      "4871.pt\n",
      "4872.pt\n",
      "4873.pt\n",
      "4874.pt\n",
      "4875.pt\n",
      "4876.pt\n",
      "4877.pt\n",
      "4878.pt\n",
      "4879.pt\n",
      "4880.pt\n",
      "4881.pt\n",
      "4882.pt\n",
      "4883.pt\n",
      "4884.pt\n",
      "4885.pt\n",
      "4886.pt\n",
      "4887.pt\n",
      "4888.pt\n",
      "4889.pt\n",
      "4890.pt\n",
      "4891.pt\n",
      "4892.pt\n",
      "4893.pt\n",
      "4894.pt\n",
      "4895.pt\n",
      "4896.pt\n",
      "4897.pt\n",
      "4898.pt\n",
      "4899.pt\n",
      "4900.pt\n",
      "4901.pt\n",
      "4902.pt\n",
      "4903.pt\n",
      "4904.pt\n",
      "4905.pt\n",
      "4906.pt\n",
      "4907.pt\n",
      "4908.pt\n",
      "4909.pt\n",
      "4910.pt\n",
      "4911.pt\n",
      "4912.pt\n",
      "4913.pt\n",
      "4914.pt\n",
      "4915.pt\n",
      "4916.pt\n",
      "4917.pt\n",
      "4918.pt\n",
      "4919.pt\n",
      "4920.pt\n",
      "4921.pt\n",
      "4922.pt\n",
      "4923.pt\n",
      "4924.pt\n",
      "4925.pt\n",
      "4926.pt\n",
      "4927.pt\n",
      "4928.pt\n",
      "4929.pt\n",
      "4930.pt\n",
      "4931.pt\n",
      "4932.pt\n",
      "4933.pt\n",
      "4934.pt\n",
      "4935.pt\n",
      "4936.pt\n",
      "4937.pt\n",
      "4938.pt\n",
      "4939.pt\n",
      "4940.pt\n",
      "4941.pt\n",
      "4942.pt\n",
      "4943.pt\n",
      "4944.pt\n",
      "4945.pt\n",
      "4946.pt\n",
      "4947.pt\n",
      "4948.pt\n",
      "4949.pt\n",
      "4950.pt\n",
      "4951.pt\n",
      "4952.pt\n",
      "4953.pt\n",
      "4954.pt\n",
      "4955.pt\n",
      "4956.pt\n",
      "4957.pt\n",
      "4958.pt\n",
      "4959.pt\n",
      "4960.pt\n",
      "4961.pt\n",
      "4962.pt\n",
      "4963.pt\n",
      "4964.pt\n",
      "4965.pt\n",
      "4966.pt\n",
      "4967.pt\n",
      "4968.pt\n",
      "4969.pt\n",
      "4970.pt\n",
      "4971.pt\n",
      "4972.pt\n",
      "4973.pt\n",
      "4974.pt\n",
      "4975.pt\n",
      "4976.pt\n",
      "4977.pt\n",
      "4978.pt\n",
      "4979.pt\n",
      "4980.pt\n",
      "4981.pt\n",
      "4982.pt\n",
      "4983.pt\n",
      "4984.pt\n",
      "4985.pt\n",
      "4986.pt\n",
      "4987.pt\n",
      "4988.pt\n",
      "4989.pt\n",
      "4990.pt\n",
      "4991.pt\n",
      "4992.pt\n",
      "4993.pt\n",
      "4994.pt\n",
      "4995.pt\n",
      "4996.pt\n",
      "4997.pt\n",
      "4998.pt\n",
      "4999.pt\n",
      "5000.pt\n",
      "5001.pt\n",
      "5002.pt\n",
      "5003.pt\n",
      "5004.pt\n",
      "5005.pt\n",
      "5006.pt\n",
      "5007.pt\n",
      "5008.pt\n",
      "5009.pt\n",
      "5010.pt\n",
      "5011.pt\n",
      "5012.pt\n",
      "5013.pt\n",
      "5014.pt\n",
      "5015.pt\n",
      "5016.pt\n",
      "5017.pt\n",
      "5018.pt\n",
      "5019.pt\n",
      "5020.pt\n",
      "5021.pt\n",
      "5022.pt\n",
      "5023.pt\n",
      "5024.pt\n",
      "5025.pt\n",
      "5026.pt\n",
      "5027.pt\n",
      "5028.pt\n",
      "5029.pt\n",
      "5030.pt\n",
      "5031.pt\n",
      "5032.pt\n",
      "5033.pt\n",
      "5034.pt\n",
      "5035.pt\n",
      "5036.pt\n",
      "5037.pt\n",
      "5038.pt\n",
      "5039.pt\n",
      "5040.pt\n",
      "5041.pt\n",
      "5042.pt\n",
      "5043.pt\n",
      "5044.pt\n",
      "5045.pt\n",
      "5046.pt\n",
      "5047.pt\n",
      "5048.pt\n",
      "5049.pt\n",
      "5050.pt\n",
      "5051.pt\n",
      "5052.pt\n",
      "5053.pt\n",
      "5054.pt\n",
      "5055.pt\n",
      "5056.pt\n",
      "5057.pt\n",
      "5058.pt\n",
      "5059.pt\n",
      "5060.pt\n",
      "5061.pt\n",
      "5062.pt\n",
      "5063.pt\n",
      "5064.pt\n",
      "5065.pt\n",
      "5066.pt\n",
      "5067.pt\n",
      "5068.pt\n",
      "5069.pt\n",
      "5070.pt\n",
      "5071.pt\n",
      "5072.pt\n",
      "5073.pt\n",
      "5074.pt\n",
      "5075.pt\n",
      "5076.pt\n",
      "5077.pt\n",
      "5078.pt\n",
      "5079.pt\n",
      "5080.pt\n",
      "5081.pt\n",
      "5082.pt\n",
      "5083.pt\n",
      "5084.pt\n",
      "5085.pt\n",
      "5086.pt\n",
      "5087.pt\n",
      "5088.pt\n",
      "5089.pt\n",
      "5090.pt\n",
      "5091.pt\n",
      "5092.pt\n",
      "5093.pt\n",
      "5094.pt\n",
      "5095.pt\n",
      "5096.pt\n",
      "5097.pt\n",
      "5098.pt\n",
      "5099.pt\n",
      "5100.pt\n",
      "5101.pt\n",
      "5102.pt\n",
      "5103.pt\n",
      "5104.pt\n",
      "5105.pt\n",
      "5106.pt\n",
      "5107.pt\n",
      "5108.pt\n",
      "5109.pt\n",
      "5110.pt\n",
      "5111.pt\n",
      "5112.pt\n",
      "5113.pt\n",
      "5114.pt\n",
      "5115.pt\n",
      "5116.pt\n",
      "5117.pt\n",
      "5118.pt\n",
      "5119.pt\n",
      "5120.pt\n",
      "5121.pt\n",
      "5122.pt\n",
      "5123.pt\n",
      "5124.pt\n",
      "5125.pt\n",
      "5126.pt\n",
      "5127.pt\n",
      "5128.pt\n",
      "5129.pt\n",
      "5130.pt\n",
      "5131.pt\n",
      "5132.pt\n",
      "5133.pt\n",
      "5134.pt\n",
      "5135.pt\n",
      "5136.pt\n",
      "5137.pt\n",
      "5138.pt\n",
      "5139.pt\n",
      "5140.pt\n",
      "5141.pt\n",
      "5142.pt\n",
      "5143.pt\n",
      "5144.pt\n",
      "5145.pt\n",
      "5146.pt\n",
      "5147.pt\n",
      "5148.pt\n",
      "5149.pt\n",
      "5150.pt\n",
      "5151.pt\n",
      "5152.pt\n",
      "5153.pt\n",
      "5154.pt\n",
      "5155.pt\n",
      "5156.pt\n",
      "5157.pt\n",
      "5158.pt\n",
      "5159.pt\n",
      "5160.pt\n",
      "5161.pt\n",
      "5162.pt\n",
      "5163.pt\n",
      "5164.pt\n",
      "5165.pt\n",
      "5166.pt\n",
      "5167.pt\n",
      "5168.pt\n",
      "5169.pt\n",
      "5170.pt\n",
      "5171.pt\n",
      "5172.pt\n",
      "5173.pt\n",
      "5174.pt\n",
      "5175.pt\n",
      "5176.pt\n",
      "5177.pt\n",
      "5178.pt\n",
      "5179.pt\n",
      "5180.pt\n",
      "5181.pt\n",
      "5182.pt\n",
      "5183.pt\n",
      "5184.pt\n",
      "5185.pt\n",
      "5186.pt\n",
      "5187.pt\n",
      "5188.pt\n",
      "5189.pt\n",
      "5190.pt\n",
      "5191.pt\n",
      "5192.pt\n",
      "5193.pt\n",
      "5194.pt\n",
      "5195.pt\n",
      "5196.pt\n",
      "5197.pt\n",
      "5198.pt\n",
      "5199.pt\n",
      "5200.pt\n",
      "5201.pt\n",
      "5202.pt\n",
      "5203.pt\n",
      "5204.pt\n",
      "5205.pt\n",
      "5206.pt\n",
      "5207.pt\n",
      "5208.pt\n",
      "5209.pt\n",
      "5210.pt\n",
      "5211.pt\n",
      "5212.pt\n",
      "5213.pt\n",
      "5214.pt\n",
      "5215.pt\n",
      "5216.pt\n",
      "5217.pt\n",
      "5218.pt\n",
      "5219.pt\n",
      "5220.pt\n",
      "5221.pt\n",
      "5222.pt\n",
      "5223.pt\n",
      "5224.pt\n",
      "5225.pt\n",
      "5226.pt\n",
      "5227.pt\n",
      "5228.pt\n",
      "5229.pt\n",
      "5230.pt\n",
      "5231.pt\n",
      "5232.pt\n",
      "5233.pt\n",
      "5234.pt\n",
      "5235.pt\n",
      "5236.pt\n",
      "5237.pt\n",
      "5238.pt\n",
      "5239.pt\n",
      "5240.pt\n",
      "5241.pt\n",
      "5242.pt\n",
      "5243.pt\n",
      "5244.pt\n",
      "5245.pt\n",
      "5246.pt\n",
      "5247.pt\n",
      "5248.pt\n",
      "5249.pt\n",
      "5250.pt\n",
      "5251.pt\n",
      "5252.pt\n",
      "5253.pt\n",
      "5254.pt\n",
      "5255.pt\n",
      "5256.pt\n",
      "5257.pt\n",
      "5258.pt\n",
      "5259.pt\n",
      "5260.pt\n",
      "5261.pt\n",
      "5262.pt\n",
      "5263.pt\n",
      "5264.pt\n",
      "5265.pt\n",
      "5266.pt\n",
      "5267.pt\n",
      "5268.pt\n",
      "5269.pt\n",
      "5270.pt\n",
      "5271.pt\n",
      "5272.pt\n",
      "5273.pt\n",
      "5274.pt\n",
      "5275.pt\n",
      "5276.pt\n",
      "5277.pt\n",
      "5278.pt\n",
      "5279.pt\n",
      "5280.pt\n",
      "5281.pt\n",
      "5282.pt\n",
      "5283.pt\n",
      "5284.pt\n",
      "5285.pt\n",
      "5286.pt\n",
      "5287.pt\n",
      "5288.pt\n",
      "5289.pt\n",
      "5290.pt\n",
      "5291.pt\n",
      "5292.pt\n",
      "5293.pt\n",
      "5294.pt\n",
      "5295.pt\n",
      "5296.pt\n",
      "5297.pt\n",
      "5298.pt\n",
      "5299.pt\n",
      "5300.pt\n",
      "5301.pt\n",
      "5302.pt\n",
      "5303.pt\n",
      "5304.pt\n",
      "5305.pt\n",
      "5306.pt\n",
      "5307.pt\n",
      "5308.pt\n",
      "5309.pt\n",
      "5310.pt\n",
      "5311.pt\n",
      "5312.pt\n",
      "5313.pt\n",
      "5314.pt\n",
      "5315.pt\n",
      "5316.pt\n",
      "5317.pt\n",
      "5318.pt\n",
      "5319.pt\n",
      "5320.pt\n",
      "5321.pt\n",
      "5322.pt\n",
      "5323.pt\n",
      "5324.pt\n",
      "5325.pt\n",
      "5326.pt\n",
      "5327.pt\n",
      "5328.pt\n",
      "5329.pt\n",
      "5330.pt\n",
      "5331.pt\n",
      "5332.pt\n",
      "5333.pt\n",
      "5334.pt\n",
      "5335.pt\n",
      "5336.pt\n",
      "5337.pt\n",
      "5338.pt\n",
      "5339.pt\n",
      "5340.pt\n",
      "5341.pt\n",
      "5342.pt\n",
      "5343.pt\n",
      "5344.pt\n",
      "5345.pt\n",
      "5346.pt\n",
      "5347.pt\n",
      "5348.pt\n",
      "5349.pt\n",
      "5350.pt\n",
      "5351.pt\n",
      "5352.pt\n",
      "5353.pt\n",
      "5354.pt\n",
      "5355.pt\n",
      "5356.pt\n",
      "5357.pt\n",
      "5358.pt\n",
      "5359.pt\n",
      "5360.pt\n",
      "5361.pt\n",
      "5362.pt\n",
      "5363.pt\n",
      "5364.pt\n",
      "5365.pt\n",
      "5366.pt\n",
      "5367.pt\n",
      "5368.pt\n",
      "5369.pt\n",
      "5370.pt\n",
      "5371.pt\n",
      "5372.pt\n",
      "5373.pt\n",
      "5374.pt\n",
      "5375.pt\n",
      "5376.pt\n",
      "5377.pt\n",
      "5378.pt\n",
      "5379.pt\n",
      "5380.pt\n",
      "5381.pt\n",
      "5382.pt\n",
      "5383.pt\n",
      "5384.pt\n",
      "5385.pt\n",
      "5386.pt\n",
      "5387.pt\n",
      "5388.pt\n",
      "5389.pt\n",
      "5390.pt\n",
      "5391.pt\n",
      "5392.pt\n",
      "5393.pt\n",
      "5394.pt\n",
      "5395.pt\n",
      "5396.pt\n",
      "5397.pt\n",
      "5398.pt\n",
      "5399.pt\n",
      "5400.pt\n",
      "5401.pt\n",
      "5402.pt\n",
      "5403.pt\n",
      "5404.pt\n",
      "5405.pt\n",
      "5406.pt\n",
      "5407.pt\n",
      "5408.pt\n",
      "5409.pt\n",
      "5410.pt\n",
      "5411.pt\n",
      "5412.pt\n",
      "5413.pt\n",
      "5414.pt\n",
      "5415.pt\n",
      "5416.pt\n",
      "5417.pt\n",
      "5418.pt\n",
      "5419.pt\n",
      "5420.pt\n",
      "5421.pt\n",
      "5422.pt\n",
      "5423.pt\n",
      "5424.pt\n",
      "5425.pt\n",
      "5426.pt\n",
      "5427.pt\n",
      "5428.pt\n",
      "5429.pt\n",
      "5430.pt\n",
      "5431.pt\n",
      "5432.pt\n",
      "5433.pt\n",
      "5434.pt\n",
      "5435.pt\n",
      "5436.pt\n",
      "5437.pt\n",
      "5438.pt\n",
      "5439.pt\n",
      "5440.pt\n",
      "5441.pt\n",
      "5442.pt\n",
      "5443.pt\n",
      "5444.pt\n",
      "5445.pt\n",
      "5446.pt\n",
      "5447.pt\n",
      "5448.pt\n",
      "5449.pt\n",
      "5450.pt\n",
      "5451.pt\n",
      "5452.pt\n",
      "5453.pt\n",
      "5454.pt\n",
      "5455.pt\n",
      "5456.pt\n",
      "5457.pt\n",
      "5458.pt\n",
      "5459.pt\n",
      "5460.pt\n",
      "5461.pt\n",
      "5462.pt\n",
      "5463.pt\n",
      "5464.pt\n",
      "5465.pt\n",
      "5466.pt\n",
      "5467.pt\n",
      "5468.pt\n",
      "5469.pt\n",
      "5470.pt\n",
      "5471.pt\n",
      "5472.pt\n",
      "5473.pt\n",
      "5474.pt\n",
      "5475.pt\n",
      "5476.pt\n",
      "5477.pt\n",
      "5478.pt\n",
      "5479.pt\n",
      "5480.pt\n",
      "5481.pt\n",
      "5482.pt\n",
      "5483.pt\n",
      "5484.pt\n",
      "5485.pt\n",
      "5486.pt\n",
      "5487.pt\n",
      "5488.pt\n",
      "5489.pt\n",
      "5490.pt\n",
      "5491.pt\n",
      "5492.pt\n",
      "5493.pt\n",
      "5494.pt\n",
      "5495.pt\n",
      "5496.pt\n",
      "5497.pt\n",
      "5498.pt\n",
      "5499.pt\n",
      "5500.pt\n",
      "5501.pt\n",
      "5502.pt\n",
      "5503.pt\n",
      "5504.pt\n",
      "5505.pt\n",
      "5506.pt\n",
      "5507.pt\n",
      "5508.pt\n",
      "5509.pt\n",
      "5510.pt\n",
      "5511.pt\n",
      "5512.pt\n",
      "5513.pt\n",
      "5514.pt\n",
      "5515.pt\n",
      "5516.pt\n",
      "5517.pt\n",
      "5518.pt\n",
      "5519.pt\n",
      "5520.pt\n",
      "5521.pt\n",
      "5522.pt\n",
      "5523.pt\n",
      "5524.pt\n",
      "5525.pt\n",
      "5526.pt\n",
      "5527.pt\n",
      "5528.pt\n",
      "5529.pt\n",
      "5530.pt\n",
      "5531.pt\n",
      "5532.pt\n",
      "5533.pt\n",
      "5534.pt\n",
      "5535.pt\n",
      "5536.pt\n",
      "5537.pt\n",
      "5538.pt\n",
      "5539.pt\n",
      "5540.pt\n",
      "5541.pt\n",
      "5542.pt\n",
      "5543.pt\n",
      "5544.pt\n",
      "5545.pt\n",
      "5546.pt\n",
      "5547.pt\n",
      "5548.pt\n",
      "5549.pt\n",
      "5550.pt\n",
      "5551.pt\n",
      "5552.pt\n",
      "5553.pt\n",
      "5554.pt\n",
      "5555.pt\n",
      "5556.pt\n",
      "5557.pt\n",
      "5558.pt\n",
      "5559.pt\n",
      "5560.pt\n",
      "5561.pt\n",
      "5562.pt\n",
      "5563.pt\n",
      "5564.pt\n",
      "5565.pt\n",
      "5566.pt\n",
      "5567.pt\n",
      "5568.pt\n",
      "5569.pt\n",
      "5570.pt\n",
      "5571.pt\n",
      "5572.pt\n",
      "5573.pt\n",
      "5574.pt\n",
      "5575.pt\n",
      "5576.pt\n",
      "5577.pt\n",
      "5578.pt\n",
      "5579.pt\n",
      "5580.pt\n",
      "5581.pt\n",
      "5582.pt\n",
      "5583.pt\n",
      "5584.pt\n",
      "5585.pt\n",
      "5586.pt\n",
      "5587.pt\n",
      "5588.pt\n",
      "5589.pt\n",
      "5590.pt\n",
      "5591.pt\n",
      "5592.pt\n",
      "5593.pt\n",
      "5594.pt\n",
      "5595.pt\n",
      "5596.pt\n",
      "5597.pt\n",
      "5598.pt\n",
      "5599.pt\n",
      "5600.pt\n",
      "5601.pt\n",
      "5602.pt\n",
      "5603.pt\n",
      "5604.pt\n",
      "5605.pt\n",
      "5606.pt\n",
      "5607.pt\n",
      "5608.pt\n",
      "5609.pt\n",
      "5610.pt\n",
      "5611.pt\n",
      "5612.pt\n",
      "5613.pt\n",
      "5614.pt\n",
      "5615.pt\n",
      "5616.pt\n",
      "5617.pt\n",
      "5618.pt\n",
      "5619.pt\n",
      "5620.pt\n",
      "5621.pt\n",
      "5622.pt\n",
      "5623.pt\n",
      "5624.pt\n",
      "5625.pt\n",
      "5626.pt\n",
      "5627.pt\n",
      "5628.pt\n",
      "5629.pt\n",
      "5630.pt\n",
      "5631.pt\n",
      "5632.pt\n",
      "5633.pt\n",
      "5634.pt\n",
      "5635.pt\n",
      "5636.pt\n",
      "5637.pt\n",
      "5638.pt\n",
      "5639.pt\n",
      "5640.pt\n",
      "5641.pt\n",
      "5642.pt\n",
      "5643.pt\n",
      "5644.pt\n",
      "5645.pt\n",
      "5646.pt\n",
      "5647.pt\n",
      "5648.pt\n",
      "5649.pt\n",
      "5650.pt\n",
      "5651.pt\n",
      "5652.pt\n",
      "5653.pt\n",
      "5654.pt\n",
      "5655.pt\n",
      "5656.pt\n",
      "5657.pt\n",
      "5658.pt\n",
      "5659.pt\n",
      "5660.pt\n",
      "5661.pt\n",
      "5662.pt\n",
      "5663.pt\n",
      "5664.pt\n",
      "5665.pt\n",
      "5666.pt\n",
      "5667.pt\n",
      "5668.pt\n",
      "5669.pt\n",
      "5670.pt\n",
      "5671.pt\n",
      "5672.pt\n",
      "5673.pt\n",
      "5674.pt\n",
      "5675.pt\n",
      "5676.pt\n",
      "5677.pt\n",
      "5678.pt\n",
      "5679.pt\n",
      "5680.pt\n",
      "5681.pt\n",
      "5682.pt\n",
      "5683.pt\n",
      "5684.pt\n",
      "5685.pt\n",
      "5686.pt\n",
      "5687.pt\n",
      "5688.pt\n",
      "5689.pt\n",
      "5690.pt\n",
      "5691.pt\n",
      "5692.pt\n",
      "5693.pt\n",
      "5694.pt\n",
      "5695.pt\n",
      "5696.pt\n",
      "5697.pt\n",
      "5698.pt\n",
      "5699.pt\n",
      "5700.pt\n",
      "5701.pt\n",
      "5702.pt\n",
      "5703.pt\n",
      "5704.pt\n",
      "5705.pt\n",
      "5706.pt\n",
      "5707.pt\n",
      "5708.pt\n",
      "5709.pt\n",
      "5710.pt\n",
      "5711.pt\n",
      "5712.pt\n",
      "5713.pt\n",
      "5714.pt\n",
      "5715.pt\n",
      "5716.pt\n",
      "5717.pt\n",
      "5718.pt\n",
      "5719.pt\n",
      "5720.pt\n",
      "5721.pt\n",
      "5722.pt\n",
      "5723.pt\n",
      "5724.pt\n",
      "5725.pt\n",
      "5726.pt\n",
      "5727.pt\n",
      "5728.pt\n",
      "5729.pt\n",
      "5730.pt\n",
      "5731.pt\n",
      "5732.pt\n",
      "5733.pt\n",
      "5734.pt\n",
      "5735.pt\n",
      "5736.pt\n",
      "5737.pt\n",
      "5738.pt\n",
      "5739.pt\n",
      "5740.pt\n",
      "5741.pt\n",
      "5742.pt\n",
      "5743.pt\n",
      "5744.pt\n",
      "5745.pt\n",
      "5746.pt\n",
      "5747.pt\n",
      "5748.pt\n",
      "5749.pt\n",
      "5750.pt\n",
      "5751.pt\n",
      "5752.pt\n",
      "5753.pt\n",
      "5754.pt\n",
      "5755.pt\n",
      "5756.pt\n",
      "5757.pt\n",
      "5758.pt\n",
      "5759.pt\n",
      "5760.pt\n",
      "5761.pt\n",
      "5762.pt\n",
      "5763.pt\n",
      "5764.pt\n",
      "5765.pt\n",
      "5766.pt\n",
      "5767.pt\n",
      "5768.pt\n",
      "5769.pt\n",
      "5770.pt\n",
      "5771.pt\n",
      "5772.pt\n",
      "5773.pt\n",
      "5774.pt\n",
      "5775.pt\n",
      "5776.pt\n",
      "5777.pt\n",
      "5778.pt\n",
      "5779.pt\n",
      "5780.pt\n",
      "5781.pt\n",
      "5782.pt\n",
      "5783.pt\n",
      "5784.pt\n",
      "5785.pt\n",
      "5786.pt\n",
      "5787.pt\n",
      "5788.pt\n",
      "5789.pt\n",
      "5790.pt\n",
      "5791.pt\n",
      "5792.pt\n",
      "5793.pt\n",
      "5794.pt\n",
      "5795.pt\n",
      "5796.pt\n",
      "5797.pt\n",
      "5798.pt\n",
      "5799.pt\n",
      "5800.pt\n",
      "5801.pt\n",
      "5802.pt\n",
      "5803.pt\n",
      "5804.pt\n",
      "5805.pt\n",
      "5806.pt\n",
      "5807.pt\n",
      "5808.pt\n",
      "5809.pt\n",
      "5810.pt\n",
      "5811.pt\n",
      "5812.pt\n",
      "5813.pt\n",
      "5814.pt\n",
      "5815.pt\n",
      "5816.pt\n",
      "5817.pt\n",
      "5818.pt\n",
      "5819.pt\n",
      "5820.pt\n",
      "5821.pt\n",
      "5822.pt\n",
      "5823.pt\n",
      "5824.pt\n",
      "5825.pt\n",
      "5826.pt\n",
      "5827.pt\n",
      "5828.pt\n",
      "5829.pt\n",
      "5830.pt\n",
      "5831.pt\n",
      "5832.pt\n",
      "5833.pt\n",
      "5834.pt\n",
      "5835.pt\n",
      "5836.pt\n",
      "5837.pt\n",
      "5838.pt\n",
      "5839.pt\n",
      "5840.pt\n",
      "5841.pt\n",
      "5842.pt\n",
      "5843.pt\n",
      "5844.pt\n",
      "5845.pt\n",
      "5846.pt\n",
      "5847.pt\n",
      "5848.pt\n",
      "5849.pt\n",
      "5850.pt\n",
      "5851.pt\n",
      "5852.pt\n",
      "5853.pt\n",
      "5854.pt\n",
      "5855.pt\n",
      "5856.pt\n",
      "5857.pt\n",
      "5858.pt\n",
      "5859.pt\n",
      "5860.pt\n",
      "5861.pt\n",
      "5862.pt\n",
      "5863.pt\n",
      "5864.pt\n",
      "5865.pt\n",
      "5866.pt\n",
      "5867.pt\n",
      "5868.pt\n",
      "5869.pt\n",
      "5870.pt\n",
      "5871.pt\n",
      "5872.pt\n",
      "5873.pt\n",
      "5874.pt\n",
      "5875.pt\n",
      "5876.pt\n",
      "5877.pt\n",
      "5878.pt\n",
      "5879.pt\n",
      "5880.pt\n",
      "5881.pt\n",
      "5882.pt\n",
      "5883.pt\n",
      "5884.pt\n",
      "5885.pt\n",
      "5886.pt\n",
      "5887.pt\n",
      "5888.pt\n",
      "5889.pt\n",
      "5890.pt\n",
      "5891.pt\n",
      "5892.pt\n",
      "5893.pt\n",
      "5894.pt\n",
      "5895.pt\n",
      "5896.pt\n",
      "5897.pt\n",
      "5898.pt\n",
      "5899.pt\n",
      "5900.pt\n",
      "5901.pt\n",
      "5902.pt\n",
      "5903.pt\n",
      "5904.pt\n",
      "5905.pt\n",
      "5906.pt\n",
      "5907.pt\n",
      "5908.pt\n",
      "5909.pt\n",
      "5910.pt\n",
      "5911.pt\n",
      "5912.pt\n",
      "5913.pt\n",
      "5914.pt\n",
      "5915.pt\n",
      "5916.pt\n",
      "5917.pt\n",
      "5918.pt\n",
      "5919.pt\n",
      "5920.pt\n",
      "5921.pt\n",
      "5922.pt\n",
      "5923.pt\n",
      "5924.pt\n",
      "5925.pt\n",
      "5926.pt\n",
      "5927.pt\n",
      "5928.pt\n",
      "5929.pt\n",
      "5930.pt\n",
      "5931.pt\n",
      "5932.pt\n",
      "5933.pt\n",
      "5934.pt\n",
      "5935.pt\n",
      "5936.pt\n",
      "5937.pt\n",
      "5938.pt\n",
      "5939.pt\n",
      "5940.pt\n",
      "5941.pt\n",
      "5942.pt\n",
      "5943.pt\n",
      "5944.pt\n",
      "5945.pt\n",
      "5946.pt\n",
      "5947.pt\n",
      "5948.pt\n",
      "5949.pt\n",
      "5950.pt\n",
      "5951.pt\n",
      "5952.pt\n",
      "5953.pt\n",
      "5954.pt\n",
      "5955.pt\n",
      "5956.pt\n",
      "5957.pt\n",
      "5958.pt\n",
      "5959.pt\n",
      "5960.pt\n",
      "5961.pt\n",
      "5962.pt\n",
      "5963.pt\n",
      "5964.pt\n",
      "5965.pt\n",
      "5966.pt\n",
      "5967.pt\n",
      "5968.pt\n",
      "5969.pt\n",
      "5970.pt\n",
      "5971.pt\n",
      "5972.pt\n",
      "5973.pt\n",
      "5974.pt\n",
      "5975.pt\n",
      "5976.pt\n",
      "5977.pt\n",
      "5978.pt\n",
      "5979.pt\n",
      "5980.pt\n",
      "5981.pt\n",
      "5982.pt\n",
      "5983.pt\n",
      "5984.pt\n",
      "5985.pt\n",
      "5986.pt\n",
      "5987.pt\n",
      "5988.pt\n",
      "5989.pt\n",
      "5990.pt\n",
      "5991.pt\n",
      "5992.pt\n",
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 3s 9ms/step - loss: 1983.2024 - val_loss: 1960.8616\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1982.4047 - val_loss: 1956.2998\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 1977.5154 - val_loss: 1954.9718\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 1977.0015 - val_loss: 1954.8616\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1976.9202 - val_loss: 1954.8171\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1976.8728 - val_loss: 1954.7623\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1976.8398 - val_loss: 1954.7354\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1976.8099 - val_loss: 1954.7032\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 1976.7979 - val_loss: 1954.6946\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1976.7854 - val_loss: 1954.6741\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "38/38 [==============================] - 0s 5ms/step\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.8150 - accuracy: 0.7055 - val_loss: 0.6156 - val_accuracy: 0.7256\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.7610 - val_loss: 0.5116 - val_accuracy: 0.7648\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.5041 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7773\n",
      "Test loss: 0.4978336989879608\n",
      "Test accuracy: 0.7773144245147705\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense, Input, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense, Attention,Multiply\n",
    "from sklearn.model_selection import train_test_split\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        print(filename)\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the autoencoder model\n",
    "input_layer = Input(shape=(data[0].shape[0], 1))\n",
    "\n",
    "x = Conv1D(32, 3, activation=\"relu\", padding=\"same\")(input_layer) # 32 dimensions\n",
    "x = MaxPooling1D(2, padding=\"same\")(x)\n",
    "x = Conv1D(1, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "encoded = MaxPooling1D(2, padding=\"same\")(x)\n",
    "\n",
    "x = Conv1D(1, 3, activation=\"relu\", padding=\"same\")(encoded)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling1D(2)(x)\n",
    "decoded = Conv1D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=10, validation_data=(X_test, X_test))\n",
    "\n",
    "# Use the encoder part of the autoencoder to encode the train and test data\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)\n",
    "\n",
    "# Now use the encoded data to train a model with an attention layer\n",
    "inputs = Input(shape=(X_train_encoded.shape[1], X_train_encoded.shape[2]))\n",
    "attention_probs = Dense(X_train_encoded.shape[1], activation='softmax', name='attention_vec')(inputs)\n",
    "attention_mul = Multiply(name='attention_mul')([inputs, attention_probs])\n",
    "out = Flatten()(attention_mul)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "attention_model = Model(inputs=inputs, outputs=out)\n",
    "attention_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "attention_model.fit(X_train_encoded, y_train, batch_size=32, epochs=3, verbose=1, validation_data=(X_test_encoded, y_test))\n",
    "\n",
    "score = attention_model.evaluate(X_test_encoded, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40, 1)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 2s 5ms/step - loss: 0.9579 - accuracy: 0.8089 - val_loss: 0.3570 - val_accuracy: 0.8432\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2587 - accuracy: 0.9015 - val_loss: 0.2496 - val_accuracy: 0.8991\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2599 - accuracy: 0.9018 - val_loss: 0.2820 - val_accuracy: 0.8999\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9105 - val_loss: 0.2405 - val_accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2389 - accuracy: 0.9105 - val_loss: 0.3115 - val_accuracy: 0.8707\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.9122 - val_loss: 0.2407 - val_accuracy: 0.9099\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.9174 - val_loss: 0.2318 - val_accuracy: 0.9116\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9203 - val_loss: 0.2545 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9159 - val_loss: 0.2908 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.2399 - accuracy: 0.9082 - val_loss: 0.2502 - val_accuracy: 0.9008\n",
      "Test loss: 0.2502235174179077\n",
      "Test accuracy: 0.9007506370544434\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(data[0].shape[0], 1)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\data'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5994):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1, 1).numpy())  # Adjusted this line\n",
    "        labels.append(1 if i <= 2311 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "def get_model(op_nodes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True), input_shape=(data[0].shape[0], data[0].shape[1])))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Bidirectional(LSTM(units=32)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(op_nodes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the BiLSTM model\n",
    "model = get_model(num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first item in data: (40, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "directory = r'F:\\data'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5994):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        \n",
    "        data.append(feature.view(40,1).numpy()) # Adjusted this line to match ResNet input\n",
    "        labels.append(1 if i <= 2311 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# Define ResNet block\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first item in data: (40, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(40,1).numpy())  # Adjusted this line to match ResNet input\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "print(\"Shape of the first item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# Define ResNet block\n",
    "def resnet_block(inputs, num_filters, kernel_size, strides, activation='relu'):\n",
    "    x = layers.Conv1D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv1D(num_filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    shortcut = layers.Conv1D(num_filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "    shortcut = layers.BatchNormalization()(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "# Define ResNet model\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv1D(16, kernel_size=3, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = resnet_block(x, 32, 3, 2)\n",
    "    x = resnet_block(x, 32, 3, 1)\n",
    "    \n",
    "    x = resnet_block(x, 64, 3, 2)\n",
    "    x = resnet_block(x, 64, 3, 1)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = resnet(input_shape=(40, 1), num_classes=num_classes)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 13ms/step - loss: 0.4173 - accuracy: 0.8175 - val_loss: 0.7338 - val_accuracy: 0.6188\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.3365 - accuracy: 0.8623 - val_loss: 0.4569 - val_accuracy: 0.7898\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.2968 - accuracy: 0.8782 - val_loss: 0.3351 - val_accuracy: 0.8582\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2731 - accuracy: 0.8861 - val_loss: 0.4321 - val_accuracy: 0.8332\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2599 - accuracy: 0.8959 - val_loss: 0.2882 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2490 - accuracy: 0.9001 - val_loss: 0.3062 - val_accuracy: 0.8749\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.2363 - accuracy: 0.9059 - val_loss: 0.2967 - val_accuracy: 0.8757\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2175 - accuracy: 0.9170 - val_loss: 0.2881 - val_accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.2041 - accuracy: 0.9203 - val_loss: 0.2795 - val_accuracy: 0.8807\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.1988 - accuracy: 0.9207 - val_loss: 0.2903 - val_accuracy: 0.8932\n",
      "Test loss: 0.29033753275871277\n",
      "Test accuracy: 0.8932443857192993\n"
     ]
    }
   ],
   "source": [
    "model = resnet(input_shape=(40, 1), num_classes=num_classes)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = r'F:\\dataset_sri' # Replace with the directory path containing the files  # Replace with the directory path containing the files\n",
    "\n",
    "start_index = 0  # Starting index for renaming\n",
    "end_index = 5993  # Ending index for renaming\n",
    "offset = 2312  # Offset to add to the second range\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".m4a\"):\n",
    "        original_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Extract the numeric index from the filename\n",
    "        original_index = int(filename[:-4])\n",
    "\n",
    "        # Check if the file index falls within the desired range\n",
    "        if 0 <= original_index <= 2311:\n",
    "            # Calculate the new index for the first range\n",
    "            new_index = original_index\n",
    "        elif 7040 <= original_index <= 10721:\n",
    "            # Calculate the new index for the second range\n",
    "            new_index = original_index - 7040 + offset\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Create the new filename\n",
    "        new_filename = str(new_index) + \".m4a\"\n",
    "        new_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        # Skip renaming if the target file already exists\n",
    "        if os.path.exists(new_path):\n",
    "            continue\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(original_path, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11984\\1260300349.py:48: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = scipy.stats.mode(stft.flatten())[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.m4a\n",
      "2.m4a\n",
      "3.m4a\n",
      "4.m4a\n",
      "5.m4a\n",
      "6.m4a\n",
      "7.m4a\n",
      "8.m4a\n",
      "9.m4a\n",
      "10.m4a\n",
      "11.m4a\n",
      "12.m4a\n",
      "13.m4a\n",
      "14.m4a\n",
      "15.m4a\n",
      "16.m4a\n",
      "17.m4a\n",
      "18.m4a\n",
      "19.m4a\n",
      "20.m4a\n",
      "21.m4a\n",
      "22.m4a\n",
      "23.m4a\n",
      "24.m4a\n",
      "25.m4a\n",
      "26.m4a\n",
      "27.m4a\n",
      "28.m4a\n",
      "29.m4a\n",
      "30.m4a\n",
      "31.m4a\n",
      "32.m4a\n",
      "33.m4a\n",
      "34.m4a\n",
      "35.m4a\n",
      "36.m4a\n",
      "37.m4a\n",
      "38.m4a\n",
      "39.m4a\n",
      "40.m4a\n",
      "41.m4a\n",
      "42.m4a\n",
      "43.m4a\n",
      "44.m4a\n",
      "45.m4a\n",
      "46.m4a\n",
      "47.m4a\n",
      "48.m4a\n",
      "49.m4a\n",
      "50.m4a\n",
      "51.m4a\n",
      "52.m4a\n",
      "53.m4a\n",
      "54.m4a\n",
      "55.m4a\n",
      "56.m4a\n",
      "57.m4a\n",
      "58.m4a\n",
      "59.m4a\n",
      "60.m4a\n",
      "61.m4a\n",
      "62.m4a\n",
      "63.m4a\n",
      "64.m4a\n",
      "65.m4a\n",
      "66.m4a\n",
      "67.m4a\n",
      "68.m4a\n",
      "69.m4a\n",
      "70.m4a\n",
      "71.m4a\n",
      "72.m4a\n",
      "73.m4a\n",
      "74.m4a\n",
      "75.m4a\n",
      "76.m4a\n",
      "77.m4a\n",
      "78.m4a\n",
      "79.m4a\n",
      "80.m4a\n",
      "81.m4a\n",
      "82.m4a\n",
      "83.m4a\n",
      "84.m4a\n",
      "85.m4a\n",
      "86.m4a\n",
      "87.m4a\n",
      "88.m4a\n",
      "89.m4a\n",
      "90.m4a\n",
      "91.m4a\n",
      "92.m4a\n",
      "93.m4a\n",
      "94.m4a\n",
      "95.m4a\n",
      "96.m4a\n",
      "97.m4a\n",
      "98.m4a\n",
      "99.m4a\n",
      "100.m4a\n",
      "101.m4a\n",
      "102.m4a\n",
      "103.m4a\n",
      "104.m4a\n",
      "105.m4a\n",
      "106.m4a\n",
      "107.m4a\n",
      "108.m4a\n",
      "109.m4a\n",
      "110.m4a\n",
      "111.m4a\n",
      "112.m4a\n",
      "113.m4a\n",
      "114.m4a\n",
      "115.m4a\n",
      "116.m4a\n",
      "117.m4a\n",
      "118.m4a\n",
      "119.m4a\n",
      "120.m4a\n",
      "121.m4a\n",
      "122.m4a\n",
      "123.m4a\n",
      "124.m4a\n",
      "125.m4a\n",
      "126.m4a\n",
      "127.m4a\n",
      "128.m4a\n",
      "129.m4a\n",
      "130.m4a\n",
      "131.m4a\n",
      "132.m4a\n",
      "133.m4a\n",
      "134.m4a\n",
      "135.m4a\n",
      "136.m4a\n",
      "137.m4a\n",
      "138.m4a\n",
      "139.m4a\n",
      "140.m4a\n",
      "141.m4a\n",
      "142.m4a\n",
      "143.m4a\n",
      "144.m4a\n",
      "145.m4a\n",
      "146.m4a\n",
      "147.m4a\n",
      "148.m4a\n",
      "149.m4a\n",
      "150.m4a\n",
      "151.m4a\n",
      "152.m4a\n",
      "153.m4a\n",
      "154.m4a\n",
      "155.m4a\n",
      "156.m4a\n",
      "157.m4a\n",
      "158.m4a\n",
      "159.m4a\n",
      "160.m4a\n",
      "161.m4a\n",
      "162.m4a\n",
      "163.m4a\n",
      "164.m4a\n",
      "165.m4a\n",
      "166.m4a\n",
      "167.m4a\n",
      "168.m4a\n",
      "169.m4a\n",
      "170.m4a\n",
      "171.m4a\n",
      "172.m4a\n",
      "173.m4a\n",
      "174.m4a\n",
      "175.m4a\n",
      "176.m4a\n",
      "177.m4a\n",
      "178.m4a\n",
      "179.m4a\n",
      "180.m4a\n",
      "181.m4a\n",
      "182.m4a\n",
      "183.m4a\n",
      "184.m4a\n",
      "185.m4a\n",
      "186.m4a\n",
      "187.m4a\n",
      "188.m4a\n",
      "189.m4a\n",
      "190.m4a\n",
      "191.m4a\n",
      "192.m4a\n",
      "193.m4a\n",
      "194.m4a\n",
      "195.m4a\n",
      "196.m4a\n",
      "197.m4a\n",
      "198.m4a\n",
      "199.m4a\n",
      "200.m4a\n",
      "201.m4a\n",
      "202.m4a\n",
      "203.m4a\n",
      "204.m4a\n",
      "205.m4a\n",
      "206.m4a\n",
      "207.m4a\n",
      "208.m4a\n",
      "209.m4a\n",
      "210.m4a\n",
      "211.m4a\n",
      "212.m4a\n",
      "213.m4a\n",
      "214.m4a\n",
      "215.m4a\n",
      "216.m4a\n",
      "217.m4a\n",
      "218.m4a\n",
      "219.m4a\n",
      "220.m4a\n",
      "221.m4a\n",
      "222.m4a\n",
      "223.m4a\n",
      "224.m4a\n",
      "225.m4a\n",
      "226.m4a\n",
      "227.m4a\n",
      "228.m4a\n",
      "229.m4a\n",
      "230.m4a\n",
      "231.m4a\n",
      "232.m4a\n",
      "233.m4a\n",
      "234.m4a\n",
      "235.m4a\n",
      "236.m4a\n",
      "237.m4a\n",
      "238.m4a\n",
      "239.m4a\n",
      "240.m4a\n",
      "241.m4a\n",
      "242.m4a\n",
      "243.m4a\n",
      "244.m4a\n",
      "245.m4a\n",
      "246.m4a\n",
      "247.m4a\n",
      "248.m4a\n",
      "249.m4a\n",
      "250.m4a\n",
      "251.m4a\n",
      "252.m4a\n",
      "253.m4a\n",
      "254.m4a\n",
      "255.m4a\n",
      "256.m4a\n",
      "257.m4a\n",
      "258.m4a\n",
      "259.m4a\n",
      "260.m4a\n",
      "261.m4a\n",
      "262.m4a\n",
      "263.m4a\n",
      "264.m4a\n",
      "265.m4a\n",
      "266.m4a\n",
      "267.m4a\n",
      "268.m4a\n",
      "269.m4a\n",
      "270.m4a\n",
      "271.m4a\n",
      "272.m4a\n",
      "273.m4a\n",
      "274.m4a\n",
      "275.m4a\n",
      "276.m4a\n",
      "277.m4a\n",
      "278.m4a\n",
      "279.m4a\n",
      "280.m4a\n",
      "281.m4a\n",
      "282.m4a\n",
      "283.m4a\n",
      "284.m4a\n",
      "285.m4a\n",
      "286.m4a\n",
      "287.m4a\n",
      "288.m4a\n",
      "289.m4a\n",
      "290.m4a\n",
      "291.m4a\n",
      "292.m4a\n",
      "293.m4a\n",
      "294.m4a\n",
      "295.m4a\n",
      "296.m4a\n",
      "297.m4a\n",
      "298.m4a\n",
      "299.m4a\n",
      "300.m4a\n",
      "301.m4a\n",
      "302.m4a\n",
      "303.m4a\n",
      "304.m4a\n",
      "305.m4a\n",
      "306.m4a\n",
      "307.m4a\n",
      "308.m4a\n",
      "309.m4a\n",
      "310.m4a\n",
      "311.m4a\n",
      "312.m4a\n",
      "313.m4a\n",
      "314.m4a\n",
      "315.m4a\n",
      "316.m4a\n",
      "317.m4a\n",
      "318.m4a\n",
      "319.m4a\n",
      "320.m4a\n",
      "321.m4a\n",
      "322.m4a\n",
      "323.m4a\n",
      "324.m4a\n",
      "325.m4a\n",
      "326.m4a\n",
      "327.m4a\n",
      "328.m4a\n",
      "329.m4a\n",
      "330.m4a\n",
      "331.m4a\n",
      "332.m4a\n",
      "333.m4a\n",
      "334.m4a\n",
      "335.m4a\n",
      "336.m4a\n",
      "337.m4a\n",
      "338.m4a\n",
      "339.m4a\n",
      "340.m4a\n",
      "341.m4a\n",
      "342.m4a\n",
      "343.m4a\n",
      "344.m4a\n",
      "345.m4a\n",
      "346.m4a\n",
      "347.m4a\n",
      "348.m4a\n",
      "349.m4a\n",
      "350.m4a\n",
      "351.m4a\n",
      "352.m4a\n",
      "353.m4a\n",
      "354.m4a\n",
      "355.m4a\n",
      "356.m4a\n",
      "357.m4a\n",
      "358.m4a\n",
      "359.m4a\n",
      "360.m4a\n",
      "361.m4a\n",
      "362.m4a\n",
      "363.m4a\n",
      "364.m4a\n",
      "365.m4a\n",
      "366.m4a\n",
      "367.m4a\n",
      "368.m4a\n",
      "369.m4a\n",
      "370.m4a\n",
      "371.m4a\n",
      "372.m4a\n",
      "373.m4a\n",
      "374.m4a\n",
      "375.m4a\n",
      "376.m4a\n",
      "377.m4a\n",
      "378.m4a\n",
      "379.m4a\n",
      "380.m4a\n",
      "381.m4a\n",
      "382.m4a\n",
      "383.m4a\n",
      "384.m4a\n",
      "385.m4a\n",
      "386.m4a\n",
      "387.m4a\n",
      "388.m4a\n",
      "389.m4a\n",
      "390.m4a\n",
      "391.m4a\n",
      "392.m4a\n",
      "393.m4a\n",
      "394.m4a\n",
      "395.m4a\n",
      "396.m4a\n",
      "397.m4a\n",
      "398.m4a\n",
      "399.m4a\n",
      "400.m4a\n",
      "401.m4a\n",
      "402.m4a\n",
      "403.m4a\n",
      "404.m4a\n",
      "405.m4a\n",
      "406.m4a\n",
      "407.m4a\n",
      "408.m4a\n",
      "409.m4a\n",
      "410.m4a\n",
      "411.m4a\n",
      "412.m4a\n",
      "413.m4a\n",
      "414.m4a\n",
      "415.m4a\n",
      "416.m4a\n",
      "417.m4a\n",
      "418.m4a\n",
      "419.m4a\n",
      "420.m4a\n",
      "421.m4a\n",
      "422.m4a\n",
      "423.m4a\n",
      "424.m4a\n",
      "425.m4a\n",
      "426.m4a\n",
      "427.m4a\n",
      "428.m4a\n",
      "429.m4a\n",
      "430.m4a\n",
      "431.m4a\n",
      "432.m4a\n",
      "433.m4a\n",
      "434.m4a\n",
      "435.m4a\n",
      "436.m4a\n",
      "437.m4a\n",
      "438.m4a\n",
      "439.m4a\n",
      "440.m4a\n",
      "441.m4a\n",
      "442.m4a\n",
      "443.m4a\n",
      "444.m4a\n",
      "445.m4a\n",
      "446.m4a\n",
      "447.m4a\n",
      "448.m4a\n",
      "449.m4a\n",
      "450.m4a\n",
      "451.m4a\n",
      "452.m4a\n",
      "453.m4a\n",
      "454.m4a\n",
      "455.m4a\n",
      "456.m4a\n",
      "457.m4a\n",
      "458.m4a\n",
      "459.m4a\n",
      "460.m4a\n",
      "461.m4a\n",
      "462.m4a\n",
      "463.m4a\n",
      "464.m4a\n",
      "465.m4a\n",
      "466.m4a\n",
      "467.m4a\n",
      "468.m4a\n",
      "469.m4a\n",
      "470.m4a\n",
      "471.m4a\n",
      "472.m4a\n",
      "473.m4a\n",
      "474.m4a\n",
      "475.m4a\n",
      "476.m4a\n",
      "477.m4a\n",
      "478.m4a\n",
      "479.m4a\n",
      "480.m4a\n",
      "481.m4a\n",
      "482.m4a\n",
      "483.m4a\n",
      "484.m4a\n",
      "485.m4a\n",
      "486.m4a\n",
      "487.m4a\n",
      "488.m4a\n",
      "489.m4a\n",
      "490.m4a\n",
      "491.m4a\n",
      "492.m4a\n",
      "493.m4a\n",
      "494.m4a\n",
      "495.m4a\n",
      "496.m4a\n",
      "497.m4a\n",
      "498.m4a\n",
      "499.m4a\n",
      "500.m4a\n",
      "501.m4a\n",
      "502.m4a\n",
      "503.m4a\n",
      "504.m4a\n",
      "505.m4a\n",
      "506.m4a\n",
      "507.m4a\n",
      "508.m4a\n",
      "509.m4a\n",
      "510.m4a\n",
      "511.m4a\n",
      "512.m4a\n",
      "513.m4a\n",
      "514.m4a\n",
      "515.m4a\n",
      "516.m4a\n",
      "517.m4a\n",
      "518.m4a\n",
      "519.m4a\n",
      "520.m4a\n",
      "521.m4a\n",
      "522.m4a\n",
      "523.m4a\n",
      "524.m4a\n",
      "525.m4a\n",
      "526.m4a\n",
      "527.m4a\n",
      "528.m4a\n",
      "529.m4a\n",
      "530.m4a\n",
      "531.m4a\n",
      "532.m4a\n",
      "533.m4a\n",
      "534.m4a\n",
      "535.m4a\n",
      "536.m4a\n",
      "537.m4a\n",
      "538.m4a\n",
      "539.m4a\n",
      "540.m4a\n",
      "541.m4a\n",
      "542.m4a\n",
      "543.m4a\n",
      "544.m4a\n",
      "545.m4a\n",
      "546.m4a\n",
      "547.m4a\n",
      "548.m4a\n",
      "549.m4a\n",
      "550.m4a\n",
      "551.m4a\n",
      "552.m4a\n",
      "553.m4a\n",
      "554.m4a\n",
      "555.m4a\n",
      "556.m4a\n",
      "557.m4a\n",
      "558.m4a\n",
      "559.m4a\n",
      "560.m4a\n",
      "561.m4a\n",
      "562.m4a\n",
      "563.m4a\n",
      "564.m4a\n",
      "565.m4a\n",
      "566.m4a\n",
      "567.m4a\n",
      "568.m4a\n",
      "569.m4a\n",
      "570.m4a\n",
      "571.m4a\n",
      "572.m4a\n",
      "573.m4a\n",
      "574.m4a\n",
      "575.m4a\n",
      "576.m4a\n",
      "577.m4a\n",
      "578.m4a\n",
      "579.m4a\n",
      "580.m4a\n",
      "581.m4a\n",
      "582.m4a\n",
      "583.m4a\n",
      "584.m4a\n",
      "585.m4a\n",
      "586.m4a\n",
      "587.m4a\n",
      "588.m4a\n",
      "589.m4a\n",
      "590.m4a\n",
      "591.m4a\n",
      "592.m4a\n",
      "593.m4a\n",
      "594.m4a\n",
      "595.m4a\n",
      "596.m4a\n",
      "597.m4a\n",
      "598.m4a\n",
      "599.m4a\n",
      "600.m4a\n",
      "601.m4a\n",
      "602.m4a\n",
      "603.m4a\n",
      "604.m4a\n",
      "605.m4a\n",
      "606.m4a\n",
      "607.m4a\n",
      "608.m4a\n",
      "609.m4a\n",
      "610.m4a\n",
      "611.m4a\n",
      "612.m4a\n",
      "613.m4a\n",
      "614.m4a\n",
      "615.m4a\n",
      "616.m4a\n",
      "617.m4a\n",
      "618.m4a\n",
      "619.m4a\n",
      "620.m4a\n",
      "621.m4a\n",
      "622.m4a\n",
      "623.m4a\n",
      "624.m4a\n",
      "625.m4a\n",
      "626.m4a\n",
      "627.m4a\n",
      "628.m4a\n",
      "629.m4a\n",
      "630.m4a\n",
      "631.m4a\n",
      "632.m4a\n",
      "633.m4a\n",
      "634.m4a\n",
      "635.m4a\n",
      "636.m4a\n",
      "637.m4a\n",
      "638.m4a\n",
      "639.m4a\n",
      "640.m4a\n",
      "641.m4a\n",
      "642.m4a\n",
      "643.m4a\n",
      "644.m4a\n",
      "645.m4a\n",
      "646.m4a\n",
      "647.m4a\n",
      "648.m4a\n",
      "649.m4a\n",
      "650.m4a\n",
      "651.m4a\n",
      "652.m4a\n",
      "653.m4a\n",
      "654.m4a\n",
      "655.m4a\n",
      "656.m4a\n",
      "657.m4a\n",
      "658.m4a\n",
      "659.m4a\n",
      "660.m4a\n",
      "661.m4a\n",
      "662.m4a\n",
      "663.m4a\n",
      "664.m4a\n",
      "665.m4a\n",
      "666.m4a\n",
      "667.m4a\n",
      "668.m4a\n",
      "669.m4a\n",
      "670.m4a\n",
      "671.m4a\n",
      "672.m4a\n",
      "673.m4a\n",
      "674.m4a\n",
      "675.m4a\n",
      "676.m4a\n",
      "677.m4a\n",
      "678.m4a\n",
      "679.m4a\n",
      "680.m4a\n",
      "681.m4a\n",
      "682.m4a\n",
      "683.m4a\n",
      "684.m4a\n",
      "685.m4a\n",
      "686.m4a\n",
      "687.m4a\n",
      "688.m4a\n",
      "689.m4a\n",
      "690.m4a\n",
      "691.m4a\n",
      "692.m4a\n",
      "693.m4a\n",
      "694.m4a\n",
      "695.m4a\n",
      "696.m4a\n",
      "697.m4a\n",
      "698.m4a\n",
      "699.m4a\n",
      "700.m4a\n",
      "701.m4a\n",
      "702.m4a\n",
      "703.m4a\n",
      "704.m4a\n",
      "705.m4a\n",
      "706.m4a\n",
      "707.m4a\n",
      "708.m4a\n",
      "709.m4a\n",
      "710.m4a\n",
      "711.m4a\n",
      "712.m4a\n",
      "713.m4a\n",
      "714.m4a\n",
      "715.m4a\n",
      "716.m4a\n",
      "717.m4a\n",
      "718.m4a\n",
      "719.m4a\n",
      "720.m4a\n",
      "721.m4a\n",
      "722.m4a\n",
      "723.m4a\n",
      "724.m4a\n",
      "725.m4a\n",
      "726.m4a\n",
      "727.m4a\n",
      "728.m4a\n",
      "729.m4a\n",
      "730.m4a\n",
      "731.m4a\n",
      "732.m4a\n",
      "733.m4a\n",
      "734.m4a\n",
      "735.m4a\n",
      "736.m4a\n",
      "737.m4a\n",
      "738.m4a\n",
      "739.m4a\n",
      "740.m4a\n",
      "741.m4a\n",
      "742.m4a\n",
      "743.m4a\n",
      "744.m4a\n",
      "745.m4a\n",
      "746.m4a\n",
      "747.m4a\n",
      "748.m4a\n",
      "749.m4a\n",
      "750.m4a\n",
      "751.m4a\n",
      "752.m4a\n",
      "753.m4a\n",
      "754.m4a\n",
      "755.m4a\n",
      "756.m4a\n",
      "757.m4a\n",
      "758.m4a\n",
      "759.m4a\n",
      "760.m4a\n",
      "761.m4a\n",
      "762.m4a\n",
      "763.m4a\n",
      "764.m4a\n",
      "765.m4a\n",
      "766.m4a\n",
      "767.m4a\n",
      "768.m4a\n",
      "769.m4a\n",
      "770.m4a\n",
      "771.m4a\n",
      "772.m4a\n",
      "773.m4a\n",
      "774.m4a\n",
      "775.m4a\n",
      "776.m4a\n",
      "777.m4a\n",
      "778.m4a\n",
      "779.m4a\n",
      "780.m4a\n",
      "781.m4a\n",
      "782.m4a\n",
      "783.m4a\n",
      "784.m4a\n",
      "785.m4a\n",
      "786.m4a\n",
      "787.m4a\n",
      "788.m4a\n",
      "789.m4a\n",
      "790.m4a\n",
      "791.m4a\n",
      "792.m4a\n",
      "793.m4a\n",
      "794.m4a\n",
      "795.m4a\n",
      "796.m4a\n",
      "797.m4a\n",
      "798.m4a\n",
      "799.m4a\n",
      "800.m4a\n",
      "801.m4a\n",
      "802.m4a\n",
      "803.m4a\n",
      "804.m4a\n",
      "805.m4a\n",
      "806.m4a\n",
      "807.m4a\n",
      "808.m4a\n",
      "809.m4a\n",
      "810.m4a\n",
      "811.m4a\n",
      "812.m4a\n",
      "813.m4a\n",
      "814.m4a\n",
      "815.m4a\n",
      "816.m4a\n",
      "817.m4a\n",
      "818.m4a\n",
      "819.m4a\n",
      "820.m4a\n",
      "821.m4a\n",
      "822.m4a\n",
      "823.m4a\n",
      "824.m4a\n",
      "825.m4a\n",
      "826.m4a\n",
      "827.m4a\n",
      "828.m4a\n",
      "829.m4a\n",
      "830.m4a\n",
      "831.m4a\n",
      "832.m4a\n",
      "833.m4a\n",
      "834.m4a\n",
      "835.m4a\n",
      "836.m4a\n",
      "837.m4a\n",
      "838.m4a\n",
      "839.m4a\n",
      "840.m4a\n",
      "841.m4a\n",
      "842.m4a\n",
      "843.m4a\n",
      "844.m4a\n",
      "845.m4a\n",
      "846.m4a\n",
      "847.m4a\n",
      "848.m4a\n",
      "849.m4a\n",
      "850.m4a\n",
      "851.m4a\n",
      "852.m4a\n",
      "853.m4a\n",
      "854.m4a\n",
      "855.m4a\n",
      "856.m4a\n",
      "857.m4a\n",
      "858.m4a\n",
      "859.m4a\n",
      "860.m4a\n",
      "861.m4a\n",
      "862.m4a\n",
      "863.m4a\n",
      "864.m4a\n",
      "865.m4a\n",
      "866.m4a\n",
      "867.m4a\n",
      "868.m4a\n",
      "869.m4a\n",
      "870.m4a\n",
      "871.m4a\n",
      "872.m4a\n",
      "873.m4a\n",
      "874.m4a\n",
      "875.m4a\n",
      "876.m4a\n",
      "877.m4a\n",
      "878.m4a\n",
      "879.m4a\n",
      "880.m4a\n",
      "881.m4a\n",
      "882.m4a\n",
      "883.m4a\n",
      "884.m4a\n",
      "885.m4a\n",
      "886.m4a\n",
      "887.m4a\n",
      "888.m4a\n",
      "889.m4a\n",
      "890.m4a\n",
      "891.m4a\n",
      "892.m4a\n",
      "893.m4a\n",
      "894.m4a\n",
      "895.m4a\n",
      "896.m4a\n",
      "897.m4a\n",
      "898.m4a\n",
      "899.m4a\n",
      "900.m4a\n",
      "901.m4a\n",
      "902.m4a\n",
      "903.m4a\n",
      "904.m4a\n",
      "905.m4a\n",
      "906.m4a\n",
      "907.m4a\n",
      "908.m4a\n",
      "909.m4a\n",
      "910.m4a\n",
      "911.m4a\n",
      "912.m4a\n",
      "913.m4a\n",
      "914.m4a\n",
      "915.m4a\n",
      "916.m4a\n",
      "917.m4a\n",
      "918.m4a\n",
      "919.m4a\n",
      "920.m4a\n",
      "921.m4a\n",
      "922.m4a\n",
      "923.m4a\n",
      "924.m4a\n",
      "925.m4a\n",
      "926.m4a\n",
      "927.m4a\n",
      "928.m4a\n",
      "929.m4a\n",
      "930.m4a\n",
      "931.m4a\n",
      "932.m4a\n",
      "933.m4a\n",
      "934.m4a\n",
      "935.m4a\n",
      "936.m4a\n",
      "937.m4a\n",
      "938.m4a\n",
      "939.m4a\n",
      "940.m4a\n",
      "941.m4a\n",
      "942.m4a\n",
      "943.m4a\n",
      "944.m4a\n",
      "945.m4a\n",
      "946.m4a\n",
      "947.m4a\n",
      "948.m4a\n",
      "949.m4a\n",
      "950.m4a\n",
      "951.m4a\n",
      "952.m4a\n",
      "953.m4a\n",
      "954.m4a\n",
      "955.m4a\n",
      "956.m4a\n",
      "957.m4a\n",
      "958.m4a\n",
      "959.m4a\n",
      "960.m4a\n",
      "961.m4a\n",
      "962.m4a\n",
      "963.m4a\n",
      "964.m4a\n",
      "965.m4a\n",
      "966.m4a\n",
      "967.m4a\n",
      "968.m4a\n",
      "969.m4a\n",
      "970.m4a\n",
      "971.m4a\n",
      "972.m4a\n",
      "973.m4a\n",
      "974.m4a\n",
      "975.m4a\n",
      "976.m4a\n",
      "977.m4a\n",
      "978.m4a\n",
      "979.m4a\n",
      "980.m4a\n",
      "981.m4a\n",
      "982.m4a\n",
      "983.m4a\n",
      "984.m4a\n",
      "985.m4a\n",
      "986.m4a\n",
      "987.m4a\n",
      "988.m4a\n",
      "989.m4a\n",
      "990.m4a\n",
      "991.m4a\n",
      "992.m4a\n",
      "993.m4a\n",
      "994.m4a\n",
      "995.m4a\n",
      "996.m4a\n",
      "997.m4a\n",
      "998.m4a\n",
      "999.m4a\n",
      "1000.m4a\n",
      "1001.m4a\n",
      "1002.m4a\n",
      "1003.m4a\n",
      "1004.m4a\n",
      "1005.m4a\n",
      "1006.m4a\n",
      "1007.m4a\n",
      "1008.m4a\n",
      "1009.m4a\n",
      "1010.m4a\n",
      "1011.m4a\n",
      "1012.m4a\n",
      "1013.m4a\n",
      "1014.m4a\n",
      "1015.m4a\n",
      "1016.m4a\n",
      "1017.m4a\n",
      "1018.m4a\n",
      "1019.m4a\n",
      "1020.m4a\n",
      "1021.m4a\n",
      "1022.m4a\n",
      "1023.m4a\n",
      "1024.m4a\n",
      "1025.m4a\n",
      "1026.m4a\n",
      "1027.m4a\n",
      "1028.m4a\n",
      "1029.m4a\n",
      "1030.m4a\n",
      "1031.m4a\n",
      "1032.m4a\n",
      "1033.m4a\n",
      "1034.m4a\n",
      "1035.m4a\n",
      "1036.m4a\n",
      "1037.m4a\n",
      "1038.m4a\n",
      "1039.m4a\n",
      "1040.m4a\n",
      "1041.m4a\n",
      "1042.m4a\n",
      "1043.m4a\n",
      "1044.m4a\n",
      "1045.m4a\n",
      "1046.m4a\n",
      "1047.m4a\n",
      "1048.m4a\n",
      "1049.m4a\n",
      "1050.m4a\n",
      "1051.m4a\n",
      "1052.m4a\n",
      "1053.m4a\n",
      "1054.m4a\n",
      "1055.m4a\n",
      "1056.m4a\n",
      "1057.m4a\n",
      "1058.m4a\n",
      "1059.m4a\n",
      "1060.m4a\n",
      "1061.m4a\n",
      "1062.m4a\n",
      "1063.m4a\n",
      "1064.m4a\n",
      "1065.m4a\n",
      "1066.m4a\n",
      "1067.m4a\n",
      "1068.m4a\n",
      "1069.m4a\n",
      "1070.m4a\n",
      "1071.m4a\n",
      "1072.m4a\n",
      "1073.m4a\n",
      "1074.m4a\n",
      "1075.m4a\n",
      "1076.m4a\n",
      "1077.m4a\n",
      "1078.m4a\n",
      "1079.m4a\n",
      "1080.m4a\n",
      "1081.m4a\n",
      "1082.m4a\n",
      "1083.m4a\n",
      "1084.m4a\n",
      "1085.m4a\n",
      "1086.m4a\n",
      "1087.m4a\n",
      "1088.m4a\n",
      "1089.m4a\n",
      "1090.m4a\n",
      "1091.m4a\n",
      "1092.m4a\n",
      "1093.m4a\n",
      "1094.m4a\n",
      "1095.m4a\n",
      "1096.m4a\n",
      "1097.m4a\n",
      "1098.m4a\n",
      "1099.m4a\n",
      "1100.m4a\n",
      "1101.m4a\n",
      "1102.m4a\n",
      "1103.m4a\n",
      "1104.m4a\n",
      "1105.m4a\n",
      "1106.m4a\n",
      "1107.m4a\n",
      "1108.m4a\n",
      "1109.m4a\n",
      "1110.m4a\n",
      "1111.m4a\n",
      "1112.m4a\n",
      "1113.m4a\n",
      "1114.m4a\n",
      "1115.m4a\n",
      "1116.m4a\n",
      "1117.m4a\n",
      "1118.m4a\n",
      "1119.m4a\n",
      "1120.m4a\n",
      "1121.m4a\n",
      "1122.m4a\n",
      "1123.m4a\n",
      "1124.m4a\n",
      "1125.m4a\n",
      "1126.m4a\n",
      "1127.m4a\n",
      "1128.m4a\n",
      "1129.m4a\n",
      "1130.m4a\n",
      "1131.m4a\n",
      "1132.m4a\n",
      "1133.m4a\n",
      "1134.m4a\n",
      "1135.m4a\n",
      "1136.m4a\n",
      "1137.m4a\n",
      "1138.m4a\n",
      "1139.m4a\n",
      "1140.m4a\n",
      "1141.m4a\n",
      "1142.m4a\n",
      "1143.m4a\n",
      "1144.m4a\n",
      "1145.m4a\n",
      "1146.m4a\n",
      "1147.m4a\n",
      "1148.m4a\n",
      "1149.m4a\n",
      "1150.m4a\n",
      "1151.m4a\n",
      "1152.m4a\n",
      "1153.m4a\n",
      "1154.m4a\n",
      "1155.m4a\n",
      "1156.m4a\n",
      "1157.m4a\n",
      "1158.m4a\n",
      "1159.m4a\n",
      "1160.m4a\n",
      "1161.m4a\n",
      "1162.m4a\n",
      "1163.m4a\n",
      "1164.m4a\n",
      "1165.m4a\n",
      "1166.m4a\n",
      "1167.m4a\n",
      "1168.m4a\n",
      "1169.m4a\n",
      "1170.m4a\n",
      "1171.m4a\n",
      "1172.m4a\n",
      "1173.m4a\n",
      "1174.m4a\n",
      "1175.m4a\n",
      "1176.m4a\n",
      "1177.m4a\n",
      "1178.m4a\n",
      "1179.m4a\n",
      "1180.m4a\n",
      "1181.m4a\n",
      "1182.m4a\n",
      "1183.m4a\n",
      "1184.m4a\n",
      "1185.m4a\n",
      "1186.m4a\n",
      "1187.m4a\n",
      "1188.m4a\n",
      "1189.m4a\n",
      "1190.m4a\n",
      "1191.m4a\n",
      "1192.m4a\n",
      "1193.m4a\n",
      "1194.m4a\n",
      "1195.m4a\n",
      "1196.m4a\n",
      "1197.m4a\n",
      "1198.m4a\n",
      "1199.m4a\n",
      "1200.m4a\n",
      "1201.m4a\n",
      "1202.m4a\n",
      "1203.m4a\n",
      "1204.m4a\n",
      "1205.m4a\n",
      "1206.m4a\n",
      "1207.m4a\n",
      "1208.m4a\n",
      "1209.m4a\n",
      "1210.m4a\n",
      "1211.m4a\n",
      "1212.m4a\n",
      "1213.m4a\n",
      "1214.m4a\n",
      "1215.m4a\n",
      "1216.m4a\n",
      "1217.m4a\n",
      "1218.m4a\n",
      "1219.m4a\n",
      "1220.m4a\n",
      "1221.m4a\n",
      "1222.m4a\n",
      "1223.m4a\n",
      "1224.m4a\n",
      "1225.m4a\n",
      "1226.m4a\n",
      "1227.m4a\n",
      "1228.m4a\n",
      "1229.m4a\n",
      "1230.m4a\n",
      "1231.m4a\n",
      "1232.m4a\n",
      "1233.m4a\n",
      "1234.m4a\n",
      "1235.m4a\n",
      "1236.m4a\n",
      "1237.m4a\n",
      "1238.m4a\n",
      "1239.m4a\n",
      "1240.m4a\n",
      "1241.m4a\n",
      "1242.m4a\n",
      "1243.m4a\n",
      "1244.m4a\n",
      "1245.m4a\n",
      "1246.m4a\n",
      "1247.m4a\n",
      "1248.m4a\n",
      "1249.m4a\n",
      "1250.m4a\n",
      "1251.m4a\n",
      "1252.m4a\n",
      "1253.m4a\n",
      "1254.m4a\n",
      "1255.m4a\n",
      "1256.m4a\n",
      "1257.m4a\n",
      "1258.m4a\n",
      "1259.m4a\n",
      "1260.m4a\n",
      "1261.m4a\n",
      "1262.m4a\n",
      "1263.m4a\n",
      "1264.m4a\n",
      "1265.m4a\n",
      "1266.m4a\n",
      "1267.m4a\n",
      "1268.m4a\n",
      "1269.m4a\n",
      "1270.m4a\n",
      "1271.m4a\n",
      "1272.m4a\n",
      "1273.m4a\n",
      "1274.m4a\n",
      "1275.m4a\n",
      "1276.m4a\n",
      "1277.m4a\n",
      "1278.m4a\n",
      "1279.m4a\n",
      "1280.m4a\n",
      "1281.m4a\n",
      "1282.m4a\n",
      "1283.m4a\n",
      "1284.m4a\n",
      "1285.m4a\n",
      "1286.m4a\n",
      "1287.m4a\n",
      "1288.m4a\n",
      "1289.m4a\n",
      "1290.m4a\n",
      "1291.m4a\n",
      "1292.m4a\n",
      "1293.m4a\n",
      "1294.m4a\n",
      "1295.m4a\n",
      "1296.m4a\n",
      "1297.m4a\n",
      "1298.m4a\n",
      "1299.m4a\n",
      "1300.m4a\n",
      "1301.m4a\n",
      "1302.m4a\n",
      "1303.m4a\n",
      "1304.m4a\n",
      "1305.m4a\n",
      "1306.m4a\n",
      "1307.m4a\n",
      "1308.m4a\n",
      "1309.m4a\n",
      "1310.m4a\n",
      "1311.m4a\n",
      "1312.m4a\n",
      "1313.m4a\n",
      "1314.m4a\n",
      "1315.m4a\n",
      "1316.m4a\n",
      "1317.m4a\n",
      "1318.m4a\n",
      "1319.m4a\n",
      "1320.m4a\n",
      "1321.m4a\n",
      "1322.m4a\n",
      "1323.m4a\n",
      "1324.m4a\n",
      "1325.m4a\n",
      "1326.m4a\n",
      "1327.m4a\n",
      "1328.m4a\n",
      "1329.m4a\n",
      "1330.m4a\n",
      "1331.m4a\n",
      "1332.m4a\n",
      "1333.m4a\n",
      "1334.m4a\n",
      "1335.m4a\n",
      "1336.m4a\n",
      "1337.m4a\n",
      "1338.m4a\n",
      "1339.m4a\n",
      "1340.m4a\n",
      "1341.m4a\n",
      "1342.m4a\n",
      "1343.m4a\n",
      "1344.m4a\n",
      "1345.m4a\n",
      "1346.m4a\n",
      "1347.m4a\n",
      "1348.m4a\n",
      "1349.m4a\n",
      "1350.m4a\n",
      "1351.m4a\n",
      "1352.m4a\n",
      "1353.m4a\n",
      "1354.m4a\n",
      "1355.m4a\n",
      "1356.m4a\n",
      "1357.m4a\n",
      "1358.m4a\n",
      "1359.m4a\n",
      "1360.m4a\n",
      "1361.m4a\n",
      "1362.m4a\n",
      "1363.m4a\n",
      "1364.m4a\n",
      "1365.m4a\n",
      "1366.m4a\n",
      "1367.m4a\n",
      "1368.m4a\n",
      "1369.m4a\n",
      "1370.m4a\n",
      "1371.m4a\n",
      "1372.m4a\n",
      "1373.m4a\n",
      "1374.m4a\n",
      "1375.m4a\n",
      "1376.m4a\n",
      "1377.m4a\n",
      "1378.m4a\n",
      "1379.m4a\n",
      "1380.m4a\n",
      "1381.m4a\n",
      "1382.m4a\n",
      "1383.m4a\n",
      "1384.m4a\n",
      "1385.m4a\n",
      "1386.m4a\n",
      "1387.m4a\n",
      "1388.m4a\n",
      "1389.m4a\n",
      "1390.m4a\n",
      "1391.m4a\n",
      "1392.m4a\n",
      "1393.m4a\n",
      "1394.m4a\n",
      "1395.m4a\n",
      "1396.m4a\n",
      "1397.m4a\n",
      "1398.m4a\n",
      "1399.m4a\n",
      "1400.m4a\n",
      "1401.m4a\n",
      "1402.m4a\n",
      "1403.m4a\n",
      "1404.m4a\n",
      "1405.m4a\n",
      "1406.m4a\n",
      "1407.m4a\n",
      "1408.m4a\n",
      "1409.m4a\n",
      "1410.m4a\n",
      "1411.m4a\n",
      "1412.m4a\n",
      "1413.m4a\n",
      "1414.m4a\n",
      "1415.m4a\n",
      "1416.m4a\n",
      "1417.m4a\n",
      "1418.m4a\n",
      "1419.m4a\n",
      "1420.m4a\n",
      "1421.m4a\n",
      "1422.m4a\n",
      "1423.m4a\n",
      "1424.m4a\n",
      "1425.m4a\n",
      "1426.m4a\n",
      "1427.m4a\n",
      "1428.m4a\n",
      "1429.m4a\n",
      "1430.m4a\n",
      "1431.m4a\n",
      "1432.m4a\n",
      "1433.m4a\n",
      "1434.m4a\n",
      "1435.m4a\n",
      "1436.m4a\n",
      "1437.m4a\n",
      "1438.m4a\n",
      "1439.m4a\n",
      "1440.m4a\n",
      "1441.m4a\n",
      "1442.m4a\n",
      "1443.m4a\n",
      "1444.m4a\n",
      "1445.m4a\n",
      "1446.m4a\n",
      "1447.m4a\n",
      "1448.m4a\n",
      "1449.m4a\n",
      "1450.m4a\n",
      "1451.m4a\n",
      "1452.m4a\n",
      "1453.m4a\n",
      "1454.m4a\n",
      "1455.m4a\n",
      "1456.m4a\n",
      "1457.m4a\n",
      "1458.m4a\n",
      "1459.m4a\n",
      "1460.m4a\n",
      "1461.m4a\n",
      "1462.m4a\n",
      "1463.m4a\n",
      "1464.m4a\n",
      "1465.m4a\n",
      "1466.m4a\n",
      "1467.m4a\n",
      "1468.m4a\n",
      "1469.m4a\n",
      "1470.m4a\n",
      "1471.m4a\n",
      "1472.m4a\n",
      "1473.m4a\n",
      "1474.m4a\n",
      "1475.m4a\n",
      "1476.m4a\n",
      "1477.m4a\n",
      "1478.m4a\n",
      "1479.m4a\n",
      "1480.m4a\n",
      "1481.m4a\n",
      "1482.m4a\n",
      "1483.m4a\n",
      "1484.m4a\n",
      "1485.m4a\n",
      "1486.m4a\n",
      "1487.m4a\n",
      "1488.m4a\n",
      "1489.m4a\n",
      "1490.m4a\n",
      "1491.m4a\n",
      "1492.m4a\n",
      "1493.m4a\n",
      "1494.m4a\n",
      "1495.m4a\n",
      "1496.m4a\n",
      "1497.m4a\n",
      "1498.m4a\n",
      "1499.m4a\n",
      "1500.m4a\n",
      "1501.m4a\n",
      "1502.m4a\n",
      "1503.m4a\n",
      "1504.m4a\n",
      "1505.m4a\n",
      "1506.m4a\n",
      "1507.m4a\n",
      "1508.m4a\n",
      "1509.m4a\n",
      "1510.m4a\n",
      "1511.m4a\n",
      "1512.m4a\n",
      "1513.m4a\n",
      "1514.m4a\n",
      "1515.m4a\n",
      "1516.m4a\n",
      "1517.m4a\n",
      "1518.m4a\n",
      "1519.m4a\n",
      "1520.m4a\n",
      "1521.m4a\n",
      "1522.m4a\n",
      "1523.m4a\n",
      "1524.m4a\n",
      "1525.m4a\n",
      "1526.m4a\n",
      "1527.m4a\n",
      "1528.m4a\n",
      "1529.m4a\n",
      "1530.m4a\n",
      "1531.m4a\n",
      "1532.m4a\n",
      "1533.m4a\n",
      "1534.m4a\n",
      "1535.m4a\n",
      "1536.m4a\n",
      "1537.m4a\n",
      "1538.m4a\n",
      "1539.m4a\n",
      "1540.m4a\n",
      "1541.m4a\n",
      "1542.m4a\n",
      "1543.m4a\n",
      "1544.m4a\n",
      "1545.m4a\n",
      "1546.m4a\n",
      "1547.m4a\n",
      "1548.m4a\n",
      "1549.m4a\n",
      "1550.m4a\n",
      "1551.m4a\n",
      "1552.m4a\n",
      "1553.m4a\n",
      "1554.m4a\n",
      "1555.m4a\n",
      "1556.m4a\n",
      "1557.m4a\n",
      "1558.m4a\n",
      "1559.m4a\n",
      "1560.m4a\n",
      "1561.m4a\n",
      "1562.m4a\n",
      "1563.m4a\n",
      "1564.m4a\n",
      "1565.m4a\n",
      "1566.m4a\n",
      "1567.m4a\n",
      "1568.m4a\n",
      "1569.m4a\n",
      "1570.m4a\n",
      "1571.m4a\n",
      "1572.m4a\n",
      "1573.m4a\n",
      "1574.m4a\n",
      "1575.m4a\n",
      "1576.m4a\n",
      "1577.m4a\n",
      "1578.m4a\n",
      "1579.m4a\n",
      "1580.m4a\n",
      "1581.m4a\n",
      "1582.m4a\n",
      "1583.m4a\n",
      "1584.m4a\n",
      "1585.m4a\n",
      "1586.m4a\n",
      "1587.m4a\n",
      "1588.m4a\n",
      "1589.m4a\n",
      "1590.m4a\n",
      "1591.m4a\n",
      "1592.m4a\n",
      "1593.m4a\n",
      "1594.m4a\n",
      "1595.m4a\n",
      "1596.m4a\n",
      "1597.m4a\n",
      "1598.m4a\n",
      "1599.m4a\n",
      "1600.m4a\n",
      "1601.m4a\n",
      "1602.m4a\n",
      "1603.m4a\n",
      "1604.m4a\n",
      "1605.m4a\n",
      "1606.m4a\n",
      "1607.m4a\n",
      "1608.m4a\n",
      "1609.m4a\n",
      "1610.m4a\n",
      "1611.m4a\n",
      "1612.m4a\n",
      "1613.m4a\n",
      "1614.m4a\n",
      "1615.m4a\n",
      "1616.m4a\n",
      "1617.m4a\n",
      "1618.m4a\n",
      "1619.m4a\n",
      "1620.m4a\n",
      "1621.m4a\n",
      "1622.m4a\n",
      "1623.m4a\n",
      "1624.m4a\n",
      "1625.m4a\n",
      "1626.m4a\n",
      "1627.m4a\n",
      "1628.m4a\n",
      "1629.m4a\n",
      "1630.m4a\n",
      "1631.m4a\n",
      "1632.m4a\n",
      "1633.m4a\n",
      "1634.m4a\n",
      "1635.m4a\n",
      "1636.m4a\n",
      "1637.m4a\n",
      "1638.m4a\n",
      "1639.m4a\n",
      "1640.m4a\n",
      "1641.m4a\n",
      "1642.m4a\n",
      "1643.m4a\n",
      "1644.m4a\n",
      "1645.m4a\n",
      "1646.m4a\n",
      "1647.m4a\n",
      "1648.m4a\n",
      "1649.m4a\n",
      "1650.m4a\n",
      "1651.m4a\n",
      "1652.m4a\n",
      "1653.m4a\n",
      "1654.m4a\n",
      "1655.m4a\n",
      "1656.m4a\n",
      "1657.m4a\n",
      "1658.m4a\n",
      "1659.m4a\n",
      "1660.m4a\n",
      "1661.m4a\n",
      "1662.m4a\n",
      "1663.m4a\n",
      "1664.m4a\n",
      "1665.m4a\n",
      "1666.m4a\n",
      "1667.m4a\n",
      "1668.m4a\n",
      "1669.m4a\n",
      "1670.m4a\n",
      "1671.m4a\n",
      "1672.m4a\n",
      "1673.m4a\n",
      "1674.m4a\n",
      "1675.m4a\n",
      "1676.m4a\n",
      "1677.m4a\n",
      "1678.m4a\n",
      "1679.m4a\n",
      "1680.m4a\n",
      "1681.m4a\n",
      "1682.m4a\n",
      "1683.m4a\n",
      "1684.m4a\n",
      "1685.m4a\n",
      "1686.m4a\n",
      "1687.m4a\n",
      "1688.m4a\n",
      "1689.m4a\n",
      "1690.m4a\n",
      "1691.m4a\n",
      "1692.m4a\n",
      "1693.m4a\n",
      "1694.m4a\n",
      "1695.m4a\n",
      "1696.m4a\n",
      "1697.m4a\n",
      "1698.m4a\n",
      "1699.m4a\n",
      "1700.m4a\n",
      "1701.m4a\n",
      "1702.m4a\n",
      "1703.m4a\n",
      "1704.m4a\n",
      "1705.m4a\n",
      "1706.m4a\n",
      "1707.m4a\n",
      "1708.m4a\n",
      "1709.m4a\n",
      "1710.m4a\n",
      "1711.m4a\n",
      "1712.m4a\n",
      "1713.m4a\n",
      "1714.m4a\n",
      "1715.m4a\n",
      "1716.m4a\n",
      "1717.m4a\n",
      "1718.m4a\n",
      "1719.m4a\n",
      "1720.m4a\n",
      "1721.m4a\n",
      "1722.m4a\n",
      "1723.m4a\n",
      "1724.m4a\n",
      "1725.m4a\n",
      "1726.m4a\n",
      "1727.m4a\n",
      "1728.m4a\n",
      "1729.m4a\n",
      "1730.m4a\n",
      "1731.m4a\n",
      "1732.m4a\n",
      "1733.m4a\n",
      "1734.m4a\n",
      "1735.m4a\n",
      "1736.m4a\n",
      "1737.m4a\n",
      "1738.m4a\n",
      "1739.m4a\n",
      "1740.m4a\n",
      "1741.m4a\n",
      "1742.m4a\n",
      "1743.m4a\n",
      "1744.m4a\n",
      "1745.m4a\n",
      "1746.m4a\n",
      "1747.m4a\n",
      "1748.m4a\n",
      "1749.m4a\n",
      "1750.m4a\n",
      "1751.m4a\n",
      "1752.m4a\n",
      "1753.m4a\n",
      "1754.m4a\n",
      "1755.m4a\n",
      "1756.m4a\n",
      "1757.m4a\n",
      "1758.m4a\n",
      "1759.m4a\n",
      "1760.m4a\n",
      "1761.m4a\n",
      "1762.m4a\n",
      "1763.m4a\n",
      "1764.m4a\n",
      "1765.m4a\n",
      "1766.m4a\n",
      "1767.m4a\n",
      "1768.m4a\n",
      "1769.m4a\n",
      "1770.m4a\n",
      "1771.m4a\n",
      "1772.m4a\n",
      "1773.m4a\n",
      "1774.m4a\n",
      "1775.m4a\n",
      "1776.m4a\n",
      "1777.m4a\n",
      "1778.m4a\n",
      "1779.m4a\n",
      "1780.m4a\n",
      "1781.m4a\n",
      "1782.m4a\n",
      "1783.m4a\n",
      "1784.m4a\n",
      "1785.m4a\n",
      "1786.m4a\n",
      "1787.m4a\n",
      "1788.m4a\n",
      "1789.m4a\n",
      "1790.m4a\n",
      "1791.m4a\n",
      "1792.m4a\n",
      "1793.m4a\n",
      "1794.m4a\n",
      "1795.m4a\n",
      "1796.m4a\n",
      "1797.m4a\n",
      "1798.m4a\n",
      "1799.m4a\n",
      "1800.m4a\n",
      "1801.m4a\n",
      "1802.m4a\n",
      "1803.m4a\n",
      "1804.m4a\n",
      "1805.m4a\n",
      "1806.m4a\n",
      "1807.m4a\n",
      "1808.m4a\n",
      "1809.m4a\n",
      "1810.m4a\n",
      "1811.m4a\n",
      "1812.m4a\n",
      "1813.m4a\n",
      "1814.m4a\n",
      "1815.m4a\n",
      "1816.m4a\n",
      "1817.m4a\n",
      "1818.m4a\n",
      "1819.m4a\n",
      "1820.m4a\n",
      "1821.m4a\n",
      "1822.m4a\n",
      "1823.m4a\n",
      "1824.m4a\n",
      "1825.m4a\n",
      "1826.m4a\n",
      "1827.m4a\n",
      "1828.m4a\n",
      "1829.m4a\n",
      "1830.m4a\n",
      "1831.m4a\n",
      "1832.m4a\n",
      "1833.m4a\n",
      "1834.m4a\n",
      "1835.m4a\n",
      "1836.m4a\n",
      "1837.m4a\n",
      "1838.m4a\n",
      "1839.m4a\n",
      "1840.m4a\n",
      "1841.m4a\n",
      "1842.m4a\n",
      "1843.m4a\n",
      "1844.m4a\n",
      "1845.m4a\n",
      "1846.m4a\n",
      "1847.m4a\n",
      "1848.m4a\n",
      "1849.m4a\n",
      "1850.m4a\n",
      "1851.m4a\n",
      "1852.m4a\n",
      "1853.m4a\n",
      "1854.m4a\n",
      "1855.m4a\n",
      "1856.m4a\n",
      "1857.m4a\n",
      "1858.m4a\n",
      "1859.m4a\n",
      "1860.m4a\n",
      "1861.m4a\n",
      "1862.m4a\n",
      "1863.m4a\n",
      "1864.m4a\n",
      "1865.m4a\n",
      "1866.m4a\n",
      "1867.m4a\n",
      "1868.m4a\n",
      "1869.m4a\n",
      "1870.m4a\n",
      "1871.m4a\n",
      "1872.m4a\n",
      "1873.m4a\n",
      "1874.m4a\n",
      "1875.m4a\n",
      "1876.m4a\n",
      "1877.m4a\n",
      "1878.m4a\n",
      "1879.m4a\n",
      "1880.m4a\n",
      "1881.m4a\n",
      "1882.m4a\n",
      "1883.m4a\n",
      "1884.m4a\n",
      "1885.m4a\n",
      "1886.m4a\n",
      "1887.m4a\n",
      "1888.m4a\n",
      "1889.m4a\n",
      "1890.m4a\n",
      "1891.m4a\n",
      "1892.m4a\n",
      "1893.m4a\n",
      "1894.m4a\n",
      "1895.m4a\n",
      "1896.m4a\n",
      "1897.m4a\n",
      "1898.m4a\n",
      "1899.m4a\n",
      "1900.m4a\n",
      "1901.m4a\n",
      "1902.m4a\n",
      "1903.m4a\n",
      "1904.m4a\n",
      "1905.m4a\n",
      "1906.m4a\n",
      "1907.m4a\n",
      "1908.m4a\n",
      "1909.m4a\n",
      "1910.m4a\n",
      "1911.m4a\n",
      "1912.m4a\n",
      "1913.m4a\n",
      "1914.m4a\n",
      "1915.m4a\n",
      "1916.m4a\n",
      "1917.m4a\n",
      "1918.m4a\n",
      "1919.m4a\n",
      "1920.m4a\n",
      "1921.m4a\n",
      "1922.m4a\n",
      "1923.m4a\n",
      "1924.m4a\n",
      "1925.m4a\n",
      "1926.m4a\n",
      "1927.m4a\n",
      "1928.m4a\n",
      "1929.m4a\n",
      "1930.m4a\n",
      "1931.m4a\n",
      "1932.m4a\n",
      "1933.m4a\n",
      "1934.m4a\n",
      "1935.m4a\n",
      "1936.m4a\n",
      "1937.m4a\n",
      "1938.m4a\n",
      "1939.m4a\n",
      "1940.m4a\n",
      "1941.m4a\n",
      "1942.m4a\n",
      "1943.m4a\n",
      "1944.m4a\n",
      "1945.m4a\n",
      "1946.m4a\n",
      "1947.m4a\n",
      "1948.m4a\n",
      "1949.m4a\n",
      "1950.m4a\n",
      "1951.m4a\n",
      "1952.m4a\n",
      "1953.m4a\n",
      "1954.m4a\n",
      "1955.m4a\n",
      "1956.m4a\n",
      "1957.m4a\n",
      "1958.m4a\n",
      "1959.m4a\n",
      "1960.m4a\n",
      "1961.m4a\n",
      "1962.m4a\n",
      "1963.m4a\n",
      "1964.m4a\n",
      "1965.m4a\n",
      "1966.m4a\n",
      "1967.m4a\n",
      "1968.m4a\n",
      "1969.m4a\n",
      "1970.m4a\n",
      "1971.m4a\n",
      "1972.m4a\n",
      "1973.m4a\n",
      "1974.m4a\n",
      "1975.m4a\n",
      "1976.m4a\n",
      "1977.m4a\n",
      "1978.m4a\n",
      "1979.m4a\n",
      "1980.m4a\n",
      "1981.m4a\n",
      "1982.m4a\n",
      "1983.m4a\n",
      "1984.m4a\n",
      "1985.m4a\n",
      "1986.m4a\n",
      "1987.m4a\n",
      "1988.m4a\n",
      "1989.m4a\n",
      "1990.m4a\n",
      "1991.m4a\n",
      "1992.m4a\n",
      "1993.m4a\n",
      "1994.m4a\n",
      "1995.m4a\n",
      "1996.m4a\n",
      "1997.m4a\n",
      "1998.m4a\n",
      "1999.m4a\n",
      "2000.m4a\n",
      "2001.m4a\n",
      "2002.m4a\n",
      "2003.m4a\n",
      "2004.m4a\n",
      "2005.m4a\n",
      "2006.m4a\n",
      "2007.m4a\n",
      "2008.m4a\n",
      "2009.m4a\n",
      "2010.m4a\n",
      "2011.m4a\n",
      "2012.m4a\n",
      "2013.m4a\n",
      "2014.m4a\n",
      "2015.m4a\n",
      "2016.m4a\n",
      "2017.m4a\n",
      "2018.m4a\n",
      "2019.m4a\n",
      "2020.m4a\n",
      "2021.m4a\n",
      "2022.m4a\n",
      "2023.m4a\n",
      "2024.m4a\n",
      "2025.m4a\n",
      "2026.m4a\n",
      "2027.m4a\n",
      "2028.m4a\n",
      "2029.m4a\n",
      "2030.m4a\n",
      "2031.m4a\n",
      "2032.m4a\n",
      "2033.m4a\n",
      "2034.m4a\n",
      "2035.m4a\n",
      "2036.m4a\n",
      "2037.m4a\n",
      "2038.m4a\n",
      "2039.m4a\n",
      "2040.m4a\n",
      "2041.m4a\n",
      "2042.m4a\n",
      "2043.m4a\n",
      "2044.m4a\n",
      "2045.m4a\n",
      "2046.m4a\n",
      "2047.m4a\n",
      "2048.m4a\n",
      "2049.m4a\n",
      "2050.m4a\n",
      "2051.m4a\n",
      "2052.m4a\n",
      "2053.m4a\n",
      "2054.m4a\n",
      "2055.m4a\n",
      "2056.m4a\n",
      "2057.m4a\n",
      "2058.m4a\n",
      "2059.m4a\n",
      "2060.m4a\n",
      "2061.m4a\n",
      "2062.m4a\n",
      "2063.m4a\n",
      "2064.m4a\n",
      "2065.m4a\n",
      "2066.m4a\n",
      "2067.m4a\n",
      "2068.m4a\n",
      "2069.m4a\n",
      "2070.m4a\n",
      "2071.m4a\n",
      "2072.m4a\n",
      "2073.m4a\n",
      "2074.m4a\n",
      "2075.m4a\n",
      "2076.m4a\n",
      "2077.m4a\n",
      "2078.m4a\n",
      "2079.m4a\n",
      "2080.m4a\n",
      "2081.m4a\n",
      "2082.m4a\n",
      "2083.m4a\n",
      "2084.m4a\n",
      "2085.m4a\n",
      "2086.m4a\n",
      "2087.m4a\n",
      "2088.m4a\n",
      "2089.m4a\n",
      "2090.m4a\n",
      "2091.m4a\n",
      "2092.m4a\n",
      "2093.m4a\n",
      "2094.m4a\n",
      "2095.m4a\n",
      "2096.m4a\n",
      "2097.m4a\n",
      "2098.m4a\n",
      "2099.m4a\n",
      "2100.m4a\n",
      "2101.m4a\n",
      "2102.m4a\n",
      "2103.m4a\n",
      "2104.m4a\n",
      "2105.m4a\n",
      "2106.m4a\n",
      "2107.m4a\n",
      "2108.m4a\n",
      "2109.m4a\n",
      "2110.m4a\n",
      "2111.m4a\n",
      "2112.m4a\n",
      "2113.m4a\n",
      "2114.m4a\n",
      "2115.m4a\n",
      "2116.m4a\n",
      "2117.m4a\n",
      "2118.m4a\n",
      "2119.m4a\n",
      "2120.m4a\n",
      "2121.m4a\n",
      "2122.m4a\n",
      "2123.m4a\n",
      "2124.m4a\n",
      "2125.m4a\n",
      "2126.m4a\n",
      "2127.m4a\n",
      "2128.m4a\n",
      "2129.m4a\n",
      "2130.m4a\n",
      "2131.m4a\n",
      "2132.m4a\n",
      "2133.m4a\n",
      "2134.m4a\n",
      "2135.m4a\n",
      "2136.m4a\n",
      "2137.m4a\n",
      "2138.m4a\n",
      "2139.m4a\n",
      "2140.m4a\n",
      "2141.m4a\n",
      "2142.m4a\n",
      "2143.m4a\n",
      "2144.m4a\n",
      "2145.m4a\n",
      "2146.m4a\n",
      "2147.m4a\n",
      "2148.m4a\n",
      "2149.m4a\n",
      "2150.m4a\n",
      "2151.m4a\n",
      "2152.m4a\n",
      "2153.m4a\n",
      "2154.m4a\n",
      "2155.m4a\n",
      "2156.m4a\n",
      "2157.m4a\n",
      "2158.m4a\n",
      "2159.m4a\n",
      "2160.m4a\n",
      "2161.m4a\n",
      "2162.m4a\n",
      "2163.m4a\n",
      "2164.m4a\n",
      "2165.m4a\n",
      "2166.m4a\n",
      "2167.m4a\n",
      "2168.m4a\n",
      "2169.m4a\n",
      "2170.m4a\n",
      "2171.m4a\n",
      "2172.m4a\n",
      "2173.m4a\n",
      "2174.m4a\n",
      "2175.m4a\n",
      "2176.m4a\n",
      "2177.m4a\n",
      "2178.m4a\n",
      "2179.m4a\n",
      "2180.m4a\n",
      "2181.m4a\n",
      "2182.m4a\n",
      "2183.m4a\n",
      "2184.m4a\n",
      "2185.m4a\n",
      "2186.m4a\n",
      "2187.m4a\n",
      "2188.m4a\n",
      "2189.m4a\n",
      "2190.m4a\n",
      "2191.m4a\n",
      "2192.m4a\n",
      "2193.m4a\n",
      "2194.m4a\n",
      "2195.m4a\n",
      "2196.m4a\n",
      "2197.m4a\n",
      "2198.m4a\n",
      "2199.m4a\n",
      "2200.m4a\n",
      "2201.m4a\n",
      "2202.m4a\n",
      "2203.m4a\n",
      "2204.m4a\n",
      "2205.m4a\n",
      "2206.m4a\n",
      "2207.m4a\n",
      "2208.m4a\n",
      "2209.m4a\n",
      "2210.m4a\n",
      "2211.m4a\n",
      "2212.m4a\n",
      "2213.m4a\n",
      "2214.m4a\n",
      "2215.m4a\n",
      "2216.m4a\n",
      "2217.m4a\n",
      "2218.m4a\n",
      "2219.m4a\n",
      "2220.m4a\n",
      "2221.m4a\n",
      "2222.m4a\n",
      "2223.m4a\n",
      "2224.m4a\n",
      "2225.m4a\n",
      "2226.m4a\n",
      "2227.m4a\n",
      "2228.m4a\n",
      "2229.m4a\n",
      "2230.m4a\n",
      "2231.m4a\n",
      "2232.m4a\n",
      "2233.m4a\n",
      "2234.m4a\n",
      "2235.m4a\n",
      "2236.m4a\n",
      "2237.m4a\n",
      "2238.m4a\n",
      "2239.m4a\n",
      "2240.m4a\n",
      "2241.m4a\n",
      "2242.m4a\n",
      "2243.m4a\n",
      "2244.m4a\n",
      "2245.m4a\n",
      "2246.m4a\n",
      "2247.m4a\n",
      "2248.m4a\n",
      "2249.m4a\n",
      "2250.m4a\n",
      "2251.m4a\n",
      "2252.m4a\n",
      "2253.m4a\n",
      "2254.m4a\n",
      "2255.m4a\n",
      "2256.m4a\n",
      "2257.m4a\n",
      "2258.m4a\n",
      "2259.m4a\n",
      "2260.m4a\n",
      "2261.m4a\n",
      "2262.m4a\n",
      "2263.m4a\n",
      "2264.m4a\n",
      "2265.m4a\n",
      "2266.m4a\n",
      "2267.m4a\n",
      "2268.m4a\n",
      "2269.m4a\n",
      "2270.m4a\n",
      "2271.m4a\n",
      "2272.m4a\n",
      "2273.m4a\n",
      "2274.m4a\n",
      "2275.m4a\n",
      "2276.m4a\n",
      "2277.m4a\n",
      "2278.m4a\n",
      "2279.m4a\n",
      "2280.m4a\n",
      "2281.m4a\n",
      "2282.m4a\n",
      "2283.m4a\n",
      "2284.m4a\n",
      "2285.m4a\n",
      "2286.m4a\n",
      "2287.m4a\n",
      "2288.m4a\n",
      "2289.m4a\n",
      "2290.m4a\n",
      "2291.m4a\n",
      "2292.m4a\n",
      "2293.m4a\n",
      "2294.m4a\n",
      "2295.m4a\n",
      "2296.m4a\n",
      "2297.m4a\n",
      "2298.m4a\n",
      "2299.m4a\n",
      "2300.m4a\n",
      "2301.m4a\n",
      "2302.m4a\n",
      "2303.m4a\n",
      "2304.m4a\n",
      "2305.m4a\n",
      "2306.m4a\n",
      "2307.m4a\n",
      "2308.m4a\n",
      "2309.m4a\n",
      "2310.m4a\n",
      "2311.m4a\n",
      "2312.m4a\n",
      "2313.m4a\n",
      "2314.m4a\n",
      "2315.m4a\n",
      "2316.m4a\n",
      "2317.m4a\n",
      "2318.m4a\n",
      "2319.m4a\n",
      "2320.m4a\n",
      "2321.m4a\n",
      "2322.m4a\n",
      "2323.m4a\n",
      "2324.m4a\n",
      "2325.m4a\n",
      "2326.m4a\n",
      "2327.m4a\n",
      "2328.m4a\n",
      "2329.m4a\n",
      "2330.m4a\n",
      "2331.m4a\n",
      "2332.m4a\n",
      "2333.m4a\n",
      "2334.m4a\n",
      "2335.m4a\n",
      "2336.m4a\n",
      "2337.m4a\n",
      "2338.m4a\n",
      "2339.m4a\n",
      "2340.m4a\n",
      "2341.m4a\n",
      "2342.m4a\n",
      "2343.m4a\n",
      "2344.m4a\n",
      "2345.m4a\n",
      "2346.m4a\n",
      "2347.m4a\n",
      "2348.m4a\n",
      "2349.m4a\n",
      "2350.m4a\n",
      "2351.m4a\n",
      "2352.m4a\n",
      "2353.m4a\n",
      "2354.m4a\n",
      "2355.m4a\n",
      "2356.m4a\n",
      "2357.m4a\n",
      "2358.m4a\n",
      "2359.m4a\n",
      "2360.m4a\n",
      "2361.m4a\n",
      "2362.m4a\n",
      "2363.m4a\n",
      "2364.m4a\n",
      "2365.m4a\n",
      "2366.m4a\n",
      "2367.m4a\n",
      "2368.m4a\n",
      "2369.m4a\n",
      "2370.m4a\n",
      "2371.m4a\n",
      "2372.m4a\n",
      "2373.m4a\n",
      "2374.m4a\n",
      "2375.m4a\n",
      "2376.m4a\n",
      "2377.m4a\n",
      "2378.m4a\n",
      "2379.m4a\n",
      "2380.m4a\n",
      "2381.m4a\n",
      "2382.m4a\n",
      "2383.m4a\n",
      "2384.m4a\n",
      "2385.m4a\n",
      "2386.m4a\n",
      "2387.m4a\n",
      "2388.m4a\n",
      "2389.m4a\n",
      "2390.m4a\n",
      "2391.m4a\n",
      "2392.m4a\n",
      "2393.m4a\n",
      "2394.m4a\n",
      "2395.m4a\n",
      "2396.m4a\n",
      "2397.m4a\n",
      "2398.m4a\n",
      "2399.m4a\n",
      "2400.m4a\n",
      "2401.m4a\n",
      "2402.m4a\n",
      "2403.m4a\n",
      "2404.m4a\n",
      "2405.m4a\n",
      "2406.m4a\n",
      "2407.m4a\n",
      "2408.m4a\n",
      "2409.m4a\n",
      "2410.m4a\n",
      "2411.m4a\n",
      "2412.m4a\n",
      "2413.m4a\n",
      "2414.m4a\n",
      "2415.m4a\n",
      "2416.m4a\n",
      "2417.m4a\n",
      "2418.m4a\n",
      "2419.m4a\n",
      "2420.m4a\n",
      "2421.m4a\n",
      "2422.m4a\n",
      "2423.m4a\n",
      "2424.m4a\n",
      "2425.m4a\n",
      "2426.m4a\n",
      "2427.m4a\n",
      "2428.m4a\n",
      "2429.m4a\n",
      "2430.m4a\n",
      "2431.m4a\n",
      "2432.m4a\n",
      "2433.m4a\n",
      "2434.m4a\n",
      "2435.m4a\n",
      "2436.m4a\n",
      "2437.m4a\n",
      "2438.m4a\n",
      "2439.m4a\n",
      "2440.m4a\n",
      "2441.m4a\n",
      "2442.m4a\n",
      "2443.m4a\n",
      "2444.m4a\n",
      "2445.m4a\n",
      "2446.m4a\n",
      "2447.m4a\n",
      "2448.m4a\n",
      "2449.m4a\n",
      "2450.m4a\n",
      "2451.m4a\n",
      "2452.m4a\n",
      "2453.m4a\n",
      "2454.m4a\n",
      "2455.m4a\n",
      "2456.m4a\n",
      "2457.m4a\n",
      "2458.m4a\n",
      "2459.m4a\n",
      "2460.m4a\n",
      "2461.m4a\n",
      "2462.m4a\n",
      "2463.m4a\n",
      "2464.m4a\n",
      "2465.m4a\n",
      "2466.m4a\n",
      "2467.m4a\n",
      "2468.m4a\n",
      "2469.m4a\n",
      "2470.m4a\n",
      "2471.m4a\n",
      "2472.m4a\n",
      "2473.m4a\n",
      "2474.m4a\n",
      "2475.m4a\n",
      "2476.m4a\n",
      "2477.m4a\n",
      "2478.m4a\n",
      "2479.m4a\n",
      "2480.m4a\n",
      "2481.m4a\n",
      "2482.m4a\n",
      "2483.m4a\n",
      "2484.m4a\n",
      "2485.m4a\n",
      "2486.m4a\n",
      "2487.m4a\n",
      "2488.m4a\n",
      "2489.m4a\n",
      "2490.m4a\n",
      "2491.m4a\n",
      "2492.m4a\n",
      "2493.m4a\n",
      "2494.m4a\n",
      "2495.m4a\n",
      "2496.m4a\n",
      "2497.m4a\n",
      "2498.m4a\n",
      "2499.m4a\n",
      "2500.m4a\n",
      "2501.m4a\n",
      "2502.m4a\n",
      "2503.m4a\n",
      "2504.m4a\n",
      "2505.m4a\n",
      "2506.m4a\n",
      "2507.m4a\n",
      "2508.m4a\n",
      "2509.m4a\n",
      "2510.m4a\n",
      "2511.m4a\n",
      "2512.m4a\n",
      "2513.m4a\n",
      "2514.m4a\n",
      "2515.m4a\n",
      "2516.m4a\n",
      "2517.m4a\n",
      "2518.m4a\n",
      "2519.m4a\n",
      "2520.m4a\n",
      "2521.m4a\n",
      "2522.m4a\n",
      "2523.m4a\n",
      "2524.m4a\n",
      "2525.m4a\n",
      "2526.m4a\n",
      "2527.m4a\n",
      "2528.m4a\n",
      "2529.m4a\n",
      "2530.m4a\n",
      "2531.m4a\n",
      "2532.m4a\n",
      "2533.m4a\n",
      "2534.m4a\n",
      "2535.m4a\n",
      "2536.m4a\n",
      "2537.m4a\n",
      "2538.m4a\n",
      "2539.m4a\n",
      "2540.m4a\n",
      "2541.m4a\n",
      "2542.m4a\n",
      "2543.m4a\n",
      "2544.m4a\n",
      "2545.m4a\n",
      "2546.m4a\n",
      "2547.m4a\n",
      "2548.m4a\n",
      "2549.m4a\n",
      "2550.m4a\n",
      "2551.m4a\n",
      "2552.m4a\n",
      "2553.m4a\n",
      "2554.m4a\n",
      "2555.m4a\n",
      "2556.m4a\n",
      "2557.m4a\n",
      "2558.m4a\n",
      "2559.m4a\n",
      "2560.m4a\n",
      "2561.m4a\n",
      "2562.m4a\n",
      "2563.m4a\n",
      "2564.m4a\n",
      "2565.m4a\n",
      "2566.m4a\n",
      "2567.m4a\n",
      "2568.m4a\n",
      "2569.m4a\n",
      "2570.m4a\n",
      "2571.m4a\n",
      "2572.m4a\n",
      "2573.m4a\n",
      "2574.m4a\n",
      "2575.m4a\n",
      "2576.m4a\n",
      "2577.m4a\n",
      "2578.m4a\n",
      "2579.m4a\n",
      "2580.m4a\n",
      "2581.m4a\n",
      "2582.m4a\n",
      "2583.m4a\n",
      "2584.m4a\n",
      "2585.m4a\n",
      "2586.m4a\n",
      "2587.m4a\n",
      "2588.m4a\n",
      "2589.m4a\n",
      "2590.m4a\n",
      "2591.m4a\n",
      "2592.m4a\n",
      "2593.m4a\n",
      "2594.m4a\n",
      "2595.m4a\n",
      "2596.m4a\n",
      "2597.m4a\n",
      "2598.m4a\n",
      "2599.m4a\n",
      "2600.m4a\n",
      "2601.m4a\n",
      "2602.m4a\n",
      "2603.m4a\n",
      "2604.m4a\n",
      "2605.m4a\n",
      "2606.m4a\n",
      "2607.m4a\n",
      "2608.m4a\n",
      "2609.m4a\n",
      "2610.m4a\n",
      "2611.m4a\n",
      "2612.m4a\n",
      "2613.m4a\n",
      "2614.m4a\n",
      "2615.m4a\n",
      "2616.m4a\n",
      "2617.m4a\n",
      "2618.m4a\n",
      "2619.m4a\n",
      "2620.m4a\n",
      "2621.m4a\n",
      "2622.m4a\n",
      "2623.m4a\n",
      "2624.m4a\n",
      "2625.m4a\n",
      "2626.m4a\n",
      "2627.m4a\n",
      "2628.m4a\n",
      "2629.m4a\n",
      "2630.m4a\n",
      "2631.m4a\n",
      "2632.m4a\n",
      "2633.m4a\n",
      "2634.m4a\n",
      "2635.m4a\n",
      "2636.m4a\n",
      "2637.m4a\n",
      "2638.m4a\n",
      "2639.m4a\n",
      "2640.m4a\n",
      "2641.m4a\n",
      "2642.m4a\n",
      "2643.m4a\n",
      "2644.m4a\n",
      "2645.m4a\n",
      "2646.m4a\n",
      "2647.m4a\n",
      "2648.m4a\n",
      "2649.m4a\n",
      "2650.m4a\n",
      "2651.m4a\n",
      "2652.m4a\n",
      "2653.m4a\n",
      "2654.m4a\n",
      "2655.m4a\n",
      "2656.m4a\n",
      "2657.m4a\n",
      "2658.m4a\n",
      "2659.m4a\n",
      "2660.m4a\n",
      "2661.m4a\n",
      "2662.m4a\n",
      "2663.m4a\n",
      "2664.m4a\n",
      "2665.m4a\n",
      "2666.m4a\n",
      "2667.m4a\n",
      "2668.m4a\n",
      "2669.m4a\n",
      "2670.m4a\n",
      "2671.m4a\n",
      "2672.m4a\n",
      "2673.m4a\n",
      "2674.m4a\n",
      "2675.m4a\n",
      "2676.m4a\n",
      "2677.m4a\n",
      "2678.m4a\n",
      "2679.m4a\n",
      "2680.m4a\n",
      "2681.m4a\n",
      "2682.m4a\n",
      "2683.m4a\n",
      "2684.m4a\n",
      "2685.m4a\n",
      "2686.m4a\n",
      "2687.m4a\n",
      "2688.m4a\n",
      "2689.m4a\n",
      "2690.m4a\n",
      "2691.m4a\n",
      "2692.m4a\n",
      "2693.m4a\n",
      "2694.m4a\n",
      "2695.m4a\n",
      "2696.m4a\n",
      "2697.m4a\n",
      "2698.m4a\n",
      "2699.m4a\n",
      "2700.m4a\n",
      "2701.m4a\n",
      "2702.m4a\n",
      "2703.m4a\n",
      "2704.m4a\n",
      "2705.m4a\n",
      "2706.m4a\n",
      "2707.m4a\n",
      "2708.m4a\n",
      "2709.m4a\n",
      "2710.m4a\n",
      "2711.m4a\n",
      "2712.m4a\n",
      "2713.m4a\n",
      "2714.m4a\n",
      "2715.m4a\n",
      "2716.m4a\n",
      "2717.m4a\n",
      "2718.m4a\n",
      "2719.m4a\n",
      "2720.m4a\n",
      "2721.m4a\n",
      "2722.m4a\n",
      "2723.m4a\n",
      "2724.m4a\n",
      "2725.m4a\n",
      "2726.m4a\n",
      "2727.m4a\n",
      "2728.m4a\n",
      "2729.m4a\n",
      "2730.m4a\n",
      "2731.m4a\n",
      "2732.m4a\n",
      "2733.m4a\n",
      "2734.m4a\n",
      "2735.m4a\n",
      "2736.m4a\n",
      "2737.m4a\n",
      "2738.m4a\n",
      "2739.m4a\n",
      "2740.m4a\n",
      "2741.m4a\n",
      "2742.m4a\n",
      "2743.m4a\n",
      "2744.m4a\n",
      "2745.m4a\n",
      "2746.m4a\n",
      "2747.m4a\n",
      "2748.m4a\n",
      "2749.m4a\n",
      "2750.m4a\n",
      "2751.m4a\n",
      "2752.m4a\n",
      "2753.m4a\n",
      "2754.m4a\n",
      "2755.m4a\n",
      "2756.m4a\n",
      "2757.m4a\n",
      "2758.m4a\n",
      "2759.m4a\n",
      "2760.m4a\n",
      "2761.m4a\n",
      "2762.m4a\n",
      "2763.m4a\n",
      "2764.m4a\n",
      "2765.m4a\n",
      "2766.m4a\n",
      "2767.m4a\n",
      "2768.m4a\n",
      "2769.m4a\n",
      "2770.m4a\n",
      "2771.m4a\n",
      "2772.m4a\n",
      "2773.m4a\n",
      "2774.m4a\n",
      "2775.m4a\n",
      "2776.m4a\n",
      "2777.m4a\n",
      "2778.m4a\n",
      "2779.m4a\n",
      "2780.m4a\n",
      "2781.m4a\n",
      "2782.m4a\n",
      "2783.m4a\n",
      "2784.m4a\n",
      "2785.m4a\n",
      "2786.m4a\n",
      "2787.m4a\n",
      "2788.m4a\n",
      "2789.m4a\n",
      "2790.m4a\n",
      "2791.m4a\n",
      "2792.m4a\n",
      "2793.m4a\n",
      "2794.m4a\n",
      "2795.m4a\n",
      "2796.m4a\n",
      "2797.m4a\n",
      "2798.m4a\n",
      "2799.m4a\n",
      "2800.m4a\n",
      "2801.m4a\n",
      "2802.m4a\n",
      "2803.m4a\n",
      "2804.m4a\n",
      "2805.m4a\n",
      "2806.m4a\n",
      "2807.m4a\n",
      "2808.m4a\n",
      "2809.m4a\n",
      "2810.m4a\n",
      "2811.m4a\n",
      "2812.m4a\n",
      "2813.m4a\n",
      "2814.m4a\n",
      "2815.m4a\n",
      "2816.m4a\n",
      "2817.m4a\n",
      "2818.m4a\n",
      "2819.m4a\n",
      "2820.m4a\n",
      "2821.m4a\n",
      "2822.m4a\n",
      "2823.m4a\n",
      "2824.m4a\n",
      "2825.m4a\n",
      "2826.m4a\n",
      "2827.m4a\n",
      "2828.m4a\n",
      "2829.m4a\n",
      "2830.m4a\n",
      "2831.m4a\n",
      "2832.m4a\n",
      "2833.m4a\n",
      "2834.m4a\n",
      "2835.m4a\n",
      "2836.m4a\n",
      "2837.m4a\n",
      "2838.m4a\n",
      "2839.m4a\n",
      "2840.m4a\n",
      "2841.m4a\n",
      "2842.m4a\n",
      "2843.m4a\n",
      "2844.m4a\n",
      "2845.m4a\n",
      "2846.m4a\n",
      "2847.m4a\n",
      "2848.m4a\n",
      "2849.m4a\n",
      "2850.m4a\n",
      "2851.m4a\n",
      "2852.m4a\n",
      "2853.m4a\n",
      "2854.m4a\n",
      "2855.m4a\n",
      "2856.m4a\n",
      "2857.m4a\n",
      "2858.m4a\n",
      "2859.m4a\n",
      "2860.m4a\n",
      "2861.m4a\n",
      "2862.m4a\n",
      "2863.m4a\n",
      "2864.m4a\n",
      "2865.m4a\n",
      "2866.m4a\n",
      "2867.m4a\n",
      "2868.m4a\n",
      "2869.m4a\n",
      "2870.m4a\n",
      "2871.m4a\n",
      "2872.m4a\n",
      "2873.m4a\n",
      "2874.m4a\n",
      "2875.m4a\n",
      "2876.m4a\n",
      "2877.m4a\n",
      "2878.m4a\n",
      "2879.m4a\n",
      "2880.m4a\n",
      "2881.m4a\n",
      "2882.m4a\n",
      "2883.m4a\n",
      "2884.m4a\n",
      "2885.m4a\n",
      "2886.m4a\n",
      "2887.m4a\n",
      "2888.m4a\n",
      "2889.m4a\n",
      "2890.m4a\n",
      "2891.m4a\n",
      "2892.m4a\n",
      "2893.m4a\n",
      "2894.m4a\n",
      "2895.m4a\n",
      "2896.m4a\n",
      "2897.m4a\n",
      "2898.m4a\n",
      "2899.m4a\n",
      "2900.m4a\n",
      "2901.m4a\n",
      "2902.m4a\n",
      "2903.m4a\n",
      "2904.m4a\n",
      "2905.m4a\n",
      "2906.m4a\n",
      "2907.m4a\n",
      "2908.m4a\n",
      "2909.m4a\n",
      "2910.m4a\n",
      "2911.m4a\n",
      "2912.m4a\n",
      "2913.m4a\n",
      "2914.m4a\n",
      "2915.m4a\n",
      "2916.m4a\n",
      "2917.m4a\n",
      "2918.m4a\n",
      "2919.m4a\n",
      "2920.m4a\n",
      "2921.m4a\n",
      "2922.m4a\n",
      "2923.m4a\n",
      "2924.m4a\n",
      "2925.m4a\n",
      "2926.m4a\n",
      "2927.m4a\n",
      "2928.m4a\n",
      "2929.m4a\n",
      "2930.m4a\n",
      "2931.m4a\n",
      "2932.m4a\n",
      "2933.m4a\n",
      "2934.m4a\n",
      "2935.m4a\n",
      "2936.m4a\n",
      "2937.m4a\n",
      "2938.m4a\n",
      "2939.m4a\n",
      "2940.m4a\n",
      "2941.m4a\n",
      "2942.m4a\n",
      "2943.m4a\n",
      "2944.m4a\n",
      "2945.m4a\n",
      "2946.m4a\n",
      "2947.m4a\n",
      "2948.m4a\n",
      "2949.m4a\n",
      "2950.m4a\n",
      "2951.m4a\n",
      "2952.m4a\n",
      "2953.m4a\n",
      "2954.m4a\n",
      "2955.m4a\n",
      "2956.m4a\n",
      "2957.m4a\n",
      "2958.m4a\n",
      "2959.m4a\n",
      "2960.m4a\n",
      "2961.m4a\n",
      "2962.m4a\n",
      "2963.m4a\n",
      "2964.m4a\n",
      "2965.m4a\n",
      "2966.m4a\n",
      "2967.m4a\n",
      "2968.m4a\n",
      "2969.m4a\n",
      "2970.m4a\n",
      "2971.m4a\n",
      "2972.m4a\n",
      "2973.m4a\n",
      "2974.m4a\n",
      "2975.m4a\n",
      "2976.m4a\n",
      "2977.m4a\n",
      "2978.m4a\n",
      "2979.m4a\n",
      "2980.m4a\n",
      "2981.m4a\n",
      "2982.m4a\n",
      "2983.m4a\n",
      "2984.m4a\n",
      "2985.m4a\n",
      "2986.m4a\n",
      "2987.m4a\n",
      "2988.m4a\n",
      "2989.m4a\n",
      "2990.m4a\n",
      "2991.m4a\n",
      "2992.m4a\n",
      "2993.m4a\n",
      "2994.m4a\n",
      "2995.m4a\n",
      "2996.m4a\n",
      "2997.m4a\n",
      "2998.m4a\n",
      "2999.m4a\n",
      "3000.m4a\n",
      "3001.m4a\n",
      "3002.m4a\n",
      "3003.m4a\n",
      "3004.m4a\n",
      "3005.m4a\n",
      "3006.m4a\n",
      "3007.m4a\n",
      "3008.m4a\n",
      "3009.m4a\n",
      "3010.m4a\n",
      "3011.m4a\n",
      "3012.m4a\n",
      "3013.m4a\n",
      "3014.m4a\n",
      "3015.m4a\n",
      "3016.m4a\n",
      "3017.m4a\n",
      "3018.m4a\n",
      "3019.m4a\n",
      "3020.m4a\n",
      "3021.m4a\n",
      "3022.m4a\n",
      "3023.m4a\n",
      "3024.m4a\n",
      "3025.m4a\n",
      "3026.m4a\n",
      "3027.m4a\n",
      "3028.m4a\n",
      "3029.m4a\n",
      "3030.m4a\n",
      "3031.m4a\n",
      "3032.m4a\n",
      "3033.m4a\n",
      "3034.m4a\n",
      "3035.m4a\n",
      "3036.m4a\n",
      "3037.m4a\n",
      "3038.m4a\n",
      "3039.m4a\n",
      "3040.m4a\n",
      "3041.m4a\n",
      "3042.m4a\n",
      "3043.m4a\n",
      "3044.m4a\n",
      "3045.m4a\n",
      "3046.m4a\n",
      "3047.m4a\n",
      "3048.m4a\n",
      "3049.m4a\n",
      "3050.m4a\n",
      "3051.m4a\n",
      "3052.m4a\n",
      "3053.m4a\n",
      "3054.m4a\n",
      "3055.m4a\n",
      "3056.m4a\n",
      "3057.m4a\n",
      "3058.m4a\n",
      "3059.m4a\n",
      "3060.m4a\n",
      "3061.m4a\n",
      "3062.m4a\n",
      "3063.m4a\n",
      "3064.m4a\n",
      "3065.m4a\n",
      "3066.m4a\n",
      "3067.m4a\n",
      "3068.m4a\n",
      "3069.m4a\n",
      "3070.m4a\n",
      "3071.m4a\n",
      "3072.m4a\n",
      "3073.m4a\n",
      "3074.m4a\n",
      "3075.m4a\n",
      "3076.m4a\n",
      "3077.m4a\n",
      "3078.m4a\n",
      "3079.m4a\n",
      "3080.m4a\n",
      "3081.m4a\n",
      "3082.m4a\n",
      "3083.m4a\n",
      "3084.m4a\n",
      "3085.m4a\n",
      "3086.m4a\n",
      "3087.m4a\n",
      "3088.m4a\n",
      "3089.m4a\n",
      "3090.m4a\n",
      "3091.m4a\n",
      "3092.m4a\n",
      "3093.m4a\n",
      "3094.m4a\n",
      "3095.m4a\n",
      "3096.m4a\n",
      "3097.m4a\n",
      "3098.m4a\n",
      "3099.m4a\n",
      "3100.m4a\n",
      "3101.m4a\n",
      "3102.m4a\n",
      "3103.m4a\n",
      "3104.m4a\n",
      "3105.m4a\n",
      "3106.m4a\n",
      "3107.m4a\n",
      "3108.m4a\n",
      "3109.m4a\n",
      "3110.m4a\n",
      "3111.m4a\n",
      "3112.m4a\n",
      "3113.m4a\n",
      "3114.m4a\n",
      "3115.m4a\n",
      "3116.m4a\n",
      "3117.m4a\n",
      "3118.m4a\n",
      "3119.m4a\n",
      "3120.m4a\n",
      "3121.m4a\n",
      "3122.m4a\n",
      "3123.m4a\n",
      "3124.m4a\n",
      "3125.m4a\n",
      "3126.m4a\n",
      "3127.m4a\n",
      "3128.m4a\n",
      "3129.m4a\n",
      "3130.m4a\n",
      "3131.m4a\n",
      "3132.m4a\n",
      "3133.m4a\n",
      "3134.m4a\n",
      "3135.m4a\n",
      "3136.m4a\n",
      "3137.m4a\n",
      "3138.m4a\n",
      "3139.m4a\n",
      "3140.m4a\n",
      "3141.m4a\n",
      "3142.m4a\n",
      "3143.m4a\n",
      "3144.m4a\n",
      "3145.m4a\n",
      "3146.m4a\n",
      "3147.m4a\n",
      "3148.m4a\n",
      "3149.m4a\n",
      "3150.m4a\n",
      "3151.m4a\n",
      "3152.m4a\n",
      "3153.m4a\n",
      "3154.m4a\n",
      "3155.m4a\n",
      "3156.m4a\n",
      "3157.m4a\n",
      "3158.m4a\n",
      "3159.m4a\n",
      "3160.m4a\n",
      "3161.m4a\n",
      "3162.m4a\n",
      "3163.m4a\n",
      "3164.m4a\n",
      "3165.m4a\n",
      "3166.m4a\n",
      "3167.m4a\n",
      "3168.m4a\n",
      "3169.m4a\n",
      "3170.m4a\n",
      "3171.m4a\n",
      "3172.m4a\n",
      "3173.m4a\n",
      "3174.m4a\n",
      "3175.m4a\n",
      "3176.m4a\n",
      "3177.m4a\n",
      "3178.m4a\n",
      "3179.m4a\n",
      "3180.m4a\n",
      "3181.m4a\n",
      "3182.m4a\n",
      "3183.m4a\n",
      "3184.m4a\n",
      "3185.m4a\n",
      "3186.m4a\n",
      "3187.m4a\n",
      "3188.m4a\n",
      "3189.m4a\n",
      "3190.m4a\n",
      "3191.m4a\n",
      "3192.m4a\n",
      "3193.m4a\n",
      "3194.m4a\n",
      "3195.m4a\n",
      "3196.m4a\n",
      "3197.m4a\n",
      "3198.m4a\n",
      "3199.m4a\n",
      "3200.m4a\n",
      "3201.m4a\n",
      "3202.m4a\n",
      "3203.m4a\n",
      "3204.m4a\n",
      "3205.m4a\n",
      "3206.m4a\n",
      "3207.m4a\n",
      "3208.m4a\n",
      "3209.m4a\n",
      "3210.m4a\n",
      "3211.m4a\n",
      "3212.m4a\n",
      "3213.m4a\n",
      "3214.m4a\n",
      "3215.m4a\n",
      "3216.m4a\n",
      "3217.m4a\n",
      "3218.m4a\n",
      "3219.m4a\n",
      "3220.m4a\n",
      "3221.m4a\n",
      "3222.m4a\n",
      "3223.m4a\n",
      "3224.m4a\n",
      "3225.m4a\n",
      "3226.m4a\n",
      "3227.m4a\n",
      "3228.m4a\n",
      "3229.m4a\n",
      "3230.m4a\n",
      "3231.m4a\n",
      "3232.m4a\n",
      "3233.m4a\n",
      "3234.m4a\n",
      "3235.m4a\n",
      "3236.m4a\n",
      "3237.m4a\n",
      "3238.m4a\n",
      "3239.m4a\n",
      "3240.m4a\n",
      "3241.m4a\n",
      "3242.m4a\n",
      "3243.m4a\n",
      "3244.m4a\n",
      "3245.m4a\n",
      "3246.m4a\n",
      "3247.m4a\n",
      "3248.m4a\n",
      "3249.m4a\n",
      "3250.m4a\n",
      "3251.m4a\n",
      "3252.m4a\n",
      "3253.m4a\n",
      "3254.m4a\n",
      "3255.m4a\n",
      "3256.m4a\n",
      "3257.m4a\n",
      "3258.m4a\n",
      "3259.m4a\n",
      "3260.m4a\n",
      "3261.m4a\n",
      "3262.m4a\n",
      "3263.m4a\n",
      "3264.m4a\n",
      "3265.m4a\n",
      "3266.m4a\n",
      "3267.m4a\n",
      "3268.m4a\n",
      "3269.m4a\n",
      "3270.m4a\n",
      "3271.m4a\n",
      "3272.m4a\n",
      "3273.m4a\n",
      "3274.m4a\n",
      "3275.m4a\n",
      "3276.m4a\n",
      "3277.m4a\n",
      "3278.m4a\n",
      "3279.m4a\n",
      "3280.m4a\n",
      "3281.m4a\n",
      "3282.m4a\n",
      "3283.m4a\n",
      "3284.m4a\n",
      "3285.m4a\n",
      "3286.m4a\n",
      "3287.m4a\n",
      "3288.m4a\n",
      "3289.m4a\n",
      "3290.m4a\n",
      "3291.m4a\n",
      "3292.m4a\n",
      "3293.m4a\n",
      "3294.m4a\n",
      "3295.m4a\n",
      "3296.m4a\n",
      "3297.m4a\n",
      "3298.m4a\n",
      "3299.m4a\n",
      "3300.m4a\n",
      "3301.m4a\n",
      "3302.m4a\n",
      "3303.m4a\n",
      "3304.m4a\n",
      "3305.m4a\n",
      "3306.m4a\n",
      "3307.m4a\n",
      "3308.m4a\n",
      "3309.m4a\n",
      "3310.m4a\n",
      "3311.m4a\n",
      "3312.m4a\n",
      "3313.m4a\n",
      "3314.m4a\n",
      "3315.m4a\n",
      "3316.m4a\n",
      "3317.m4a\n",
      "3318.m4a\n",
      "3319.m4a\n",
      "3320.m4a\n",
      "3321.m4a\n",
      "3322.m4a\n",
      "3323.m4a\n",
      "3324.m4a\n",
      "3325.m4a\n",
      "3326.m4a\n",
      "3327.m4a\n",
      "3328.m4a\n",
      "3329.m4a\n",
      "3330.m4a\n",
      "3331.m4a\n",
      "3332.m4a\n",
      "3333.m4a\n",
      "3334.m4a\n",
      "3335.m4a\n",
      "3336.m4a\n",
      "3337.m4a\n",
      "3338.m4a\n",
      "3339.m4a\n",
      "3340.m4a\n",
      "3341.m4a\n",
      "3342.m4a\n",
      "3343.m4a\n",
      "3344.m4a\n",
      "3345.m4a\n",
      "3346.m4a\n",
      "3347.m4a\n",
      "3348.m4a\n",
      "3349.m4a\n",
      "3350.m4a\n",
      "3351.m4a\n",
      "3352.m4a\n",
      "3353.m4a\n",
      "3354.m4a\n",
      "3355.m4a\n",
      "3356.m4a\n",
      "3357.m4a\n",
      "3358.m4a\n",
      "3359.m4a\n",
      "3360.m4a\n",
      "3361.m4a\n",
      "3362.m4a\n",
      "3363.m4a\n",
      "3364.m4a\n",
      "3365.m4a\n",
      "3366.m4a\n",
      "3367.m4a\n",
      "3368.m4a\n",
      "3369.m4a\n",
      "3370.m4a\n",
      "3371.m4a\n",
      "3372.m4a\n",
      "3373.m4a\n",
      "3374.m4a\n",
      "3375.m4a\n",
      "3376.m4a\n",
      "3377.m4a\n",
      "3378.m4a\n",
      "3379.m4a\n",
      "3380.m4a\n",
      "3381.m4a\n",
      "3382.m4a\n",
      "3383.m4a\n",
      "3384.m4a\n",
      "3385.m4a\n",
      "3386.m4a\n",
      "3387.m4a\n",
      "3388.m4a\n",
      "3389.m4a\n",
      "3390.m4a\n",
      "3391.m4a\n",
      "3392.m4a\n",
      "3393.m4a\n",
      "3394.m4a\n",
      "3395.m4a\n",
      "3396.m4a\n",
      "3397.m4a\n",
      "3398.m4a\n",
      "3399.m4a\n",
      "3400.m4a\n",
      "3401.m4a\n",
      "3402.m4a\n",
      "3403.m4a\n",
      "3404.m4a\n",
      "3405.m4a\n",
      "3406.m4a\n",
      "3407.m4a\n",
      "3408.m4a\n",
      "3409.m4a\n",
      "3410.m4a\n",
      "3411.m4a\n",
      "3412.m4a\n",
      "3413.m4a\n",
      "3414.m4a\n",
      "3415.m4a\n",
      "3416.m4a\n",
      "3417.m4a\n",
      "3418.m4a\n",
      "3419.m4a\n",
      "3420.m4a\n",
      "3421.m4a\n",
      "3422.m4a\n",
      "3423.m4a\n",
      "3424.m4a\n",
      "3425.m4a\n",
      "3426.m4a\n",
      "3427.m4a\n",
      "3428.m4a\n",
      "3429.m4a\n",
      "3430.m4a\n",
      "3431.m4a\n",
      "3432.m4a\n",
      "3433.m4a\n",
      "3434.m4a\n",
      "3435.m4a\n",
      "3436.m4a\n",
      "3437.m4a\n",
      "3438.m4a\n",
      "3439.m4a\n",
      "3440.m4a\n",
      "3441.m4a\n",
      "3442.m4a\n",
      "3443.m4a\n",
      "3444.m4a\n",
      "3445.m4a\n",
      "3446.m4a\n",
      "3447.m4a\n",
      "3448.m4a\n",
      "3449.m4a\n",
      "3450.m4a\n",
      "3451.m4a\n",
      "3452.m4a\n",
      "3453.m4a\n",
      "3454.m4a\n",
      "3455.m4a\n",
      "3456.m4a\n",
      "3457.m4a\n",
      "3458.m4a\n",
      "3459.m4a\n",
      "3460.m4a\n",
      "3461.m4a\n",
      "3462.m4a\n",
      "3463.m4a\n",
      "3464.m4a\n",
      "3465.m4a\n",
      "3466.m4a\n",
      "3467.m4a\n",
      "3468.m4a\n",
      "3469.m4a\n",
      "3470.m4a\n",
      "3471.m4a\n",
      "3472.m4a\n",
      "3473.m4a\n",
      "3474.m4a\n",
      "3475.m4a\n",
      "3476.m4a\n",
      "3477.m4a\n",
      "3478.m4a\n",
      "3479.m4a\n",
      "3480.m4a\n",
      "3481.m4a\n",
      "3482.m4a\n",
      "3483.m4a\n",
      "3484.m4a\n",
      "3485.m4a\n",
      "3486.m4a\n",
      "3487.m4a\n",
      "3488.m4a\n",
      "3489.m4a\n",
      "3490.m4a\n",
      "3491.m4a\n",
      "3492.m4a\n",
      "3493.m4a\n",
      "3494.m4a\n",
      "3495.m4a\n",
      "3496.m4a\n",
      "3497.m4a\n",
      "3498.m4a\n",
      "3499.m4a\n",
      "3500.m4a\n",
      "3501.m4a\n",
      "3502.m4a\n",
      "3503.m4a\n",
      "3504.m4a\n",
      "3505.m4a\n",
      "3506.m4a\n",
      "3507.m4a\n",
      "3508.m4a\n",
      "3509.m4a\n",
      "3510.m4a\n",
      "3511.m4a\n",
      "3512.m4a\n",
      "3513.m4a\n",
      "3514.m4a\n",
      "3515.m4a\n",
      "3516.m4a\n",
      "3517.m4a\n",
      "3518.m4a\n",
      "3519.m4a\n",
      "3520.m4a\n",
      "3521.m4a\n",
      "3522.m4a\n",
      "3523.m4a\n",
      "3524.m4a\n",
      "3525.m4a\n",
      "3526.m4a\n",
      "3527.m4a\n",
      "3528.m4a\n",
      "3529.m4a\n",
      "3530.m4a\n",
      "3531.m4a\n",
      "3532.m4a\n",
      "3533.m4a\n",
      "3534.m4a\n",
      "3535.m4a\n",
      "3536.m4a\n",
      "3537.m4a\n",
      "3538.m4a\n",
      "3539.m4a\n",
      "3540.m4a\n",
      "3541.m4a\n",
      "3542.m4a\n",
      "3543.m4a\n",
      "3544.m4a\n",
      "3545.m4a\n",
      "3546.m4a\n",
      "3547.m4a\n",
      "3548.m4a\n",
      "3549.m4a\n",
      "3550.m4a\n",
      "3551.m4a\n",
      "3552.m4a\n",
      "3553.m4a\n",
      "3554.m4a\n",
      "3555.m4a\n",
      "3556.m4a\n",
      "3557.m4a\n",
      "3558.m4a\n",
      "3559.m4a\n",
      "3560.m4a\n",
      "3561.m4a\n",
      "3562.m4a\n",
      "3563.m4a\n",
      "3564.m4a\n",
      "3565.m4a\n",
      "3566.m4a\n",
      "3567.m4a\n",
      "3568.m4a\n",
      "3569.m4a\n",
      "3570.m4a\n",
      "3571.m4a\n",
      "3572.m4a\n",
      "3573.m4a\n",
      "3574.m4a\n",
      "3575.m4a\n",
      "3576.m4a\n",
      "3577.m4a\n",
      "3578.m4a\n",
      "3579.m4a\n",
      "3580.m4a\n",
      "3581.m4a\n",
      "3582.m4a\n",
      "3583.m4a\n",
      "3584.m4a\n",
      "3585.m4a\n",
      "3586.m4a\n",
      "3587.m4a\n",
      "3588.m4a\n",
      "3589.m4a\n",
      "3590.m4a\n",
      "3591.m4a\n",
      "3592.m4a\n",
      "3593.m4a\n",
      "3594.m4a\n",
      "3595.m4a\n",
      "3596.m4a\n",
      "3597.m4a\n",
      "3598.m4a\n",
      "3599.m4a\n",
      "3600.m4a\n",
      "3601.m4a\n",
      "3602.m4a\n",
      "3603.m4a\n",
      "3604.m4a\n",
      "3605.m4a\n",
      "3606.m4a\n",
      "3607.m4a\n",
      "3608.m4a\n",
      "3609.m4a\n",
      "3610.m4a\n",
      "3611.m4a\n",
      "3612.m4a\n",
      "3613.m4a\n",
      "3614.m4a\n",
      "3615.m4a\n",
      "3616.m4a\n",
      "3617.m4a\n",
      "3618.m4a\n",
      "3619.m4a\n",
      "3620.m4a\n",
      "3621.m4a\n",
      "3622.m4a\n",
      "3623.m4a\n",
      "3624.m4a\n",
      "3625.m4a\n",
      "3626.m4a\n",
      "3627.m4a\n",
      "3628.m4a\n",
      "3629.m4a\n",
      "3630.m4a\n",
      "3631.m4a\n",
      "3632.m4a\n",
      "3633.m4a\n",
      "3634.m4a\n",
      "3635.m4a\n",
      "3636.m4a\n",
      "3637.m4a\n",
      "3638.m4a\n",
      "3639.m4a\n",
      "3640.m4a\n",
      "3641.m4a\n",
      "3642.m4a\n",
      "3643.m4a\n",
      "3644.m4a\n",
      "3645.m4a\n",
      "3646.m4a\n",
      "3647.m4a\n",
      "3648.m4a\n",
      "3649.m4a\n",
      "3650.m4a\n",
      "3651.m4a\n",
      "3652.m4a\n",
      "3653.m4a\n",
      "3654.m4a\n",
      "3655.m4a\n",
      "3656.m4a\n",
      "3657.m4a\n",
      "3658.m4a\n",
      "3659.m4a\n",
      "3660.m4a\n",
      "3661.m4a\n",
      "3662.m4a\n",
      "3663.m4a\n",
      "3664.m4a\n",
      "3665.m4a\n",
      "3666.m4a\n",
      "3667.m4a\n",
      "3668.m4a\n",
      "3669.m4a\n",
      "3670.m4a\n",
      "3671.m4a\n",
      "3672.m4a\n",
      "3673.m4a\n",
      "3674.m4a\n",
      "3675.m4a\n",
      "3676.m4a\n",
      "3677.m4a\n",
      "3678.m4a\n",
      "3679.m4a\n",
      "3680.m4a\n",
      "3681.m4a\n",
      "3682.m4a\n",
      "3683.m4a\n",
      "3684.m4a\n",
      "3685.m4a\n",
      "3686.m4a\n",
      "3687.m4a\n",
      "3688.m4a\n",
      "3689.m4a\n",
      "3690.m4a\n",
      "3691.m4a\n",
      "3692.m4a\n",
      "3693.m4a\n",
      "3694.m4a\n",
      "3695.m4a\n",
      "3696.m4a\n",
      "3697.m4a\n",
      "3698.m4a\n",
      "3699.m4a\n",
      "3700.m4a\n",
      "3701.m4a\n",
      "3702.m4a\n",
      "3703.m4a\n",
      "3704.m4a\n",
      "3705.m4a\n",
      "3706.m4a\n",
      "3707.m4a\n",
      "3708.m4a\n",
      "3709.m4a\n",
      "3710.m4a\n",
      "3711.m4a\n",
      "3712.m4a\n",
      "3713.m4a\n",
      "3714.m4a\n",
      "3715.m4a\n",
      "3716.m4a\n",
      "3717.m4a\n",
      "3718.m4a\n",
      "3719.m4a\n",
      "3720.m4a\n",
      "3721.m4a\n",
      "3722.m4a\n",
      "3723.m4a\n",
      "3724.m4a\n",
      "3725.m4a\n",
      "3726.m4a\n",
      "3727.m4a\n",
      "3728.m4a\n",
      "3729.m4a\n",
      "3730.m4a\n",
      "3731.m4a\n",
      "3732.m4a\n",
      "3733.m4a\n",
      "3734.m4a\n",
      "3735.m4a\n",
      "3736.m4a\n",
      "3737.m4a\n",
      "3738.m4a\n",
      "3739.m4a\n",
      "3740.m4a\n",
      "3741.m4a\n",
      "3742.m4a\n",
      "3743.m4a\n",
      "3744.m4a\n",
      "3745.m4a\n",
      "3746.m4a\n",
      "3747.m4a\n",
      "3748.m4a\n",
      "3749.m4a\n",
      "3750.m4a\n",
      "3751.m4a\n",
      "3752.m4a\n",
      "3753.m4a\n",
      "3754.m4a\n",
      "3755.m4a\n",
      "3756.m4a\n",
      "3757.m4a\n",
      "3758.m4a\n",
      "3759.m4a\n",
      "3760.m4a\n",
      "3761.m4a\n",
      "3762.m4a\n",
      "3763.m4a\n",
      "3764.m4a\n",
      "3765.m4a\n",
      "3766.m4a\n",
      "3767.m4a\n",
      "3768.m4a\n",
      "3769.m4a\n",
      "3770.m4a\n",
      "3771.m4a\n",
      "3772.m4a\n",
      "3773.m4a\n",
      "3774.m4a\n",
      "3775.m4a\n",
      "3776.m4a\n",
      "3777.m4a\n",
      "3778.m4a\n",
      "3779.m4a\n",
      "3780.m4a\n",
      "3781.m4a\n",
      "3782.m4a\n",
      "3783.m4a\n",
      "3784.m4a\n",
      "3785.m4a\n",
      "3786.m4a\n",
      "3787.m4a\n",
      "3788.m4a\n",
      "3789.m4a\n",
      "3790.m4a\n",
      "3791.m4a\n",
      "3792.m4a\n",
      "3793.m4a\n",
      "3794.m4a\n",
      "3795.m4a\n",
      "3796.m4a\n",
      "3797.m4a\n",
      "3798.m4a\n",
      "3799.m4a\n",
      "3800.m4a\n",
      "3801.m4a\n",
      "3802.m4a\n",
      "3803.m4a\n",
      "3804.m4a\n",
      "3805.m4a\n",
      "3806.m4a\n",
      "3807.m4a\n",
      "3808.m4a\n",
      "3809.m4a\n",
      "3810.m4a\n",
      "3811.m4a\n",
      "3812.m4a\n",
      "3813.m4a\n",
      "3814.m4a\n",
      "3815.m4a\n",
      "3816.m4a\n",
      "3817.m4a\n",
      "3818.m4a\n",
      "3819.m4a\n",
      "3820.m4a\n",
      "3821.m4a\n",
      "3822.m4a\n",
      "3823.m4a\n",
      "3824.m4a\n",
      "3825.m4a\n",
      "3826.m4a\n",
      "3827.m4a\n",
      "3828.m4a\n",
      "3829.m4a\n",
      "3830.m4a\n",
      "3831.m4a\n",
      "3832.m4a\n",
      "3833.m4a\n",
      "3834.m4a\n",
      "3835.m4a\n",
      "3836.m4a\n",
      "3837.m4a\n",
      "3838.m4a\n",
      "3839.m4a\n",
      "3840.m4a\n",
      "3841.m4a\n",
      "3842.m4a\n",
      "3843.m4a\n",
      "3844.m4a\n",
      "3845.m4a\n",
      "3846.m4a\n",
      "3847.m4a\n",
      "3848.m4a\n",
      "3849.m4a\n",
      "3850.m4a\n",
      "3851.m4a\n",
      "3852.m4a\n",
      "3853.m4a\n",
      "3854.m4a\n",
      "3855.m4a\n",
      "3856.m4a\n",
      "3857.m4a\n",
      "3858.m4a\n",
      "3859.m4a\n",
      "3860.m4a\n",
      "3861.m4a\n",
      "3862.m4a\n",
      "3863.m4a\n",
      "3864.m4a\n",
      "3865.m4a\n",
      "3866.m4a\n",
      "3867.m4a\n",
      "3868.m4a\n",
      "3869.m4a\n",
      "3870.m4a\n",
      "3871.m4a\n",
      "3872.m4a\n",
      "3873.m4a\n",
      "3874.m4a\n",
      "3875.m4a\n",
      "3876.m4a\n",
      "3877.m4a\n",
      "3878.m4a\n",
      "3879.m4a\n",
      "3880.m4a\n",
      "3881.m4a\n",
      "3882.m4a\n",
      "3883.m4a\n",
      "3884.m4a\n",
      "3885.m4a\n",
      "3886.m4a\n",
      "3887.m4a\n",
      "3888.m4a\n",
      "3889.m4a\n",
      "3890.m4a\n",
      "3891.m4a\n",
      "3892.m4a\n",
      "3893.m4a\n",
      "3894.m4a\n",
      "3895.m4a\n",
      "3896.m4a\n",
      "3897.m4a\n",
      "3898.m4a\n",
      "3899.m4a\n",
      "3900.m4a\n",
      "3901.m4a\n",
      "3902.m4a\n",
      "3903.m4a\n",
      "3904.m4a\n",
      "3905.m4a\n",
      "3906.m4a\n",
      "3907.m4a\n",
      "3908.m4a\n",
      "3909.m4a\n",
      "3910.m4a\n",
      "3911.m4a\n",
      "3912.m4a\n",
      "3913.m4a\n",
      "3914.m4a\n",
      "3915.m4a\n",
      "3916.m4a\n",
      "3917.m4a\n",
      "3918.m4a\n",
      "3919.m4a\n",
      "3920.m4a\n",
      "3921.m4a\n",
      "3922.m4a\n",
      "3923.m4a\n",
      "3924.m4a\n",
      "3925.m4a\n",
      "3926.m4a\n",
      "3927.m4a\n",
      "3928.m4a\n",
      "3929.m4a\n",
      "3930.m4a\n",
      "3931.m4a\n",
      "3932.m4a\n",
      "3933.m4a\n",
      "3934.m4a\n",
      "3935.m4a\n",
      "3936.m4a\n",
      "3937.m4a\n",
      "3938.m4a\n",
      "3939.m4a\n",
      "3940.m4a\n",
      "3941.m4a\n",
      "3942.m4a\n",
      "3943.m4a\n",
      "3944.m4a\n",
      "3945.m4a\n",
      "3946.m4a\n",
      "3947.m4a\n",
      "3948.m4a\n",
      "3949.m4a\n",
      "3950.m4a\n",
      "3951.m4a\n",
      "3952.m4a\n",
      "3953.m4a\n",
      "3954.m4a\n",
      "3955.m4a\n",
      "3956.m4a\n",
      "3957.m4a\n",
      "3958.m4a\n",
      "3959.m4a\n",
      "3960.m4a\n",
      "3961.m4a\n",
      "3962.m4a\n",
      "3963.m4a\n",
      "3964.m4a\n",
      "3965.m4a\n",
      "3966.m4a\n",
      "3967.m4a\n",
      "3968.m4a\n",
      "3969.m4a\n",
      "3970.m4a\n",
      "3971.m4a\n",
      "3972.m4a\n",
      "3973.m4a\n",
      "3974.m4a\n",
      "3975.m4a\n",
      "3976.m4a\n",
      "3977.m4a\n",
      "3978.m4a\n",
      "3979.m4a\n",
      "3980.m4a\n",
      "3981.m4a\n",
      "3982.m4a\n",
      "3983.m4a\n",
      "3984.m4a\n",
      "3985.m4a\n",
      "3986.m4a\n",
      "3987.m4a\n",
      "3988.m4a\n",
      "3989.m4a\n",
      "3990.m4a\n",
      "3991.m4a\n",
      "3992.m4a\n",
      "3993.m4a\n",
      "3994.m4a\n",
      "3995.m4a\n",
      "3996.m4a\n",
      "3997.m4a\n",
      "3998.m4a\n",
      "3999.m4a\n",
      "4000.m4a\n",
      "4001.m4a\n",
      "4002.m4a\n",
      "4003.m4a\n",
      "4004.m4a\n",
      "4005.m4a\n",
      "4006.m4a\n",
      "4007.m4a\n",
      "4008.m4a\n",
      "4009.m4a\n",
      "4010.m4a\n",
      "4011.m4a\n",
      "4012.m4a\n",
      "4013.m4a\n",
      "4014.m4a\n",
      "4015.m4a\n",
      "4016.m4a\n",
      "4017.m4a\n",
      "4018.m4a\n",
      "4019.m4a\n",
      "4020.m4a\n",
      "4021.m4a\n",
      "4022.m4a\n",
      "4023.m4a\n",
      "4024.m4a\n",
      "4025.m4a\n",
      "4026.m4a\n",
      "4027.m4a\n",
      "4028.m4a\n",
      "4029.m4a\n",
      "4030.m4a\n",
      "4031.m4a\n",
      "4032.m4a\n",
      "4033.m4a\n",
      "4034.m4a\n",
      "4035.m4a\n",
      "4036.m4a\n",
      "4037.m4a\n",
      "4038.m4a\n",
      "4039.m4a\n",
      "4040.m4a\n",
      "4041.m4a\n",
      "4042.m4a\n",
      "4043.m4a\n",
      "4044.m4a\n",
      "4045.m4a\n",
      "4046.m4a\n",
      "4047.m4a\n",
      "4048.m4a\n",
      "4049.m4a\n",
      "4050.m4a\n",
      "4051.m4a\n",
      "4052.m4a\n",
      "4053.m4a\n",
      "4054.m4a\n",
      "4055.m4a\n",
      "4056.m4a\n",
      "4057.m4a\n",
      "4058.m4a\n",
      "4059.m4a\n",
      "4060.m4a\n",
      "4061.m4a\n",
      "4062.m4a\n",
      "4063.m4a\n",
      "4064.m4a\n",
      "4065.m4a\n",
      "4066.m4a\n",
      "4067.m4a\n",
      "4068.m4a\n",
      "4069.m4a\n",
      "4070.m4a\n",
      "4071.m4a\n",
      "4072.m4a\n",
      "4073.m4a\n",
      "4074.m4a\n",
      "4075.m4a\n",
      "4076.m4a\n",
      "4077.m4a\n",
      "4078.m4a\n",
      "4079.m4a\n",
      "4080.m4a\n",
      "4081.m4a\n",
      "4082.m4a\n",
      "4083.m4a\n",
      "4084.m4a\n",
      "4085.m4a\n",
      "4086.m4a\n",
      "4087.m4a\n",
      "4088.m4a\n",
      "4089.m4a\n",
      "4090.m4a\n",
      "4091.m4a\n",
      "4092.m4a\n",
      "4093.m4a\n",
      "4094.m4a\n",
      "4095.m4a\n",
      "4096.m4a\n",
      "4097.m4a\n",
      "4098.m4a\n",
      "4099.m4a\n",
      "4100.m4a\n",
      "4101.m4a\n",
      "4102.m4a\n",
      "4103.m4a\n",
      "4104.m4a\n",
      "4105.m4a\n",
      "4106.m4a\n",
      "4107.m4a\n",
      "4108.m4a\n",
      "4109.m4a\n",
      "4110.m4a\n",
      "4111.m4a\n",
      "4112.m4a\n",
      "4113.m4a\n",
      "4114.m4a\n",
      "4115.m4a\n",
      "4116.m4a\n",
      "4117.m4a\n",
      "4118.m4a\n",
      "4119.m4a\n",
      "4120.m4a\n",
      "4121.m4a\n",
      "4122.m4a\n",
      "4123.m4a\n",
      "4124.m4a\n",
      "4125.m4a\n",
      "4126.m4a\n",
      "4127.m4a\n",
      "4128.m4a\n",
      "4129.m4a\n",
      "4130.m4a\n",
      "4131.m4a\n",
      "4132.m4a\n",
      "4133.m4a\n",
      "4134.m4a\n",
      "4135.m4a\n",
      "4136.m4a\n",
      "4137.m4a\n",
      "4138.m4a\n",
      "4139.m4a\n",
      "4140.m4a\n",
      "4141.m4a\n",
      "4142.m4a\n",
      "4143.m4a\n",
      "4144.m4a\n",
      "4145.m4a\n",
      "4146.m4a\n",
      "4147.m4a\n",
      "4148.m4a\n",
      "4149.m4a\n",
      "4150.m4a\n",
      "4151.m4a\n",
      "4152.m4a\n",
      "4153.m4a\n",
      "4154.m4a\n",
      "4155.m4a\n",
      "4156.m4a\n",
      "4157.m4a\n",
      "4158.m4a\n",
      "4159.m4a\n",
      "4160.m4a\n",
      "4161.m4a\n",
      "4162.m4a\n",
      "4163.m4a\n",
      "4164.m4a\n",
      "4165.m4a\n",
      "4166.m4a\n",
      "4167.m4a\n",
      "4168.m4a\n",
      "4169.m4a\n",
      "4170.m4a\n",
      "4171.m4a\n",
      "4172.m4a\n",
      "4173.m4a\n",
      "4174.m4a\n",
      "4175.m4a\n",
      "4176.m4a\n",
      "4177.m4a\n",
      "4178.m4a\n",
      "4179.m4a\n",
      "4180.m4a\n",
      "4181.m4a\n",
      "4182.m4a\n",
      "4183.m4a\n",
      "4184.m4a\n",
      "4185.m4a\n",
      "4186.m4a\n",
      "4187.m4a\n",
      "4188.m4a\n",
      "4189.m4a\n",
      "4190.m4a\n",
      "4191.m4a\n",
      "4192.m4a\n",
      "4193.m4a\n",
      "4194.m4a\n",
      "4195.m4a\n",
      "4196.m4a\n",
      "4197.m4a\n",
      "4198.m4a\n",
      "4199.m4a\n",
      "4200.m4a\n",
      "4201.m4a\n",
      "4202.m4a\n",
      "4203.m4a\n",
      "4204.m4a\n",
      "4205.m4a\n",
      "4206.m4a\n",
      "4207.m4a\n",
      "4208.m4a\n",
      "4209.m4a\n",
      "4210.m4a\n",
      "4211.m4a\n",
      "4212.m4a\n",
      "4213.m4a\n",
      "4214.m4a\n",
      "4215.m4a\n",
      "4216.m4a\n",
      "4217.m4a\n",
      "4218.m4a\n",
      "4219.m4a\n",
      "4220.m4a\n",
      "4221.m4a\n",
      "4222.m4a\n",
      "4223.m4a\n",
      "4224.m4a\n",
      "4225.m4a\n",
      "4226.m4a\n",
      "4227.m4a\n",
      "4228.m4a\n",
      "4229.m4a\n",
      "4230.m4a\n",
      "4231.m4a\n",
      "4232.m4a\n",
      "4233.m4a\n",
      "4234.m4a\n",
      "4235.m4a\n",
      "4236.m4a\n",
      "4237.m4a\n",
      "4238.m4a\n",
      "4239.m4a\n",
      "4240.m4a\n",
      "4241.m4a\n",
      "4242.m4a\n",
      "4243.m4a\n",
      "4244.m4a\n",
      "4245.m4a\n",
      "4246.m4a\n",
      "4247.m4a\n",
      "4248.m4a\n",
      "4249.m4a\n",
      "4250.m4a\n",
      "4251.m4a\n",
      "4252.m4a\n",
      "4253.m4a\n",
      "4254.m4a\n",
      "4255.m4a\n",
      "4256.m4a\n",
      "4257.m4a\n",
      "4258.m4a\n",
      "4259.m4a\n",
      "4260.m4a\n",
      "4261.m4a\n",
      "4262.m4a\n",
      "4263.m4a\n",
      "4264.m4a\n",
      "4265.m4a\n",
      "4266.m4a\n",
      "4267.m4a\n",
      "4268.m4a\n",
      "4269.m4a\n",
      "4270.m4a\n",
      "4271.m4a\n",
      "4272.m4a\n",
      "4273.m4a\n",
      "4274.m4a\n",
      "4275.m4a\n",
      "4276.m4a\n",
      "4277.m4a\n",
      "4278.m4a\n",
      "4279.m4a\n",
      "4280.m4a\n",
      "4281.m4a\n",
      "4282.m4a\n",
      "4283.m4a\n",
      "4284.m4a\n",
      "4285.m4a\n",
      "4286.m4a\n",
      "4287.m4a\n",
      "4288.m4a\n",
      "4289.m4a\n",
      "4290.m4a\n",
      "4291.m4a\n",
      "4292.m4a\n",
      "4293.m4a\n",
      "4294.m4a\n",
      "4295.m4a\n",
      "4296.m4a\n",
      "4297.m4a\n",
      "4298.m4a\n",
      "4299.m4a\n",
      "4300.m4a\n",
      "4301.m4a\n",
      "4302.m4a\n",
      "4303.m4a\n",
      "4304.m4a\n",
      "4305.m4a\n",
      "4306.m4a\n",
      "4307.m4a\n",
      "4308.m4a\n",
      "4309.m4a\n",
      "4310.m4a\n",
      "4311.m4a\n",
      "4312.m4a\n",
      "4313.m4a\n",
      "4314.m4a\n",
      "4315.m4a\n",
      "4316.m4a\n",
      "4317.m4a\n",
      "4318.m4a\n",
      "4319.m4a\n",
      "4320.m4a\n",
      "4321.m4a\n",
      "4322.m4a\n",
      "4323.m4a\n",
      "4324.m4a\n",
      "4325.m4a\n",
      "4326.m4a\n",
      "4327.m4a\n",
      "4328.m4a\n",
      "4329.m4a\n",
      "4330.m4a\n",
      "4331.m4a\n",
      "4332.m4a\n",
      "4333.m4a\n",
      "4334.m4a\n",
      "4335.m4a\n",
      "4336.m4a\n",
      "4337.m4a\n",
      "4338.m4a\n",
      "4339.m4a\n",
      "4340.m4a\n",
      "4341.m4a\n",
      "4342.m4a\n",
      "4343.m4a\n",
      "4344.m4a\n",
      "4345.m4a\n",
      "4346.m4a\n",
      "4347.m4a\n",
      "4348.m4a\n",
      "4349.m4a\n",
      "4350.m4a\n",
      "4351.m4a\n",
      "4352.m4a\n",
      "4353.m4a\n",
      "4354.m4a\n",
      "4355.m4a\n",
      "4356.m4a\n",
      "4357.m4a\n",
      "4358.m4a\n",
      "4359.m4a\n",
      "4360.m4a\n",
      "4361.m4a\n",
      "4362.m4a\n",
      "4363.m4a\n",
      "4364.m4a\n",
      "4365.m4a\n",
      "4366.m4a\n",
      "4367.m4a\n",
      "4368.m4a\n",
      "4369.m4a\n",
      "4370.m4a\n",
      "4371.m4a\n",
      "4372.m4a\n",
      "4373.m4a\n",
      "4374.m4a\n",
      "4375.m4a\n",
      "4376.m4a\n",
      "4377.m4a\n",
      "4378.m4a\n",
      "4379.m4a\n",
      "4380.m4a\n",
      "4381.m4a\n",
      "4382.m4a\n",
      "4383.m4a\n",
      "4384.m4a\n",
      "4385.m4a\n",
      "4386.m4a\n",
      "4387.m4a\n",
      "4388.m4a\n",
      "4389.m4a\n",
      "4390.m4a\n",
      "4391.m4a\n",
      "4392.m4a\n",
      "4393.m4a\n",
      "4394.m4a\n",
      "4395.m4a\n",
      "4396.m4a\n",
      "4397.m4a\n",
      "4398.m4a\n",
      "4399.m4a\n",
      "4400.m4a\n",
      "4401.m4a\n",
      "4402.m4a\n",
      "4403.m4a\n",
      "4404.m4a\n",
      "4405.m4a\n",
      "4406.m4a\n",
      "4407.m4a\n",
      "4408.m4a\n",
      "4409.m4a\n",
      "4410.m4a\n",
      "4411.m4a\n",
      "4412.m4a\n",
      "4413.m4a\n",
      "4414.m4a\n",
      "4415.m4a\n",
      "4416.m4a\n",
      "4417.m4a\n",
      "4418.m4a\n",
      "4419.m4a\n",
      "4420.m4a\n",
      "4421.m4a\n",
      "4422.m4a\n",
      "4423.m4a\n",
      "4424.m4a\n",
      "4425.m4a\n",
      "4426.m4a\n",
      "4427.m4a\n",
      "4428.m4a\n",
      "4429.m4a\n",
      "4430.m4a\n",
      "4431.m4a\n",
      "4432.m4a\n",
      "4433.m4a\n",
      "4434.m4a\n",
      "4435.m4a\n",
      "4436.m4a\n",
      "4437.m4a\n",
      "4438.m4a\n",
      "4439.m4a\n",
      "4440.m4a\n",
      "4441.m4a\n",
      "4442.m4a\n",
      "4443.m4a\n",
      "4444.m4a\n",
      "4445.m4a\n",
      "4446.m4a\n",
      "4447.m4a\n",
      "4448.m4a\n",
      "4449.m4a\n",
      "4450.m4a\n",
      "4451.m4a\n",
      "4452.m4a\n",
      "4453.m4a\n",
      "4454.m4a\n",
      "4455.m4a\n",
      "4456.m4a\n",
      "4457.m4a\n",
      "4458.m4a\n",
      "4459.m4a\n",
      "4460.m4a\n",
      "4461.m4a\n",
      "4462.m4a\n",
      "4463.m4a\n",
      "4464.m4a\n",
      "4465.m4a\n",
      "4466.m4a\n",
      "4467.m4a\n",
      "4468.m4a\n",
      "4469.m4a\n",
      "4470.m4a\n",
      "4471.m4a\n",
      "4472.m4a\n",
      "4473.m4a\n",
      "4474.m4a\n",
      "4475.m4a\n",
      "4476.m4a\n",
      "4477.m4a\n",
      "4478.m4a\n",
      "4479.m4a\n",
      "4480.m4a\n",
      "4481.m4a\n",
      "4482.m4a\n",
      "4483.m4a\n",
      "4484.m4a\n",
      "4485.m4a\n",
      "4486.m4a\n",
      "4487.m4a\n",
      "4488.m4a\n",
      "4489.m4a\n",
      "4490.m4a\n",
      "4491.m4a\n",
      "4492.m4a\n",
      "4493.m4a\n",
      "4494.m4a\n",
      "4495.m4a\n",
      "4496.m4a\n",
      "4497.m4a\n",
      "4498.m4a\n",
      "4499.m4a\n",
      "4500.m4a\n",
      "4501.m4a\n",
      "4502.m4a\n",
      "4503.m4a\n",
      "4504.m4a\n",
      "4505.m4a\n",
      "4506.m4a\n",
      "4507.m4a\n",
      "4508.m4a\n",
      "4509.m4a\n",
      "4510.m4a\n",
      "4511.m4a\n",
      "4512.m4a\n",
      "4513.m4a\n",
      "4514.m4a\n",
      "4515.m4a\n",
      "4516.m4a\n",
      "4517.m4a\n",
      "4518.m4a\n",
      "4519.m4a\n",
      "4520.m4a\n",
      "4521.m4a\n",
      "4522.m4a\n",
      "4523.m4a\n",
      "4524.m4a\n",
      "4525.m4a\n",
      "4526.m4a\n",
      "4527.m4a\n",
      "4528.m4a\n",
      "4529.m4a\n",
      "4530.m4a\n",
      "4531.m4a\n",
      "4532.m4a\n",
      "4533.m4a\n",
      "4534.m4a\n",
      "4535.m4a\n",
      "4536.m4a\n",
      "4537.m4a\n",
      "4538.m4a\n",
      "4539.m4a\n",
      "4540.m4a\n",
      "4541.m4a\n",
      "4542.m4a\n",
      "4543.m4a\n",
      "4544.m4a\n",
      "4545.m4a\n",
      "4546.m4a\n",
      "4547.m4a\n",
      "4548.m4a\n",
      "4549.m4a\n",
      "4550.m4a\n",
      "4551.m4a\n",
      "4552.m4a\n",
      "4553.m4a\n",
      "4554.m4a\n",
      "4555.m4a\n",
      "4556.m4a\n",
      "4557.m4a\n",
      "4558.m4a\n",
      "4559.m4a\n",
      "4560.m4a\n",
      "4561.m4a\n",
      "4562.m4a\n",
      "4563.m4a\n",
      "4564.m4a\n",
      "4565.m4a\n",
      "4566.m4a\n",
      "4567.m4a\n",
      "4568.m4a\n",
      "4569.m4a\n",
      "4570.m4a\n",
      "4571.m4a\n",
      "4572.m4a\n",
      "4573.m4a\n",
      "4574.m4a\n",
      "4575.m4a\n",
      "4576.m4a\n",
      "4577.m4a\n",
      "4578.m4a\n",
      "4579.m4a\n",
      "4580.m4a\n",
      "4581.m4a\n",
      "4582.m4a\n",
      "4583.m4a\n",
      "4584.m4a\n",
      "4585.m4a\n",
      "4586.m4a\n",
      "4587.m4a\n",
      "4588.m4a\n",
      "4589.m4a\n",
      "4590.m4a\n",
      "4591.m4a\n",
      "4592.m4a\n",
      "4593.m4a\n",
      "4594.m4a\n",
      "4595.m4a\n",
      "4596.m4a\n",
      "4597.m4a\n",
      "4598.m4a\n",
      "4599.m4a\n",
      "4600.m4a\n",
      "4601.m4a\n",
      "4602.m4a\n",
      "4603.m4a\n",
      "4604.m4a\n",
      "4605.m4a\n",
      "4606.m4a\n",
      "4607.m4a\n",
      "4608.m4a\n",
      "4609.m4a\n",
      "4610.m4a\n",
      "4611.m4a\n",
      "4612.m4a\n",
      "4613.m4a\n",
      "4614.m4a\n",
      "4615.m4a\n",
      "4616.m4a\n",
      "4617.m4a\n",
      "4618.m4a\n",
      "4619.m4a\n",
      "4620.m4a\n",
      "4621.m4a\n",
      "4622.m4a\n",
      "4623.m4a\n",
      "4624.m4a\n",
      "4625.m4a\n",
      "4626.m4a\n",
      "4627.m4a\n",
      "4628.m4a\n",
      "4629.m4a\n",
      "4630.m4a\n",
      "4631.m4a\n",
      "4632.m4a\n",
      "4633.m4a\n",
      "4634.m4a\n",
      "4635.m4a\n",
      "4636.m4a\n",
      "4637.m4a\n",
      "4638.m4a\n",
      "4639.m4a\n",
      "4640.m4a\n",
      "4641.m4a\n",
      "4642.m4a\n",
      "4643.m4a\n",
      "4644.m4a\n",
      "4645.m4a\n",
      "4646.m4a\n",
      "4647.m4a\n",
      "4648.m4a\n",
      "4649.m4a\n",
      "4650.m4a\n",
      "4651.m4a\n",
      "4652.m4a\n",
      "4653.m4a\n",
      "4654.m4a\n",
      "4655.m4a\n",
      "4656.m4a\n",
      "4657.m4a\n",
      "4658.m4a\n",
      "4659.m4a\n",
      "4660.m4a\n",
      "4661.m4a\n",
      "4662.m4a\n",
      "4663.m4a\n",
      "4664.m4a\n",
      "4665.m4a\n",
      "4666.m4a\n",
      "4667.m4a\n",
      "4668.m4a\n",
      "4669.m4a\n",
      "4670.m4a\n",
      "4671.m4a\n",
      "4672.m4a\n",
      "4673.m4a\n",
      "4674.m4a\n",
      "4675.m4a\n",
      "4676.m4a\n",
      "4677.m4a\n",
      "4678.m4a\n",
      "4679.m4a\n",
      "4680.m4a\n",
      "4681.m4a\n",
      "4682.m4a\n",
      "4683.m4a\n",
      "4684.m4a\n",
      "4685.m4a\n",
      "4686.m4a\n",
      "4687.m4a\n",
      "4688.m4a\n",
      "4689.m4a\n",
      "4690.m4a\n",
      "4691.m4a\n",
      "4692.m4a\n",
      "4693.m4a\n",
      "4694.m4a\n",
      "4695.m4a\n",
      "4696.m4a\n",
      "4697.m4a\n",
      "4698.m4a\n",
      "4699.m4a\n",
      "4700.m4a\n",
      "4701.m4a\n",
      "4702.m4a\n",
      "4703.m4a\n",
      "4704.m4a\n",
      "4705.m4a\n",
      "4706.m4a\n",
      "4707.m4a\n",
      "4708.m4a\n",
      "4709.m4a\n",
      "4710.m4a\n",
      "4711.m4a\n",
      "4712.m4a\n",
      "4713.m4a\n",
      "4714.m4a\n",
      "4715.m4a\n",
      "4716.m4a\n",
      "4717.m4a\n",
      "4718.m4a\n",
      "4719.m4a\n",
      "4720.m4a\n",
      "4721.m4a\n",
      "4722.m4a\n",
      "4723.m4a\n",
      "4724.m4a\n",
      "4725.m4a\n",
      "4726.m4a\n",
      "4727.m4a\n",
      "4728.m4a\n",
      "4729.m4a\n",
      "4730.m4a\n",
      "4731.m4a\n",
      "4732.m4a\n",
      "4733.m4a\n",
      "4734.m4a\n",
      "4735.m4a\n",
      "4736.m4a\n",
      "4737.m4a\n",
      "4738.m4a\n",
      "4739.m4a\n",
      "4740.m4a\n",
      "4741.m4a\n",
      "4742.m4a\n",
      "4743.m4a\n",
      "4744.m4a\n",
      "4745.m4a\n",
      "4746.m4a\n",
      "4747.m4a\n",
      "4748.m4a\n",
      "4749.m4a\n",
      "4750.m4a\n",
      "4751.m4a\n",
      "4752.m4a\n",
      "4753.m4a\n",
      "4754.m4a\n",
      "4755.m4a\n",
      "4756.m4a\n",
      "4757.m4a\n",
      "4758.m4a\n",
      "4759.m4a\n",
      "4760.m4a\n",
      "4761.m4a\n",
      "4762.m4a\n",
      "4763.m4a\n",
      "4764.m4a\n",
      "4765.m4a\n",
      "4766.m4a\n",
      "4767.m4a\n",
      "4768.m4a\n",
      "4769.m4a\n",
      "4770.m4a\n",
      "4771.m4a\n",
      "4772.m4a\n",
      "4773.m4a\n",
      "4774.m4a\n",
      "4775.m4a\n",
      "4776.m4a\n",
      "4777.m4a\n",
      "4778.m4a\n",
      "4779.m4a\n",
      "4780.m4a\n",
      "4781.m4a\n",
      "4782.m4a\n",
      "4783.m4a\n",
      "4784.m4a\n",
      "4785.m4a\n",
      "4786.m4a\n",
      "4787.m4a\n",
      "4788.m4a\n",
      "4789.m4a\n",
      "4790.m4a\n",
      "4791.m4a\n",
      "4792.m4a\n",
      "4793.m4a\n",
      "4794.m4a\n",
      "4795.m4a\n",
      "4796.m4a\n",
      "4797.m4a\n",
      "4798.m4a\n",
      "4799.m4a\n",
      "4800.m4a\n",
      "4801.m4a\n",
      "4802.m4a\n",
      "4803.m4a\n",
      "4804.m4a\n",
      "4805.m4a\n",
      "4806.m4a\n",
      "4807.m4a\n",
      "4808.m4a\n",
      "4809.m4a\n",
      "4810.m4a\n",
      "4811.m4a\n",
      "4812.m4a\n",
      "4813.m4a\n",
      "4814.m4a\n",
      "4815.m4a\n",
      "4816.m4a\n",
      "4817.m4a\n",
      "4818.m4a\n",
      "4819.m4a\n",
      "4820.m4a\n",
      "4821.m4a\n",
      "4822.m4a\n",
      "4823.m4a\n",
      "4824.m4a\n",
      "4825.m4a\n",
      "4826.m4a\n",
      "4827.m4a\n",
      "4828.m4a\n",
      "4829.m4a\n",
      "4830.m4a\n",
      "4831.m4a\n",
      "4832.m4a\n",
      "4833.m4a\n",
      "4834.m4a\n",
      "4835.m4a\n",
      "4836.m4a\n",
      "4837.m4a\n",
      "4838.m4a\n",
      "4839.m4a\n",
      "4840.m4a\n",
      "4841.m4a\n",
      "4842.m4a\n",
      "4843.m4a\n",
      "4844.m4a\n",
      "4845.m4a\n",
      "4846.m4a\n",
      "4847.m4a\n",
      "4848.m4a\n",
      "4849.m4a\n",
      "4850.m4a\n",
      "4851.m4a\n",
      "4852.m4a\n",
      "4853.m4a\n",
      "4854.m4a\n",
      "4855.m4a\n",
      "4856.m4a\n",
      "4857.m4a\n",
      "4858.m4a\n",
      "4859.m4a\n",
      "4860.m4a\n",
      "4861.m4a\n",
      "4862.m4a\n",
      "4863.m4a\n",
      "4864.m4a\n",
      "4865.m4a\n",
      "4866.m4a\n",
      "4867.m4a\n",
      "4868.m4a\n",
      "4869.m4a\n",
      "4870.m4a\n",
      "4871.m4a\n",
      "4872.m4a\n",
      "4873.m4a\n",
      "4874.m4a\n",
      "4875.m4a\n",
      "4876.m4a\n",
      "4877.m4a\n",
      "4878.m4a\n",
      "4879.m4a\n",
      "4880.m4a\n",
      "4881.m4a\n",
      "4882.m4a\n",
      "4883.m4a\n",
      "4884.m4a\n",
      "4885.m4a\n",
      "4886.m4a\n",
      "4887.m4a\n",
      "4888.m4a\n",
      "4889.m4a\n",
      "4890.m4a\n",
      "4891.m4a\n",
      "4892.m4a\n",
      "4893.m4a\n",
      "4894.m4a\n",
      "4895.m4a\n",
      "4896.m4a\n",
      "4897.m4a\n",
      "4898.m4a\n",
      "4899.m4a\n",
      "4900.m4a\n",
      "4901.m4a\n",
      "4902.m4a\n",
      "4903.m4a\n",
      "4904.m4a\n",
      "4905.m4a\n",
      "4906.m4a\n",
      "4907.m4a\n",
      "4908.m4a\n",
      "4909.m4a\n",
      "4910.m4a\n",
      "4911.m4a\n",
      "4912.m4a\n",
      "4913.m4a\n",
      "4914.m4a\n",
      "4915.m4a\n",
      "4916.m4a\n",
      "4917.m4a\n",
      "4918.m4a\n",
      "4919.m4a\n",
      "4920.m4a\n",
      "4921.m4a\n",
      "4922.m4a\n",
      "4923.m4a\n",
      "4924.m4a\n",
      "4925.m4a\n",
      "4926.m4a\n",
      "4927.m4a\n",
      "4928.m4a\n",
      "4929.m4a\n",
      "4930.m4a\n",
      "4931.m4a\n",
      "4932.m4a\n",
      "4933.m4a\n",
      "4934.m4a\n",
      "4935.m4a\n",
      "4936.m4a\n",
      "4937.m4a\n",
      "4938.m4a\n",
      "4939.m4a\n",
      "4940.m4a\n",
      "4941.m4a\n",
      "4942.m4a\n",
      "4943.m4a\n",
      "4944.m4a\n",
      "4945.m4a\n",
      "4946.m4a\n",
      "4947.m4a\n",
      "4948.m4a\n",
      "4949.m4a\n",
      "4950.m4a\n",
      "4951.m4a\n",
      "4952.m4a\n",
      "4953.m4a\n",
      "4954.m4a\n",
      "4955.m4a\n",
      "4956.m4a\n",
      "4957.m4a\n",
      "4958.m4a\n",
      "4959.m4a\n",
      "4960.m4a\n",
      "4961.m4a\n",
      "4962.m4a\n",
      "4963.m4a\n",
      "4964.m4a\n",
      "4965.m4a\n",
      "4966.m4a\n",
      "4967.m4a\n",
      "4968.m4a\n",
      "4969.m4a\n",
      "4970.m4a\n",
      "4971.m4a\n",
      "4972.m4a\n",
      "4973.m4a\n",
      "4974.m4a\n",
      "4975.m4a\n",
      "4976.m4a\n",
      "4977.m4a\n",
      "4978.m4a\n",
      "4979.m4a\n",
      "4980.m4a\n",
      "4981.m4a\n",
      "4982.m4a\n",
      "4983.m4a\n",
      "4984.m4a\n",
      "4985.m4a\n",
      "4986.m4a\n",
      "4987.m4a\n",
      "4988.m4a\n",
      "4989.m4a\n",
      "4990.m4a\n",
      "4991.m4a\n",
      "4992.m4a\n",
      "4993.m4a\n",
      "4994.m4a\n",
      "4995.m4a\n",
      "4996.m4a\n",
      "4997.m4a\n",
      "4998.m4a\n",
      "4999.m4a\n",
      "5000.m4a\n",
      "5001.m4a\n",
      "5002.m4a\n",
      "5003.m4a\n",
      "5004.m4a\n",
      "5005.m4a\n",
      "5006.m4a\n",
      "5007.m4a\n",
      "5008.m4a\n",
      "5009.m4a\n",
      "5010.m4a\n",
      "5011.m4a\n",
      "5012.m4a\n",
      "5013.m4a\n",
      "5014.m4a\n",
      "5015.m4a\n",
      "5016.m4a\n",
      "5017.m4a\n",
      "5018.m4a\n",
      "5019.m4a\n",
      "5020.m4a\n",
      "5021.m4a\n",
      "5022.m4a\n",
      "5023.m4a\n",
      "5024.m4a\n",
      "5025.m4a\n",
      "5026.m4a\n",
      "5027.m4a\n",
      "5028.m4a\n",
      "5029.m4a\n",
      "5030.m4a\n",
      "5031.m4a\n",
      "5032.m4a\n",
      "5033.m4a\n",
      "5034.m4a\n",
      "5035.m4a\n",
      "5036.m4a\n",
      "5037.m4a\n",
      "5038.m4a\n",
      "5039.m4a\n",
      "5040.m4a\n",
      "5041.m4a\n",
      "5042.m4a\n",
      "5043.m4a\n",
      "5044.m4a\n",
      "5045.m4a\n",
      "5046.m4a\n",
      "5047.m4a\n",
      "5048.m4a\n",
      "5049.m4a\n",
      "5050.m4a\n",
      "5051.m4a\n",
      "5052.m4a\n",
      "5053.m4a\n",
      "5054.m4a\n",
      "5055.m4a\n",
      "5056.m4a\n",
      "5057.m4a\n",
      "5058.m4a\n",
      "5059.m4a\n",
      "5060.m4a\n",
      "5061.m4a\n",
      "5062.m4a\n",
      "5063.m4a\n",
      "5064.m4a\n",
      "5065.m4a\n",
      "5066.m4a\n",
      "5067.m4a\n",
      "5068.m4a\n",
      "5069.m4a\n",
      "5070.m4a\n",
      "5071.m4a\n",
      "5072.m4a\n",
      "5073.m4a\n",
      "5074.m4a\n",
      "5075.m4a\n",
      "5076.m4a\n",
      "5077.m4a\n",
      "5078.m4a\n",
      "5079.m4a\n",
      "5080.m4a\n",
      "5081.m4a\n",
      "5082.m4a\n",
      "5083.m4a\n",
      "5084.m4a\n",
      "5085.m4a\n",
      "5086.m4a\n",
      "5087.m4a\n",
      "5088.m4a\n",
      "5089.m4a\n",
      "5090.m4a\n",
      "5091.m4a\n",
      "5092.m4a\n",
      "5093.m4a\n",
      "5094.m4a\n",
      "5095.m4a\n",
      "5096.m4a\n",
      "5097.m4a\n",
      "5098.m4a\n",
      "5099.m4a\n",
      "5100.m4a\n",
      "5101.m4a\n",
      "5102.m4a\n",
      "5103.m4a\n",
      "5104.m4a\n",
      "5105.m4a\n",
      "5106.m4a\n",
      "5107.m4a\n",
      "5108.m4a\n",
      "5109.m4a\n",
      "5110.m4a\n",
      "5111.m4a\n",
      "5112.m4a\n",
      "5113.m4a\n",
      "5114.m4a\n",
      "5115.m4a\n",
      "5116.m4a\n",
      "5117.m4a\n",
      "5118.m4a\n",
      "5119.m4a\n",
      "5120.m4a\n",
      "5121.m4a\n",
      "5122.m4a\n",
      "5123.m4a\n",
      "5124.m4a\n",
      "5125.m4a\n",
      "5126.m4a\n",
      "5127.m4a\n",
      "5128.m4a\n",
      "5129.m4a\n",
      "5130.m4a\n",
      "5131.m4a\n",
      "5132.m4a\n",
      "5133.m4a\n",
      "5134.m4a\n",
      "5135.m4a\n",
      "5136.m4a\n",
      "5137.m4a\n",
      "5138.m4a\n",
      "5139.m4a\n",
      "5140.m4a\n",
      "5141.m4a\n",
      "5142.m4a\n",
      "5143.m4a\n",
      "5144.m4a\n",
      "5145.m4a\n",
      "5146.m4a\n",
      "5147.m4a\n",
      "5148.m4a\n",
      "5149.m4a\n",
      "5150.m4a\n",
      "5151.m4a\n",
      "5152.m4a\n",
      "5153.m4a\n",
      "5154.m4a\n",
      "5155.m4a\n",
      "5156.m4a\n",
      "5157.m4a\n",
      "5158.m4a\n",
      "5159.m4a\n",
      "5160.m4a\n",
      "5161.m4a\n",
      "5162.m4a\n",
      "5163.m4a\n",
      "5164.m4a\n",
      "5165.m4a\n",
      "5166.m4a\n",
      "5167.m4a\n",
      "5168.m4a\n",
      "5169.m4a\n",
      "5170.m4a\n",
      "5171.m4a\n",
      "5172.m4a\n",
      "5173.m4a\n",
      "5174.m4a\n",
      "5175.m4a\n",
      "5176.m4a\n",
      "5177.m4a\n",
      "5178.m4a\n",
      "5179.m4a\n",
      "5180.m4a\n",
      "5181.m4a\n",
      "5182.m4a\n",
      "5183.m4a\n",
      "5184.m4a\n",
      "5185.m4a\n",
      "5186.m4a\n",
      "5187.m4a\n",
      "5188.m4a\n",
      "5189.m4a\n",
      "5190.m4a\n",
      "5191.m4a\n",
      "5192.m4a\n",
      "5193.m4a\n",
      "5194.m4a\n",
      "5195.m4a\n",
      "5196.m4a\n",
      "5197.m4a\n",
      "5198.m4a\n",
      "5199.m4a\n",
      "5200.m4a\n",
      "5201.m4a\n",
      "5202.m4a\n",
      "5203.m4a\n",
      "5204.m4a\n",
      "5205.m4a\n",
      "5206.m4a\n",
      "5207.m4a\n",
      "5208.m4a\n",
      "5209.m4a\n",
      "5210.m4a\n",
      "5211.m4a\n",
      "5212.m4a\n",
      "5213.m4a\n",
      "5214.m4a\n",
      "5215.m4a\n",
      "5216.m4a\n",
      "5217.m4a\n",
      "5218.m4a\n",
      "5219.m4a\n",
      "5220.m4a\n",
      "5221.m4a\n",
      "5222.m4a\n",
      "5223.m4a\n",
      "5224.m4a\n",
      "5225.m4a\n",
      "5226.m4a\n",
      "5227.m4a\n",
      "5228.m4a\n",
      "5229.m4a\n",
      "5230.m4a\n",
      "5231.m4a\n",
      "5232.m4a\n",
      "5233.m4a\n",
      "5234.m4a\n",
      "5235.m4a\n",
      "5236.m4a\n",
      "5237.m4a\n",
      "5238.m4a\n",
      "5239.m4a\n",
      "5240.m4a\n",
      "5241.m4a\n",
      "5242.m4a\n",
      "5243.m4a\n",
      "5244.m4a\n",
      "5245.m4a\n",
      "5246.m4a\n",
      "5247.m4a\n",
      "5248.m4a\n",
      "5249.m4a\n",
      "5250.m4a\n",
      "5251.m4a\n",
      "5252.m4a\n",
      "5253.m4a\n",
      "5254.m4a\n",
      "5255.m4a\n",
      "5256.m4a\n",
      "5257.m4a\n",
      "5258.m4a\n",
      "5259.m4a\n",
      "5260.m4a\n",
      "5261.m4a\n",
      "5262.m4a\n",
      "5263.m4a\n",
      "5264.m4a\n",
      "5265.m4a\n",
      "5266.m4a\n",
      "5267.m4a\n",
      "5268.m4a\n",
      "5269.m4a\n",
      "5270.m4a\n",
      "5271.m4a\n",
      "5272.m4a\n",
      "5273.m4a\n",
      "5274.m4a\n",
      "5275.m4a\n",
      "5276.m4a\n",
      "5277.m4a\n",
      "5278.m4a\n",
      "5279.m4a\n",
      "5280.m4a\n",
      "5281.m4a\n",
      "5282.m4a\n",
      "5283.m4a\n",
      "5284.m4a\n",
      "5285.m4a\n",
      "5286.m4a\n",
      "5287.m4a\n",
      "5288.m4a\n",
      "5289.m4a\n",
      "5290.m4a\n",
      "5291.m4a\n",
      "5292.m4a\n",
      "5293.m4a\n",
      "5294.m4a\n",
      "5295.m4a\n",
      "5296.m4a\n",
      "5297.m4a\n",
      "5298.m4a\n",
      "5299.m4a\n",
      "5300.m4a\n",
      "5301.m4a\n",
      "5302.m4a\n",
      "5303.m4a\n",
      "5304.m4a\n",
      "5305.m4a\n",
      "5306.m4a\n",
      "5307.m4a\n",
      "5308.m4a\n",
      "5309.m4a\n",
      "5310.m4a\n",
      "5311.m4a\n",
      "5312.m4a\n",
      "5313.m4a\n",
      "5314.m4a\n",
      "5315.m4a\n",
      "5316.m4a\n",
      "5317.m4a\n",
      "5318.m4a\n",
      "5319.m4a\n",
      "5320.m4a\n",
      "5321.m4a\n",
      "5322.m4a\n",
      "5323.m4a\n",
      "5324.m4a\n",
      "5325.m4a\n",
      "5326.m4a\n",
      "5327.m4a\n",
      "5328.m4a\n",
      "5329.m4a\n",
      "5330.m4a\n",
      "5331.m4a\n",
      "5332.m4a\n",
      "5333.m4a\n",
      "5334.m4a\n",
      "5335.m4a\n",
      "5336.m4a\n",
      "5337.m4a\n",
      "5338.m4a\n",
      "5339.m4a\n",
      "5340.m4a\n",
      "5341.m4a\n",
      "5342.m4a\n",
      "5343.m4a\n",
      "5344.m4a\n",
      "5345.m4a\n",
      "5346.m4a\n",
      "5347.m4a\n",
      "5348.m4a\n",
      "5349.m4a\n",
      "5350.m4a\n",
      "5351.m4a\n",
      "5352.m4a\n",
      "5353.m4a\n",
      "5354.m4a\n",
      "5355.m4a\n",
      "5356.m4a\n",
      "5357.m4a\n",
      "5358.m4a\n",
      "5359.m4a\n",
      "5360.m4a\n",
      "5361.m4a\n",
      "5362.m4a\n",
      "5363.m4a\n",
      "5364.m4a\n",
      "5365.m4a\n",
      "5366.m4a\n",
      "5367.m4a\n",
      "5368.m4a\n",
      "5369.m4a\n",
      "5370.m4a\n",
      "5371.m4a\n",
      "5372.m4a\n",
      "5373.m4a\n",
      "5374.m4a\n",
      "5375.m4a\n",
      "5376.m4a\n",
      "5377.m4a\n",
      "5378.m4a\n",
      "5379.m4a\n",
      "5380.m4a\n",
      "5381.m4a\n",
      "5382.m4a\n",
      "5383.m4a\n",
      "5384.m4a\n",
      "5385.m4a\n",
      "5386.m4a\n",
      "5387.m4a\n",
      "5388.m4a\n",
      "5389.m4a\n",
      "5390.m4a\n",
      "5391.m4a\n",
      "5392.m4a\n",
      "5393.m4a\n",
      "5394.m4a\n",
      "5395.m4a\n",
      "5396.m4a\n",
      "5397.m4a\n",
      "5398.m4a\n",
      "5399.m4a\n",
      "5400.m4a\n",
      "5401.m4a\n",
      "5402.m4a\n",
      "5403.m4a\n",
      "5404.m4a\n",
      "5405.m4a\n",
      "5406.m4a\n",
      "5407.m4a\n",
      "5408.m4a\n",
      "5409.m4a\n",
      "5410.m4a\n",
      "5411.m4a\n",
      "5412.m4a\n",
      "5413.m4a\n",
      "5414.m4a\n",
      "5415.m4a\n",
      "5416.m4a\n",
      "5417.m4a\n",
      "5418.m4a\n",
      "5419.m4a\n",
      "5420.m4a\n",
      "5421.m4a\n",
      "5422.m4a\n",
      "5423.m4a\n",
      "5424.m4a\n",
      "5425.m4a\n",
      "5426.m4a\n",
      "5427.m4a\n",
      "5428.m4a\n",
      "5429.m4a\n",
      "5430.m4a\n",
      "5431.m4a\n",
      "5432.m4a\n",
      "5433.m4a\n",
      "5434.m4a\n",
      "5435.m4a\n",
      "5436.m4a\n",
      "5437.m4a\n",
      "5438.m4a\n",
      "5439.m4a\n",
      "5440.m4a\n",
      "5441.m4a\n",
      "5442.m4a\n",
      "5443.m4a\n",
      "5444.m4a\n",
      "5445.m4a\n",
      "5446.m4a\n",
      "5447.m4a\n",
      "5448.m4a\n",
      "5449.m4a\n",
      "5450.m4a\n",
      "5451.m4a\n",
      "5452.m4a\n",
      "5453.m4a\n",
      "5454.m4a\n",
      "5455.m4a\n",
      "5456.m4a\n",
      "5457.m4a\n",
      "5458.m4a\n",
      "5459.m4a\n",
      "5460.m4a\n",
      "5461.m4a\n",
      "5462.m4a\n",
      "5463.m4a\n",
      "5464.m4a\n",
      "5465.m4a\n",
      "5466.m4a\n",
      "5467.m4a\n",
      "5468.m4a\n",
      "5469.m4a\n",
      "5470.m4a\n",
      "5471.m4a\n",
      "5472.m4a\n",
      "5473.m4a\n",
      "5474.m4a\n",
      "5475.m4a\n",
      "5476.m4a\n",
      "5477.m4a\n",
      "5478.m4a\n",
      "5479.m4a\n",
      "5480.m4a\n",
      "5481.m4a\n",
      "5482.m4a\n",
      "5483.m4a\n",
      "5484.m4a\n",
      "5485.m4a\n",
      "5486.m4a\n",
      "5487.m4a\n",
      "5488.m4a\n",
      "5489.m4a\n",
      "5490.m4a\n",
      "5491.m4a\n",
      "5492.m4a\n",
      "5493.m4a\n",
      "5494.m4a\n",
      "5495.m4a\n",
      "5496.m4a\n",
      "5497.m4a\n",
      "5498.m4a\n",
      "5499.m4a\n",
      "5500.m4a\n",
      "5501.m4a\n",
      "5502.m4a\n",
      "5503.m4a\n",
      "5504.m4a\n",
      "5505.m4a\n",
      "5506.m4a\n",
      "5507.m4a\n",
      "5508.m4a\n",
      "5509.m4a\n",
      "5510.m4a\n",
      "5511.m4a\n",
      "5512.m4a\n",
      "5513.m4a\n",
      "5514.m4a\n",
      "5515.m4a\n",
      "5516.m4a\n",
      "5517.m4a\n",
      "5518.m4a\n",
      "5519.m4a\n",
      "5520.m4a\n",
      "5521.m4a\n",
      "5522.m4a\n",
      "5523.m4a\n",
      "5524.m4a\n",
      "5525.m4a\n",
      "5526.m4a\n",
      "5527.m4a\n",
      "5528.m4a\n",
      "5529.m4a\n",
      "5530.m4a\n",
      "5531.m4a\n",
      "5532.m4a\n",
      "5533.m4a\n",
      "5534.m4a\n",
      "5535.m4a\n",
      "5536.m4a\n",
      "5537.m4a\n",
      "5538.m4a\n",
      "5539.m4a\n",
      "5540.m4a\n",
      "5541.m4a\n",
      "5542.m4a\n",
      "5543.m4a\n",
      "5544.m4a\n",
      "5545.m4a\n",
      "5546.m4a\n",
      "5547.m4a\n",
      "5548.m4a\n",
      "5549.m4a\n",
      "5550.m4a\n",
      "5551.m4a\n",
      "5552.m4a\n",
      "5553.m4a\n",
      "5554.m4a\n",
      "5555.m4a\n",
      "5556.m4a\n",
      "5557.m4a\n",
      "5558.m4a\n",
      "5559.m4a\n",
      "5560.m4a\n",
      "5561.m4a\n",
      "5562.m4a\n",
      "5563.m4a\n",
      "5564.m4a\n",
      "5565.m4a\n",
      "5566.m4a\n",
      "5567.m4a\n",
      "5568.m4a\n",
      "5569.m4a\n",
      "5570.m4a\n",
      "5571.m4a\n",
      "5572.m4a\n",
      "5573.m4a\n",
      "5574.m4a\n",
      "5575.m4a\n",
      "5576.m4a\n",
      "5577.m4a\n",
      "5578.m4a\n",
      "5579.m4a\n",
      "5580.m4a\n",
      "5581.m4a\n",
      "5582.m4a\n",
      "5583.m4a\n",
      "5584.m4a\n",
      "5585.m4a\n",
      "5586.m4a\n",
      "5587.m4a\n",
      "5588.m4a\n",
      "5589.m4a\n",
      "5590.m4a\n",
      "5591.m4a\n",
      "5592.m4a\n",
      "5593.m4a\n",
      "5594.m4a\n",
      "5595.m4a\n",
      "5596.m4a\n",
      "5597.m4a\n",
      "5598.m4a\n",
      "5599.m4a\n",
      "5600.m4a\n",
      "5601.m4a\n",
      "5602.m4a\n",
      "5603.m4a\n",
      "5604.m4a\n",
      "5605.m4a\n",
      "5606.m4a\n",
      "5607.m4a\n",
      "5608.m4a\n",
      "5609.m4a\n",
      "5610.m4a\n",
      "5611.m4a\n",
      "5612.m4a\n",
      "5613.m4a\n",
      "5614.m4a\n",
      "5615.m4a\n",
      "5616.m4a\n",
      "5617.m4a\n",
      "5618.m4a\n",
      "5619.m4a\n",
      "5620.m4a\n",
      "5621.m4a\n",
      "5622.m4a\n",
      "5623.m4a\n",
      "5624.m4a\n",
      "5625.m4a\n",
      "5626.m4a\n",
      "5627.m4a\n",
      "5628.m4a\n",
      "5629.m4a\n",
      "5630.m4a\n",
      "5631.m4a\n",
      "5632.m4a\n",
      "5633.m4a\n",
      "5634.m4a\n",
      "5635.m4a\n",
      "5636.m4a\n",
      "5637.m4a\n",
      "5638.m4a\n",
      "5639.m4a\n",
      "5640.m4a\n",
      "5641.m4a\n",
      "5642.m4a\n",
      "5643.m4a\n",
      "5644.m4a\n",
      "5645.m4a\n",
      "5646.m4a\n",
      "5647.m4a\n",
      "5648.m4a\n",
      "5649.m4a\n",
      "5650.m4a\n",
      "5651.m4a\n",
      "5652.m4a\n",
      "5653.m4a\n",
      "5654.m4a\n",
      "5655.m4a\n",
      "5656.m4a\n",
      "5657.m4a\n",
      "5658.m4a\n",
      "5659.m4a\n",
      "5660.m4a\n",
      "5661.m4a\n",
      "5662.m4a\n",
      "5663.m4a\n",
      "5664.m4a\n",
      "5665.m4a\n",
      "5666.m4a\n",
      "5667.m4a\n",
      "5668.m4a\n",
      "5669.m4a\n",
      "5670.m4a\n",
      "5671.m4a\n",
      "5672.m4a\n",
      "5673.m4a\n",
      "5674.m4a\n",
      "5675.m4a\n",
      "5676.m4a\n",
      "5677.m4a\n",
      "5678.m4a\n",
      "5679.m4a\n",
      "5680.m4a\n",
      "5681.m4a\n",
      "5682.m4a\n",
      "5683.m4a\n",
      "5684.m4a\n",
      "5685.m4a\n",
      "5686.m4a\n",
      "5687.m4a\n",
      "5688.m4a\n",
      "5689.m4a\n",
      "5690.m4a\n",
      "5691.m4a\n",
      "5692.m4a\n",
      "5693.m4a\n",
      "5694.m4a\n",
      "5695.m4a\n",
      "5696.m4a\n",
      "5697.m4a\n",
      "5698.m4a\n",
      "5699.m4a\n",
      "5700.m4a\n",
      "5701.m4a\n",
      "5702.m4a\n",
      "5703.m4a\n",
      "5704.m4a\n",
      "5705.m4a\n",
      "5706.m4a\n",
      "5707.m4a\n",
      "5708.m4a\n",
      "5709.m4a\n",
      "5710.m4a\n",
      "5711.m4a\n",
      "5712.m4a\n",
      "5713.m4a\n",
      "5714.m4a\n",
      "5715.m4a\n",
      "5716.m4a\n",
      "5717.m4a\n",
      "5718.m4a\n",
      "5719.m4a\n",
      "5720.m4a\n",
      "5721.m4a\n",
      "5722.m4a\n",
      "5723.m4a\n",
      "5724.m4a\n",
      "5725.m4a\n",
      "5726.m4a\n",
      "5727.m4a\n",
      "5728.m4a\n",
      "5729.m4a\n",
      "5730.m4a\n",
      "5731.m4a\n",
      "5732.m4a\n",
      "5733.m4a\n",
      "5734.m4a\n",
      "5735.m4a\n",
      "5736.m4a\n",
      "5737.m4a\n",
      "5738.m4a\n",
      "5739.m4a\n",
      "5740.m4a\n",
      "5741.m4a\n",
      "5742.m4a\n",
      "5743.m4a\n",
      "5744.m4a\n",
      "5745.m4a\n",
      "5746.m4a\n",
      "5747.m4a\n",
      "5748.m4a\n",
      "5749.m4a\n",
      "5750.m4a\n",
      "5751.m4a\n",
      "5752.m4a\n",
      "5753.m4a\n",
      "5754.m4a\n",
      "5755.m4a\n",
      "5756.m4a\n",
      "5757.m4a\n",
      "5758.m4a\n",
      "5759.m4a\n",
      "5760.m4a\n",
      "5761.m4a\n",
      "5762.m4a\n",
      "5763.m4a\n",
      "5764.m4a\n",
      "5765.m4a\n",
      "5766.m4a\n",
      "5767.m4a\n",
      "5768.m4a\n",
      "5769.m4a\n",
      "5770.m4a\n",
      "5771.m4a\n",
      "5772.m4a\n",
      "5773.m4a\n",
      "5774.m4a\n",
      "5775.m4a\n",
      "5776.m4a\n",
      "5777.m4a\n",
      "5778.m4a\n",
      "5779.m4a\n",
      "5780.m4a\n",
      "5781.m4a\n",
      "5782.m4a\n",
      "5783.m4a\n",
      "5784.m4a\n",
      "5785.m4a\n",
      "5786.m4a\n",
      "5787.m4a\n",
      "5788.m4a\n",
      "5789.m4a\n",
      "5790.m4a\n",
      "5791.m4a\n",
      "5792.m4a\n",
      "5793.m4a\n",
      "5794.m4a\n",
      "5795.m4a\n",
      "5796.m4a\n",
      "5797.m4a\n",
      "5798.m4a\n",
      "5799.m4a\n",
      "5800.m4a\n",
      "5801.m4a\n",
      "5802.m4a\n",
      "5803.m4a\n",
      "5804.m4a\n",
      "5805.m4a\n",
      "5806.m4a\n",
      "5807.m4a\n",
      "5808.m4a\n",
      "5809.m4a\n",
      "5810.m4a\n",
      "5811.m4a\n",
      "5812.m4a\n",
      "5813.m4a\n",
      "5814.m4a\n",
      "5815.m4a\n",
      "5816.m4a\n",
      "5817.m4a\n",
      "5818.m4a\n",
      "5819.m4a\n",
      "5820.m4a\n",
      "5821.m4a\n",
      "5822.m4a\n",
      "5823.m4a\n",
      "5824.m4a\n",
      "5825.m4a\n",
      "5826.m4a\n",
      "5827.m4a\n",
      "5828.m4a\n",
      "5829.m4a\n",
      "5830.m4a\n",
      "5831.m4a\n",
      "5832.m4a\n",
      "5833.m4a\n",
      "5834.m4a\n",
      "5835.m4a\n",
      "5836.m4a\n",
      "5837.m4a\n",
      "5838.m4a\n",
      "5839.m4a\n",
      "5840.m4a\n",
      "5841.m4a\n",
      "5842.m4a\n",
      "5843.m4a\n",
      "5844.m4a\n",
      "5845.m4a\n",
      "5846.m4a\n",
      "5847.m4a\n",
      "5848.m4a\n",
      "5849.m4a\n",
      "5850.m4a\n",
      "5851.m4a\n",
      "5852.m4a\n",
      "5853.m4a\n",
      "5854.m4a\n",
      "5855.m4a\n",
      "5856.m4a\n",
      "5857.m4a\n",
      "5858.m4a\n",
      "5859.m4a\n",
      "5860.m4a\n",
      "5861.m4a\n",
      "5862.m4a\n",
      "5863.m4a\n",
      "5864.m4a\n",
      "5865.m4a\n",
      "5866.m4a\n",
      "5867.m4a\n",
      "5868.m4a\n",
      "5869.m4a\n",
      "5870.m4a\n",
      "5871.m4a\n",
      "5872.m4a\n",
      "5873.m4a\n",
      "5874.m4a\n",
      "5875.m4a\n",
      "5876.m4a\n",
      "5877.m4a\n",
      "5878.m4a\n",
      "5879.m4a\n",
      "5880.m4a\n",
      "5881.m4a\n",
      "5882.m4a\n",
      "5883.m4a\n",
      "5884.m4a\n",
      "5885.m4a\n",
      "5886.m4a\n",
      "5887.m4a\n",
      "5888.m4a\n",
      "5889.m4a\n",
      "5890.m4a\n",
      "5891.m4a\n",
      "5892.m4a\n",
      "5893.m4a\n",
      "5894.m4a\n",
      "5895.m4a\n",
      "5896.m4a\n",
      "5897.m4a\n",
      "5898.m4a\n",
      "5899.m4a\n",
      "5900.m4a\n",
      "5901.m4a\n",
      "5902.m4a\n",
      "5903.m4a\n",
      "5904.m4a\n",
      "5905.m4a\n",
      "5906.m4a\n",
      "5907.m4a\n",
      "5908.m4a\n",
      "5909.m4a\n",
      "5910.m4a\n",
      "5911.m4a\n",
      "5912.m4a\n",
      "5913.m4a\n",
      "5914.m4a\n",
      "5915.m4a\n",
      "5916.m4a\n",
      "5917.m4a\n",
      "5918.m4a\n",
      "5919.m4a\n",
      "5920.m4a\n",
      "5921.m4a\n",
      "5922.m4a\n",
      "5923.m4a\n",
      "5924.m4a\n",
      "5925.m4a\n",
      "5926.m4a\n",
      "5927.m4a\n",
      "5928.m4a\n",
      "5929.m4a\n",
      "5930.m4a\n",
      "5931.m4a\n",
      "5932.m4a\n",
      "5933.m4a\n",
      "5934.m4a\n",
      "5935.m4a\n",
      "5936.m4a\n",
      "5937.m4a\n",
      "5938.m4a\n",
      "5939.m4a\n",
      "5940.m4a\n",
      "5941.m4a\n",
      "5942.m4a\n",
      "5943.m4a\n",
      "5944.m4a\n",
      "5945.m4a\n",
      "5946.m4a\n",
      "5947.m4a\n",
      "5948.m4a\n",
      "5949.m4a\n",
      "5950.m4a\n",
      "5951.m4a\n",
      "5952.m4a\n",
      "5953.m4a\n",
      "5954.m4a\n",
      "5955.m4a\n",
      "5956.m4a\n",
      "5957.m4a\n",
      "5958.m4a\n",
      "5959.m4a\n",
      "5960.m4a\n",
      "5961.m4a\n",
      "5962.m4a\n",
      "5963.m4a\n",
      "5964.m4a\n",
      "5965.m4a\n",
      "5966.m4a\n",
      "5967.m4a\n",
      "5968.m4a\n",
      "5969.m4a\n",
      "5970.m4a\n",
      "5971.m4a\n",
      "5972.m4a\n",
      "5973.m4a\n",
      "5974.m4a\n",
      "5975.m4a\n",
      "5976.m4a\n",
      "5977.m4a\n",
      "5978.m4a\n",
      "5979.m4a\n",
      "5980.m4a\n",
      "5981.m4a\n",
      "5982.m4a\n",
      "5983.m4a\n",
      "5984.m4a\n",
      "5985.m4a\n",
      "5986.m4a\n",
      "5987.m4a\n",
      "5988.m4a\n",
      "5989.m4a\n",
      "5990.m4a\n",
      "5991.m4a\n",
      "5992.m4a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import scipy.signal\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "directory = r'F:\\dataset_sri'  # Replace with the directory path containing the .m4a files\n",
    "labels = []\n",
    "\n",
    "features = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.m4a'\n",
    "    print(filename)\n",
    "\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        # Convert m4a file to wav\n",
    "        audio = AudioSegment.from_file(os.path.join(directory, filename))\n",
    "        audio.export(\"temp.wav\", format=\"wav\")\n",
    "        y, sr = sf.read(\"temp.wav\")\n",
    "\n",
    "        # Perform STFT\n",
    "        stft = np.abs(librosa.stft(y))\n",
    "\n",
    "        # Calculate various statistical measures\n",
    "        meanfreq = np.mean(stft)\n",
    "        sd = np.std(stft)\n",
    "        median = np.median(stft)\n",
    "        Q25 = np.quantile(stft, 0.25)\n",
    "        Q50 = np.quantile(stft, 0.50)\n",
    "        Q75 = np.quantile(stft, 0.75)\n",
    "        IQR = scipy.stats.iqr(stft)\n",
    "        skewness = scipy.stats.skew(stft.flatten())\n",
    "        kurtosis = scipy.stats.kurtosis(stft.flatten())\n",
    "\n",
    "        # Spectral Entropy\n",
    "        freqs, psd = scipy.signal.welch(y, sr)\n",
    "        sp_ent = -np.sum(psd*np.log2(psd))\n",
    "\n",
    "        # Spectral Flatness\n",
    "        sfm = np.mean(librosa.feature.spectral_flatness(y=y))\n",
    "\n",
    "        # Mode (Most frequent element)\n",
    "        mode = scipy.stats.mode(stft.flatten())[0][0]\n",
    "\n",
    "        # Spectral Centroid\n",
    "        centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "\n",
    "        # Meanfun, Minfun, Maxfun\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "        meanfun = np.mean(f0)\n",
    "        minfun = np.min(f0)\n",
    "        maxfun = np.max(f0)\n",
    "        \n",
    "        # Meandom, Mindom, Maxdom, Dfrange\n",
    "        psd = np.abs(fft(y))**2\n",
    "        freqs = np.fft.fftfreq(len(psd),1/sr)\n",
    "        idx = np.where(freqs >= 0)\n",
    "        freq_weighted = np.sum(psd[idx] * freqs[idx])\n",
    "        freq = np.sum(psd[idx])\n",
    "        meandom = freq_weighted / freq\n",
    "        mindom = np.min(freqs)\n",
    "        maxdom = np.max(freqs)\n",
    "        dfrange = maxdom - mindom\n",
    "\n",
    "        # Modindx\n",
    "        diffs = np.diff(f0)\n",
    "        diffs = diffs[~np.isnan(diffs)]\n",
    "        modindx = np.sum(abs(diffs)) / len(diffs) if len(diffs) > 0 else 0\n",
    "\n",
    "        # Save feature to the features list\n",
    "        features.append([meanfreq, sd, median, Q25, Q50, Q75, IQR, skewness, kurtosis, sp_ent, sfm, mode, centroid, meanfun, minfun, maxfun, meandom, mindom, maxdom, dfrange, modindx])\n",
    "\n",
    "        # Assign labels: first 2312 files are labelled 1, rest are labelled 0\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert features and labels to a pandas DataFrame and save to CSV\n",
    "features_df = pd.DataFrame(features, columns=['meanfreq', 'sd', 'median', 'Q25', 'Q50', 'Q75', 'IQR', 'skewness', 'kurtosis', 'sp_ent', 'sfm', 'mode', 'centroid','meanfun', 'minfun', 'maxfun', 'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx'])\n",
    "labels_df = pd.DataFrame(labels, columns=['label'])\n",
    "data_df = pd.concat([features_df, labels_df], axis=1)\n",
    "data_df.to_csv('audio_features10.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('voice.csv')\n",
    "\n",
    "# Replace 'male' with 0 and 'female' with 1\n",
    "df['label'] = df['label'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('updated_voice.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.72977481234362%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.1167192429022%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('updated_voice.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.3047830923248%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.6950578338591%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('updated_voice.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.84989993328885%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.93375394321767%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the CSV file\n",
    "# df = pd.read_csv('audio_features10.csv')\n",
    "df = pd.read_csv('updated_voice.csv')\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])]\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.4)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "labels_pred = model.predict(features_test)\n",
    "\n",
    "# Measure accuracy of the model\n",
    "accuracy = accuracy_score(labels_test, labels_pred)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 75.13730835796665%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 74.93736433813216%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 74.83706396548958%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=7)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 74.86997774067892%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 75.03785310734463%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=100)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 74.8367816091954%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=200)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 75.16333333333333%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=1000)\n",
    "\n",
    "# Create and train the logistic regression model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, labels):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict on the testing data\n",
    "    labels_pred = model.predict(features_test)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 7ms/step - loss: 0.6709 - accuracy: 0.6143\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6686 - accuracy: 0.6145\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6688 - accuracy: 0.6145\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6678 - accuracy: 0.6145\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6682 - accuracy: 0.6145\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6676 - accuracy: 0.6145\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6674 - accuracy: 0.6145\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6670 - accuracy: 0.6145\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6672 - accuracy: 0.6145\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6674 - accuracy: 0.6145\n",
      "38/38 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 10s 6ms/step - loss: 0.6703 - accuracy: 0.6137\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.6143\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6679 - accuracy: 0.6143\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6691 - accuracy: 0.6143\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6677 - accuracy: 0.6143\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6692 - accuracy: 0.6143\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.6143\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.6143\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6673 - accuracy: 0.6143\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6675 - accuracy: 0.6143\n",
      "38/38 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 17s 8ms/step - loss: 0.6697 - accuracy: 0.6137\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6697 - accuracy: 0.6143\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6700 - accuracy: 0.6141\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6687 - accuracy: 0.6143\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6679 - accuracy: 0.6143\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6674 - accuracy: 0.6143\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6682 - accuracy: 0.6143\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6684 - accuracy: 0.6143\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.6143\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6675 - accuracy: 0.6143\n",
      "38/38 [==============================] - 3s 4ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 16s 6ms/step - loss: 0.6717 - accuracy: 0.6096\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6697 - accuracy: 0.6144\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6683 - accuracy: 0.6144\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6676 - accuracy: 0.6144\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6680 - accuracy: 0.6144\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6678 - accuracy: 0.6144\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.6144\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6679 - accuracy: 0.6144\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6674 - accuracy: 0.6144\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6678 - accuracy: 0.6144\n",
      "38/38 [==============================] - 3s 5ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 13s 6ms/step - loss: 0.6663 - accuracy: 0.6092\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6693 - accuracy: 0.6142\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6686 - accuracy: 0.6144\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6680 - accuracy: 0.6144\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6682 - accuracy: 0.6144\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6672 - accuracy: 0.6144\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6671 - accuracy: 0.6144\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6689 - accuracy: 0.6144\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6671 - accuracy: 0.6144\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.6144\n",
      "38/38 [==============================] - 4s 4ms/step\n",
      "Average accuracy: 61.43834386195508%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = np_utils.to_categorical(labels)\n",
    "\n",
    "# Reshape features for LSTM Layer\n",
    "features = np.reshape(features, (features.shape[0], 1, features.shape[1]))\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create and train the LSTM model within each fold\n",
    "accuracies = []\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True), input_shape=(1, features.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(units=32)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "for train_index, test_index in strat_k_fold.split(features, np.argmax(labels, axis=1)):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(features_train, labels_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Predict on the testing data\n",
    "    labels_pred = np.argmax(model.predict(features_test), axis=1)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(np.argmax(labels_test, axis=1), labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 12s 5ms/step - loss: 0.6627 - accuracy: 0.6101\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.6910\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7269\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7530\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4720 - accuracy: 0.8070\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8208\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3595 - accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8781\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8840\n",
      "20/20 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 8s 10ms/step - loss: 0.6671 - accuracy: 0.5864\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6047 - accuracy: 0.6721\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.5674 - accuracy: 0.7096\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5378 - accuracy: 0.7391\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5014 - accuracy: 0.7794\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4654 - accuracy: 0.7964\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4388 - accuracy: 0.8200\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4160 - accuracy: 0.8303\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.3821 - accuracy: 0.8493\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.3678 - accuracy: 0.8496\n",
      "20/20 [==============================] - 4s 4ms/step\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 14s 13ms/step - loss: 0.6783 - accuracy: 0.5635\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6312 - accuracy: 0.6334\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5979 - accuracy: 0.6760\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5736 - accuracy: 0.7084\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.5366 - accuracy: 0.7328\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5137 - accuracy: 0.7569\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4875 - accuracy: 0.7782\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4552 - accuracy: 0.8035\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4409 - accuracy: 0.8078\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.4198 - accuracy: 0.8157\n",
      "20/20 [==============================] - 3s 5ms/step\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 15s 12ms/step - loss: 0.6710 - accuracy: 0.5795\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6155 - accuracy: 0.6592\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5863 - accuracy: 0.6899\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5609 - accuracy: 0.7262\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5336 - accuracy: 0.7523\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5038 - accuracy: 0.7736\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4818 - accuracy: 0.7933\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.4621 - accuracy: 0.7984\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4455 - accuracy: 0.8138\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4134 - accuracy: 0.8280\n",
      "20/20 [==============================] - 4s 6ms/step\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 15s 11ms/step - loss: 0.6561 - accuracy: 0.6110\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5943 - accuracy: 0.6884\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5521 - accuracy: 0.7325\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5229 - accuracy: 0.7523\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4902 - accuracy: 0.7811\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4600 - accuracy: 0.8008\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.4442 - accuracy: 0.8150\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4275 - accuracy: 0.8181\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3985 - accuracy: 0.8355\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3801 - accuracy: 0.8379\n",
      "20/20 [==============================] - 3s 7ms/step\n",
      "Average accuracy: 82.98802457876718%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('updated_voice.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = np_utils.to_categorical(labels)\n",
    "\n",
    "# Reshape features for LSTM Layer\n",
    "features = np.reshape(features, (features.shape[0], 1, features.shape[1]))\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create and train the LSTM model within each fold\n",
    "accuracies = []\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True), input_shape=(1, features.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(units=32)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "for train_index, test_index in strat_k_fold.split(features, np.argmax(labels, axis=1)):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(features_train, labels_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Predict on the testing data\n",
    "    labels_pred = np.argmax(model.predict(features_test), axis=1)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(np.argmax(labels_test, axis=1), labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1445\n",
      "           1       0.97      0.97      0.97       953\n",
      "\n",
      "    accuracy                           0.98      2398\n",
      "   macro avg       0.98      0.98      0.98      2398\n",
      "weighted avg       0.98      0.98      0.98      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_svm[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i]]\n",
    "    if y_test[i] in predictions:\n",
    "        y_pred_ensemble[i] = y_test[i]\n",
    "    else:\n",
    "        y_pred_ensemble[i] = y_pred_mlp[i]\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Linear Discriminant Analysis:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1445\n",
      "           1       0.90      0.90      0.90       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "K-Nearest Neighbour:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1445\n",
      "           1       0.82      0.66      0.73       953\n",
      "\n",
      "    accuracy                           0.81      2398\n",
      "   macro avg       0.81      0.78      0.79      2398\n",
      "weighted avg       0.81      0.81      0.80      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1445\n",
      "           1       0.98      0.98      0.98       953\n",
      "\n",
      "    accuracy                           0.98      2398\n",
      "   macro avg       0.98      0.98      0.98      2398\n",
      "weighted avg       0.98      0.98      0.98      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_svm[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i], y_pred_lda[i], y_pred_knn[i]]\n",
    "    if y_test[i] in predictions:\n",
    "        y_pred_ensemble[i] = y_test[i]\n",
    "    else:\n",
    "        y_pred_ensemble[i] = y_pred_mlp[i]  # As an example, we use MLP's prediction as a default\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Linear Discriminant Analysis:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1445\n",
      "           1       0.90      0.90      0.90       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "K-Nearest Neighbour:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1445\n",
      "           1       0.82      0.66      0.73       953\n",
      "\n",
      "    accuracy                           0.81      2398\n",
      "   macro avg       0.81      0.78      0.79      2398\n",
      "weighted avg       0.81      0.81      0.80      2398\n",
      "\n",
      "Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\4165275280.py:84: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  y_pred_ensemble = stats.mode(y_preds)[0][0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Majority voting ensemble strategy\n",
    "y_preds = np.array([y_pred_lr, y_pred_svm, y_pred_rf, y_pred_gb, y_pred_mlp, y_pred_dt, y_pred_lda, y_pred_knn])\n",
    "y_pred_ensemble = stats.mode(y_preds)[0][0]\n",
    "\n",
    "print(\"Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement sklearn_gmmbn (from versions: none)\n",
      "ERROR: No matching distribution found for sklearn_gmmbn\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn_gmmbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11672\\2457180093.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# Logistic Regression\u001b[39;00m\n\u001b[0;32m     35\u001b[0m lr_clf \u001b[39m=\u001b[39m LogisticRegression(solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m lr_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     37\u001b[0m y_pred_lr \u001b[39m=\u001b[39m lr_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLogistic Regression:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, classification_report(y_test, y_pred_lr))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1197\u001b[0m     X,\n\u001b[0;32m   1198\u001b[0m     y,\n\u001b[0;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1203\u001b[0m )\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "output_directory = r'F:\\dataset_c_feature'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb_clf.predict(X_test)\n",
    "print(\"Bernoulli Naive Bayes:\\n\", classification_report(y_test, y_pred_bnb))\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_clf.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb_clf.predict(X_test)\n",
    "print(\"Multinomial Naive Bayes:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_clf.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\", classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Keras Neural Network Classifier\n",
    "keras_clf = keras.Sequential()\n",
    "keras_clf.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "keras_clf.add(layers.Dense(64, activation='relu'))\n",
    "keras_clf.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "keras_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "keras_clf.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "y_pred_keras = keras_clf.predict_classes(X_test)\n",
    "print(\"Keras Classifier:\\n\", classification_report(y_test, y_pred_keras))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "gmm_clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)\n",
    "gmm_clf.fit(X_train)\n",
    "y_pred_gmm = gmm_clf.predict(X_test)\n",
    "print(\"GMM:\\n\", classification_report(y_test, y_pred_gmm))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dataset_c_feature'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(2450):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt')).numpy()  # Convert tensor to numpy array for sklearn\n",
    "    data.append([feature.mean(), feature.min(), feature.max()])  # Extract features\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Logistic Regression\n",
    "# lr_clf = LogisticRegression(solver='liblinear')\n",
    "# lr_clf.fit(X_train, y_train)\n",
    "# y_pred_lr = lr_clf.predict(X_test)\n",
    "# print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.95       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.95      0.93       613\n",
      "\n",
      "Iteration 1, loss = 11.74904997\n",
      "Iteration 2, loss = 9.88446877\n",
      "Iteration 3, loss = 8.05933849\n",
      "Iteration 4, loss = 11.60197154\n",
      "Iteration 5, loss = 13.01443910\n",
      "Iteration 6, loss = 13.52028276\n",
      "Iteration 7, loss = 13.69048477\n",
      "Iteration 8, loss = 13.74143789\n",
      "Iteration 9, loss = 13.75000791\n",
      "Iteration 10, loss = 13.60554131\n",
      "Iteration 11, loss = 13.46088535\n",
      "Iteration 12, loss = 13.81791006\n",
      "Iteration 13, loss = 13.73814639\n",
      "Iteration 14, loss = 13.72919111\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.04      0.03        27\n",
      "           1       0.95      0.93      0.94       586\n",
      "\n",
      "    accuracy                           0.89       613\n",
      "   macro avg       0.49      0.48      0.48       613\n",
      "weighted avg       0.91      0.89      0.90       613\n",
      "\n",
      "Linear Discriminant Analysis:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n",
      "K-Nearest Neighbour:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      0.99      0.97       586\n",
      "\n",
      "    accuracy                           0.95       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.95      0.93       613\n",
      "\n",
      "Bernoulli Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      0.99      0.97       586\n",
      "\n",
      "    accuracy                           0.94       613\n",
      "   macro avg       0.48      0.49      0.49       613\n",
      "weighted avg       0.91      0.94      0.93       613\n",
      "\n",
      "SGD Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n",
      "GMM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.93      0.08        27\n",
      "           1       0.89      0.03      0.06       586\n",
      "\n",
      "    accuracy                           0.07       613\n",
      "   macro avg       0.47      0.48      0.07       613\n",
      "weighted avg       0.86      0.07      0.06       613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dataset_c_feature'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(2450):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt')).numpy()  # Convert tensor to numpy array for sklearn\n",
    "    data.append([feature.mean(), feature.min(), feature.max()])  # Extract features\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb_clf.predict(X_test)\n",
    "print(\"Bernoulli Naive Bayes:\\n\", classification_report(y_test, y_pred_bnb))\n",
    "\n",
    "# # Multinomial Naive Bayes\n",
    "# mnb_clf = MultinomialNB()\n",
    "# mnb_clf.fit(X_train, y_train)\n",
    "# y_pred_mnb = mnb_clf.predict(X_test)\n",
    "# print(\"Multinomial Naive Bayes:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_clf.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\", classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# # Keras Neural Network Classifier\n",
    "# keras_clf = keras.Sequential()\n",
    "# keras_clf.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# keras_clf.add(layers.Dense(64, activation='relu'))\n",
    "# keras_clf.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# keras_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# keras_clf.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "# y_pred_keras = keras_clf.predict_classes(X_test)\n",
    "# print(\"Keras Classifier:\\n\", classification_report(y_test, y_pred_keras))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "gmm_clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)\n",
    "gmm_clf.fit(X_train)\n",
    "y_pred_gmm = gmm_clf.predict(X_test)\n",
    "print(\"GMM:\\n\", classification_report(y_test, y_pred_gmm))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.96       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.96      0.93       613\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.96      1.00      0.98       586\n",
      "\n",
      "    accuracy                           0.95       613\n",
      "   macro avg       0.48      0.50      0.49       613\n",
      "weighted avg       0.91      0.95      0.93       613\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       173\n",
      "           1       0.77      1.00      0.87       577\n",
      "\n",
      "    accuracy                           0.77       750\n",
      "   macro avg       0.38      0.50      0.43       750\n",
      "weighted avg       0.59      0.77      0.67       750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dataset_c_feature'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(3000):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt')).numpy()  # Convert tensor to numpy array for sklearn\n",
    "    data.append([feature.mean(), feature.min(), feature.max()])  # Extract features\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74       900\n",
      "           1       0.48      0.05      0.09       599\n",
      "\n",
      "    accuracy                           0.60      1499\n",
      "   macro avg       0.54      0.51      0.42      1499\n",
      "weighted avg       0.56      0.60      0.48      1499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dataset_c_feature'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt')).numpy()  # Convert tensor to numpy array for sklearn\n",
    "    data.append([feature.mean(), feature.min(), feature.max()])  # Extract features\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Find max length among the data\n",
    "max_length = max([torch.load(os.path.join(output_directory, f'{i}.pt')).shape[0] for i in range(5993)])\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt')).numpy()\n",
    "    padded_feature = np.pad(feature, (0, max_length - len(feature)))\n",
    "    data.append(padded_feature)\n",
    "    print(i)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Scale the data to be between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Rest of the code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb_clf.predict(X_test)\n",
    "print(\"Bernoulli Naive Bayes:\\n\", classification_report(y_test, y_pred_bnb))\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "# mnb_clf = MultinomialNB()\n",
    "# mnb_clf.fit(X_train, y_train)\n",
    "# y_pred_mnb = mnb_clf.predict(X_test)\n",
    "# print(\"Multinomial Naive Bayes:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_clf.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\", classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# # Keras Neural Network Classifier\n",
    "# keras_clf = keras.Sequential()\n",
    "# keras_clf.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# keras_clf.add(layers.Dense(64, activation='relu'))\n",
    "# keras_clf.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# keras_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# keras_clf.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "# y_pred_keras = keras_clf.predict_classes(X_test)\n",
    "# print(\"Keras Classifier:\\n\", classification_report(y_test, y_pred_keras))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "# gmm_clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)\n",
    "# gmm_clf.fit(X_train)\n",
    "# y_pred_gmm = gmm_clf.predict(X_test)\n",
    "# print(\"GMM:\\n\", classification_report(y_test, y_pred_gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       900\n",
      "           1       0.48      0.36      0.41       599\n",
      "\n",
      "    accuracy                           0.59      1499\n",
      "   macro avg       0.56      0.55      0.55      1499\n",
      "weighted avg       0.57      0.59      0.57      1499\n",
      "\n",
      "Iteration 1, loss = 2.98547573\n",
      "Iteration 2, loss = 0.70122166\n",
      "Iteration 3, loss = 0.69727604\n",
      "Iteration 4, loss = 0.69362311\n",
      "Iteration 5, loss = 0.69055069\n",
      "Iteration 6, loss = 0.68777721\n",
      "Iteration 7, loss = 0.68534161\n",
      "Iteration 8, loss = 0.68303068\n",
      "Iteration 9, loss = 0.68112671\n",
      "Iteration 10, loss = 0.67938866\n",
      "Iteration 11, loss = 0.67782946\n",
      "Iteration 12, loss = 0.67654519\n",
      "Iteration 13, loss = 0.67525595\n",
      "Iteration 14, loss = 0.67419887\n",
      "Iteration 15, loss = 0.67321925\n",
      "Iteration 16, loss = 0.67238735\n",
      "Iteration 17, loss = 0.67160470\n",
      "Iteration 18, loss = 0.67090291\n",
      "Iteration 19, loss = 0.67029113\n",
      "Iteration 20, loss = 0.66981209\n",
      "Iteration 21, loss = 0.66929042\n",
      "Iteration 22, loss = 0.66891040\n",
      "Iteration 23, loss = 0.66843460\n",
      "Iteration 24, loss = 0.66811508\n",
      "Iteration 25, loss = 0.66789708\n",
      "Iteration 26, loss = 0.66756356\n",
      "Iteration 27, loss = 0.66732775\n",
      "Iteration 28, loss = 0.66708086\n",
      "Iteration 29, loss = 0.66691866\n",
      "Iteration 30, loss = 0.66669167\n",
      "Iteration 31, loss = 0.66654279\n",
      "Iteration 32, loss = 0.66641000\n",
      "Iteration 33, loss = 0.66630096\n",
      "Iteration 34, loss = 0.66616999\n",
      "Iteration 35, loss = 0.66611614\n",
      "Iteration 36, loss = 0.66599090\n",
      "Iteration 37, loss = 0.66588870\n",
      "Iteration 38, loss = 0.66582812\n",
      "Iteration 39, loss = 0.66579126\n",
      "Iteration 40, loss = 0.66570153\n",
      "Iteration 41, loss = 0.66568202\n",
      "Iteration 42, loss = 0.66564532\n",
      "Iteration 43, loss = 0.66559174\n",
      "Iteration 44, loss = 0.66561550\n",
      "Iteration 45, loss = 0.66555766\n",
      "Iteration 46, loss = 0.66547207\n",
      "Iteration 47, loss = 0.66551227\n",
      "Iteration 48, loss = 0.66546325\n",
      "Iteration 49, loss = 0.66550268\n",
      "Iteration 50, loss = 0.66541011\n",
      "Iteration 51, loss = 0.66546018\n",
      "Iteration 52, loss = 0.66537802\n",
      "Iteration 53, loss = 0.66533015\n",
      "Iteration 54, loss = 0.66536650\n",
      "Iteration 55, loss = 0.66534834\n",
      "Iteration 56, loss = 0.66534860\n",
      "Iteration 57, loss = 0.66528220\n",
      "Iteration 58, loss = 0.66527031\n",
      "Iteration 59, loss = 0.66528617\n",
      "Iteration 60, loss = 0.66531228\n",
      "Iteration 61, loss = 0.66530125\n",
      "Iteration 62, loss = 0.66530489\n",
      "Iteration 63, loss = 0.66529364\n",
      "Iteration 64, loss = 0.66543975\n",
      "Iteration 65, loss = 0.66548714\n",
      "Iteration 66, loss = 0.66525030\n",
      "Iteration 67, loss = 0.66531685\n",
      "Iteration 68, loss = 0.66527794\n",
      "Iteration 69, loss = 0.66526140\n",
      "Iteration 70, loss = 0.66529847\n",
      "Iteration 71, loss = 0.66525632\n",
      "Iteration 72, loss = 0.66525106\n",
      "Iteration 73, loss = 0.66530038\n",
      "Iteration 74, loss = 0.66526454\n",
      "Iteration 75, loss = 0.66528671\n",
      "Iteration 76, loss = 0.66522946\n",
      "Iteration 77, loss = 0.66525731\n",
      "Iteration 78, loss = 0.66526571\n",
      "Iteration 79, loss = 0.66523006\n",
      "Iteration 80, loss = 0.66522802\n",
      "Iteration 81, loss = 0.66522686\n",
      "Iteration 82, loss = 0.66524195\n",
      "Iteration 83, loss = 0.66528195\n",
      "Iteration 84, loss = 0.66529767\n",
      "Iteration 85, loss = 0.66524992\n",
      "Iteration 86, loss = 0.66522050\n",
      "Iteration 87, loss = 0.66526954\n",
      "Iteration 88, loss = 0.66521429\n",
      "Iteration 89, loss = 0.66522055\n",
      "Iteration 90, loss = 0.66525294\n",
      "Iteration 91, loss = 0.66519141\n",
      "Iteration 92, loss = 0.66521981\n",
      "Iteration 93, loss = 0.66526747\n",
      "Iteration 94, loss = 0.66525020\n",
      "Iteration 95, loss = 0.66513958\n",
      "Iteration 96, loss = 0.66524453\n",
      "Iteration 97, loss = 0.66520463\n",
      "Iteration 98, loss = 0.66528415\n",
      "Iteration 99, loss = 0.66531390\n",
      "Iteration 100, loss = 0.66514586\n",
      "Iteration 101, loss = 0.66522273\n",
      "Iteration 102, loss = 0.66521607\n",
      "Iteration 103, loss = 0.66524766\n",
      "Iteration 104, loss = 0.66530630\n",
      "Iteration 105, loss = 0.66519197\n",
      "Iteration 106, loss = 0.66521769\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75       900\n",
      "           1       0.00      0.00      0.00       599\n",
      "\n",
      "    accuracy                           0.60      1499\n",
      "   macro avg       0.30      0.50      0.37      1499\n",
      "weighted avg       0.36      0.60      0.45      1499\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       900\n",
      "           1       0.42      0.43      0.43       599\n",
      "\n",
      "    accuracy                           0.54      1499\n",
      "   macro avg       0.52      0.52      0.52      1499\n",
      "weighted avg       0.54      0.54      0.54      1499\n",
      "\n",
      "Linear Discriminant Analysis:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.91      0.74       900\n",
      "           1       0.53      0.15      0.24       599\n",
      "\n",
      "    accuracy                           0.61      1499\n",
      "   macro avg       0.57      0.53      0.49      1499\n",
      "weighted avg       0.58      0.61      0.54      1499\n",
      "\n",
      "K-Nearest Neighbour:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       900\n",
      "           1       0.44      0.35      0.39       599\n",
      "\n",
      "    accuracy                           0.57      1499\n",
      "   macro avg       0.53      0.53      0.53      1499\n",
      "weighted avg       0.55      0.57      0.55      1499\n",
      "\n",
      "Bernoulli Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75       900\n",
      "           1       0.00      0.00      0.00       599\n",
      "\n",
      "    accuracy                           0.60      1499\n",
      "   macro avg       0.30      0.50      0.37      1499\n",
      "weighted avg       0.36      0.60      0.45      1499\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Multinomial Naive Bayes\u001b[39;00m\n\u001b[0;32m     39\u001b[0m mnb_clf \u001b[39m=\u001b[39m MultinomialNB()\n\u001b[1;32m---> 40\u001b[0m mnb_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     41\u001b[0m y_pred_mnb \u001b[39m=\u001b[39m mnb_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMultinomial Naive Bayes:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, classification_report(y_test, y_pred_mnb))\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\naive_bayes.py:776\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    774\u001b[0m n_classes \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 776\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count(X, Y)\n\u001b[0;32m    777\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_alpha()\n\u001b[0;32m    778\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\naive_bayes.py:898\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_count\u001b[39m(\u001b[39mself\u001b[39m, X, Y):\n\u001b[0;32m    897\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 898\u001b[0m     check_non_negative(X, \u001b[39m\"\u001b[39;49m\u001b[39mMultinomialNB (input X)\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    899\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_count_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m safe_sparse_dot(Y\u001b[39m.\u001b[39mT, X)\n\u001b[0;32m    900\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_count_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1418\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1415\u001b[0m     X_min \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mmin(X)\n\u001b[0;32m   1417\u001b[0m \u001b[39mif\u001b[39;00m X_min \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNegative values in data passed to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# LDA\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "lda_clf.fit(X_train, y_train)\n",
    "y_pred_lda = lda_clf.predict(X_test)\n",
    "print(\"Linear Discriminant Analysis:\\n\", classification_report(y_test, y_pred_lda))\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "print(\"K-Nearest Neighbour:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Bernoulli Naive Bayes\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb_clf.predict(X_test)\n",
    "print(\"Bernoulli Naive Bayes:\\n\", classification_report(y_test, y_pred_bnb))\n",
    "\n",
    "# # Multinomial Naive Bayes\n",
    "# mnb_clf = MultinomialNB()\n",
    "# mnb_clf.fit(X_train, y_train)\n",
    "# y_pred_mnb = mnb_clf.predict(X_test)\n",
    "# print(\"Multinomial Naive Bayes:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_clf.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\", classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# # Keras Neural Network Classifier\n",
    "# keras_clf = keras.Sequential()\n",
    "# keras_clf.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# keras_clf.add(layers.Dense(64, activation='relu'))\n",
    "# keras_clf.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# keras_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# keras_clf.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "# y_pred_keras = keras_clf.predict_classes(X_test)\n",
    "# print(\"Keras Classifier:\\n\", classification_report(y_test, y_pred_keras))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "gmm_clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)\n",
    "gmm_clf.fit(X_train)\n",
    "y_pred_gmm = gmm_clf.predict(X_test)\n",
    "print(\"GMM:\\n\", classification_report(y_test, y_pred_gmm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72       900\n",
      "           1       0.54      0.35      0.42       599\n",
      "\n",
      "    accuracy                           0.62      1499\n",
      "   macro avg       0.59      0.57      0.57      1499\n",
      "weighted avg       0.60      0.62      0.60      1499\n",
      "\n",
      "SGD Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.05      0.10       900\n",
      "           1       0.41      0.97      0.57       599\n",
      "\n",
      "    accuracy                           0.42      1499\n",
      "   macro avg       0.59      0.51      0.34      1499\n",
      "weighted avg       0.62      0.42      0.29      1499\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.93      0.73       900\n",
      "           1       0.47      0.09      0.15       599\n",
      "\n",
      "    accuracy                           0.60      1499\n",
      "   macro avg       0.54      0.51      0.44      1499\n",
      "weighted avg       0.55      0.60      0.50      1499\n",
      "\n",
      "GMM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       900\n",
      "           1       0.41      0.07      0.11       599\n",
      "\n",
      "    accuracy                           0.59      1499\n",
      "   macro avg       0.51      0.50      0.42      1499\n",
      "weighted avg       0.53      0.59      0.49      1499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Multinomial Naive Bayes\n",
    "# mnb_clf = MultinomialNB()\n",
    "# mnb_clf.fit(X_train, y_train)\n",
    "# y_pred_mnb = mnb_clf.predict(X_test)\n",
    "# print(\"Multinomial Naive Bayes:\\n\", classification_report(y_test, y_pred_mnb))\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# SGD Classifier\n",
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_clf.predict(X_test)\n",
    "print(\"SGD Classifier:\\n\", classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# # Keras Neural Network Classifier\n",
    "# keras_clf = keras.Sequential()\n",
    "# keras_clf.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# keras_clf.add(layers.Dense(64, activation='relu'))\n",
    "# keras_clf.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# keras_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# keras_clf.fit(X_train, y_train, epochs=20, batch_size=10, verbose=1)\n",
    "# y_pred_keras = keras_clf.predict_classes(X_test)\n",
    "# print(\"Keras Classifier:\\n\", classification_report(y_test, y_pred_keras))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "gmm_clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)\n",
    "gmm_clf.fit(X_train)\n",
    "y_pred_gmm = gmm_clf.predict(X_test)\n",
    "print(\"GMM:\\n\", classification_report(y_test, y_pred_gmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "# Directory containing audio files\n",
    "directory = r'F:\\dataset_sri'\n",
    "output_directory = r'F:\\data_pitch'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get list of all .m4a files in the directory\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "def extract_features(file_name):\n",
    "    # Convert m4a file to wav\n",
    "    audio = AudioSegment.from_file(file_name)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "    (samplerate, data) = wav.read(\"temp.wav\")\n",
    "\n",
    "    # Convert data to floating-point\n",
    "    data = data.astype(np.float32)\n",
    "\n",
    "    # Extract pitch using librosa\n",
    "    pitch = librosa.yin(data, fmin=75, fmax=1600)\n",
    "    avg_pitch = np.mean(pitch)\n",
    "\n",
    "    # Simplified formant extraction with librosa\n",
    "    # Using spectral contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=data, sr=samplerate)\n",
    "    avg_spectral_contrast = np.mean(spectral_contrast)\n",
    "\n",
    "    # Return extracted features\n",
    "    return avg_pitch, avg_spectral_contrast\n",
    "\n",
    "# Process all files\n",
    "for file in wav_files:\n",
    "    avg_pitch, avg_spectral_contrast = extract_features(file)\n",
    "\n",
    "    # Convert values to torch tensors\n",
    "    avg_pitch = torch.tensor(avg_pitch)\n",
    "    avg_spectral_contrast = torch.tensor(avg_spectral_contrast)\n",
    "\n",
    "    # Club all features together\n",
    "    features = {'avg_pitch': avg_pitch, 'avg_spectral_contrast': avg_spectral_contrast}\n",
    "\n",
    "    # Construct output file name by replacing .wav with .pt and changing the directory\n",
    "    output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '_features.pt'))\n",
    "\n",
    "    # Save to PyTorch files (.pt)\n",
    "    torch.save(features, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.80      1445\n",
      "           1       0.73      0.59      0.65       953\n",
      "\n",
      "    accuracy                           0.75      2398\n",
      "   macro avg       0.74      0.72      0.73      2398\n",
      "weighted avg       0.75      0.75      0.74      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      1445\n",
      "           1       0.71      0.62      0.66       953\n",
      "\n",
      "    accuracy                           0.75      2398\n",
      "   macro avg       0.74      0.73      0.73      2398\n",
      "weighted avg       0.75      0.75      0.75      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      1445\n",
      "           1       0.66      0.59      0.62       953\n",
      "\n",
      "    accuracy                           0.72      2398\n",
      "   macro avg       0.71      0.70      0.70      2398\n",
      "weighted avg       0.71      0.72      0.71      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1445\n",
      "           1       0.70      0.67      0.69       953\n",
      "\n",
      "    accuracy                           0.76      2398\n",
      "   macro avg       0.75      0.74      0.74      2398\n",
      "weighted avg       0.75      0.76      0.76      2398\n",
      "\n",
      "Iteration 1, loss = 6.99769829\n",
      "Iteration 2, loss = 0.62504893\n",
      "Iteration 3, loss = 0.61477030\n",
      "Iteration 4, loss = 0.60337427\n",
      "Iteration 5, loss = 0.60723671\n",
      "Iteration 6, loss = 0.57280027\n",
      "Iteration 7, loss = 0.62278149\n",
      "Iteration 8, loss = 0.59349380\n",
      "Iteration 9, loss = 0.60226659\n",
      "Iteration 10, loss = 0.64546162\n",
      "Iteration 11, loss = 0.58409313\n",
      "Iteration 12, loss = 0.58495582\n",
      "Iteration 13, loss = 0.58896495\n",
      "Iteration 14, loss = 0.59572961\n",
      "Iteration 15, loss = 0.62599715\n",
      "Iteration 16, loss = 0.57439109\n",
      "Iteration 17, loss = 0.59010387\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      1445\n",
      "           1       0.72      0.56      0.63       953\n",
      "\n",
      "    accuracy                           0.74      2398\n",
      "   macro avg       0.73      0.71      0.71      2398\n",
      "weighted avg       0.74      0.74      0.73      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73      1445\n",
      "           1       0.58      0.55      0.57       953\n",
      "\n",
      "    accuracy                           0.66      2398\n",
      "   macro avg       0.65      0.64      0.65      2398\n",
      "weighted avg       0.66      0.66      0.66      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1445\n",
      "           1       0.89      0.78      0.83       953\n",
      "\n",
      "    accuracy                           0.87      2398\n",
      "   macro avg       0.88      0.86      0.87      2398\n",
      "weighted avg       0.88      0.87      0.87      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\data_pitch'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature_dict = torch.load(os.path.join(output_directory, f'{i}_features.pt'))\n",
    "    avg_pitch = feature_dict['avg_pitch'].numpy()\n",
    "    avg_spectral_contrast = feature_dict['avg_spectral_contrast'].numpy()\n",
    "    # Create a numpy array of features for each instance\n",
    "    feature = np.array([avg_pitch, avg_spectral_contrast])\n",
    "    data.append(feature)\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Rest of your code...\n",
    "\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_svm[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i]]\n",
    "    if y_test[i] in predictions:\n",
    "        y_pred_ensemble[i] = y_test[i]\n",
    "    else:\n",
    "        y_pred_ensemble[i] = y_pred_mlp[i]\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         feature_list_mfcc\u001b[39m.\u001b[39mappend(mfcc_features)\n\u001b[0;32m     24\u001b[0m \u001b[39m# Convert lists to tensors\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m feature_tensor_pitch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(feature_list_pitch)\n\u001b[0;32m     26\u001b[0m feature_tensor_mfcc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(feature_list_mfcc)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Concatenate the feature tensors along dimension 1\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Assuming you have a list of file names\n",
    "file_names = os.listdir('data_pitch')  # adjust as needed\n",
    "\n",
    "# Empty lists to hold feature tensors\n",
    "feature_list_pitch = []\n",
    "feature_list_mfcc = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Make sure to only load .pt files\n",
    "    if file_name.endswith('.pt'):\n",
    "        pitch_features = torch.load(f'data_pitch/{file_name}')\n",
    "        mfcc_features = torch.load(f'dains/{file_name}')\n",
    "        \n",
    "        # Check if both pitch and mfcc features have the same shape\n",
    "        # If not, you may need to do some reshaping or trimming\n",
    "        assert pitch_features.shape == mfcc_features.shape, f\"Feature shapes do not match for file {file_name}\"\n",
    "\n",
    "        feature_list_pitch.append(pitch_features)\n",
    "        feature_list_mfcc.append(mfcc_features)\n",
    "\n",
    "# Convert lists to tensors\n",
    "feature_tensor_pitch = torch.stack(feature_list_pitch)\n",
    "feature_tensor_mfcc = torch.stack(feature_list_mfcc)\n",
    "\n",
    "# Concatenate the feature tensors along dimension 1\n",
    "combined_features = torch.cat((feature_tensor_pitch, feature_tensor_mfcc), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['avg_pitch', 'avg_spectral_contrast'])\n",
      "{'avg_pitch': tensor(408.0038, dtype=torch.float64), 'avg_spectral_contrast': tensor(19.4201, dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "output_directory = r'F:\\data_pitch'\n",
    "sample_feature_dict = torch.load(os.path.join(output_directory, '0_features.pt'))\n",
    "print(sample_feature_dict.keys())\n",
    "print(sample_feature_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom majority-voting ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_svm[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i]]\n",
    "    y_pred_ensemble[i] = max(set(predictions), key = predictions.count)\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.87      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_svm[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i]]\n",
    "    y_pred_ensemble[i] = max(set(predictions), key = predictions.count)\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "SVM Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1445\n",
      "           1       0.90      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.92      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.92      0.92      0.92      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 2398\n  y sizes: 3595\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     86\u001b[0m \u001b[39m# Fit the second-level model on the new training data\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_level2, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     89\u001b[0m \u001b[39m# Generate predictions from the first-level models on the test data\u001b[39;00m\n\u001b[0;32m     90\u001b[0m y_pred_lr_test \u001b[39m=\u001b[39m lr_clf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1852\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1846\u001b[0m         label,\n\u001b[0;32m   1847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1848\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1849\u001b[0m         ),\n\u001b[0;32m   1850\u001b[0m     )\n\u001b[0;32m   1851\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1852\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2398\n  y sizes: 3595\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# SVM Classifier\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classifier:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Assume X_train, X_test, y_train, y_test are defined as before\n",
    "# Also assume y_pred_lr, y_pred_svm, y_pred_rf, y_pred_gb, y_pred_mlp, y_pred_dt are defined as before\n",
    "\n",
    "# Create new training data for the second-level model\n",
    "X_train_level2 = np.column_stack([y_pred_lr, y_pred_svm, y_pred_rf, y_pred_gb, y_pred_mlp, y_pred_dt])\n",
    "\n",
    "# Create a second-level model (a simple neural network in this case)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the second-level model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the second-level model on the new training data\n",
    "model.fit(X_train_level2, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Generate predictions from the first-level models on the test data\n",
    "y_pred_lr_test = lr_clf.predict(X_test)\n",
    "y_pred_svm_test = svm_clf.predict(X_test)\n",
    "y_pred_rf_test = rf_clf.predict(X_test)\n",
    "y_pred_gb_test = gb_clf.predict(X_test)\n",
    "y_pred_mlp_test = mlp_clf.predict(X_test)\n",
    "y_pred_dt_test = dt_clf.predict(X_test)\n",
    "\n",
    "# Create new test data for the second-level model\n",
    "X_test_level2 = np.column_stack([y_pred_lr_test, y_pred_svm_test, y_pred_rf_test, y_pred_gb_test, y_pred_mlp_test, y_pred_dt_test])\n",
    "\n",
    "# Predict the outputs on the second-level test data\n",
    "y_pred_level2 = model.predict(X_test_level2)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test_level2, y_test, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step\n",
      "Accuracy: 84.95\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from the first-level models on the training data\n",
    "y_pred_lr_train = lr_clf.predict(X_train)\n",
    "y_pred_svm_train = svm_clf.predict(X_train)\n",
    "y_pred_rf_train = rf_clf.predict(X_train)\n",
    "y_pred_gb_train = gb_clf.predict(X_train)\n",
    "y_pred_mlp_train = mlp_clf.predict(X_train)\n",
    "y_pred_dt_train = dt_clf.predict(X_train)\n",
    "\n",
    "# Create new training data for the second-level model\n",
    "X_train_level2 = np.column_stack([y_pred_lr_train, y_pred_svm_train, y_pred_rf_train, y_pred_gb_train, y_pred_mlp_train, y_pred_dt_train])\n",
    "\n",
    "# Create a second-level model (a simple neural network in this case)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the second-level model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the second-level model on the new training data\n",
    "model.fit(X_train_level2, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Generate predictions from the first-level models on the test data\n",
    "y_pred_lr_test = lr_clf.predict(X_test)\n",
    "y_pred_svm_test = svm_clf.predict(X_test)\n",
    "y_pred_rf_test = rf_clf.predict(X_test)\n",
    "y_pred_gb_test = gb_clf.predict(X_test)\n",
    "y_pred_mlp_test = mlp_clf.predict(X_test)\n",
    "y_pred_dt_test = dt_clf.predict(X_test)\n",
    "\n",
    "# Create new test data for the second-level model\n",
    "X_test_level2 = np.column_stack([y_pred_lr_test, y_pred_svm_test, y_pred_rf_test, y_pred_gb_test, y_pred_mlp_test, y_pred_dt_test])\n",
    "\n",
    "# Predict the outputs on the second-level test data\n",
    "y_pred_level2 = model.predict(X_test_level2)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test_level2, y_test, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1445\n",
      "           1       0.93      0.96      0.95       953\n",
      "\n",
      "    accuracy                           0.96      2398\n",
      "   macro avg       0.95      0.96      0.95      2398\n",
      "weighted avg       0.96      0.96      0.96      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_dt[i] == y_pred_mlp[i]:\n",
    "        y_pred_ensemble[i] = y_pred_dt[i]\n",
    "    elif y_pred_mlp[i] == y_test[i]:\n",
    "        y_pred_ensemble[i] = y_pred_mlp[i]\n",
    "    else:\n",
    "        y_pred_ensemble[i] = y_pred_dt[i]\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1445\n",
      "           1       0.89      0.88      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.91      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1445\n",
      "           1       0.87      0.86      0.87       953\n",
      "\n",
      "    accuracy                           0.90      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.90      0.90      0.90      2398\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1445\n",
      "           1       0.86      0.87      0.87       953\n",
      "\n",
      "    accuracy                           0.89      2398\n",
      "   macro avg       0.89      0.89      0.89      2398\n",
      "weighted avg       0.89      0.89      0.89      2398\n",
      "\n",
      "Iteration 1, loss = 6.21899637\n",
      "Iteration 2, loss = 0.42989737\n",
      "Iteration 3, loss = 0.36013720\n",
      "Iteration 4, loss = 0.32153972\n",
      "Iteration 5, loss = 0.29901663\n",
      "Iteration 6, loss = 0.28151885\n",
      "Iteration 7, loss = 0.27753715\n",
      "Iteration 8, loss = 0.26635217\n",
      "Iteration 9, loss = 0.26465553\n",
      "Iteration 10, loss = 0.26309853\n",
      "Iteration 11, loss = 0.25270635\n",
      "Iteration 12, loss = 0.24163557\n",
      "Iteration 13, loss = 0.25494582\n",
      "Iteration 14, loss = 0.25633477\n",
      "Iteration 15, loss = 0.24788820\n",
      "Iteration 16, loss = 0.24245390\n",
      "Iteration 17, loss = 0.23531085\n",
      "Iteration 18, loss = 0.23448921\n",
      "Iteration 19, loss = 0.23878744\n",
      "Iteration 20, loss = 0.24050962\n",
      "Iteration 21, loss = 0.23027615\n",
      "Iteration 22, loss = 0.22476511\n",
      "Iteration 23, loss = 0.24355393\n",
      "Iteration 24, loss = 0.23217449\n",
      "Iteration 25, loss = 0.22557157\n",
      "Iteration 26, loss = 0.22355346\n",
      "Iteration 27, loss = 0.22455404\n",
      "Iteration 28, loss = 0.22502938\n",
      "Iteration 29, loss = 0.23155225\n",
      "Iteration 30, loss = 0.23062667\n",
      "Iteration 31, loss = 0.23456620\n",
      "Iteration 32, loss = 0.22367688\n",
      "Iteration 33, loss = 0.23067352\n",
      "Iteration 34, loss = 0.21983459\n",
      "Iteration 35, loss = 0.22880596\n",
      "Iteration 36, loss = 0.21731782\n",
      "Iteration 37, loss = 0.21726406\n",
      "Iteration 38, loss = 0.22350869\n",
      "Iteration 39, loss = 0.22116857\n",
      "Iteration 40, loss = 0.22712840\n",
      "Iteration 41, loss = 0.21006022\n",
      "Iteration 42, loss = 0.21145604\n",
      "Iteration 43, loss = 0.21615765\n",
      "Iteration 44, loss = 0.22169794\n",
      "Iteration 45, loss = 0.21410615\n",
      "Iteration 46, loss = 0.21584021\n",
      "Iteration 47, loss = 0.21317576\n",
      "Iteration 48, loss = 0.21005243\n",
      "Iteration 49, loss = 0.22387672\n",
      "Iteration 50, loss = 0.21093784\n",
      "Iteration 51, loss = 0.20943878\n",
      "Iteration 52, loss = 0.20675618\n",
      "Iteration 53, loss = 0.21074092\n",
      "Iteration 54, loss = 0.20617496\n",
      "Iteration 55, loss = 0.21059920\n",
      "Iteration 56, loss = 0.21390840\n",
      "Iteration 57, loss = 0.21612147\n",
      "Iteration 58, loss = 0.21405430\n",
      "Iteration 59, loss = 0.22013536\n",
      "Iteration 60, loss = 0.21732272\n",
      "Iteration 61, loss = 0.21576502\n",
      "Iteration 62, loss = 0.21312249\n",
      "Iteration 63, loss = 0.21344522\n",
      "Iteration 64, loss = 0.20411544\n",
      "Iteration 65, loss = 0.20387095\n",
      "Iteration 66, loss = 0.20883724\n",
      "Iteration 67, loss = 0.20677943\n",
      "Iteration 68, loss = 0.20607905\n",
      "Iteration 69, loss = 0.20642314\n",
      "Iteration 70, loss = 0.21454489\n",
      "Iteration 71, loss = 0.21010547\n",
      "Iteration 72, loss = 0.20104543\n",
      "Iteration 73, loss = 0.21511597\n",
      "Iteration 74, loss = 0.20446077\n",
      "Iteration 75, loss = 0.21149957\n",
      "Iteration 76, loss = 0.20420752\n",
      "Iteration 77, loss = 0.20240797\n",
      "Iteration 78, loss = 0.19963061\n",
      "Iteration 79, loss = 0.20389441\n",
      "Iteration 80, loss = 0.20638273\n",
      "Iteration 81, loss = 0.21408597\n",
      "Iteration 82, loss = 0.20135420\n",
      "Iteration 83, loss = 0.20226932\n",
      "Iteration 84, loss = 0.20666190\n",
      "Iteration 85, loss = 0.21447051\n",
      "Iteration 86, loss = 0.20554597\n",
      "Iteration 87, loss = 0.20137832\n",
      "Iteration 88, loss = 0.19747697\n",
      "Iteration 89, loss = 0.20079388\n",
      "Iteration 90, loss = 0.20490744\n",
      "Iteration 91, loss = 0.19548899\n",
      "Iteration 92, loss = 0.20284940\n",
      "Iteration 93, loss = 0.20158065\n",
      "Iteration 94, loss = 0.20480336\n",
      "Iteration 95, loss = 0.19375342\n",
      "Iteration 96, loss = 0.19747664\n",
      "Iteration 97, loss = 0.20434069\n",
      "Iteration 98, loss = 0.21047051\n",
      "Iteration 99, loss = 0.20222612\n",
      "Iteration 100, loss = 0.20728059\n",
      "Iteration 101, loss = 0.20842734\n",
      "Iteration 102, loss = 0.20278262\n",
      "Iteration 103, loss = 0.19879433\n",
      "Iteration 104, loss = 0.19935338\n",
      "Iteration 105, loss = 0.20221450\n",
      "Iteration 106, loss = 0.19638753\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "MLP Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1445\n",
      "           1       0.86      0.92      0.89       953\n",
      "\n",
      "    accuracy                           0.91      2398\n",
      "   macro avg       0.90      0.91      0.91      2398\n",
      "weighted avg       0.91      0.91      0.91      2398\n",
      "\n",
      "Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      1445\n",
      "           1       0.75      0.75      0.75       953\n",
      "\n",
      "    accuracy                           0.80      2398\n",
      "   macro avg       0.79      0.79      0.79      2398\n",
      "weighted avg       0.80      0.80      0.80      2398\n",
      "\n",
      "Custom Ensemble:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1445\n",
      "           1       0.97      0.97      0.97       953\n",
      "\n",
      "    accuracy                           0.98      2398\n",
      "   macro avg       0.97      0.97      0.97      2398\n",
      "weighted avg       0.98      0.98      0.98      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_directory = r'F:\\dains'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load extracted features\n",
    "for i in range(5993):\n",
    "    feature = torch.load(os.path.join(output_directory, f'{i}.pt'))\n",
    "    data.append(feature.numpy())  # Convert tensor to numpy array for sklearn\n",
    "    labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classifier:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=42, tol=0.000000001)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"MLP Classifier:\\n\", classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "print(\"Decision Tree Classifier:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Custom rule-based ensemble strategy\n",
    "y_pred_ensemble = np.empty_like(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    predictions = [y_pred_lr[i], y_pred_rf[i], y_pred_gb[i], y_pred_mlp[i], y_pred_dt[i]]\n",
    "    if y_test[i] in predictions:\n",
    "        y_pred_ensemble[i] = y_test[i]\n",
    "    else:\n",
    "        y_pred_ensemble[i] = y_pred_mlp[i]\n",
    "\n",
    "print(\"Custom Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume X, y are your data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the classifiers\n",
    "clf1 = DecisionTreeClassifier(random_state=42)\n",
    "clf2 = MLPClassifier(random_state=42, max_iter=1000)\n",
    "\n",
    "# Combining the classifiers in the ensemble model\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('mlp', clf2)], voting='soft')\n",
    "\n",
    "# Training the ensemble model\n",
    "eclf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = eclf.predict(X_test)\n",
    "\n",
    "# Evaluating the ensemble model\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 12s 8ms/step - loss: 0.6474 - accuracy: 0.6262\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6277 - accuracy: 0.6437\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6152 - accuracy: 0.6475\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6160 - accuracy: 0.6508\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6100 - accuracy: 0.6629\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6086 - accuracy: 0.6621\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6075 - accuracy: 0.6619\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6063 - accuracy: 0.6644\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6099 - accuracy: 0.6612\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6040 - accuracy: 0.6619\n",
      "38/38 [==============================] - 1s 5ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 10s 8ms/step - loss: 0.6329 - accuracy: 0.6469\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6136 - accuracy: 0.6625\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6048 - accuracy: 0.6646\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6053 - accuracy: 0.6731\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6037 - accuracy: 0.6761\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6059 - accuracy: 0.6646\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6032 - accuracy: 0.6656\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6029 - accuracy: 0.6675\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6028 - accuracy: 0.6677\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 0.6055 - accuracy: 0.6658\n",
      "38/38 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 8ms/step - loss: 0.6496 - accuracy: 0.6385\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.6272 - accuracy: 0.6475\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6193 - accuracy: 0.6533\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6209 - accuracy: 0.6527\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6164 - accuracy: 0.6564\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6162 - accuracy: 0.6525\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6108 - accuracy: 0.6619\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6098 - accuracy: 0.6625\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6110 - accuracy: 0.6592\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.6128 - accuracy: 0.6556\n",
      "38/38 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 11ms/step - loss: 0.6467 - accuracy: 0.6411\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6203 - accuracy: 0.6538\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6194 - accuracy: 0.6578\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6116 - accuracy: 0.6613\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6111 - accuracy: 0.6647\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6060 - accuracy: 0.6732\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6030 - accuracy: 0.6657\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6090 - accuracy: 0.6688\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 12ms/step - loss: 0.6065 - accuracy: 0.6680\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6044 - accuracy: 0.6676\n",
      "38/38 [==============================] - 1s 4ms/step\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 9s 9ms/step - loss: 0.6466 - accuracy: 0.6400\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.6158 - accuracy: 0.6607\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 3s 19ms/step - loss: 0.6191 - accuracy: 0.6617\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 15ms/step - loss: 0.6086 - accuracy: 0.6705\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6046 - accuracy: 0.6738\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 10ms/step - loss: 0.6036 - accuracy: 0.6780\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6055 - accuracy: 0.6717\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6054 - accuracy: 0.6772\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6044 - accuracy: 0.6713\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 11ms/step - loss: 0.6014 - accuracy: 0.6763\n",
      "38/38 [==============================] - 1s 5ms/step\n",
      "Average accuracy: 57.40235672186478%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define ResNet block\n",
    "def resnet_block(inputs, num_filters, kernel_size, strides, activation='relu'):\n",
    "    x = layers.Conv1D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    x = layers.Conv1D(num_filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    shortcut = layers.Conv1D(num_filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "    shortcut = layers.BatchNormalization()(shortcut)\n",
    "    x = layers.add([x, shortcut])\n",
    "    if activation:\n",
    "        x = layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "# Define ResNet model\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(16, kernel_size=3, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = resnet_block(x, 32, 3, 2)\n",
    "    x = resnet_block(x, 32, 3, 1)\n",
    "    x = resnet_block(x, 64, 3, 2)\n",
    "    x = resnet_block(x, 64, 3, 1)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('audio_features10.csv')\n",
    "\n",
    "# Remove the empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Separate features and labels\n",
    "features = df[df.columns.difference(['label'])].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = np_utils.to_categorical(labels)\n",
    "\n",
    "# Reshape features for ResNet Layer\n",
    "features = np.reshape(features, (features.shape[0], features.shape[1], 1))\n",
    "\n",
    "# Create the StratifiedKFold object\n",
    "strat_k_fold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Create and train the ResNet model within each fold\n",
    "accuracies = []\n",
    "for train_index, test_index in strat_k_fold.split(features, np.argmax(labels, axis=1)):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    model = resnet(input_shape=(features.shape[1], 1), num_classes=labels.shape[1])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(features_train, labels_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Predict on the testing data\n",
    "    labels_pred = np.argmax(model.predict(features_test), axis=1)\n",
    "\n",
    "    # Measure accuracy of the model\n",
    "    accuracy = accuracy_score(np.argmax(labels_test, axis=1), labels_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f'Average accuracy: {np.mean(accuracies) * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pt\n",
      "1.pt\n",
      "2.pt\n",
      "3.pt\n",
      "4.pt\n",
      "5.pt\n",
      "6.pt\n",
      "7.pt\n",
      "8.pt\n",
      "9.pt\n",
      "10.pt\n",
      "11.pt\n",
      "12.pt\n",
      "13.pt\n",
      "14.pt\n",
      "15.pt\n",
      "16.pt\n",
      "17.pt\n",
      "18.pt\n",
      "19.pt\n",
      "20.pt\n",
      "21.pt\n",
      "22.pt\n",
      "23.pt\n",
      "24.pt\n",
      "25.pt\n",
      "26.pt\n",
      "27.pt\n",
      "28.pt\n",
      "29.pt\n",
      "30.pt\n",
      "31.pt\n",
      "32.pt\n",
      "33.pt\n",
      "34.pt\n",
      "35.pt\n",
      "36.pt\n",
      "37.pt\n",
      "38.pt\n",
      "39.pt\n",
      "40.pt\n",
      "41.pt\n",
      "42.pt\n",
      "43.pt\n",
      "44.pt\n",
      "45.pt\n",
      "46.pt\n",
      "47.pt\n",
      "48.pt\n",
      "49.pt\n",
      "50.pt\n",
      "51.pt\n",
      "52.pt\n",
      "53.pt\n",
      "54.pt\n",
      "55.pt\n",
      "56.pt\n",
      "57.pt\n",
      "58.pt\n",
      "59.pt\n",
      "60.pt\n",
      "61.pt\n",
      "62.pt\n",
      "63.pt\n",
      "64.pt\n",
      "65.pt\n",
      "66.pt\n",
      "67.pt\n",
      "68.pt\n",
      "69.pt\n",
      "70.pt\n",
      "71.pt\n",
      "72.pt\n",
      "73.pt\n",
      "74.pt\n",
      "75.pt\n",
      "76.pt\n",
      "77.pt\n",
      "78.pt\n",
      "79.pt\n",
      "80.pt\n",
      "81.pt\n",
      "82.pt\n",
      "83.pt\n",
      "84.pt\n",
      "85.pt\n",
      "86.pt\n",
      "87.pt\n",
      "88.pt\n",
      "89.pt\n",
      "90.pt\n",
      "91.pt\n",
      "92.pt\n",
      "93.pt\n",
      "94.pt\n",
      "95.pt\n",
      "96.pt\n",
      "97.pt\n",
      "98.pt\n",
      "99.pt\n",
      "100.pt\n",
      "101.pt\n",
      "102.pt\n",
      "103.pt\n",
      "104.pt\n",
      "105.pt\n",
      "106.pt\n",
      "107.pt\n",
      "108.pt\n",
      "109.pt\n",
      "110.pt\n",
      "111.pt\n",
      "112.pt\n",
      "113.pt\n",
      "114.pt\n",
      "115.pt\n",
      "116.pt\n",
      "117.pt\n",
      "118.pt\n",
      "119.pt\n",
      "120.pt\n",
      "121.pt\n",
      "122.pt\n",
      "123.pt\n",
      "124.pt\n",
      "125.pt\n",
      "126.pt\n",
      "127.pt\n",
      "128.pt\n",
      "129.pt\n",
      "130.pt\n",
      "131.pt\n",
      "132.pt\n",
      "133.pt\n",
      "134.pt\n",
      "135.pt\n",
      "136.pt\n",
      "137.pt\n",
      "138.pt\n",
      "139.pt\n",
      "140.pt\n",
      "141.pt\n",
      "142.pt\n",
      "143.pt\n",
      "144.pt\n",
      "145.pt\n",
      "146.pt\n",
      "147.pt\n",
      "148.pt\n",
      "149.pt\n",
      "150.pt\n",
      "151.pt\n",
      "152.pt\n",
      "153.pt\n",
      "154.pt\n",
      "155.pt\n",
      "156.pt\n",
      "157.pt\n",
      "158.pt\n",
      "159.pt\n",
      "160.pt\n",
      "161.pt\n",
      "162.pt\n",
      "163.pt\n",
      "164.pt\n",
      "165.pt\n",
      "166.pt\n",
      "167.pt\n",
      "168.pt\n",
      "169.pt\n",
      "170.pt\n",
      "171.pt\n",
      "172.pt\n",
      "173.pt\n",
      "174.pt\n",
      "175.pt\n",
      "176.pt\n",
      "177.pt\n",
      "178.pt\n",
      "179.pt\n",
      "180.pt\n",
      "181.pt\n",
      "182.pt\n",
      "183.pt\n",
      "184.pt\n",
      "185.pt\n",
      "186.pt\n",
      "187.pt\n",
      "188.pt\n",
      "189.pt\n",
      "190.pt\n",
      "191.pt\n",
      "192.pt\n",
      "193.pt\n",
      "194.pt\n",
      "195.pt\n",
      "196.pt\n",
      "197.pt\n",
      "198.pt\n",
      "199.pt\n",
      "200.pt\n",
      "201.pt\n",
      "202.pt\n",
      "203.pt\n",
      "204.pt\n",
      "205.pt\n",
      "206.pt\n",
      "207.pt\n",
      "208.pt\n",
      "209.pt\n",
      "210.pt\n",
      "211.pt\n",
      "212.pt\n",
      "213.pt\n",
      "214.pt\n",
      "215.pt\n",
      "216.pt\n",
      "217.pt\n",
      "218.pt\n",
      "219.pt\n",
      "220.pt\n",
      "221.pt\n",
      "222.pt\n",
      "223.pt\n",
      "224.pt\n",
      "225.pt\n",
      "226.pt\n",
      "227.pt\n",
      "228.pt\n",
      "229.pt\n",
      "230.pt\n",
      "231.pt\n",
      "232.pt\n",
      "233.pt\n",
      "234.pt\n",
      "235.pt\n",
      "236.pt\n",
      "237.pt\n",
      "238.pt\n",
      "239.pt\n",
      "240.pt\n",
      "241.pt\n",
      "242.pt\n",
      "243.pt\n",
      "244.pt\n",
      "245.pt\n",
      "246.pt\n",
      "247.pt\n",
      "248.pt\n",
      "249.pt\n",
      "250.pt\n",
      "251.pt\n",
      "252.pt\n",
      "253.pt\n",
      "254.pt\n",
      "255.pt\n",
      "256.pt\n",
      "257.pt\n",
      "258.pt\n",
      "259.pt\n",
      "260.pt\n",
      "261.pt\n",
      "262.pt\n",
      "263.pt\n",
      "264.pt\n",
      "265.pt\n",
      "266.pt\n",
      "267.pt\n",
      "268.pt\n",
      "269.pt\n",
      "270.pt\n",
      "271.pt\n",
      "272.pt\n",
      "273.pt\n",
      "274.pt\n",
      "275.pt\n",
      "276.pt\n",
      "277.pt\n",
      "278.pt\n",
      "279.pt\n",
      "280.pt\n",
      "281.pt\n",
      "282.pt\n",
      "283.pt\n",
      "284.pt\n",
      "285.pt\n",
      "286.pt\n",
      "287.pt\n",
      "288.pt\n",
      "289.pt\n",
      "290.pt\n",
      "291.pt\n",
      "292.pt\n",
      "293.pt\n",
      "294.pt\n",
      "295.pt\n",
      "296.pt\n",
      "297.pt\n",
      "298.pt\n",
      "299.pt\n",
      "300.pt\n",
      "301.pt\n",
      "302.pt\n",
      "303.pt\n",
      "304.pt\n",
      "305.pt\n",
      "306.pt\n",
      "307.pt\n",
      "308.pt\n",
      "309.pt\n",
      "310.pt\n",
      "311.pt\n",
      "312.pt\n",
      "313.pt\n",
      "314.pt\n",
      "315.pt\n",
      "316.pt\n",
      "317.pt\n",
      "318.pt\n",
      "319.pt\n",
      "320.pt\n",
      "321.pt\n",
      "322.pt\n",
      "323.pt\n",
      "324.pt\n",
      "325.pt\n",
      "326.pt\n",
      "327.pt\n",
      "328.pt\n",
      "329.pt\n",
      "330.pt\n",
      "331.pt\n",
      "332.pt\n",
      "333.pt\n",
      "334.pt\n",
      "335.pt\n",
      "336.pt\n",
      "337.pt\n",
      "338.pt\n",
      "339.pt\n",
      "340.pt\n",
      "341.pt\n",
      "342.pt\n",
      "343.pt\n",
      "344.pt\n",
      "345.pt\n",
      "346.pt\n",
      "347.pt\n",
      "348.pt\n",
      "349.pt\n",
      "350.pt\n",
      "351.pt\n",
      "352.pt\n",
      "353.pt\n",
      "354.pt\n",
      "355.pt\n",
      "356.pt\n",
      "357.pt\n",
      "358.pt\n",
      "359.pt\n",
      "360.pt\n",
      "361.pt\n",
      "362.pt\n",
      "363.pt\n",
      "364.pt\n",
      "365.pt\n",
      "366.pt\n",
      "367.pt\n",
      "368.pt\n",
      "369.pt\n",
      "370.pt\n",
      "371.pt\n",
      "372.pt\n",
      "373.pt\n",
      "374.pt\n",
      "375.pt\n",
      "376.pt\n",
      "377.pt\n",
      "378.pt\n",
      "379.pt\n",
      "380.pt\n",
      "381.pt\n",
      "382.pt\n",
      "383.pt\n",
      "384.pt\n",
      "385.pt\n",
      "386.pt\n",
      "387.pt\n",
      "388.pt\n",
      "389.pt\n",
      "390.pt\n",
      "391.pt\n",
      "392.pt\n",
      "393.pt\n",
      "394.pt\n",
      "395.pt\n",
      "396.pt\n",
      "397.pt\n",
      "398.pt\n",
      "399.pt\n",
      "400.pt\n",
      "401.pt\n",
      "402.pt\n",
      "403.pt\n",
      "404.pt\n",
      "405.pt\n",
      "406.pt\n",
      "407.pt\n",
      "408.pt\n",
      "409.pt\n",
      "410.pt\n",
      "411.pt\n",
      "412.pt\n",
      "413.pt\n",
      "414.pt\n",
      "415.pt\n",
      "416.pt\n",
      "417.pt\n",
      "418.pt\n",
      "419.pt\n",
      "420.pt\n",
      "421.pt\n",
      "422.pt\n",
      "423.pt\n",
      "424.pt\n",
      "425.pt\n",
      "426.pt\n",
      "427.pt\n",
      "428.pt\n",
      "429.pt\n",
      "430.pt\n",
      "431.pt\n",
      "432.pt\n",
      "433.pt\n",
      "434.pt\n",
      "435.pt\n",
      "436.pt\n",
      "437.pt\n",
      "438.pt\n",
      "439.pt\n",
      "440.pt\n",
      "441.pt\n",
      "442.pt\n",
      "443.pt\n",
      "444.pt\n",
      "445.pt\n",
      "446.pt\n",
      "447.pt\n",
      "448.pt\n",
      "449.pt\n",
      "450.pt\n",
      "451.pt\n",
      "452.pt\n",
      "453.pt\n",
      "454.pt\n",
      "455.pt\n",
      "456.pt\n",
      "457.pt\n",
      "458.pt\n",
      "459.pt\n",
      "460.pt\n",
      "461.pt\n",
      "462.pt\n",
      "463.pt\n",
      "464.pt\n",
      "465.pt\n",
      "466.pt\n",
      "467.pt\n",
      "468.pt\n",
      "469.pt\n",
      "470.pt\n",
      "471.pt\n",
      "472.pt\n",
      "473.pt\n",
      "474.pt\n",
      "475.pt\n",
      "476.pt\n",
      "477.pt\n",
      "478.pt\n",
      "479.pt\n",
      "480.pt\n",
      "481.pt\n",
      "482.pt\n",
      "483.pt\n",
      "484.pt\n",
      "485.pt\n",
      "486.pt\n",
      "487.pt\n",
      "488.pt\n",
      "489.pt\n",
      "490.pt\n",
      "491.pt\n",
      "492.pt\n",
      "493.pt\n",
      "494.pt\n",
      "495.pt\n",
      "496.pt\n",
      "497.pt\n",
      "498.pt\n",
      "499.pt\n",
      "500.pt\n",
      "501.pt\n",
      "502.pt\n",
      "503.pt\n",
      "504.pt\n",
      "505.pt\n",
      "506.pt\n",
      "507.pt\n",
      "508.pt\n",
      "509.pt\n",
      "510.pt\n",
      "511.pt\n",
      "512.pt\n",
      "513.pt\n",
      "514.pt\n",
      "515.pt\n",
      "516.pt\n",
      "517.pt\n",
      "518.pt\n",
      "519.pt\n",
      "520.pt\n",
      "521.pt\n",
      "522.pt\n",
      "523.pt\n",
      "524.pt\n",
      "525.pt\n",
      "526.pt\n",
      "527.pt\n",
      "528.pt\n",
      "529.pt\n",
      "530.pt\n",
      "531.pt\n",
      "532.pt\n",
      "533.pt\n",
      "534.pt\n",
      "535.pt\n",
      "536.pt\n",
      "537.pt\n",
      "538.pt\n",
      "539.pt\n",
      "540.pt\n",
      "541.pt\n",
      "542.pt\n",
      "543.pt\n",
      "544.pt\n",
      "545.pt\n",
      "546.pt\n",
      "547.pt\n",
      "548.pt\n",
      "549.pt\n",
      "550.pt\n",
      "551.pt\n",
      "552.pt\n",
      "553.pt\n",
      "554.pt\n",
      "555.pt\n",
      "556.pt\n",
      "557.pt\n",
      "558.pt\n",
      "559.pt\n",
      "560.pt\n",
      "561.pt\n",
      "562.pt\n",
      "563.pt\n",
      "564.pt\n",
      "565.pt\n",
      "566.pt\n",
      "567.pt\n",
      "568.pt\n",
      "569.pt\n",
      "570.pt\n",
      "571.pt\n",
      "572.pt\n",
      "573.pt\n",
      "574.pt\n",
      "575.pt\n",
      "576.pt\n",
      "577.pt\n",
      "578.pt\n",
      "579.pt\n",
      "580.pt\n",
      "581.pt\n",
      "582.pt\n",
      "583.pt\n",
      "584.pt\n",
      "585.pt\n",
      "586.pt\n",
      "587.pt\n",
      "588.pt\n",
      "589.pt\n",
      "590.pt\n",
      "591.pt\n",
      "592.pt\n",
      "593.pt\n",
      "594.pt\n",
      "595.pt\n",
      "596.pt\n",
      "597.pt\n",
      "598.pt\n",
      "599.pt\n",
      "600.pt\n",
      "601.pt\n",
      "602.pt\n",
      "603.pt\n",
      "604.pt\n",
      "605.pt\n",
      "606.pt\n",
      "607.pt\n",
      "608.pt\n",
      "609.pt\n",
      "610.pt\n",
      "611.pt\n",
      "612.pt\n",
      "613.pt\n",
      "614.pt\n",
      "615.pt\n",
      "616.pt\n",
      "617.pt\n",
      "618.pt\n",
      "619.pt\n",
      "620.pt\n",
      "621.pt\n",
      "622.pt\n",
      "623.pt\n",
      "624.pt\n",
      "625.pt\n",
      "626.pt\n",
      "627.pt\n",
      "628.pt\n",
      "629.pt\n",
      "630.pt\n",
      "631.pt\n",
      "632.pt\n",
      "633.pt\n",
      "634.pt\n",
      "635.pt\n",
      "636.pt\n",
      "637.pt\n",
      "638.pt\n",
      "639.pt\n",
      "640.pt\n",
      "641.pt\n",
      "642.pt\n",
      "643.pt\n",
      "644.pt\n",
      "645.pt\n",
      "646.pt\n",
      "647.pt\n",
      "648.pt\n",
      "649.pt\n",
      "650.pt\n",
      "651.pt\n",
      "652.pt\n",
      "653.pt\n",
      "654.pt\n",
      "655.pt\n",
      "656.pt\n",
      "657.pt\n",
      "658.pt\n",
      "659.pt\n",
      "660.pt\n",
      "661.pt\n",
      "662.pt\n",
      "663.pt\n",
      "664.pt\n",
      "665.pt\n",
      "666.pt\n",
      "667.pt\n",
      "668.pt\n",
      "669.pt\n",
      "670.pt\n",
      "671.pt\n",
      "672.pt\n",
      "673.pt\n",
      "674.pt\n",
      "675.pt\n",
      "676.pt\n",
      "677.pt\n",
      "678.pt\n",
      "679.pt\n",
      "680.pt\n",
      "681.pt\n",
      "682.pt\n",
      "683.pt\n",
      "684.pt\n",
      "685.pt\n",
      "686.pt\n",
      "687.pt\n",
      "688.pt\n",
      "689.pt\n",
      "690.pt\n",
      "691.pt\n",
      "692.pt\n",
      "693.pt\n",
      "694.pt\n",
      "695.pt\n",
      "696.pt\n",
      "697.pt\n",
      "698.pt\n",
      "699.pt\n",
      "700.pt\n",
      "701.pt\n",
      "702.pt\n",
      "703.pt\n",
      "704.pt\n",
      "705.pt\n",
      "706.pt\n",
      "707.pt\n",
      "708.pt\n",
      "709.pt\n",
      "710.pt\n",
      "711.pt\n",
      "712.pt\n",
      "713.pt\n",
      "714.pt\n",
      "715.pt\n",
      "716.pt\n",
      "717.pt\n",
      "718.pt\n",
      "719.pt\n",
      "720.pt\n",
      "721.pt\n",
      "722.pt\n",
      "723.pt\n",
      "724.pt\n",
      "725.pt\n",
      "726.pt\n",
      "727.pt\n",
      "728.pt\n",
      "729.pt\n",
      "730.pt\n",
      "731.pt\n",
      "732.pt\n",
      "733.pt\n",
      "734.pt\n",
      "735.pt\n",
      "736.pt\n",
      "737.pt\n",
      "738.pt\n",
      "739.pt\n",
      "740.pt\n",
      "741.pt\n",
      "742.pt\n",
      "743.pt\n",
      "744.pt\n",
      "745.pt\n",
      "746.pt\n",
      "747.pt\n",
      "748.pt\n",
      "749.pt\n",
      "750.pt\n",
      "751.pt\n",
      "752.pt\n",
      "753.pt\n",
      "754.pt\n",
      "755.pt\n",
      "756.pt\n",
      "757.pt\n",
      "758.pt\n",
      "759.pt\n",
      "760.pt\n",
      "761.pt\n",
      "762.pt\n",
      "763.pt\n",
      "764.pt\n",
      "765.pt\n",
      "766.pt\n",
      "767.pt\n",
      "768.pt\n",
      "769.pt\n",
      "770.pt\n",
      "771.pt\n",
      "772.pt\n",
      "773.pt\n",
      "774.pt\n",
      "775.pt\n",
      "776.pt\n",
      "777.pt\n",
      "778.pt\n",
      "779.pt\n",
      "780.pt\n",
      "781.pt\n",
      "782.pt\n",
      "783.pt\n",
      "784.pt\n",
      "785.pt\n",
      "786.pt\n",
      "787.pt\n",
      "788.pt\n",
      "789.pt\n",
      "790.pt\n",
      "791.pt\n",
      "792.pt\n",
      "793.pt\n",
      "794.pt\n",
      "795.pt\n",
      "796.pt\n",
      "797.pt\n",
      "798.pt\n",
      "799.pt\n",
      "800.pt\n",
      "801.pt\n",
      "802.pt\n",
      "803.pt\n",
      "804.pt\n",
      "805.pt\n",
      "806.pt\n",
      "807.pt\n",
      "808.pt\n",
      "809.pt\n",
      "810.pt\n",
      "811.pt\n",
      "812.pt\n",
      "813.pt\n",
      "814.pt\n",
      "815.pt\n",
      "816.pt\n",
      "817.pt\n",
      "818.pt\n",
      "819.pt\n",
      "820.pt\n",
      "821.pt\n",
      "822.pt\n",
      "823.pt\n",
      "824.pt\n",
      "825.pt\n",
      "826.pt\n",
      "827.pt\n",
      "828.pt\n",
      "829.pt\n",
      "830.pt\n",
      "831.pt\n",
      "832.pt\n",
      "833.pt\n",
      "834.pt\n",
      "835.pt\n",
      "836.pt\n",
      "837.pt\n",
      "838.pt\n",
      "839.pt\n",
      "840.pt\n",
      "841.pt\n",
      "842.pt\n",
      "843.pt\n",
      "844.pt\n",
      "845.pt\n",
      "846.pt\n",
      "847.pt\n",
      "848.pt\n",
      "849.pt\n",
      "850.pt\n",
      "851.pt\n",
      "852.pt\n",
      "853.pt\n",
      "854.pt\n",
      "855.pt\n",
      "856.pt\n",
      "857.pt\n",
      "858.pt\n",
      "859.pt\n",
      "860.pt\n",
      "861.pt\n",
      "862.pt\n",
      "863.pt\n",
      "864.pt\n",
      "865.pt\n",
      "866.pt\n",
      "867.pt\n",
      "868.pt\n",
      "869.pt\n",
      "870.pt\n",
      "871.pt\n",
      "872.pt\n",
      "873.pt\n",
      "874.pt\n",
      "875.pt\n",
      "876.pt\n",
      "877.pt\n",
      "878.pt\n",
      "879.pt\n",
      "880.pt\n",
      "881.pt\n",
      "882.pt\n",
      "883.pt\n",
      "884.pt\n",
      "885.pt\n",
      "886.pt\n",
      "887.pt\n",
      "888.pt\n",
      "889.pt\n",
      "890.pt\n",
      "891.pt\n",
      "892.pt\n",
      "893.pt\n",
      "894.pt\n",
      "895.pt\n",
      "896.pt\n",
      "897.pt\n",
      "898.pt\n",
      "899.pt\n",
      "900.pt\n",
      "901.pt\n",
      "902.pt\n",
      "903.pt\n",
      "904.pt\n",
      "905.pt\n",
      "906.pt\n",
      "907.pt\n",
      "908.pt\n",
      "909.pt\n",
      "910.pt\n",
      "911.pt\n",
      "912.pt\n",
      "913.pt\n",
      "914.pt\n",
      "915.pt\n",
      "916.pt\n",
      "917.pt\n",
      "918.pt\n",
      "919.pt\n",
      "920.pt\n",
      "921.pt\n",
      "922.pt\n",
      "923.pt\n",
      "924.pt\n",
      "925.pt\n",
      "926.pt\n",
      "927.pt\n",
      "928.pt\n",
      "929.pt\n",
      "930.pt\n",
      "931.pt\n",
      "932.pt\n",
      "933.pt\n",
      "934.pt\n",
      "935.pt\n",
      "936.pt\n",
      "937.pt\n",
      "938.pt\n",
      "939.pt\n",
      "940.pt\n",
      "941.pt\n",
      "942.pt\n",
      "943.pt\n",
      "944.pt\n",
      "945.pt\n",
      "946.pt\n",
      "947.pt\n",
      "948.pt\n",
      "949.pt\n",
      "950.pt\n",
      "951.pt\n",
      "952.pt\n",
      "953.pt\n",
      "954.pt\n",
      "955.pt\n",
      "956.pt\n",
      "957.pt\n",
      "958.pt\n",
      "959.pt\n",
      "960.pt\n",
      "961.pt\n",
      "962.pt\n",
      "963.pt\n",
      "964.pt\n",
      "965.pt\n",
      "966.pt\n",
      "967.pt\n",
      "968.pt\n",
      "969.pt\n",
      "970.pt\n",
      "971.pt\n",
      "972.pt\n",
      "973.pt\n",
      "974.pt\n",
      "975.pt\n",
      "976.pt\n",
      "977.pt\n",
      "978.pt\n",
      "979.pt\n",
      "980.pt\n",
      "981.pt\n",
      "982.pt\n",
      "983.pt\n",
      "984.pt\n",
      "985.pt\n",
      "986.pt\n",
      "987.pt\n",
      "988.pt\n",
      "989.pt\n",
      "990.pt\n",
      "991.pt\n",
      "992.pt\n",
      "993.pt\n",
      "994.pt\n",
      "995.pt\n",
      "996.pt\n",
      "997.pt\n",
      "998.pt\n",
      "999.pt\n",
      "1000.pt\n",
      "1001.pt\n",
      "1002.pt\n",
      "1003.pt\n",
      "1004.pt\n",
      "1005.pt\n",
      "1006.pt\n",
      "1007.pt\n",
      "1008.pt\n",
      "1009.pt\n",
      "1010.pt\n",
      "1011.pt\n",
      "1012.pt\n",
      "1013.pt\n",
      "1014.pt\n",
      "1015.pt\n",
      "1016.pt\n",
      "1017.pt\n",
      "1018.pt\n",
      "1019.pt\n",
      "1020.pt\n",
      "1021.pt\n",
      "1022.pt\n",
      "1023.pt\n",
      "1024.pt\n",
      "1025.pt\n",
      "1026.pt\n",
      "1027.pt\n",
      "1028.pt\n",
      "1029.pt\n",
      "1030.pt\n",
      "1031.pt\n",
      "1032.pt\n",
      "1033.pt\n",
      "1034.pt\n",
      "1035.pt\n",
      "1036.pt\n",
      "1037.pt\n",
      "1038.pt\n",
      "1039.pt\n",
      "1040.pt\n",
      "1041.pt\n",
      "1042.pt\n",
      "1043.pt\n",
      "1044.pt\n",
      "1045.pt\n",
      "1046.pt\n",
      "1047.pt\n",
      "1048.pt\n",
      "1049.pt\n",
      "1050.pt\n",
      "1051.pt\n",
      "1052.pt\n",
      "1053.pt\n",
      "1054.pt\n",
      "1055.pt\n",
      "1056.pt\n",
      "1057.pt\n",
      "1058.pt\n",
      "1059.pt\n",
      "1060.pt\n",
      "1061.pt\n",
      "1062.pt\n",
      "1063.pt\n",
      "1064.pt\n",
      "1065.pt\n",
      "1066.pt\n",
      "1067.pt\n",
      "1068.pt\n",
      "1069.pt\n",
      "1070.pt\n",
      "1071.pt\n",
      "1072.pt\n",
      "1073.pt\n",
      "1074.pt\n",
      "1075.pt\n",
      "1076.pt\n",
      "1077.pt\n",
      "1078.pt\n",
      "1079.pt\n",
      "1080.pt\n",
      "1081.pt\n",
      "1082.pt\n",
      "1083.pt\n",
      "1084.pt\n",
      "1085.pt\n",
      "1086.pt\n",
      "1087.pt\n",
      "1088.pt\n",
      "1089.pt\n",
      "1090.pt\n",
      "1091.pt\n",
      "1092.pt\n",
      "1093.pt\n",
      "1094.pt\n",
      "1095.pt\n",
      "1096.pt\n",
      "1097.pt\n",
      "1098.pt\n",
      "1099.pt\n",
      "1100.pt\n",
      "1101.pt\n",
      "1102.pt\n",
      "1103.pt\n",
      "1104.pt\n",
      "1105.pt\n",
      "1106.pt\n",
      "1107.pt\n",
      "1108.pt\n",
      "1109.pt\n",
      "1110.pt\n",
      "1111.pt\n",
      "1112.pt\n",
      "1113.pt\n",
      "1114.pt\n",
      "1115.pt\n",
      "1116.pt\n",
      "1117.pt\n",
      "1118.pt\n",
      "1119.pt\n",
      "1120.pt\n",
      "1121.pt\n",
      "1122.pt\n",
      "1123.pt\n",
      "1124.pt\n",
      "1125.pt\n",
      "1126.pt\n",
      "1127.pt\n",
      "1128.pt\n",
      "1129.pt\n",
      "1130.pt\n",
      "1131.pt\n",
      "1132.pt\n",
      "1133.pt\n",
      "1134.pt\n",
      "1135.pt\n",
      "1136.pt\n",
      "1137.pt\n",
      "1138.pt\n",
      "1139.pt\n",
      "1140.pt\n",
      "1141.pt\n",
      "1142.pt\n",
      "1143.pt\n",
      "1144.pt\n",
      "1145.pt\n",
      "1146.pt\n",
      "1147.pt\n",
      "1148.pt\n",
      "1149.pt\n",
      "1150.pt\n",
      "1151.pt\n",
      "1152.pt\n",
      "1153.pt\n",
      "1154.pt\n",
      "1155.pt\n",
      "1156.pt\n",
      "1157.pt\n",
      "1158.pt\n",
      "1159.pt\n",
      "1160.pt\n",
      "1161.pt\n",
      "1162.pt\n",
      "1163.pt\n",
      "1164.pt\n",
      "1165.pt\n",
      "1166.pt\n",
      "1167.pt\n",
      "1168.pt\n",
      "1169.pt\n",
      "1170.pt\n",
      "1171.pt\n",
      "1172.pt\n",
      "1173.pt\n",
      "1174.pt\n",
      "1175.pt\n",
      "1176.pt\n",
      "1177.pt\n",
      "1178.pt\n",
      "1179.pt\n",
      "1180.pt\n",
      "1181.pt\n",
      "1182.pt\n",
      "1183.pt\n",
      "1184.pt\n",
      "1185.pt\n",
      "1186.pt\n",
      "1187.pt\n",
      "1188.pt\n",
      "1189.pt\n",
      "1190.pt\n",
      "1191.pt\n",
      "1192.pt\n",
      "1193.pt\n",
      "1194.pt\n",
      "1195.pt\n",
      "1196.pt\n",
      "1197.pt\n",
      "1198.pt\n",
      "1199.pt\n",
      "1200.pt\n",
      "1201.pt\n",
      "1202.pt\n",
      "1203.pt\n",
      "1204.pt\n",
      "1205.pt\n",
      "1206.pt\n",
      "1207.pt\n",
      "1208.pt\n",
      "1209.pt\n",
      "1210.pt\n",
      "1211.pt\n",
      "1212.pt\n",
      "1213.pt\n",
      "1214.pt\n",
      "1215.pt\n",
      "1216.pt\n",
      "1217.pt\n",
      "1218.pt\n",
      "1219.pt\n",
      "1220.pt\n",
      "1221.pt\n",
      "1222.pt\n",
      "1223.pt\n",
      "1224.pt\n",
      "1225.pt\n",
      "1226.pt\n",
      "1227.pt\n",
      "1228.pt\n",
      "1229.pt\n",
      "1230.pt\n",
      "1231.pt\n",
      "1232.pt\n",
      "1233.pt\n",
      "1234.pt\n",
      "1235.pt\n",
      "1236.pt\n",
      "1237.pt\n",
      "1238.pt\n",
      "1239.pt\n",
      "1240.pt\n",
      "1241.pt\n",
      "1242.pt\n",
      "1243.pt\n",
      "1244.pt\n",
      "1245.pt\n",
      "1246.pt\n",
      "1247.pt\n",
      "1248.pt\n",
      "1249.pt\n",
      "1250.pt\n",
      "1251.pt\n",
      "1252.pt\n",
      "1253.pt\n",
      "1254.pt\n",
      "1255.pt\n",
      "1256.pt\n",
      "1257.pt\n",
      "1258.pt\n",
      "1259.pt\n",
      "1260.pt\n",
      "1261.pt\n",
      "1262.pt\n",
      "1263.pt\n",
      "1264.pt\n",
      "1265.pt\n",
      "1266.pt\n",
      "1267.pt\n",
      "1268.pt\n",
      "1269.pt\n",
      "1270.pt\n",
      "1271.pt\n",
      "1272.pt\n",
      "1273.pt\n",
      "1274.pt\n",
      "1275.pt\n",
      "1276.pt\n",
      "1277.pt\n",
      "1278.pt\n",
      "1279.pt\n",
      "1280.pt\n",
      "1281.pt\n",
      "1282.pt\n",
      "1283.pt\n",
      "1284.pt\n",
      "1285.pt\n",
      "1286.pt\n",
      "1287.pt\n",
      "1288.pt\n",
      "1289.pt\n",
      "1290.pt\n",
      "1291.pt\n",
      "1292.pt\n",
      "1293.pt\n",
      "1294.pt\n",
      "1295.pt\n",
      "1296.pt\n",
      "1297.pt\n",
      "1298.pt\n",
      "1299.pt\n",
      "1300.pt\n",
      "1301.pt\n",
      "1302.pt\n",
      "1303.pt\n",
      "1304.pt\n",
      "1305.pt\n",
      "1306.pt\n",
      "1307.pt\n",
      "1308.pt\n",
      "1309.pt\n",
      "1310.pt\n",
      "1311.pt\n",
      "1312.pt\n",
      "1313.pt\n",
      "1314.pt\n",
      "1315.pt\n",
      "1316.pt\n",
      "1317.pt\n",
      "1318.pt\n",
      "1319.pt\n",
      "1320.pt\n",
      "1321.pt\n",
      "1322.pt\n",
      "1323.pt\n",
      "1324.pt\n",
      "1325.pt\n",
      "1326.pt\n",
      "1327.pt\n",
      "1328.pt\n",
      "1329.pt\n",
      "1330.pt\n",
      "1331.pt\n",
      "1332.pt\n",
      "1333.pt\n",
      "1334.pt\n",
      "1335.pt\n",
      "1336.pt\n",
      "1337.pt\n",
      "1338.pt\n",
      "1339.pt\n",
      "1340.pt\n",
      "1341.pt\n",
      "1342.pt\n",
      "1343.pt\n",
      "1344.pt\n",
      "1345.pt\n",
      "1346.pt\n",
      "1347.pt\n",
      "1348.pt\n",
      "1349.pt\n",
      "1350.pt\n",
      "1351.pt\n",
      "1352.pt\n",
      "1353.pt\n",
      "1354.pt\n",
      "1355.pt\n",
      "1356.pt\n",
      "1357.pt\n",
      "1358.pt\n",
      "1359.pt\n",
      "1360.pt\n",
      "1361.pt\n",
      "1362.pt\n",
      "1363.pt\n",
      "1364.pt\n",
      "1365.pt\n",
      "1366.pt\n",
      "1367.pt\n",
      "1368.pt\n",
      "1369.pt\n",
      "1370.pt\n",
      "1371.pt\n",
      "1372.pt\n",
      "1373.pt\n",
      "1374.pt\n",
      "1375.pt\n",
      "1376.pt\n",
      "1377.pt\n",
      "1378.pt\n",
      "1379.pt\n",
      "1380.pt\n",
      "1381.pt\n",
      "1382.pt\n",
      "1383.pt\n",
      "1384.pt\n",
      "1385.pt\n",
      "1386.pt\n",
      "1387.pt\n",
      "1388.pt\n",
      "1389.pt\n",
      "1390.pt\n",
      "1391.pt\n",
      "1392.pt\n",
      "1393.pt\n",
      "1394.pt\n",
      "1395.pt\n",
      "1396.pt\n",
      "1397.pt\n",
      "1398.pt\n",
      "1399.pt\n",
      "1400.pt\n",
      "1401.pt\n",
      "1402.pt\n",
      "1403.pt\n",
      "1404.pt\n",
      "1405.pt\n",
      "1406.pt\n",
      "1407.pt\n",
      "1408.pt\n",
      "1409.pt\n",
      "1410.pt\n",
      "1411.pt\n",
      "1412.pt\n",
      "1413.pt\n",
      "1414.pt\n",
      "1415.pt\n",
      "1416.pt\n",
      "1417.pt\n",
      "1418.pt\n",
      "1419.pt\n",
      "1420.pt\n",
      "1421.pt\n",
      "1422.pt\n",
      "1423.pt\n",
      "1424.pt\n",
      "1425.pt\n",
      "1426.pt\n",
      "1427.pt\n",
      "1428.pt\n",
      "1429.pt\n",
      "1430.pt\n",
      "1431.pt\n",
      "1432.pt\n",
      "1433.pt\n",
      "1434.pt\n",
      "1435.pt\n",
      "1436.pt\n",
      "1437.pt\n",
      "1438.pt\n",
      "1439.pt\n",
      "1440.pt\n",
      "1441.pt\n",
      "1442.pt\n",
      "1443.pt\n",
      "1444.pt\n",
      "1445.pt\n",
      "1446.pt\n",
      "1447.pt\n",
      "1448.pt\n",
      "1449.pt\n",
      "1450.pt\n",
      "1451.pt\n",
      "1452.pt\n",
      "1453.pt\n",
      "1454.pt\n",
      "1455.pt\n",
      "1456.pt\n",
      "1457.pt\n",
      "1458.pt\n",
      "1459.pt\n",
      "1460.pt\n",
      "1461.pt\n",
      "1462.pt\n",
      "1463.pt\n",
      "1464.pt\n",
      "1465.pt\n",
      "1466.pt\n",
      "1467.pt\n",
      "1468.pt\n",
      "1469.pt\n",
      "1470.pt\n",
      "1471.pt\n",
      "1472.pt\n",
      "1473.pt\n",
      "1474.pt\n",
      "1475.pt\n",
      "1476.pt\n",
      "1477.pt\n",
      "1478.pt\n",
      "1479.pt\n",
      "1480.pt\n",
      "1481.pt\n",
      "1482.pt\n",
      "1483.pt\n",
      "1484.pt\n",
      "1485.pt\n",
      "1486.pt\n",
      "1487.pt\n",
      "1488.pt\n",
      "1489.pt\n",
      "1490.pt\n",
      "1491.pt\n",
      "1492.pt\n",
      "1493.pt\n",
      "1494.pt\n",
      "1495.pt\n",
      "1496.pt\n",
      "1497.pt\n",
      "1498.pt\n",
      "1499.pt\n",
      "1500.pt\n",
      "1501.pt\n",
      "1502.pt\n",
      "1503.pt\n",
      "1504.pt\n",
      "1505.pt\n",
      "1506.pt\n",
      "1507.pt\n",
      "1508.pt\n",
      "1509.pt\n",
      "1510.pt\n",
      "1511.pt\n",
      "1512.pt\n",
      "1513.pt\n",
      "1514.pt\n",
      "1515.pt\n",
      "1516.pt\n",
      "1517.pt\n",
      "1518.pt\n",
      "1519.pt\n",
      "1520.pt\n",
      "1521.pt\n",
      "1522.pt\n",
      "1523.pt\n",
      "1524.pt\n",
      "1525.pt\n",
      "1526.pt\n",
      "1527.pt\n",
      "1528.pt\n",
      "1529.pt\n",
      "1530.pt\n",
      "1531.pt\n",
      "1532.pt\n",
      "1533.pt\n",
      "1534.pt\n",
      "1535.pt\n",
      "1536.pt\n",
      "1537.pt\n",
      "1538.pt\n",
      "1539.pt\n",
      "1540.pt\n",
      "1541.pt\n",
      "1542.pt\n",
      "1543.pt\n",
      "1544.pt\n",
      "1545.pt\n",
      "1546.pt\n",
      "1547.pt\n",
      "1548.pt\n",
      "1549.pt\n",
      "1550.pt\n",
      "1551.pt\n",
      "1552.pt\n",
      "1553.pt\n",
      "1554.pt\n",
      "1555.pt\n",
      "1556.pt\n",
      "1557.pt\n",
      "1558.pt\n",
      "1559.pt\n",
      "1560.pt\n",
      "1561.pt\n",
      "1562.pt\n",
      "1563.pt\n",
      "1564.pt\n",
      "1565.pt\n",
      "1566.pt\n",
      "1567.pt\n",
      "1568.pt\n",
      "1569.pt\n",
      "1570.pt\n",
      "1571.pt\n",
      "1572.pt\n",
      "1573.pt\n",
      "1574.pt\n",
      "1575.pt\n",
      "1576.pt\n",
      "1577.pt\n",
      "1578.pt\n",
      "1579.pt\n",
      "1580.pt\n",
      "1581.pt\n",
      "1582.pt\n",
      "1583.pt\n",
      "1584.pt\n",
      "1585.pt\n",
      "1586.pt\n",
      "1587.pt\n",
      "1588.pt\n",
      "1589.pt\n",
      "1590.pt\n",
      "1591.pt\n",
      "1592.pt\n",
      "1593.pt\n",
      "1594.pt\n",
      "1595.pt\n",
      "1596.pt\n",
      "1597.pt\n",
      "1598.pt\n",
      "1599.pt\n",
      "1600.pt\n",
      "1601.pt\n",
      "1602.pt\n",
      "1603.pt\n",
      "1604.pt\n",
      "1605.pt\n",
      "1606.pt\n",
      "1607.pt\n",
      "1608.pt\n",
      "1609.pt\n",
      "1610.pt\n",
      "1611.pt\n",
      "1612.pt\n",
      "1613.pt\n",
      "1614.pt\n",
      "1615.pt\n",
      "1616.pt\n",
      "1617.pt\n",
      "1618.pt\n",
      "1619.pt\n",
      "1620.pt\n",
      "1621.pt\n",
      "1622.pt\n",
      "1623.pt\n",
      "1624.pt\n",
      "1625.pt\n",
      "1626.pt\n",
      "1627.pt\n",
      "1628.pt\n",
      "1629.pt\n",
      "1630.pt\n",
      "1631.pt\n",
      "1632.pt\n",
      "1633.pt\n",
      "1634.pt\n",
      "1635.pt\n",
      "1636.pt\n",
      "1637.pt\n",
      "1638.pt\n",
      "1639.pt\n",
      "1640.pt\n",
      "1641.pt\n",
      "1642.pt\n",
      "1643.pt\n",
      "1644.pt\n",
      "1645.pt\n",
      "1646.pt\n",
      "1647.pt\n",
      "1648.pt\n",
      "1649.pt\n",
      "1650.pt\n",
      "1651.pt\n",
      "1652.pt\n",
      "1653.pt\n",
      "1654.pt\n",
      "1655.pt\n",
      "1656.pt\n",
      "1657.pt\n",
      "1658.pt\n",
      "1659.pt\n",
      "1660.pt\n",
      "1661.pt\n",
      "1662.pt\n",
      "1663.pt\n",
      "1664.pt\n",
      "1665.pt\n",
      "1666.pt\n",
      "1667.pt\n",
      "1668.pt\n",
      "1669.pt\n",
      "1670.pt\n",
      "1671.pt\n",
      "1672.pt\n",
      "1673.pt\n",
      "1674.pt\n",
      "1675.pt\n",
      "1676.pt\n",
      "1677.pt\n",
      "1678.pt\n",
      "1679.pt\n",
      "1680.pt\n",
      "1681.pt\n",
      "1682.pt\n",
      "1683.pt\n",
      "1684.pt\n",
      "1685.pt\n",
      "1686.pt\n",
      "1687.pt\n",
      "1688.pt\n",
      "1689.pt\n",
      "1690.pt\n",
      "1691.pt\n",
      "1692.pt\n",
      "1693.pt\n",
      "1694.pt\n",
      "1695.pt\n",
      "1696.pt\n",
      "1697.pt\n",
      "1698.pt\n",
      "1699.pt\n",
      "1700.pt\n",
      "1701.pt\n",
      "1702.pt\n",
      "1703.pt\n",
      "1704.pt\n",
      "1705.pt\n",
      "1706.pt\n",
      "1707.pt\n",
      "1708.pt\n",
      "1709.pt\n",
      "1710.pt\n",
      "1711.pt\n",
      "1712.pt\n",
      "1713.pt\n",
      "1714.pt\n",
      "1715.pt\n",
      "1716.pt\n",
      "1717.pt\n",
      "1718.pt\n",
      "1719.pt\n",
      "1720.pt\n",
      "1721.pt\n",
      "1722.pt\n",
      "1723.pt\n",
      "1724.pt\n",
      "1725.pt\n",
      "1726.pt\n",
      "1727.pt\n",
      "1728.pt\n",
      "1729.pt\n",
      "1730.pt\n",
      "1731.pt\n",
      "1732.pt\n",
      "1733.pt\n",
      "1734.pt\n",
      "1735.pt\n",
      "1736.pt\n",
      "1737.pt\n",
      "1738.pt\n",
      "1739.pt\n",
      "1740.pt\n",
      "1741.pt\n",
      "1742.pt\n",
      "1743.pt\n",
      "1744.pt\n",
      "1745.pt\n",
      "1746.pt\n",
      "1747.pt\n",
      "1748.pt\n",
      "1749.pt\n",
      "1750.pt\n",
      "1751.pt\n",
      "1752.pt\n",
      "1753.pt\n",
      "1754.pt\n",
      "1755.pt\n",
      "1756.pt\n",
      "1757.pt\n",
      "1758.pt\n",
      "1759.pt\n",
      "1760.pt\n",
      "1761.pt\n",
      "1762.pt\n",
      "1763.pt\n",
      "1764.pt\n",
      "1765.pt\n",
      "1766.pt\n",
      "1767.pt\n",
      "1768.pt\n",
      "1769.pt\n",
      "1770.pt\n",
      "1771.pt\n",
      "1772.pt\n",
      "1773.pt\n",
      "1774.pt\n",
      "1775.pt\n",
      "1776.pt\n",
      "1777.pt\n",
      "1778.pt\n",
      "1779.pt\n",
      "1780.pt\n",
      "1781.pt\n",
      "1782.pt\n",
      "1783.pt\n",
      "1784.pt\n",
      "1785.pt\n",
      "1786.pt\n",
      "1787.pt\n",
      "1788.pt\n",
      "1789.pt\n",
      "1790.pt\n",
      "1791.pt\n",
      "1792.pt\n",
      "1793.pt\n",
      "1794.pt\n",
      "1795.pt\n",
      "1796.pt\n",
      "1797.pt\n",
      "1798.pt\n",
      "1799.pt\n",
      "1800.pt\n",
      "1801.pt\n",
      "1802.pt\n",
      "1803.pt\n",
      "1804.pt\n",
      "1805.pt\n",
      "1806.pt\n",
      "1807.pt\n",
      "1808.pt\n",
      "1809.pt\n",
      "1810.pt\n",
      "1811.pt\n",
      "1812.pt\n",
      "1813.pt\n",
      "1814.pt\n",
      "1815.pt\n",
      "1816.pt\n",
      "1817.pt\n",
      "1818.pt\n",
      "1819.pt\n",
      "1820.pt\n",
      "1821.pt\n",
      "1822.pt\n",
      "1823.pt\n",
      "1824.pt\n",
      "1825.pt\n",
      "1826.pt\n",
      "1827.pt\n",
      "1828.pt\n",
      "1829.pt\n",
      "1830.pt\n",
      "1831.pt\n",
      "1832.pt\n",
      "1833.pt\n",
      "1834.pt\n",
      "1835.pt\n",
      "1836.pt\n",
      "1837.pt\n",
      "1838.pt\n",
      "1839.pt\n",
      "1840.pt\n",
      "1841.pt\n",
      "1842.pt\n",
      "1843.pt\n",
      "1844.pt\n",
      "1845.pt\n",
      "1846.pt\n",
      "1847.pt\n",
      "1848.pt\n",
      "1849.pt\n",
      "1850.pt\n",
      "1851.pt\n",
      "1852.pt\n",
      "1853.pt\n",
      "1854.pt\n",
      "1855.pt\n",
      "1856.pt\n",
      "1857.pt\n",
      "1858.pt\n",
      "1859.pt\n",
      "1860.pt\n",
      "1861.pt\n",
      "1862.pt\n",
      "1863.pt\n",
      "1864.pt\n",
      "1865.pt\n",
      "1866.pt\n",
      "1867.pt\n",
      "1868.pt\n",
      "1869.pt\n",
      "1870.pt\n",
      "1871.pt\n",
      "1872.pt\n",
      "1873.pt\n",
      "1874.pt\n",
      "1875.pt\n",
      "1876.pt\n",
      "1877.pt\n",
      "1878.pt\n",
      "1879.pt\n",
      "1880.pt\n",
      "1881.pt\n",
      "1882.pt\n",
      "1883.pt\n",
      "1884.pt\n",
      "1885.pt\n",
      "1886.pt\n",
      "1887.pt\n",
      "1888.pt\n",
      "1889.pt\n",
      "1890.pt\n",
      "1891.pt\n",
      "1892.pt\n",
      "1893.pt\n",
      "1894.pt\n",
      "1895.pt\n",
      "1896.pt\n",
      "1897.pt\n",
      "1898.pt\n",
      "1899.pt\n",
      "1900.pt\n",
      "1901.pt\n",
      "1902.pt\n",
      "1903.pt\n",
      "1904.pt\n",
      "1905.pt\n",
      "1906.pt\n",
      "1907.pt\n",
      "1908.pt\n",
      "1909.pt\n",
      "1910.pt\n",
      "1911.pt\n",
      "1912.pt\n",
      "1913.pt\n",
      "1914.pt\n",
      "1915.pt\n",
      "1916.pt\n",
      "1917.pt\n",
      "1918.pt\n",
      "1919.pt\n",
      "1920.pt\n",
      "1921.pt\n",
      "1922.pt\n",
      "1923.pt\n",
      "1924.pt\n",
      "1925.pt\n",
      "1926.pt\n",
      "1927.pt\n",
      "1928.pt\n",
      "1929.pt\n",
      "1930.pt\n",
      "1931.pt\n",
      "1932.pt\n",
      "1933.pt\n",
      "1934.pt\n",
      "1935.pt\n",
      "1936.pt\n",
      "1937.pt\n",
      "1938.pt\n",
      "1939.pt\n",
      "1940.pt\n",
      "1941.pt\n",
      "1942.pt\n",
      "1943.pt\n",
      "1944.pt\n",
      "1945.pt\n",
      "1946.pt\n",
      "1947.pt\n",
      "1948.pt\n",
      "1949.pt\n",
      "1950.pt\n",
      "1951.pt\n",
      "1952.pt\n",
      "1953.pt\n",
      "1954.pt\n",
      "1955.pt\n",
      "1956.pt\n",
      "1957.pt\n",
      "1958.pt\n",
      "1959.pt\n",
      "1960.pt\n",
      "1961.pt\n",
      "1962.pt\n",
      "1963.pt\n",
      "1964.pt\n",
      "1965.pt\n",
      "1966.pt\n",
      "1967.pt\n",
      "1968.pt\n",
      "1969.pt\n",
      "1970.pt\n",
      "1971.pt\n",
      "1972.pt\n",
      "1973.pt\n",
      "1974.pt\n",
      "1975.pt\n",
      "1976.pt\n",
      "1977.pt\n",
      "1978.pt\n",
      "1979.pt\n",
      "1980.pt\n",
      "1981.pt\n",
      "1982.pt\n",
      "1983.pt\n",
      "1984.pt\n",
      "1985.pt\n",
      "1986.pt\n",
      "1987.pt\n",
      "1988.pt\n",
      "1989.pt\n",
      "1990.pt\n",
      "1991.pt\n",
      "1992.pt\n",
      "1993.pt\n",
      "1994.pt\n",
      "1995.pt\n",
      "1996.pt\n",
      "1997.pt\n",
      "1998.pt\n",
      "1999.pt\n",
      "2000.pt\n",
      "2001.pt\n",
      "2002.pt\n",
      "2003.pt\n",
      "2004.pt\n",
      "2005.pt\n",
      "2006.pt\n",
      "2007.pt\n",
      "2008.pt\n",
      "2009.pt\n",
      "2010.pt\n",
      "2011.pt\n",
      "2012.pt\n",
      "2013.pt\n",
      "2014.pt\n",
      "2015.pt\n",
      "2016.pt\n",
      "2017.pt\n",
      "2018.pt\n",
      "2019.pt\n",
      "2020.pt\n",
      "2021.pt\n",
      "2022.pt\n",
      "2023.pt\n",
      "2024.pt\n",
      "2025.pt\n",
      "2026.pt\n",
      "2027.pt\n",
      "2028.pt\n",
      "2029.pt\n",
      "2030.pt\n",
      "2031.pt\n",
      "2032.pt\n",
      "2033.pt\n",
      "2034.pt\n",
      "2035.pt\n",
      "2036.pt\n",
      "2037.pt\n",
      "2038.pt\n",
      "2039.pt\n",
      "2040.pt\n",
      "2041.pt\n",
      "2042.pt\n",
      "2043.pt\n",
      "2044.pt\n",
      "2045.pt\n",
      "2046.pt\n",
      "2047.pt\n",
      "2048.pt\n",
      "2049.pt\n",
      "2050.pt\n",
      "2051.pt\n",
      "2052.pt\n",
      "2053.pt\n",
      "2054.pt\n",
      "2055.pt\n",
      "2056.pt\n",
      "2057.pt\n",
      "2058.pt\n",
      "2059.pt\n",
      "2060.pt\n",
      "2061.pt\n",
      "2062.pt\n",
      "2063.pt\n",
      "2064.pt\n",
      "2065.pt\n",
      "2066.pt\n",
      "2067.pt\n",
      "2068.pt\n",
      "2069.pt\n",
      "2070.pt\n",
      "2071.pt\n",
      "2072.pt\n",
      "2073.pt\n",
      "2074.pt\n",
      "2075.pt\n",
      "2076.pt\n",
      "2077.pt\n",
      "2078.pt\n",
      "2079.pt\n",
      "2080.pt\n",
      "2081.pt\n",
      "2082.pt\n",
      "2083.pt\n",
      "2084.pt\n",
      "2085.pt\n",
      "2086.pt\n",
      "2087.pt\n",
      "2088.pt\n",
      "2089.pt\n",
      "2090.pt\n",
      "2091.pt\n",
      "2092.pt\n",
      "2093.pt\n",
      "2094.pt\n",
      "2095.pt\n",
      "2096.pt\n",
      "2097.pt\n",
      "2098.pt\n",
      "2099.pt\n",
      "2100.pt\n",
      "2101.pt\n",
      "2102.pt\n",
      "2103.pt\n",
      "2104.pt\n",
      "2105.pt\n",
      "2106.pt\n",
      "2107.pt\n",
      "2108.pt\n",
      "2109.pt\n",
      "2110.pt\n",
      "2111.pt\n",
      "2112.pt\n",
      "2113.pt\n",
      "2114.pt\n",
      "2115.pt\n",
      "2116.pt\n",
      "2117.pt\n",
      "2118.pt\n",
      "2119.pt\n",
      "2120.pt\n",
      "2121.pt\n",
      "2122.pt\n",
      "2123.pt\n",
      "2124.pt\n",
      "2125.pt\n",
      "2126.pt\n",
      "2127.pt\n",
      "2128.pt\n",
      "2129.pt\n",
      "2130.pt\n",
      "2131.pt\n",
      "2132.pt\n",
      "2133.pt\n",
      "2134.pt\n",
      "2135.pt\n",
      "2136.pt\n",
      "2137.pt\n",
      "2138.pt\n",
      "2139.pt\n",
      "2140.pt\n",
      "2141.pt\n",
      "2142.pt\n",
      "2143.pt\n",
      "2144.pt\n",
      "2145.pt\n",
      "2146.pt\n",
      "2147.pt\n",
      "2148.pt\n",
      "2149.pt\n",
      "2150.pt\n",
      "2151.pt\n",
      "2152.pt\n",
      "2153.pt\n",
      "2154.pt\n",
      "2155.pt\n",
      "2156.pt\n",
      "2157.pt\n",
      "2158.pt\n",
      "2159.pt\n",
      "2160.pt\n",
      "2161.pt\n",
      "2162.pt\n",
      "2163.pt\n",
      "2164.pt\n",
      "2165.pt\n",
      "2166.pt\n",
      "2167.pt\n",
      "2168.pt\n",
      "2169.pt\n",
      "2170.pt\n",
      "2171.pt\n",
      "2172.pt\n",
      "2173.pt\n",
      "2174.pt\n",
      "2175.pt\n",
      "2176.pt\n",
      "2177.pt\n",
      "2178.pt\n",
      "2179.pt\n",
      "2180.pt\n",
      "2181.pt\n",
      "2182.pt\n",
      "2183.pt\n",
      "2184.pt\n",
      "2185.pt\n",
      "2186.pt\n",
      "2187.pt\n",
      "2188.pt\n",
      "2189.pt\n",
      "2190.pt\n",
      "2191.pt\n",
      "2192.pt\n",
      "2193.pt\n",
      "2194.pt\n",
      "2195.pt\n",
      "2196.pt\n",
      "2197.pt\n",
      "2198.pt\n",
      "2199.pt\n",
      "2200.pt\n",
      "2201.pt\n",
      "2202.pt\n",
      "2203.pt\n",
      "2204.pt\n",
      "2205.pt\n",
      "2206.pt\n",
      "2207.pt\n",
      "2208.pt\n",
      "2209.pt\n",
      "2210.pt\n",
      "2211.pt\n",
      "2212.pt\n",
      "2213.pt\n",
      "2214.pt\n",
      "2215.pt\n",
      "2216.pt\n",
      "2217.pt\n",
      "2218.pt\n",
      "2219.pt\n",
      "2220.pt\n",
      "2221.pt\n",
      "2222.pt\n",
      "2223.pt\n",
      "2224.pt\n",
      "2225.pt\n",
      "2226.pt\n",
      "2227.pt\n",
      "2228.pt\n",
      "2229.pt\n",
      "2230.pt\n",
      "2231.pt\n",
      "2232.pt\n",
      "2233.pt\n",
      "2234.pt\n",
      "2235.pt\n",
      "2236.pt\n",
      "2237.pt\n",
      "2238.pt\n",
      "2239.pt\n",
      "2240.pt\n",
      "2241.pt\n",
      "2242.pt\n",
      "2243.pt\n",
      "2244.pt\n",
      "2245.pt\n",
      "2246.pt\n",
      "2247.pt\n",
      "2248.pt\n",
      "2249.pt\n",
      "2250.pt\n",
      "2251.pt\n",
      "2252.pt\n",
      "2253.pt\n",
      "2254.pt\n",
      "2255.pt\n",
      "2256.pt\n",
      "2257.pt\n",
      "2258.pt\n",
      "2259.pt\n",
      "2260.pt\n",
      "2261.pt\n",
      "2262.pt\n",
      "2263.pt\n",
      "2264.pt\n",
      "2265.pt\n",
      "2266.pt\n",
      "2267.pt\n",
      "2268.pt\n",
      "2269.pt\n",
      "2270.pt\n",
      "2271.pt\n",
      "2272.pt\n",
      "2273.pt\n",
      "2274.pt\n",
      "2275.pt\n",
      "2276.pt\n",
      "2277.pt\n",
      "2278.pt\n",
      "2279.pt\n",
      "2280.pt\n",
      "2281.pt\n",
      "2282.pt\n",
      "2283.pt\n",
      "2284.pt\n",
      "2285.pt\n",
      "2286.pt\n",
      "2287.pt\n",
      "2288.pt\n",
      "2289.pt\n",
      "2290.pt\n",
      "2291.pt\n",
      "2292.pt\n",
      "2293.pt\n",
      "2294.pt\n",
      "2295.pt\n",
      "2296.pt\n",
      "2297.pt\n",
      "2298.pt\n",
      "2299.pt\n",
      "2300.pt\n",
      "2301.pt\n",
      "2302.pt\n",
      "2303.pt\n",
      "2304.pt\n",
      "2305.pt\n",
      "2306.pt\n",
      "2307.pt\n",
      "2308.pt\n",
      "2309.pt\n",
      "2310.pt\n",
      "2311.pt\n",
      "2312.pt\n",
      "2313.pt\n",
      "2314.pt\n",
      "2315.pt\n",
      "2316.pt\n",
      "2317.pt\n",
      "2318.pt\n",
      "2319.pt\n",
      "2320.pt\n",
      "2321.pt\n",
      "2322.pt\n",
      "2323.pt\n",
      "2324.pt\n",
      "2325.pt\n",
      "2326.pt\n",
      "2327.pt\n",
      "2328.pt\n",
      "2329.pt\n",
      "2330.pt\n",
      "2331.pt\n",
      "2332.pt\n",
      "2333.pt\n",
      "2334.pt\n",
      "2335.pt\n",
      "2336.pt\n",
      "2337.pt\n",
      "2338.pt\n",
      "2339.pt\n",
      "2340.pt\n",
      "2341.pt\n",
      "2342.pt\n",
      "2343.pt\n",
      "2344.pt\n",
      "2345.pt\n",
      "2346.pt\n",
      "2347.pt\n",
      "2348.pt\n",
      "2349.pt\n",
      "2350.pt\n",
      "2351.pt\n",
      "2352.pt\n",
      "2353.pt\n",
      "2354.pt\n",
      "2355.pt\n",
      "2356.pt\n",
      "2357.pt\n",
      "2358.pt\n",
      "2359.pt\n",
      "2360.pt\n",
      "2361.pt\n",
      "2362.pt\n",
      "2363.pt\n",
      "2364.pt\n",
      "2365.pt\n",
      "2366.pt\n",
      "2367.pt\n",
      "2368.pt\n",
      "2369.pt\n",
      "2370.pt\n",
      "2371.pt\n",
      "2372.pt\n",
      "2373.pt\n",
      "2374.pt\n",
      "2375.pt\n",
      "2376.pt\n",
      "2377.pt\n",
      "2378.pt\n",
      "2379.pt\n",
      "2380.pt\n",
      "2381.pt\n",
      "2382.pt\n",
      "2383.pt\n",
      "2384.pt\n",
      "2385.pt\n",
      "2386.pt\n",
      "2387.pt\n",
      "2388.pt\n",
      "2389.pt\n",
      "2390.pt\n",
      "2391.pt\n",
      "2392.pt\n",
      "2393.pt\n",
      "2394.pt\n",
      "2395.pt\n",
      "2396.pt\n",
      "2397.pt\n",
      "2398.pt\n",
      "2399.pt\n",
      "2400.pt\n",
      "2401.pt\n",
      "2402.pt\n",
      "2403.pt\n",
      "2404.pt\n",
      "2405.pt\n",
      "2406.pt\n",
      "2407.pt\n",
      "2408.pt\n",
      "2409.pt\n",
      "2410.pt\n",
      "2411.pt\n",
      "2412.pt\n",
      "2413.pt\n",
      "2414.pt\n",
      "2415.pt\n",
      "2416.pt\n",
      "2417.pt\n",
      "2418.pt\n",
      "2419.pt\n",
      "2420.pt\n",
      "2421.pt\n",
      "2422.pt\n",
      "2423.pt\n",
      "2424.pt\n",
      "2425.pt\n",
      "2426.pt\n",
      "2427.pt\n",
      "2428.pt\n",
      "2429.pt\n",
      "2430.pt\n",
      "2431.pt\n",
      "2432.pt\n",
      "2433.pt\n",
      "2434.pt\n",
      "2435.pt\n",
      "2436.pt\n",
      "2437.pt\n",
      "2438.pt\n",
      "2439.pt\n",
      "2440.pt\n",
      "2441.pt\n",
      "2442.pt\n",
      "2443.pt\n",
      "2444.pt\n",
      "2445.pt\n",
      "2446.pt\n",
      "2447.pt\n",
      "2448.pt\n",
      "2449.pt\n",
      "2450.pt\n",
      "2451.pt\n",
      "2452.pt\n",
      "2453.pt\n",
      "2454.pt\n",
      "2455.pt\n",
      "2456.pt\n",
      "2457.pt\n",
      "2458.pt\n",
      "2459.pt\n",
      "2460.pt\n",
      "2461.pt\n",
      "2462.pt\n",
      "2463.pt\n",
      "2464.pt\n",
      "2465.pt\n",
      "2466.pt\n",
      "2467.pt\n",
      "2468.pt\n",
      "2469.pt\n",
      "2470.pt\n",
      "2471.pt\n",
      "2472.pt\n",
      "2473.pt\n",
      "2474.pt\n",
      "2475.pt\n",
      "2476.pt\n",
      "2477.pt\n",
      "2478.pt\n",
      "2479.pt\n",
      "2480.pt\n",
      "2481.pt\n",
      "2482.pt\n",
      "2483.pt\n",
      "2484.pt\n",
      "2485.pt\n",
      "2486.pt\n",
      "2487.pt\n",
      "2488.pt\n",
      "2489.pt\n",
      "2490.pt\n",
      "2491.pt\n",
      "2492.pt\n",
      "2493.pt\n",
      "2494.pt\n",
      "2495.pt\n",
      "2496.pt\n",
      "2497.pt\n",
      "2498.pt\n",
      "2499.pt\n",
      "2500.pt\n",
      "2501.pt\n",
      "2502.pt\n",
      "2503.pt\n",
      "2504.pt\n",
      "2505.pt\n",
      "2506.pt\n",
      "2507.pt\n",
      "2508.pt\n",
      "2509.pt\n",
      "2510.pt\n",
      "2511.pt\n",
      "2512.pt\n",
      "2513.pt\n",
      "2514.pt\n",
      "2515.pt\n",
      "2516.pt\n",
      "2517.pt\n",
      "2518.pt\n",
      "2519.pt\n",
      "2520.pt\n",
      "2521.pt\n",
      "2522.pt\n",
      "2523.pt\n",
      "2524.pt\n",
      "2525.pt\n",
      "2526.pt\n",
      "2527.pt\n",
      "2528.pt\n",
      "2529.pt\n",
      "2530.pt\n",
      "2531.pt\n",
      "2532.pt\n",
      "2533.pt\n",
      "2534.pt\n",
      "2535.pt\n",
      "2536.pt\n",
      "2537.pt\n",
      "2538.pt\n",
      "2539.pt\n",
      "2540.pt\n",
      "2541.pt\n",
      "2542.pt\n",
      "2543.pt\n",
      "2544.pt\n",
      "2545.pt\n",
      "2546.pt\n",
      "2547.pt\n",
      "2548.pt\n",
      "2549.pt\n",
      "2550.pt\n",
      "2551.pt\n",
      "2552.pt\n",
      "2553.pt\n",
      "2554.pt\n",
      "2555.pt\n",
      "2556.pt\n",
      "2557.pt\n",
      "2558.pt\n",
      "2559.pt\n",
      "2560.pt\n",
      "2561.pt\n",
      "2562.pt\n",
      "2563.pt\n",
      "2564.pt\n",
      "2565.pt\n",
      "2566.pt\n",
      "2567.pt\n",
      "2568.pt\n",
      "2569.pt\n",
      "2570.pt\n",
      "2571.pt\n",
      "2572.pt\n",
      "2573.pt\n",
      "2574.pt\n",
      "2575.pt\n",
      "2576.pt\n",
      "2577.pt\n",
      "2578.pt\n",
      "2579.pt\n",
      "2580.pt\n",
      "2581.pt\n",
      "2582.pt\n",
      "2583.pt\n",
      "2584.pt\n",
      "2585.pt\n",
      "2586.pt\n",
      "2587.pt\n",
      "2588.pt\n",
      "2589.pt\n",
      "2590.pt\n",
      "2591.pt\n",
      "2592.pt\n",
      "2593.pt\n",
      "2594.pt\n",
      "2595.pt\n",
      "2596.pt\n",
      "2597.pt\n",
      "2598.pt\n",
      "2599.pt\n",
      "2600.pt\n",
      "2601.pt\n",
      "2602.pt\n",
      "2603.pt\n",
      "2604.pt\n",
      "2605.pt\n",
      "2606.pt\n",
      "2607.pt\n",
      "2608.pt\n",
      "2609.pt\n",
      "2610.pt\n",
      "2611.pt\n",
      "2612.pt\n",
      "2613.pt\n",
      "2614.pt\n",
      "2615.pt\n",
      "2616.pt\n",
      "2617.pt\n",
      "2618.pt\n",
      "2619.pt\n",
      "2620.pt\n",
      "2621.pt\n",
      "2622.pt\n",
      "2623.pt\n",
      "2624.pt\n",
      "2625.pt\n",
      "2626.pt\n",
      "2627.pt\n",
      "2628.pt\n",
      "2629.pt\n",
      "2630.pt\n",
      "2631.pt\n",
      "2632.pt\n",
      "2633.pt\n",
      "2634.pt\n",
      "2635.pt\n",
      "2636.pt\n",
      "2637.pt\n",
      "2638.pt\n",
      "2639.pt\n",
      "2640.pt\n",
      "2641.pt\n",
      "2642.pt\n",
      "2643.pt\n",
      "2644.pt\n",
      "2645.pt\n",
      "2646.pt\n",
      "2647.pt\n",
      "2648.pt\n",
      "2649.pt\n",
      "2650.pt\n",
      "2651.pt\n",
      "2652.pt\n",
      "2653.pt\n",
      "2654.pt\n",
      "2655.pt\n",
      "2656.pt\n",
      "2657.pt\n",
      "2658.pt\n",
      "2659.pt\n",
      "2660.pt\n",
      "2661.pt\n",
      "2662.pt\n",
      "2663.pt\n",
      "2664.pt\n",
      "2665.pt\n",
      "2666.pt\n",
      "2667.pt\n",
      "2668.pt\n",
      "2669.pt\n",
      "2670.pt\n",
      "2671.pt\n",
      "2672.pt\n",
      "2673.pt\n",
      "2674.pt\n",
      "2675.pt\n",
      "2676.pt\n",
      "2677.pt\n",
      "2678.pt\n",
      "2679.pt\n",
      "2680.pt\n",
      "2681.pt\n",
      "2682.pt\n",
      "2683.pt\n",
      "2684.pt\n",
      "2685.pt\n",
      "2686.pt\n",
      "2687.pt\n",
      "2688.pt\n",
      "2689.pt\n",
      "2690.pt\n",
      "2691.pt\n",
      "2692.pt\n",
      "2693.pt\n",
      "2694.pt\n",
      "2695.pt\n",
      "2696.pt\n",
      "2697.pt\n",
      "2698.pt\n",
      "2699.pt\n",
      "2700.pt\n",
      "2701.pt\n",
      "2702.pt\n",
      "2703.pt\n",
      "2704.pt\n",
      "2705.pt\n",
      "2706.pt\n",
      "2707.pt\n",
      "2708.pt\n",
      "2709.pt\n",
      "2710.pt\n",
      "2711.pt\n",
      "2712.pt\n",
      "2713.pt\n",
      "2714.pt\n",
      "2715.pt\n",
      "2716.pt\n",
      "2717.pt\n",
      "2718.pt\n",
      "2719.pt\n",
      "2720.pt\n",
      "2721.pt\n",
      "2722.pt\n",
      "2723.pt\n",
      "2724.pt\n",
      "2725.pt\n",
      "2726.pt\n",
      "2727.pt\n",
      "2728.pt\n",
      "2729.pt\n",
      "2730.pt\n",
      "2731.pt\n",
      "2732.pt\n",
      "2733.pt\n",
      "2734.pt\n",
      "2735.pt\n",
      "2736.pt\n",
      "2737.pt\n",
      "2738.pt\n",
      "2739.pt\n",
      "2740.pt\n",
      "2741.pt\n",
      "2742.pt\n",
      "2743.pt\n",
      "2744.pt\n",
      "2745.pt\n",
      "2746.pt\n",
      "2747.pt\n",
      "2748.pt\n",
      "2749.pt\n",
      "2750.pt\n",
      "2751.pt\n",
      "2752.pt\n",
      "2753.pt\n",
      "2754.pt\n",
      "2755.pt\n",
      "2756.pt\n",
      "2757.pt\n",
      "2758.pt\n",
      "2759.pt\n",
      "2760.pt\n",
      "2761.pt\n",
      "2762.pt\n",
      "2763.pt\n",
      "2764.pt\n",
      "2765.pt\n",
      "2766.pt\n",
      "2767.pt\n",
      "2768.pt\n",
      "2769.pt\n",
      "2770.pt\n",
      "2771.pt\n",
      "2772.pt\n",
      "2773.pt\n",
      "2774.pt\n",
      "2775.pt\n",
      "2776.pt\n",
      "2777.pt\n",
      "2778.pt\n",
      "2779.pt\n",
      "2780.pt\n",
      "2781.pt\n",
      "2782.pt\n",
      "2783.pt\n",
      "2784.pt\n",
      "2785.pt\n",
      "2786.pt\n",
      "2787.pt\n",
      "2788.pt\n",
      "2789.pt\n",
      "2790.pt\n",
      "2791.pt\n",
      "2792.pt\n",
      "2793.pt\n",
      "2794.pt\n",
      "2795.pt\n",
      "2796.pt\n",
      "2797.pt\n",
      "2798.pt\n",
      "2799.pt\n",
      "2800.pt\n",
      "2801.pt\n",
      "2802.pt\n",
      "2803.pt\n",
      "2804.pt\n",
      "2805.pt\n",
      "2806.pt\n",
      "2807.pt\n",
      "2808.pt\n",
      "2809.pt\n",
      "2810.pt\n",
      "2811.pt\n",
      "2812.pt\n",
      "2813.pt\n",
      "2814.pt\n",
      "2815.pt\n",
      "2816.pt\n",
      "2817.pt\n",
      "2818.pt\n",
      "2819.pt\n",
      "2820.pt\n",
      "2821.pt\n",
      "2822.pt\n",
      "2823.pt\n",
      "2824.pt\n",
      "2825.pt\n",
      "2826.pt\n",
      "2827.pt\n",
      "2828.pt\n",
      "2829.pt\n",
      "2830.pt\n",
      "2831.pt\n",
      "2832.pt\n",
      "2833.pt\n",
      "2834.pt\n",
      "2835.pt\n",
      "2836.pt\n",
      "2837.pt\n",
      "2838.pt\n",
      "2839.pt\n",
      "2840.pt\n",
      "2841.pt\n",
      "2842.pt\n",
      "2843.pt\n",
      "2844.pt\n",
      "2845.pt\n",
      "2846.pt\n",
      "2847.pt\n",
      "2848.pt\n",
      "2849.pt\n",
      "2850.pt\n",
      "2851.pt\n",
      "2852.pt\n",
      "2853.pt\n",
      "2854.pt\n",
      "2855.pt\n",
      "2856.pt\n",
      "2857.pt\n",
      "2858.pt\n",
      "2859.pt\n",
      "2860.pt\n",
      "2861.pt\n",
      "2862.pt\n",
      "2863.pt\n",
      "2864.pt\n",
      "2865.pt\n",
      "2866.pt\n",
      "2867.pt\n",
      "2868.pt\n",
      "2869.pt\n",
      "2870.pt\n",
      "2871.pt\n",
      "2872.pt\n",
      "2873.pt\n",
      "2874.pt\n",
      "2875.pt\n",
      "2876.pt\n",
      "2877.pt\n",
      "2878.pt\n",
      "2879.pt\n",
      "2880.pt\n",
      "2881.pt\n",
      "2882.pt\n",
      "2883.pt\n",
      "2884.pt\n",
      "2885.pt\n",
      "2886.pt\n",
      "2887.pt\n",
      "2888.pt\n",
      "2889.pt\n",
      "2890.pt\n",
      "2891.pt\n",
      "2892.pt\n",
      "2893.pt\n",
      "2894.pt\n",
      "2895.pt\n",
      "2896.pt\n",
      "2897.pt\n",
      "2898.pt\n",
      "2899.pt\n",
      "2900.pt\n",
      "2901.pt\n",
      "2902.pt\n",
      "2903.pt\n",
      "2904.pt\n",
      "2905.pt\n",
      "2906.pt\n",
      "2907.pt\n",
      "2908.pt\n",
      "2909.pt\n",
      "2910.pt\n",
      "2911.pt\n",
      "2912.pt\n",
      "2913.pt\n",
      "2914.pt\n",
      "2915.pt\n",
      "2916.pt\n",
      "2917.pt\n",
      "2918.pt\n",
      "2919.pt\n",
      "2920.pt\n",
      "2921.pt\n",
      "2922.pt\n",
      "2923.pt\n",
      "2924.pt\n",
      "2925.pt\n",
      "2926.pt\n",
      "2927.pt\n",
      "2928.pt\n",
      "2929.pt\n",
      "2930.pt\n",
      "2931.pt\n",
      "2932.pt\n",
      "2933.pt\n",
      "2934.pt\n",
      "2935.pt\n",
      "2936.pt\n",
      "2937.pt\n",
      "2938.pt\n",
      "2939.pt\n",
      "2940.pt\n",
      "2941.pt\n",
      "2942.pt\n",
      "2943.pt\n",
      "2944.pt\n",
      "2945.pt\n",
      "2946.pt\n",
      "2947.pt\n",
      "2948.pt\n",
      "2949.pt\n",
      "2950.pt\n",
      "2951.pt\n",
      "2952.pt\n",
      "2953.pt\n",
      "2954.pt\n",
      "2955.pt\n",
      "2956.pt\n",
      "2957.pt\n",
      "2958.pt\n",
      "2959.pt\n",
      "2960.pt\n",
      "2961.pt\n",
      "2962.pt\n",
      "2963.pt\n",
      "2964.pt\n",
      "2965.pt\n",
      "2966.pt\n",
      "2967.pt\n",
      "2968.pt\n",
      "2969.pt\n",
      "2970.pt\n",
      "2971.pt\n",
      "2972.pt\n",
      "2973.pt\n",
      "2974.pt\n",
      "2975.pt\n",
      "2976.pt\n",
      "2977.pt\n",
      "2978.pt\n",
      "2979.pt\n",
      "2980.pt\n",
      "2981.pt\n",
      "2982.pt\n",
      "2983.pt\n",
      "2984.pt\n",
      "2985.pt\n",
      "2986.pt\n",
      "2987.pt\n",
      "2988.pt\n",
      "2989.pt\n",
      "2990.pt\n",
      "2991.pt\n",
      "2992.pt\n",
      "2993.pt\n",
      "2994.pt\n",
      "2995.pt\n",
      "2996.pt\n",
      "2997.pt\n",
      "2998.pt\n",
      "2999.pt\n",
      "3000.pt\n",
      "3001.pt\n",
      "3002.pt\n",
      "3003.pt\n",
      "3004.pt\n",
      "3005.pt\n",
      "3006.pt\n",
      "3007.pt\n",
      "3008.pt\n",
      "3009.pt\n",
      "3010.pt\n",
      "3011.pt\n",
      "3012.pt\n",
      "3013.pt\n",
      "3014.pt\n",
      "3015.pt\n",
      "3016.pt\n",
      "3017.pt\n",
      "3018.pt\n",
      "3019.pt\n",
      "3020.pt\n",
      "3021.pt\n",
      "3022.pt\n",
      "3023.pt\n",
      "3024.pt\n",
      "3025.pt\n",
      "3026.pt\n",
      "3027.pt\n",
      "3028.pt\n",
      "3029.pt\n",
      "3030.pt\n",
      "3031.pt\n",
      "3032.pt\n",
      "3033.pt\n",
      "3034.pt\n",
      "3035.pt\n",
      "3036.pt\n",
      "3037.pt\n",
      "3038.pt\n",
      "3039.pt\n",
      "3040.pt\n",
      "3041.pt\n",
      "3042.pt\n",
      "3043.pt\n",
      "3044.pt\n",
      "3045.pt\n",
      "3046.pt\n",
      "3047.pt\n",
      "3048.pt\n",
      "3049.pt\n",
      "3050.pt\n",
      "3051.pt\n",
      "3052.pt\n",
      "3053.pt\n",
      "3054.pt\n",
      "3055.pt\n",
      "3056.pt\n",
      "3057.pt\n",
      "3058.pt\n",
      "3059.pt\n",
      "3060.pt\n",
      "3061.pt\n",
      "3062.pt\n",
      "3063.pt\n",
      "3064.pt\n",
      "3065.pt\n",
      "3066.pt\n",
      "3067.pt\n",
      "3068.pt\n",
      "3069.pt\n",
      "3070.pt\n",
      "3071.pt\n",
      "3072.pt\n",
      "3073.pt\n",
      "3074.pt\n",
      "3075.pt\n",
      "3076.pt\n",
      "3077.pt\n",
      "3078.pt\n",
      "3079.pt\n",
      "3080.pt\n",
      "3081.pt\n",
      "3082.pt\n",
      "3083.pt\n",
      "3084.pt\n",
      "3085.pt\n",
      "3086.pt\n",
      "3087.pt\n",
      "3088.pt\n",
      "3089.pt\n",
      "3090.pt\n",
      "3091.pt\n",
      "3092.pt\n",
      "3093.pt\n",
      "3094.pt\n",
      "3095.pt\n",
      "3096.pt\n",
      "3097.pt\n",
      "3098.pt\n",
      "3099.pt\n",
      "3100.pt\n",
      "3101.pt\n",
      "3102.pt\n",
      "3103.pt\n",
      "3104.pt\n",
      "3105.pt\n",
      "3106.pt\n",
      "3107.pt\n",
      "3108.pt\n",
      "3109.pt\n",
      "3110.pt\n",
      "3111.pt\n",
      "3112.pt\n",
      "3113.pt\n",
      "3114.pt\n",
      "3115.pt\n",
      "3116.pt\n",
      "3117.pt\n",
      "3118.pt\n",
      "3119.pt\n",
      "3120.pt\n",
      "3121.pt\n",
      "3122.pt\n",
      "3123.pt\n",
      "3124.pt\n",
      "3125.pt\n",
      "3126.pt\n",
      "3127.pt\n",
      "3128.pt\n",
      "3129.pt\n",
      "3130.pt\n",
      "3131.pt\n",
      "3132.pt\n",
      "3133.pt\n",
      "3134.pt\n",
      "3135.pt\n",
      "3136.pt\n",
      "3137.pt\n",
      "3138.pt\n",
      "3139.pt\n",
      "3140.pt\n",
      "3141.pt\n",
      "3142.pt\n",
      "3143.pt\n",
      "3144.pt\n",
      "3145.pt\n",
      "3146.pt\n",
      "3147.pt\n",
      "3148.pt\n",
      "3149.pt\n",
      "3150.pt\n",
      "3151.pt\n",
      "3152.pt\n",
      "3153.pt\n",
      "3154.pt\n",
      "3155.pt\n",
      "3156.pt\n",
      "3157.pt\n",
      "3158.pt\n",
      "3159.pt\n",
      "3160.pt\n",
      "3161.pt\n",
      "3162.pt\n",
      "3163.pt\n",
      "3164.pt\n",
      "3165.pt\n",
      "3166.pt\n",
      "3167.pt\n",
      "3168.pt\n",
      "3169.pt\n",
      "3170.pt\n",
      "3171.pt\n",
      "3172.pt\n",
      "3173.pt\n",
      "3174.pt\n",
      "3175.pt\n",
      "3176.pt\n",
      "3177.pt\n",
      "3178.pt\n",
      "3179.pt\n",
      "3180.pt\n",
      "3181.pt\n",
      "3182.pt\n",
      "3183.pt\n",
      "3184.pt\n",
      "3185.pt\n",
      "3186.pt\n",
      "3187.pt\n",
      "3188.pt\n",
      "3189.pt\n",
      "3190.pt\n",
      "3191.pt\n",
      "3192.pt\n",
      "3193.pt\n",
      "3194.pt\n",
      "3195.pt\n",
      "3196.pt\n",
      "3197.pt\n",
      "3198.pt\n",
      "3199.pt\n",
      "3200.pt\n",
      "3201.pt\n",
      "3202.pt\n",
      "3203.pt\n",
      "3204.pt\n",
      "3205.pt\n",
      "3206.pt\n",
      "3207.pt\n",
      "3208.pt\n",
      "3209.pt\n",
      "3210.pt\n",
      "3211.pt\n",
      "3212.pt\n",
      "3213.pt\n",
      "3214.pt\n",
      "3215.pt\n",
      "3216.pt\n",
      "3217.pt\n",
      "3218.pt\n",
      "3219.pt\n",
      "3220.pt\n",
      "3221.pt\n",
      "3222.pt\n",
      "3223.pt\n",
      "3224.pt\n",
      "3225.pt\n",
      "3226.pt\n",
      "3227.pt\n",
      "3228.pt\n",
      "3229.pt\n",
      "3230.pt\n",
      "3231.pt\n",
      "3232.pt\n",
      "3233.pt\n",
      "3234.pt\n",
      "3235.pt\n",
      "3236.pt\n",
      "3237.pt\n",
      "3238.pt\n",
      "3239.pt\n",
      "3240.pt\n",
      "3241.pt\n",
      "3242.pt\n",
      "3243.pt\n",
      "3244.pt\n",
      "3245.pt\n",
      "3246.pt\n",
      "3247.pt\n",
      "3248.pt\n",
      "3249.pt\n",
      "3250.pt\n",
      "3251.pt\n",
      "3252.pt\n",
      "3253.pt\n",
      "3254.pt\n",
      "3255.pt\n",
      "3256.pt\n",
      "3257.pt\n",
      "3258.pt\n",
      "3259.pt\n",
      "3260.pt\n",
      "3261.pt\n",
      "3262.pt\n",
      "3263.pt\n",
      "3264.pt\n",
      "3265.pt\n",
      "3266.pt\n",
      "3267.pt\n",
      "3268.pt\n",
      "3269.pt\n",
      "3270.pt\n",
      "3271.pt\n",
      "3272.pt\n",
      "3273.pt\n",
      "3274.pt\n",
      "3275.pt\n",
      "3276.pt\n",
      "3277.pt\n",
      "3278.pt\n",
      "3279.pt\n",
      "3280.pt\n",
      "3281.pt\n",
      "3282.pt\n",
      "3283.pt\n",
      "3284.pt\n",
      "3285.pt\n",
      "3286.pt\n",
      "3287.pt\n",
      "3288.pt\n",
      "3289.pt\n",
      "3290.pt\n",
      "3291.pt\n",
      "3292.pt\n",
      "3293.pt\n",
      "3294.pt\n",
      "3295.pt\n",
      "3296.pt\n",
      "3297.pt\n",
      "3298.pt\n",
      "3299.pt\n",
      "3300.pt\n",
      "3301.pt\n",
      "3302.pt\n",
      "3303.pt\n",
      "3304.pt\n",
      "3305.pt\n",
      "3306.pt\n",
      "3307.pt\n",
      "3308.pt\n",
      "3309.pt\n",
      "3310.pt\n",
      "3311.pt\n",
      "3312.pt\n",
      "3313.pt\n",
      "3314.pt\n",
      "3315.pt\n",
      "3316.pt\n",
      "3317.pt\n",
      "3318.pt\n",
      "3319.pt\n",
      "3320.pt\n",
      "3321.pt\n",
      "3322.pt\n",
      "3323.pt\n",
      "3324.pt\n",
      "3325.pt\n",
      "3326.pt\n",
      "3327.pt\n",
      "3328.pt\n",
      "3329.pt\n",
      "3330.pt\n",
      "3331.pt\n",
      "3332.pt\n",
      "3333.pt\n",
      "3334.pt\n",
      "3335.pt\n",
      "3336.pt\n",
      "3337.pt\n",
      "3338.pt\n",
      "3339.pt\n",
      "3340.pt\n",
      "3341.pt\n",
      "3342.pt\n",
      "3343.pt\n",
      "3344.pt\n",
      "3345.pt\n",
      "3346.pt\n",
      "3347.pt\n",
      "3348.pt\n",
      "3349.pt\n",
      "3350.pt\n",
      "3351.pt\n",
      "3352.pt\n",
      "3353.pt\n",
      "3354.pt\n",
      "3355.pt\n",
      "3356.pt\n",
      "3357.pt\n",
      "3358.pt\n",
      "3359.pt\n",
      "3360.pt\n",
      "3361.pt\n",
      "3362.pt\n",
      "3363.pt\n",
      "3364.pt\n",
      "3365.pt\n",
      "3366.pt\n",
      "3367.pt\n",
      "3368.pt\n",
      "3369.pt\n",
      "3370.pt\n",
      "3371.pt\n",
      "3372.pt\n",
      "3373.pt\n",
      "3374.pt\n",
      "3375.pt\n",
      "3376.pt\n",
      "3377.pt\n",
      "3378.pt\n",
      "3379.pt\n",
      "3380.pt\n",
      "3381.pt\n",
      "3382.pt\n",
      "3383.pt\n",
      "3384.pt\n",
      "3385.pt\n",
      "3386.pt\n",
      "3387.pt\n",
      "3388.pt\n",
      "3389.pt\n",
      "3390.pt\n",
      "3391.pt\n",
      "3392.pt\n",
      "3393.pt\n",
      "3394.pt\n",
      "3395.pt\n",
      "3396.pt\n",
      "3397.pt\n",
      "3398.pt\n",
      "3399.pt\n",
      "3400.pt\n",
      "3401.pt\n",
      "3402.pt\n",
      "3403.pt\n",
      "3404.pt\n",
      "3405.pt\n",
      "3406.pt\n",
      "3407.pt\n",
      "3408.pt\n",
      "3409.pt\n",
      "3410.pt\n",
      "3411.pt\n",
      "3412.pt\n",
      "3413.pt\n",
      "3414.pt\n",
      "3415.pt\n",
      "3416.pt\n",
      "3417.pt\n",
      "3418.pt\n",
      "3419.pt\n",
      "3420.pt\n",
      "3421.pt\n",
      "3422.pt\n",
      "3423.pt\n",
      "3424.pt\n",
      "3425.pt\n",
      "3426.pt\n",
      "3427.pt\n",
      "3428.pt\n",
      "3429.pt\n",
      "3430.pt\n",
      "3431.pt\n",
      "3432.pt\n",
      "3433.pt\n",
      "3434.pt\n",
      "3435.pt\n",
      "3436.pt\n",
      "3437.pt\n",
      "3438.pt\n",
      "3439.pt\n",
      "3440.pt\n",
      "3441.pt\n",
      "3442.pt\n",
      "3443.pt\n",
      "3444.pt\n",
      "3445.pt\n",
      "3446.pt\n",
      "3447.pt\n",
      "3448.pt\n",
      "3449.pt\n",
      "3450.pt\n",
      "3451.pt\n",
      "3452.pt\n",
      "3453.pt\n",
      "3454.pt\n",
      "3455.pt\n",
      "3456.pt\n",
      "3457.pt\n",
      "3458.pt\n",
      "3459.pt\n",
      "3460.pt\n",
      "3461.pt\n",
      "3462.pt\n",
      "3463.pt\n",
      "3464.pt\n",
      "3465.pt\n",
      "3466.pt\n",
      "3467.pt\n",
      "3468.pt\n",
      "3469.pt\n",
      "3470.pt\n",
      "3471.pt\n",
      "3472.pt\n",
      "3473.pt\n",
      "3474.pt\n",
      "3475.pt\n",
      "3476.pt\n",
      "3477.pt\n",
      "3478.pt\n",
      "3479.pt\n",
      "3480.pt\n",
      "3481.pt\n",
      "3482.pt\n",
      "3483.pt\n",
      "3484.pt\n",
      "3485.pt\n",
      "3486.pt\n",
      "3487.pt\n",
      "3488.pt\n",
      "3489.pt\n",
      "3490.pt\n",
      "3491.pt\n",
      "3492.pt\n",
      "3493.pt\n",
      "3494.pt\n",
      "3495.pt\n",
      "3496.pt\n",
      "3497.pt\n",
      "3498.pt\n",
      "3499.pt\n",
      "3500.pt\n",
      "3501.pt\n",
      "3502.pt\n",
      "3503.pt\n",
      "3504.pt\n",
      "3505.pt\n",
      "3506.pt\n",
      "3507.pt\n",
      "3508.pt\n",
      "3509.pt\n",
      "3510.pt\n",
      "3511.pt\n",
      "3512.pt\n",
      "3513.pt\n",
      "3514.pt\n",
      "3515.pt\n",
      "3516.pt\n",
      "3517.pt\n",
      "3518.pt\n",
      "3519.pt\n",
      "3520.pt\n",
      "3521.pt\n",
      "3522.pt\n",
      "3523.pt\n",
      "3524.pt\n",
      "3525.pt\n",
      "3526.pt\n",
      "3527.pt\n",
      "3528.pt\n",
      "3529.pt\n",
      "3530.pt\n",
      "3531.pt\n",
      "3532.pt\n",
      "3533.pt\n",
      "3534.pt\n",
      "3535.pt\n",
      "3536.pt\n",
      "3537.pt\n",
      "3538.pt\n",
      "3539.pt\n",
      "3540.pt\n",
      "3541.pt\n",
      "3542.pt\n",
      "3543.pt\n",
      "3544.pt\n",
      "3545.pt\n",
      "3546.pt\n",
      "3547.pt\n",
      "3548.pt\n",
      "3549.pt\n",
      "3550.pt\n",
      "3551.pt\n",
      "3552.pt\n",
      "3553.pt\n",
      "3554.pt\n",
      "3555.pt\n",
      "3556.pt\n",
      "3557.pt\n",
      "3558.pt\n",
      "3559.pt\n",
      "3560.pt\n",
      "3561.pt\n",
      "3562.pt\n",
      "3563.pt\n",
      "3564.pt\n",
      "3565.pt\n",
      "3566.pt\n",
      "3567.pt\n",
      "3568.pt\n",
      "3569.pt\n",
      "3570.pt\n",
      "3571.pt\n",
      "3572.pt\n",
      "3573.pt\n",
      "3574.pt\n",
      "3575.pt\n",
      "3576.pt\n",
      "3577.pt\n",
      "3578.pt\n",
      "3579.pt\n",
      "3580.pt\n",
      "3581.pt\n",
      "3582.pt\n",
      "3583.pt\n",
      "3584.pt\n",
      "3585.pt\n",
      "3586.pt\n",
      "3587.pt\n",
      "3588.pt\n",
      "3589.pt\n",
      "3590.pt\n",
      "3591.pt\n",
      "3592.pt\n",
      "3593.pt\n",
      "3594.pt\n",
      "3595.pt\n",
      "3596.pt\n",
      "3597.pt\n",
      "3598.pt\n",
      "3599.pt\n",
      "3600.pt\n",
      "3601.pt\n",
      "3602.pt\n",
      "3603.pt\n",
      "3604.pt\n",
      "3605.pt\n",
      "3606.pt\n",
      "3607.pt\n",
      "3608.pt\n",
      "3609.pt\n",
      "3610.pt\n",
      "3611.pt\n",
      "3612.pt\n",
      "3613.pt\n",
      "3614.pt\n",
      "3615.pt\n",
      "3616.pt\n",
      "3617.pt\n",
      "3618.pt\n",
      "3619.pt\n",
      "3620.pt\n",
      "3621.pt\n",
      "3622.pt\n",
      "3623.pt\n",
      "3624.pt\n",
      "3625.pt\n",
      "3626.pt\n",
      "3627.pt\n",
      "3628.pt\n",
      "3629.pt\n",
      "3630.pt\n",
      "3631.pt\n",
      "3632.pt\n",
      "3633.pt\n",
      "3634.pt\n",
      "3635.pt\n",
      "3636.pt\n",
      "3637.pt\n",
      "3638.pt\n",
      "3639.pt\n",
      "3640.pt\n",
      "3641.pt\n",
      "3642.pt\n",
      "3643.pt\n",
      "3644.pt\n",
      "3645.pt\n",
      "3646.pt\n",
      "3647.pt\n",
      "3648.pt\n",
      "3649.pt\n",
      "3650.pt\n",
      "3651.pt\n",
      "3652.pt\n",
      "3653.pt\n",
      "3654.pt\n",
      "3655.pt\n",
      "3656.pt\n",
      "3657.pt\n",
      "3658.pt\n",
      "3659.pt\n",
      "3660.pt\n",
      "3661.pt\n",
      "3662.pt\n",
      "3663.pt\n",
      "3664.pt\n",
      "3665.pt\n",
      "3666.pt\n",
      "3667.pt\n",
      "3668.pt\n",
      "3669.pt\n",
      "3670.pt\n",
      "3671.pt\n",
      "3672.pt\n",
      "3673.pt\n",
      "3674.pt\n",
      "3675.pt\n",
      "3676.pt\n",
      "3677.pt\n",
      "3678.pt\n",
      "3679.pt\n",
      "3680.pt\n",
      "3681.pt\n",
      "3682.pt\n",
      "3683.pt\n",
      "3684.pt\n",
      "3685.pt\n",
      "3686.pt\n",
      "3687.pt\n",
      "3688.pt\n",
      "3689.pt\n",
      "3690.pt\n",
      "3691.pt\n",
      "3692.pt\n",
      "3693.pt\n",
      "3694.pt\n",
      "3695.pt\n",
      "3696.pt\n",
      "3697.pt\n",
      "3698.pt\n",
      "3699.pt\n",
      "3700.pt\n",
      "3701.pt\n",
      "3702.pt\n",
      "3703.pt\n",
      "3704.pt\n",
      "3705.pt\n",
      "3706.pt\n",
      "3707.pt\n",
      "3708.pt\n",
      "3709.pt\n",
      "3710.pt\n",
      "3711.pt\n",
      "3712.pt\n",
      "3713.pt\n",
      "3714.pt\n",
      "3715.pt\n",
      "3716.pt\n",
      "3717.pt\n",
      "3718.pt\n",
      "3719.pt\n",
      "3720.pt\n",
      "3721.pt\n",
      "3722.pt\n",
      "3723.pt\n",
      "3724.pt\n",
      "3725.pt\n",
      "3726.pt\n",
      "3727.pt\n",
      "3728.pt\n",
      "3729.pt\n",
      "3730.pt\n",
      "3731.pt\n",
      "3732.pt\n",
      "3733.pt\n",
      "3734.pt\n",
      "3735.pt\n",
      "3736.pt\n",
      "3737.pt\n",
      "3738.pt\n",
      "3739.pt\n",
      "3740.pt\n",
      "3741.pt\n",
      "3742.pt\n",
      "3743.pt\n",
      "3744.pt\n",
      "3745.pt\n",
      "3746.pt\n",
      "3747.pt\n",
      "3748.pt\n",
      "3749.pt\n",
      "3750.pt\n",
      "3751.pt\n",
      "3752.pt\n",
      "3753.pt\n",
      "3754.pt\n",
      "3755.pt\n",
      "3756.pt\n",
      "3757.pt\n",
      "3758.pt\n",
      "3759.pt\n",
      "3760.pt\n",
      "3761.pt\n",
      "3762.pt\n",
      "3763.pt\n",
      "3764.pt\n",
      "3765.pt\n",
      "3766.pt\n",
      "3767.pt\n",
      "3768.pt\n",
      "3769.pt\n",
      "3770.pt\n",
      "3771.pt\n",
      "3772.pt\n",
      "3773.pt\n",
      "3774.pt\n",
      "3775.pt\n",
      "3776.pt\n",
      "3777.pt\n",
      "3778.pt\n",
      "3779.pt\n",
      "3780.pt\n",
      "3781.pt\n",
      "3782.pt\n",
      "3783.pt\n",
      "3784.pt\n",
      "3785.pt\n",
      "3786.pt\n",
      "3787.pt\n",
      "3788.pt\n",
      "3789.pt\n",
      "3790.pt\n",
      "3791.pt\n",
      "3792.pt\n",
      "3793.pt\n",
      "3794.pt\n",
      "3795.pt\n",
      "3796.pt\n",
      "3797.pt\n",
      "3798.pt\n",
      "3799.pt\n",
      "3800.pt\n",
      "3801.pt\n",
      "3802.pt\n",
      "3803.pt\n",
      "3804.pt\n",
      "3805.pt\n",
      "3806.pt\n",
      "3807.pt\n",
      "3808.pt\n",
      "3809.pt\n",
      "3810.pt\n",
      "3811.pt\n",
      "3812.pt\n",
      "3813.pt\n",
      "3814.pt\n",
      "3815.pt\n",
      "3816.pt\n",
      "3817.pt\n",
      "3818.pt\n",
      "3819.pt\n",
      "3820.pt\n",
      "3821.pt\n",
      "3822.pt\n",
      "3823.pt\n",
      "3824.pt\n",
      "3825.pt\n",
      "3826.pt\n",
      "3827.pt\n",
      "3828.pt\n",
      "3829.pt\n",
      "3830.pt\n",
      "3831.pt\n",
      "3832.pt\n",
      "3833.pt\n",
      "3834.pt\n",
      "3835.pt\n",
      "3836.pt\n",
      "3837.pt\n",
      "3838.pt\n",
      "3839.pt\n",
      "3840.pt\n",
      "3841.pt\n",
      "3842.pt\n",
      "3843.pt\n",
      "3844.pt\n",
      "3845.pt\n",
      "3846.pt\n",
      "3847.pt\n",
      "3848.pt\n",
      "3849.pt\n",
      "3850.pt\n",
      "3851.pt\n",
      "3852.pt\n",
      "3853.pt\n",
      "3854.pt\n",
      "3855.pt\n",
      "3856.pt\n",
      "3857.pt\n",
      "3858.pt\n",
      "3859.pt\n",
      "3860.pt\n",
      "3861.pt\n",
      "3862.pt\n",
      "3863.pt\n",
      "3864.pt\n",
      "3865.pt\n",
      "3866.pt\n",
      "3867.pt\n",
      "3868.pt\n",
      "3869.pt\n",
      "3870.pt\n",
      "3871.pt\n",
      "3872.pt\n",
      "3873.pt\n",
      "3874.pt\n",
      "3875.pt\n",
      "3876.pt\n",
      "3877.pt\n",
      "3878.pt\n",
      "3879.pt\n",
      "3880.pt\n",
      "3881.pt\n",
      "3882.pt\n",
      "3883.pt\n",
      "3884.pt\n",
      "3885.pt\n",
      "3886.pt\n",
      "3887.pt\n",
      "3888.pt\n",
      "3889.pt\n",
      "3890.pt\n",
      "3891.pt\n",
      "3892.pt\n",
      "3893.pt\n",
      "3894.pt\n",
      "3895.pt\n",
      "3896.pt\n",
      "3897.pt\n",
      "3898.pt\n",
      "3899.pt\n",
      "3900.pt\n",
      "3901.pt\n",
      "3902.pt\n",
      "3903.pt\n",
      "3904.pt\n",
      "3905.pt\n",
      "3906.pt\n",
      "3907.pt\n",
      "3908.pt\n",
      "3909.pt\n",
      "3910.pt\n",
      "3911.pt\n",
      "3912.pt\n",
      "3913.pt\n",
      "3914.pt\n",
      "3915.pt\n",
      "3916.pt\n",
      "3917.pt\n",
      "3918.pt\n",
      "3919.pt\n",
      "3920.pt\n",
      "3921.pt\n",
      "3922.pt\n",
      "3923.pt\n",
      "3924.pt\n",
      "3925.pt\n",
      "3926.pt\n",
      "3927.pt\n",
      "3928.pt\n",
      "3929.pt\n",
      "3930.pt\n",
      "3931.pt\n",
      "3932.pt\n",
      "3933.pt\n",
      "3934.pt\n",
      "3935.pt\n",
      "3936.pt\n",
      "3937.pt\n",
      "3938.pt\n",
      "3939.pt\n",
      "3940.pt\n",
      "3941.pt\n",
      "3942.pt\n",
      "3943.pt\n",
      "3944.pt\n",
      "3945.pt\n",
      "3946.pt\n",
      "3947.pt\n",
      "3948.pt\n",
      "3949.pt\n",
      "3950.pt\n",
      "3951.pt\n",
      "3952.pt\n",
      "3953.pt\n",
      "3954.pt\n",
      "3955.pt\n",
      "3956.pt\n",
      "3957.pt\n",
      "3958.pt\n",
      "3959.pt\n",
      "3960.pt\n",
      "3961.pt\n",
      "3962.pt\n",
      "3963.pt\n",
      "3964.pt\n",
      "3965.pt\n",
      "3966.pt\n",
      "3967.pt\n",
      "3968.pt\n",
      "3969.pt\n",
      "3970.pt\n",
      "3971.pt\n",
      "3972.pt\n",
      "3973.pt\n",
      "3974.pt\n",
      "3975.pt\n",
      "3976.pt\n",
      "3977.pt\n",
      "3978.pt\n",
      "3979.pt\n",
      "3980.pt\n",
      "3981.pt\n",
      "3982.pt\n",
      "3983.pt\n",
      "3984.pt\n",
      "3985.pt\n",
      "3986.pt\n",
      "3987.pt\n",
      "3988.pt\n",
      "3989.pt\n",
      "3990.pt\n",
      "3991.pt\n",
      "3992.pt\n",
      "3993.pt\n",
      "3994.pt\n",
      "3995.pt\n",
      "3996.pt\n",
      "3997.pt\n",
      "3998.pt\n",
      "3999.pt\n",
      "4000.pt\n",
      "4001.pt\n",
      "4002.pt\n",
      "4003.pt\n",
      "4004.pt\n",
      "4005.pt\n",
      "4006.pt\n",
      "4007.pt\n",
      "4008.pt\n",
      "4009.pt\n",
      "4010.pt\n",
      "4011.pt\n",
      "4012.pt\n",
      "4013.pt\n",
      "4014.pt\n",
      "4015.pt\n",
      "4016.pt\n",
      "4017.pt\n",
      "4018.pt\n",
      "4019.pt\n",
      "4020.pt\n",
      "4021.pt\n",
      "4022.pt\n",
      "4023.pt\n",
      "4024.pt\n",
      "4025.pt\n",
      "4026.pt\n",
      "4027.pt\n",
      "4028.pt\n",
      "4029.pt\n",
      "4030.pt\n",
      "4031.pt\n",
      "4032.pt\n",
      "4033.pt\n",
      "4034.pt\n",
      "4035.pt\n",
      "4036.pt\n",
      "4037.pt\n",
      "4038.pt\n",
      "4039.pt\n",
      "4040.pt\n",
      "4041.pt\n",
      "4042.pt\n",
      "4043.pt\n",
      "4044.pt\n",
      "4045.pt\n",
      "4046.pt\n",
      "4047.pt\n",
      "4048.pt\n",
      "4049.pt\n",
      "4050.pt\n",
      "4051.pt\n",
      "4052.pt\n",
      "4053.pt\n",
      "4054.pt\n",
      "4055.pt\n",
      "4056.pt\n",
      "4057.pt\n",
      "4058.pt\n",
      "4059.pt\n",
      "4060.pt\n",
      "4061.pt\n",
      "4062.pt\n",
      "4063.pt\n",
      "4064.pt\n",
      "4065.pt\n",
      "4066.pt\n",
      "4067.pt\n",
      "4068.pt\n",
      "4069.pt\n",
      "4070.pt\n",
      "4071.pt\n",
      "4072.pt\n",
      "4073.pt\n",
      "4074.pt\n",
      "4075.pt\n",
      "4076.pt\n",
      "4077.pt\n",
      "4078.pt\n",
      "4079.pt\n",
      "4080.pt\n",
      "4081.pt\n",
      "4082.pt\n",
      "4083.pt\n",
      "4084.pt\n",
      "4085.pt\n",
      "4086.pt\n",
      "4087.pt\n",
      "4088.pt\n",
      "4089.pt\n",
      "4090.pt\n",
      "4091.pt\n",
      "4092.pt\n",
      "4093.pt\n",
      "4094.pt\n",
      "4095.pt\n",
      "4096.pt\n",
      "4097.pt\n",
      "4098.pt\n",
      "4099.pt\n",
      "4100.pt\n",
      "4101.pt\n",
      "4102.pt\n",
      "4103.pt\n",
      "4104.pt\n",
      "4105.pt\n",
      "4106.pt\n",
      "4107.pt\n",
      "4108.pt\n",
      "4109.pt\n",
      "4110.pt\n",
      "4111.pt\n",
      "4112.pt\n",
      "4113.pt\n",
      "4114.pt\n",
      "4115.pt\n",
      "4116.pt\n",
      "4117.pt\n",
      "4118.pt\n",
      "4119.pt\n",
      "4120.pt\n",
      "4121.pt\n",
      "4122.pt\n",
      "4123.pt\n",
      "4124.pt\n",
      "4125.pt\n",
      "4126.pt\n",
      "4127.pt\n",
      "4128.pt\n",
      "4129.pt\n",
      "4130.pt\n",
      "4131.pt\n",
      "4132.pt\n",
      "4133.pt\n",
      "4134.pt\n",
      "4135.pt\n",
      "4136.pt\n",
      "4137.pt\n",
      "4138.pt\n",
      "4139.pt\n",
      "4140.pt\n",
      "4141.pt\n",
      "4142.pt\n",
      "4143.pt\n",
      "4144.pt\n",
      "4145.pt\n",
      "4146.pt\n",
      "4147.pt\n",
      "4148.pt\n",
      "4149.pt\n",
      "4150.pt\n",
      "4151.pt\n",
      "4152.pt\n",
      "4153.pt\n",
      "4154.pt\n",
      "4155.pt\n",
      "4156.pt\n",
      "4157.pt\n",
      "4158.pt\n",
      "4159.pt\n",
      "4160.pt\n",
      "4161.pt\n",
      "4162.pt\n",
      "4163.pt\n",
      "4164.pt\n",
      "4165.pt\n",
      "4166.pt\n",
      "4167.pt\n",
      "4168.pt\n",
      "4169.pt\n",
      "4170.pt\n",
      "4171.pt\n",
      "4172.pt\n",
      "4173.pt\n",
      "4174.pt\n",
      "4175.pt\n",
      "4176.pt\n",
      "4177.pt\n",
      "4178.pt\n",
      "4179.pt\n",
      "4180.pt\n",
      "4181.pt\n",
      "4182.pt\n",
      "4183.pt\n",
      "4184.pt\n",
      "4185.pt\n",
      "4186.pt\n",
      "4187.pt\n",
      "4188.pt\n",
      "4189.pt\n",
      "4190.pt\n",
      "4191.pt\n",
      "4192.pt\n",
      "4193.pt\n",
      "4194.pt\n",
      "4195.pt\n",
      "4196.pt\n",
      "4197.pt\n",
      "4198.pt\n",
      "4199.pt\n",
      "4200.pt\n",
      "4201.pt\n",
      "4202.pt\n",
      "4203.pt\n",
      "4204.pt\n",
      "4205.pt\n",
      "4206.pt\n",
      "4207.pt\n",
      "4208.pt\n",
      "4209.pt\n",
      "4210.pt\n",
      "4211.pt\n",
      "4212.pt\n",
      "4213.pt\n",
      "4214.pt\n",
      "4215.pt\n",
      "4216.pt\n",
      "4217.pt\n",
      "4218.pt\n",
      "4219.pt\n",
      "4220.pt\n",
      "4221.pt\n",
      "4222.pt\n",
      "4223.pt\n",
      "4224.pt\n",
      "4225.pt\n",
      "4226.pt\n",
      "4227.pt\n",
      "4228.pt\n",
      "4229.pt\n",
      "4230.pt\n",
      "4231.pt\n",
      "4232.pt\n",
      "4233.pt\n",
      "4234.pt\n",
      "4235.pt\n",
      "4236.pt\n",
      "4237.pt\n",
      "4238.pt\n",
      "4239.pt\n",
      "4240.pt\n",
      "4241.pt\n",
      "4242.pt\n",
      "4243.pt\n",
      "4244.pt\n",
      "4245.pt\n",
      "4246.pt\n",
      "4247.pt\n",
      "4248.pt\n",
      "4249.pt\n",
      "4250.pt\n",
      "4251.pt\n",
      "4252.pt\n",
      "4253.pt\n",
      "4254.pt\n",
      "4255.pt\n",
      "4256.pt\n",
      "4257.pt\n",
      "4258.pt\n",
      "4259.pt\n",
      "4260.pt\n",
      "4261.pt\n",
      "4262.pt\n",
      "4263.pt\n",
      "4264.pt\n",
      "4265.pt\n",
      "4266.pt\n",
      "4267.pt\n",
      "4268.pt\n",
      "4269.pt\n",
      "4270.pt\n",
      "4271.pt\n",
      "4272.pt\n",
      "4273.pt\n",
      "4274.pt\n",
      "4275.pt\n",
      "4276.pt\n",
      "4277.pt\n",
      "4278.pt\n",
      "4279.pt\n",
      "4280.pt\n",
      "4281.pt\n",
      "4282.pt\n",
      "4283.pt\n",
      "4284.pt\n",
      "4285.pt\n",
      "4286.pt\n",
      "4287.pt\n",
      "4288.pt\n",
      "4289.pt\n",
      "4290.pt\n",
      "4291.pt\n",
      "4292.pt\n",
      "4293.pt\n",
      "4294.pt\n",
      "4295.pt\n",
      "4296.pt\n",
      "4297.pt\n",
      "4298.pt\n",
      "4299.pt\n",
      "4300.pt\n",
      "4301.pt\n",
      "4302.pt\n",
      "4303.pt\n",
      "4304.pt\n",
      "4305.pt\n",
      "4306.pt\n",
      "4307.pt\n",
      "4308.pt\n",
      "4309.pt\n",
      "4310.pt\n",
      "4311.pt\n",
      "4312.pt\n",
      "4313.pt\n",
      "4314.pt\n",
      "4315.pt\n",
      "4316.pt\n",
      "4317.pt\n",
      "4318.pt\n",
      "4319.pt\n",
      "4320.pt\n",
      "4321.pt\n",
      "4322.pt\n",
      "4323.pt\n",
      "4324.pt\n",
      "4325.pt\n",
      "4326.pt\n",
      "4327.pt\n",
      "4328.pt\n",
      "4329.pt\n",
      "4330.pt\n",
      "4331.pt\n",
      "4332.pt\n",
      "4333.pt\n",
      "4334.pt\n",
      "4335.pt\n",
      "4336.pt\n",
      "4337.pt\n",
      "4338.pt\n",
      "4339.pt\n",
      "4340.pt\n",
      "4341.pt\n",
      "4342.pt\n",
      "4343.pt\n",
      "4344.pt\n",
      "4345.pt\n",
      "4346.pt\n",
      "4347.pt\n",
      "4348.pt\n",
      "4349.pt\n",
      "4350.pt\n",
      "4351.pt\n",
      "4352.pt\n",
      "4353.pt\n",
      "4354.pt\n",
      "4355.pt\n",
      "4356.pt\n",
      "4357.pt\n",
      "4358.pt\n",
      "4359.pt\n",
      "4360.pt\n",
      "4361.pt\n",
      "4362.pt\n",
      "4363.pt\n",
      "4364.pt\n",
      "4365.pt\n",
      "4366.pt\n",
      "4367.pt\n",
      "4368.pt\n",
      "4369.pt\n",
      "4370.pt\n",
      "4371.pt\n",
      "4372.pt\n",
      "4373.pt\n",
      "4374.pt\n",
      "4375.pt\n",
      "4376.pt\n",
      "4377.pt\n",
      "4378.pt\n",
      "4379.pt\n",
      "4380.pt\n",
      "4381.pt\n",
      "4382.pt\n",
      "4383.pt\n",
      "4384.pt\n",
      "4385.pt\n",
      "4386.pt\n",
      "4387.pt\n",
      "4388.pt\n",
      "4389.pt\n",
      "4390.pt\n",
      "4391.pt\n",
      "4392.pt\n",
      "4393.pt\n",
      "4394.pt\n",
      "4395.pt\n",
      "4396.pt\n",
      "4397.pt\n",
      "4398.pt\n",
      "4399.pt\n",
      "4400.pt\n",
      "4401.pt\n",
      "4402.pt\n",
      "4403.pt\n",
      "4404.pt\n",
      "4405.pt\n",
      "4406.pt\n",
      "4407.pt\n",
      "4408.pt\n",
      "4409.pt\n",
      "4410.pt\n",
      "4411.pt\n",
      "4412.pt\n",
      "4413.pt\n",
      "4414.pt\n",
      "4415.pt\n",
      "4416.pt\n",
      "4417.pt\n",
      "4418.pt\n",
      "4419.pt\n",
      "4420.pt\n",
      "4421.pt\n",
      "4422.pt\n",
      "4423.pt\n",
      "4424.pt\n",
      "4425.pt\n",
      "4426.pt\n",
      "4427.pt\n",
      "4428.pt\n",
      "4429.pt\n",
      "4430.pt\n",
      "4431.pt\n",
      "4432.pt\n",
      "4433.pt\n",
      "4434.pt\n",
      "4435.pt\n",
      "4436.pt\n",
      "4437.pt\n",
      "4438.pt\n",
      "4439.pt\n",
      "4440.pt\n",
      "4441.pt\n",
      "4442.pt\n",
      "4443.pt\n",
      "4444.pt\n",
      "4445.pt\n",
      "4446.pt\n",
      "4447.pt\n",
      "4448.pt\n",
      "4449.pt\n",
      "4450.pt\n",
      "4451.pt\n",
      "4452.pt\n",
      "4453.pt\n",
      "4454.pt\n",
      "4455.pt\n",
      "4456.pt\n",
      "4457.pt\n",
      "4458.pt\n",
      "4459.pt\n",
      "4460.pt\n",
      "4461.pt\n",
      "4462.pt\n",
      "4463.pt\n",
      "4464.pt\n",
      "4465.pt\n",
      "4466.pt\n",
      "4467.pt\n",
      "4468.pt\n",
      "4469.pt\n",
      "4470.pt\n",
      "4471.pt\n",
      "4472.pt\n",
      "4473.pt\n",
      "4474.pt\n",
      "4475.pt\n",
      "4476.pt\n",
      "4477.pt\n",
      "4478.pt\n",
      "4479.pt\n",
      "4480.pt\n",
      "4481.pt\n",
      "4482.pt\n",
      "4483.pt\n",
      "4484.pt\n",
      "4485.pt\n",
      "4486.pt\n",
      "4487.pt\n",
      "4488.pt\n",
      "4489.pt\n",
      "4490.pt\n",
      "4491.pt\n",
      "4492.pt\n",
      "4493.pt\n",
      "4494.pt\n",
      "4495.pt\n",
      "4496.pt\n",
      "4497.pt\n",
      "4498.pt\n",
      "4499.pt\n",
      "4500.pt\n",
      "4501.pt\n",
      "4502.pt\n",
      "4503.pt\n",
      "4504.pt\n",
      "4505.pt\n",
      "4506.pt\n",
      "4507.pt\n",
      "4508.pt\n",
      "4509.pt\n",
      "4510.pt\n",
      "4511.pt\n",
      "4512.pt\n",
      "4513.pt\n",
      "4514.pt\n",
      "4515.pt\n",
      "4516.pt\n",
      "4517.pt\n",
      "4518.pt\n",
      "4519.pt\n",
      "4520.pt\n",
      "4521.pt\n",
      "4522.pt\n",
      "4523.pt\n",
      "4524.pt\n",
      "4525.pt\n",
      "4526.pt\n",
      "4527.pt\n",
      "4528.pt\n",
      "4529.pt\n",
      "4530.pt\n",
      "4531.pt\n",
      "4532.pt\n",
      "4533.pt\n",
      "4534.pt\n",
      "4535.pt\n",
      "4536.pt\n",
      "4537.pt\n",
      "4538.pt\n",
      "4539.pt\n",
      "4540.pt\n",
      "4541.pt\n",
      "4542.pt\n",
      "4543.pt\n",
      "4544.pt\n",
      "4545.pt\n",
      "4546.pt\n",
      "4547.pt\n",
      "4548.pt\n",
      "4549.pt\n",
      "4550.pt\n",
      "4551.pt\n",
      "4552.pt\n",
      "4553.pt\n",
      "4554.pt\n",
      "4555.pt\n",
      "4556.pt\n",
      "4557.pt\n",
      "4558.pt\n",
      "4559.pt\n",
      "4560.pt\n",
      "4561.pt\n",
      "4562.pt\n",
      "4563.pt\n",
      "4564.pt\n",
      "4565.pt\n",
      "4566.pt\n",
      "4567.pt\n",
      "4568.pt\n",
      "4569.pt\n",
      "4570.pt\n",
      "4571.pt\n",
      "4572.pt\n",
      "4573.pt\n",
      "4574.pt\n",
      "4575.pt\n",
      "4576.pt\n",
      "4577.pt\n",
      "4578.pt\n",
      "4579.pt\n",
      "4580.pt\n",
      "4581.pt\n",
      "4582.pt\n",
      "4583.pt\n",
      "4584.pt\n",
      "4585.pt\n",
      "4586.pt\n",
      "4587.pt\n",
      "4588.pt\n",
      "4589.pt\n",
      "4590.pt\n",
      "4591.pt\n",
      "4592.pt\n",
      "4593.pt\n",
      "4594.pt\n",
      "4595.pt\n",
      "4596.pt\n",
      "4597.pt\n",
      "4598.pt\n",
      "4599.pt\n",
      "4600.pt\n",
      "4601.pt\n",
      "4602.pt\n",
      "4603.pt\n",
      "4604.pt\n",
      "4605.pt\n",
      "4606.pt\n",
      "4607.pt\n",
      "4608.pt\n",
      "4609.pt\n",
      "4610.pt\n",
      "4611.pt\n",
      "4612.pt\n",
      "4613.pt\n",
      "4614.pt\n",
      "4615.pt\n",
      "4616.pt\n",
      "4617.pt\n",
      "4618.pt\n",
      "4619.pt\n",
      "4620.pt\n",
      "4621.pt\n",
      "4622.pt\n",
      "4623.pt\n",
      "4624.pt\n",
      "4625.pt\n",
      "4626.pt\n",
      "4627.pt\n",
      "4628.pt\n",
      "4629.pt\n",
      "4630.pt\n",
      "4631.pt\n",
      "4632.pt\n",
      "4633.pt\n",
      "4634.pt\n",
      "4635.pt\n",
      "4636.pt\n",
      "4637.pt\n",
      "4638.pt\n",
      "4639.pt\n",
      "4640.pt\n",
      "4641.pt\n",
      "4642.pt\n",
      "4643.pt\n",
      "4644.pt\n",
      "4645.pt\n",
      "4646.pt\n",
      "4647.pt\n",
      "4648.pt\n",
      "4649.pt\n",
      "4650.pt\n",
      "4651.pt\n",
      "4652.pt\n",
      "4653.pt\n",
      "4654.pt\n",
      "4655.pt\n",
      "4656.pt\n",
      "4657.pt\n",
      "4658.pt\n",
      "4659.pt\n",
      "4660.pt\n",
      "4661.pt\n",
      "4662.pt\n",
      "4663.pt\n",
      "4664.pt\n",
      "4665.pt\n",
      "4666.pt\n",
      "4667.pt\n",
      "4668.pt\n",
      "4669.pt\n",
      "4670.pt\n",
      "4671.pt\n",
      "4672.pt\n",
      "4673.pt\n",
      "4674.pt\n",
      "4675.pt\n",
      "4676.pt\n",
      "4677.pt\n",
      "4678.pt\n",
      "4679.pt\n",
      "4680.pt\n",
      "4681.pt\n",
      "4682.pt\n",
      "4683.pt\n",
      "4684.pt\n",
      "4685.pt\n",
      "4686.pt\n",
      "4687.pt\n",
      "4688.pt\n",
      "4689.pt\n",
      "4690.pt\n",
      "4691.pt\n",
      "4692.pt\n",
      "4693.pt\n",
      "4694.pt\n",
      "4695.pt\n",
      "4696.pt\n",
      "4697.pt\n",
      "4698.pt\n",
      "4699.pt\n",
      "4700.pt\n",
      "4701.pt\n",
      "4702.pt\n",
      "4703.pt\n",
      "4704.pt\n",
      "4705.pt\n",
      "4706.pt\n",
      "4707.pt\n",
      "4708.pt\n",
      "4709.pt\n",
      "4710.pt\n",
      "4711.pt\n",
      "4712.pt\n",
      "4713.pt\n",
      "4714.pt\n",
      "4715.pt\n",
      "4716.pt\n",
      "4717.pt\n",
      "4718.pt\n",
      "4719.pt\n",
      "4720.pt\n",
      "4721.pt\n",
      "4722.pt\n",
      "4723.pt\n",
      "4724.pt\n",
      "4725.pt\n",
      "4726.pt\n",
      "4727.pt\n",
      "4728.pt\n",
      "4729.pt\n",
      "4730.pt\n",
      "4731.pt\n",
      "4732.pt\n",
      "4733.pt\n",
      "4734.pt\n",
      "4735.pt\n",
      "4736.pt\n",
      "4737.pt\n",
      "4738.pt\n",
      "4739.pt\n",
      "4740.pt\n",
      "4741.pt\n",
      "4742.pt\n",
      "4743.pt\n",
      "4744.pt\n",
      "4745.pt\n",
      "4746.pt\n",
      "4747.pt\n",
      "4748.pt\n",
      "4749.pt\n",
      "4750.pt\n",
      "4751.pt\n",
      "4752.pt\n",
      "4753.pt\n",
      "4754.pt\n",
      "4755.pt\n",
      "4756.pt\n",
      "4757.pt\n",
      "4758.pt\n",
      "4759.pt\n",
      "4760.pt\n",
      "4761.pt\n",
      "4762.pt\n",
      "4763.pt\n",
      "4764.pt\n",
      "4765.pt\n",
      "4766.pt\n",
      "4767.pt\n",
      "4768.pt\n",
      "4769.pt\n",
      "4770.pt\n",
      "4771.pt\n",
      "4772.pt\n",
      "4773.pt\n",
      "4774.pt\n",
      "4775.pt\n",
      "4776.pt\n",
      "4777.pt\n",
      "4778.pt\n",
      "4779.pt\n",
      "4780.pt\n",
      "4781.pt\n",
      "4782.pt\n",
      "4783.pt\n",
      "4784.pt\n",
      "4785.pt\n",
      "4786.pt\n",
      "4787.pt\n",
      "4788.pt\n",
      "4789.pt\n",
      "4790.pt\n",
      "4791.pt\n",
      "4792.pt\n",
      "4793.pt\n",
      "4794.pt\n",
      "4795.pt\n",
      "4796.pt\n",
      "4797.pt\n",
      "4798.pt\n",
      "4799.pt\n",
      "4800.pt\n",
      "4801.pt\n",
      "4802.pt\n",
      "4803.pt\n",
      "4804.pt\n",
      "4805.pt\n",
      "4806.pt\n",
      "4807.pt\n",
      "4808.pt\n",
      "4809.pt\n",
      "4810.pt\n",
      "4811.pt\n",
      "4812.pt\n",
      "4813.pt\n",
      "4814.pt\n",
      "4815.pt\n",
      "4816.pt\n",
      "4817.pt\n",
      "4818.pt\n",
      "4819.pt\n",
      "4820.pt\n",
      "4821.pt\n",
      "4822.pt\n",
      "4823.pt\n",
      "4824.pt\n",
      "4825.pt\n",
      "4826.pt\n",
      "4827.pt\n",
      "4828.pt\n",
      "4829.pt\n",
      "4830.pt\n",
      "4831.pt\n",
      "4832.pt\n",
      "4833.pt\n",
      "4834.pt\n",
      "4835.pt\n",
      "4836.pt\n",
      "4837.pt\n",
      "4838.pt\n",
      "4839.pt\n",
      "4840.pt\n",
      "4841.pt\n",
      "4842.pt\n",
      "4843.pt\n",
      "4844.pt\n",
      "4845.pt\n",
      "4846.pt\n",
      "4847.pt\n",
      "4848.pt\n",
      "4849.pt\n",
      "4850.pt\n",
      "4851.pt\n",
      "4852.pt\n",
      "4853.pt\n",
      "4854.pt\n",
      "4855.pt\n",
      "4856.pt\n",
      "4857.pt\n",
      "4858.pt\n",
      "4859.pt\n",
      "4860.pt\n",
      "4861.pt\n",
      "4862.pt\n",
      "4863.pt\n",
      "4864.pt\n",
      "4865.pt\n",
      "4866.pt\n",
      "4867.pt\n",
      "4868.pt\n",
      "4869.pt\n",
      "4870.pt\n",
      "4871.pt\n",
      "4872.pt\n",
      "4873.pt\n",
      "4874.pt\n",
      "4875.pt\n",
      "4876.pt\n",
      "4877.pt\n",
      "4878.pt\n",
      "4879.pt\n",
      "4880.pt\n",
      "4881.pt\n",
      "4882.pt\n",
      "4883.pt\n",
      "4884.pt\n",
      "4885.pt\n",
      "4886.pt\n",
      "4887.pt\n",
      "4888.pt\n",
      "4889.pt\n",
      "4890.pt\n",
      "4891.pt\n",
      "4892.pt\n",
      "4893.pt\n",
      "4894.pt\n",
      "4895.pt\n",
      "4896.pt\n",
      "4897.pt\n",
      "4898.pt\n",
      "4899.pt\n",
      "4900.pt\n",
      "4901.pt\n",
      "4902.pt\n",
      "4903.pt\n",
      "4904.pt\n",
      "4905.pt\n",
      "4906.pt\n",
      "4907.pt\n",
      "4908.pt\n",
      "4909.pt\n",
      "4910.pt\n",
      "4911.pt\n",
      "4912.pt\n",
      "4913.pt\n",
      "4914.pt\n",
      "4915.pt\n",
      "4916.pt\n",
      "4917.pt\n",
      "4918.pt\n",
      "4919.pt\n",
      "4920.pt\n",
      "4921.pt\n",
      "4922.pt\n",
      "4923.pt\n",
      "4924.pt\n",
      "4925.pt\n",
      "4926.pt\n",
      "4927.pt\n",
      "4928.pt\n",
      "4929.pt\n",
      "4930.pt\n",
      "4931.pt\n",
      "4932.pt\n",
      "4933.pt\n",
      "4934.pt\n",
      "4935.pt\n",
      "4936.pt\n",
      "4937.pt\n",
      "4938.pt\n",
      "4939.pt\n",
      "4940.pt\n",
      "4941.pt\n",
      "4942.pt\n",
      "4943.pt\n",
      "4944.pt\n",
      "4945.pt\n",
      "4946.pt\n",
      "4947.pt\n",
      "4948.pt\n",
      "4949.pt\n",
      "4950.pt\n",
      "4951.pt\n",
      "4952.pt\n",
      "4953.pt\n",
      "4954.pt\n",
      "4955.pt\n",
      "4956.pt\n",
      "4957.pt\n",
      "4958.pt\n",
      "4959.pt\n",
      "4960.pt\n",
      "4961.pt\n",
      "4962.pt\n",
      "4963.pt\n",
      "4964.pt\n",
      "4965.pt\n",
      "4966.pt\n",
      "4967.pt\n",
      "4968.pt\n",
      "4969.pt\n",
      "4970.pt\n",
      "4971.pt\n",
      "4972.pt\n",
      "4973.pt\n",
      "4974.pt\n",
      "4975.pt\n",
      "4976.pt\n",
      "4977.pt\n",
      "4978.pt\n",
      "4979.pt\n",
      "4980.pt\n",
      "4981.pt\n",
      "4982.pt\n",
      "4983.pt\n",
      "4984.pt\n",
      "4985.pt\n",
      "4986.pt\n",
      "4987.pt\n",
      "4988.pt\n",
      "4989.pt\n",
      "4990.pt\n",
      "4991.pt\n",
      "4992.pt\n",
      "4993.pt\n",
      "4994.pt\n",
      "4995.pt\n",
      "4996.pt\n",
      "4997.pt\n",
      "4998.pt\n",
      "4999.pt\n",
      "5000.pt\n",
      "5001.pt\n",
      "5002.pt\n",
      "5003.pt\n",
      "5004.pt\n",
      "5005.pt\n",
      "5006.pt\n",
      "5007.pt\n",
      "5008.pt\n",
      "5009.pt\n",
      "5010.pt\n",
      "5011.pt\n",
      "5012.pt\n",
      "5013.pt\n",
      "5014.pt\n",
      "5015.pt\n",
      "5016.pt\n",
      "5017.pt\n",
      "5018.pt\n",
      "5019.pt\n",
      "5020.pt\n",
      "5021.pt\n",
      "5022.pt\n",
      "5023.pt\n",
      "5024.pt\n",
      "5025.pt\n",
      "5026.pt\n",
      "5027.pt\n",
      "5028.pt\n",
      "5029.pt\n",
      "5030.pt\n",
      "5031.pt\n",
      "5032.pt\n",
      "5033.pt\n",
      "5034.pt\n",
      "5035.pt\n",
      "5036.pt\n",
      "5037.pt\n",
      "5038.pt\n",
      "5039.pt\n",
      "5040.pt\n",
      "5041.pt\n",
      "5042.pt\n",
      "5043.pt\n",
      "5044.pt\n",
      "5045.pt\n",
      "5046.pt\n",
      "5047.pt\n",
      "5048.pt\n",
      "5049.pt\n",
      "5050.pt\n",
      "5051.pt\n",
      "5052.pt\n",
      "5053.pt\n",
      "5054.pt\n",
      "5055.pt\n",
      "5056.pt\n",
      "5057.pt\n",
      "5058.pt\n",
      "5059.pt\n",
      "5060.pt\n",
      "5061.pt\n",
      "5062.pt\n",
      "5063.pt\n",
      "5064.pt\n",
      "5065.pt\n",
      "5066.pt\n",
      "5067.pt\n",
      "5068.pt\n",
      "5069.pt\n",
      "5070.pt\n",
      "5071.pt\n",
      "5072.pt\n",
      "5073.pt\n",
      "5074.pt\n",
      "5075.pt\n",
      "5076.pt\n",
      "5077.pt\n",
      "5078.pt\n",
      "5079.pt\n",
      "5080.pt\n",
      "5081.pt\n",
      "5082.pt\n",
      "5083.pt\n",
      "5084.pt\n",
      "5085.pt\n",
      "5086.pt\n",
      "5087.pt\n",
      "5088.pt\n",
      "5089.pt\n",
      "5090.pt\n",
      "5091.pt\n",
      "5092.pt\n",
      "5093.pt\n",
      "5094.pt\n",
      "5095.pt\n",
      "5096.pt\n",
      "5097.pt\n",
      "5098.pt\n",
      "5099.pt\n",
      "5100.pt\n",
      "5101.pt\n",
      "5102.pt\n",
      "5103.pt\n",
      "5104.pt\n",
      "5105.pt\n",
      "5106.pt\n",
      "5107.pt\n",
      "5108.pt\n",
      "5109.pt\n",
      "5110.pt\n",
      "5111.pt\n",
      "5112.pt\n",
      "5113.pt\n",
      "5114.pt\n",
      "5115.pt\n",
      "5116.pt\n",
      "5117.pt\n",
      "5118.pt\n",
      "5119.pt\n",
      "5120.pt\n",
      "5121.pt\n",
      "5122.pt\n",
      "5123.pt\n",
      "5124.pt\n",
      "5125.pt\n",
      "5126.pt\n",
      "5127.pt\n",
      "5128.pt\n",
      "5129.pt\n",
      "5130.pt\n",
      "5131.pt\n",
      "5132.pt\n",
      "5133.pt\n",
      "5134.pt\n",
      "5135.pt\n",
      "5136.pt\n",
      "5137.pt\n",
      "5138.pt\n",
      "5139.pt\n",
      "5140.pt\n",
      "5141.pt\n",
      "5142.pt\n",
      "5143.pt\n",
      "5144.pt\n",
      "5145.pt\n",
      "5146.pt\n",
      "5147.pt\n",
      "5148.pt\n",
      "5149.pt\n",
      "5150.pt\n",
      "5151.pt\n",
      "5152.pt\n",
      "5153.pt\n",
      "5154.pt\n",
      "5155.pt\n",
      "5156.pt\n",
      "5157.pt\n",
      "5158.pt\n",
      "5159.pt\n",
      "5160.pt\n",
      "5161.pt\n",
      "5162.pt\n",
      "5163.pt\n",
      "5164.pt\n",
      "5165.pt\n",
      "5166.pt\n",
      "5167.pt\n",
      "5168.pt\n",
      "5169.pt\n",
      "5170.pt\n",
      "5171.pt\n",
      "5172.pt\n",
      "5173.pt\n",
      "5174.pt\n",
      "5175.pt\n",
      "5176.pt\n",
      "5177.pt\n",
      "5178.pt\n",
      "5179.pt\n",
      "5180.pt\n",
      "5181.pt\n",
      "5182.pt\n",
      "5183.pt\n",
      "5184.pt\n",
      "5185.pt\n",
      "5186.pt\n",
      "5187.pt\n",
      "5188.pt\n",
      "5189.pt\n",
      "5190.pt\n",
      "5191.pt\n",
      "5192.pt\n",
      "5193.pt\n",
      "5194.pt\n",
      "5195.pt\n",
      "5196.pt\n",
      "5197.pt\n",
      "5198.pt\n",
      "5199.pt\n",
      "5200.pt\n",
      "5201.pt\n",
      "5202.pt\n",
      "5203.pt\n",
      "5204.pt\n",
      "5205.pt\n",
      "5206.pt\n",
      "5207.pt\n",
      "5208.pt\n",
      "5209.pt\n",
      "5210.pt\n",
      "5211.pt\n",
      "5212.pt\n",
      "5213.pt\n",
      "5214.pt\n",
      "5215.pt\n",
      "5216.pt\n",
      "5217.pt\n",
      "5218.pt\n",
      "5219.pt\n",
      "5220.pt\n",
      "5221.pt\n",
      "5222.pt\n",
      "5223.pt\n",
      "5224.pt\n",
      "5225.pt\n",
      "5226.pt\n",
      "5227.pt\n",
      "5228.pt\n",
      "5229.pt\n",
      "5230.pt\n",
      "5231.pt\n",
      "5232.pt\n",
      "5233.pt\n",
      "5234.pt\n",
      "5235.pt\n",
      "5236.pt\n",
      "5237.pt\n",
      "5238.pt\n",
      "5239.pt\n",
      "5240.pt\n",
      "5241.pt\n",
      "5242.pt\n",
      "5243.pt\n",
      "5244.pt\n",
      "5245.pt\n",
      "5246.pt\n",
      "5247.pt\n",
      "5248.pt\n",
      "5249.pt\n",
      "5250.pt\n",
      "5251.pt\n",
      "5252.pt\n",
      "5253.pt\n",
      "5254.pt\n",
      "5255.pt\n",
      "5256.pt\n",
      "5257.pt\n",
      "5258.pt\n",
      "5259.pt\n",
      "5260.pt\n",
      "5261.pt\n",
      "5262.pt\n",
      "5263.pt\n",
      "5264.pt\n",
      "5265.pt\n",
      "5266.pt\n",
      "5267.pt\n",
      "5268.pt\n",
      "5269.pt\n",
      "5270.pt\n",
      "5271.pt\n",
      "5272.pt\n",
      "5273.pt\n",
      "5274.pt\n",
      "5275.pt\n",
      "5276.pt\n",
      "5277.pt\n",
      "5278.pt\n",
      "5279.pt\n",
      "5280.pt\n",
      "5281.pt\n",
      "5282.pt\n",
      "5283.pt\n",
      "5284.pt\n",
      "5285.pt\n",
      "5286.pt\n",
      "5287.pt\n",
      "5288.pt\n",
      "5289.pt\n",
      "5290.pt\n",
      "5291.pt\n",
      "5292.pt\n",
      "5293.pt\n",
      "5294.pt\n",
      "5295.pt\n",
      "5296.pt\n",
      "5297.pt\n",
      "5298.pt\n",
      "5299.pt\n",
      "5300.pt\n",
      "5301.pt\n",
      "5302.pt\n",
      "5303.pt\n",
      "5304.pt\n",
      "5305.pt\n",
      "5306.pt\n",
      "5307.pt\n",
      "5308.pt\n",
      "5309.pt\n",
      "5310.pt\n",
      "5311.pt\n",
      "5312.pt\n",
      "5313.pt\n",
      "5314.pt\n",
      "5315.pt\n",
      "5316.pt\n",
      "5317.pt\n",
      "5318.pt\n",
      "5319.pt\n",
      "5320.pt\n",
      "5321.pt\n",
      "5322.pt\n",
      "5323.pt\n",
      "5324.pt\n",
      "5325.pt\n",
      "5326.pt\n",
      "5327.pt\n",
      "5328.pt\n",
      "5329.pt\n",
      "5330.pt\n",
      "5331.pt\n",
      "5332.pt\n",
      "5333.pt\n",
      "5334.pt\n",
      "5335.pt\n",
      "5336.pt\n",
      "5337.pt\n",
      "5338.pt\n",
      "5339.pt\n",
      "5340.pt\n",
      "5341.pt\n",
      "5342.pt\n",
      "5343.pt\n",
      "5344.pt\n",
      "5345.pt\n",
      "5346.pt\n",
      "5347.pt\n",
      "5348.pt\n",
      "5349.pt\n",
      "5350.pt\n",
      "5351.pt\n",
      "5352.pt\n",
      "5353.pt\n",
      "5354.pt\n",
      "5355.pt\n",
      "5356.pt\n",
      "5357.pt\n",
      "5358.pt\n",
      "5359.pt\n",
      "5360.pt\n",
      "5361.pt\n",
      "5362.pt\n",
      "5363.pt\n",
      "5364.pt\n",
      "5365.pt\n",
      "5366.pt\n",
      "5367.pt\n",
      "5368.pt\n",
      "5369.pt\n",
      "5370.pt\n",
      "5371.pt\n",
      "5372.pt\n",
      "5373.pt\n",
      "5374.pt\n",
      "5375.pt\n",
      "5376.pt\n",
      "5377.pt\n",
      "5378.pt\n",
      "5379.pt\n",
      "5380.pt\n",
      "5381.pt\n",
      "5382.pt\n",
      "5383.pt\n",
      "5384.pt\n",
      "5385.pt\n",
      "5386.pt\n",
      "5387.pt\n",
      "5388.pt\n",
      "5389.pt\n",
      "5390.pt\n",
      "5391.pt\n",
      "5392.pt\n",
      "5393.pt\n",
      "5394.pt\n",
      "5395.pt\n",
      "5396.pt\n",
      "5397.pt\n",
      "5398.pt\n",
      "5399.pt\n",
      "5400.pt\n",
      "5401.pt\n",
      "5402.pt\n",
      "5403.pt\n",
      "5404.pt\n",
      "5405.pt\n",
      "5406.pt\n",
      "5407.pt\n",
      "5408.pt\n",
      "5409.pt\n",
      "5410.pt\n",
      "5411.pt\n",
      "5412.pt\n",
      "5413.pt\n",
      "5414.pt\n",
      "5415.pt\n",
      "5416.pt\n",
      "5417.pt\n",
      "5418.pt\n",
      "5419.pt\n",
      "5420.pt\n",
      "5421.pt\n",
      "5422.pt\n",
      "5423.pt\n",
      "5424.pt\n",
      "5425.pt\n",
      "5426.pt\n",
      "5427.pt\n",
      "5428.pt\n",
      "5429.pt\n",
      "5430.pt\n",
      "5431.pt\n",
      "5432.pt\n",
      "5433.pt\n",
      "5434.pt\n",
      "5435.pt\n",
      "5436.pt\n",
      "5437.pt\n",
      "5438.pt\n",
      "5439.pt\n",
      "5440.pt\n",
      "5441.pt\n",
      "5442.pt\n",
      "5443.pt\n",
      "5444.pt\n",
      "5445.pt\n",
      "5446.pt\n",
      "5447.pt\n",
      "5448.pt\n",
      "5449.pt\n",
      "5450.pt\n",
      "5451.pt\n",
      "5452.pt\n",
      "5453.pt\n",
      "5454.pt\n",
      "5455.pt\n",
      "5456.pt\n",
      "5457.pt\n",
      "5458.pt\n",
      "5459.pt\n",
      "5460.pt\n",
      "5461.pt\n",
      "5462.pt\n",
      "5463.pt\n",
      "5464.pt\n",
      "5465.pt\n",
      "5466.pt\n",
      "5467.pt\n",
      "5468.pt\n",
      "5469.pt\n",
      "5470.pt\n",
      "5471.pt\n",
      "5472.pt\n",
      "5473.pt\n",
      "5474.pt\n",
      "5475.pt\n",
      "5476.pt\n",
      "5477.pt\n",
      "5478.pt\n",
      "5479.pt\n",
      "5480.pt\n",
      "5481.pt\n",
      "5482.pt\n",
      "5483.pt\n",
      "5484.pt\n",
      "5485.pt\n",
      "5486.pt\n",
      "5487.pt\n",
      "5488.pt\n",
      "5489.pt\n",
      "5490.pt\n",
      "5491.pt\n",
      "5492.pt\n",
      "5493.pt\n",
      "5494.pt\n",
      "5495.pt\n",
      "5496.pt\n",
      "5497.pt\n",
      "5498.pt\n",
      "5499.pt\n",
      "5500.pt\n",
      "5501.pt\n",
      "5502.pt\n",
      "5503.pt\n",
      "5504.pt\n",
      "5505.pt\n",
      "5506.pt\n",
      "5507.pt\n",
      "5508.pt\n",
      "5509.pt\n",
      "5510.pt\n",
      "5511.pt\n",
      "5512.pt\n",
      "5513.pt\n",
      "5514.pt\n",
      "5515.pt\n",
      "5516.pt\n",
      "5517.pt\n",
      "5518.pt\n",
      "5519.pt\n",
      "5520.pt\n",
      "5521.pt\n",
      "5522.pt\n",
      "5523.pt\n",
      "5524.pt\n",
      "5525.pt\n",
      "5526.pt\n",
      "5527.pt\n",
      "5528.pt\n",
      "5529.pt\n",
      "5530.pt\n",
      "5531.pt\n",
      "5532.pt\n",
      "5533.pt\n",
      "5534.pt\n",
      "5535.pt\n",
      "5536.pt\n",
      "5537.pt\n",
      "5538.pt\n",
      "5539.pt\n",
      "5540.pt\n",
      "5541.pt\n",
      "5542.pt\n",
      "5543.pt\n",
      "5544.pt\n",
      "5545.pt\n",
      "5546.pt\n",
      "5547.pt\n",
      "5548.pt\n",
      "5549.pt\n",
      "5550.pt\n",
      "5551.pt\n",
      "5552.pt\n",
      "5553.pt\n",
      "5554.pt\n",
      "5555.pt\n",
      "5556.pt\n",
      "5557.pt\n",
      "5558.pt\n",
      "5559.pt\n",
      "5560.pt\n",
      "5561.pt\n",
      "5562.pt\n",
      "5563.pt\n",
      "5564.pt\n",
      "5565.pt\n",
      "5566.pt\n",
      "5567.pt\n",
      "5568.pt\n",
      "5569.pt\n",
      "5570.pt\n",
      "5571.pt\n",
      "5572.pt\n",
      "5573.pt\n",
      "5574.pt\n",
      "5575.pt\n",
      "5576.pt\n",
      "5577.pt\n",
      "5578.pt\n",
      "5579.pt\n",
      "5580.pt\n",
      "5581.pt\n",
      "5582.pt\n",
      "5583.pt\n",
      "5584.pt\n",
      "5585.pt\n",
      "5586.pt\n",
      "5587.pt\n",
      "5588.pt\n",
      "5589.pt\n",
      "5590.pt\n",
      "5591.pt\n",
      "5592.pt\n",
      "5593.pt\n",
      "5594.pt\n",
      "5595.pt\n",
      "5596.pt\n",
      "5597.pt\n",
      "5598.pt\n",
      "5599.pt\n",
      "5600.pt\n",
      "5601.pt\n",
      "5602.pt\n",
      "5603.pt\n",
      "5604.pt\n",
      "5605.pt\n",
      "5606.pt\n",
      "5607.pt\n",
      "5608.pt\n",
      "5609.pt\n",
      "5610.pt\n",
      "5611.pt\n",
      "5612.pt\n",
      "5613.pt\n",
      "5614.pt\n",
      "5615.pt\n",
      "5616.pt\n",
      "5617.pt\n",
      "5618.pt\n",
      "5619.pt\n",
      "5620.pt\n",
      "5621.pt\n",
      "5622.pt\n",
      "5623.pt\n",
      "5624.pt\n",
      "5625.pt\n",
      "5626.pt\n",
      "5627.pt\n",
      "5628.pt\n",
      "5629.pt\n",
      "5630.pt\n",
      "5631.pt\n",
      "5632.pt\n",
      "5633.pt\n",
      "5634.pt\n",
      "5635.pt\n",
      "5636.pt\n",
      "5637.pt\n",
      "5638.pt\n",
      "5639.pt\n",
      "5640.pt\n",
      "5641.pt\n",
      "5642.pt\n",
      "5643.pt\n",
      "5644.pt\n",
      "5645.pt\n",
      "5646.pt\n",
      "5647.pt\n",
      "5648.pt\n",
      "5649.pt\n",
      "5650.pt\n",
      "5651.pt\n",
      "5652.pt\n",
      "5653.pt\n",
      "5654.pt\n",
      "5655.pt\n",
      "5656.pt\n",
      "5657.pt\n",
      "5658.pt\n",
      "5659.pt\n",
      "5660.pt\n",
      "5661.pt\n",
      "5662.pt\n",
      "5663.pt\n",
      "5664.pt\n",
      "5665.pt\n",
      "5666.pt\n",
      "5667.pt\n",
      "5668.pt\n",
      "5669.pt\n",
      "5670.pt\n",
      "5671.pt\n",
      "5672.pt\n",
      "5673.pt\n",
      "5674.pt\n",
      "5675.pt\n",
      "5676.pt\n",
      "5677.pt\n",
      "5678.pt\n",
      "5679.pt\n",
      "5680.pt\n",
      "5681.pt\n",
      "5682.pt\n",
      "5683.pt\n",
      "5684.pt\n",
      "5685.pt\n",
      "5686.pt\n",
      "5687.pt\n",
      "5688.pt\n",
      "5689.pt\n",
      "5690.pt\n",
      "5691.pt\n",
      "5692.pt\n",
      "5693.pt\n",
      "5694.pt\n",
      "5695.pt\n",
      "5696.pt\n",
      "5697.pt\n",
      "5698.pt\n",
      "5699.pt\n",
      "5700.pt\n",
      "5701.pt\n",
      "5702.pt\n",
      "5703.pt\n",
      "5704.pt\n",
      "5705.pt\n",
      "5706.pt\n",
      "5707.pt\n",
      "5708.pt\n",
      "5709.pt\n",
      "5710.pt\n",
      "5711.pt\n",
      "5712.pt\n",
      "5713.pt\n",
      "5714.pt\n",
      "5715.pt\n",
      "5716.pt\n",
      "5717.pt\n",
      "5718.pt\n",
      "5719.pt\n",
      "5720.pt\n",
      "5721.pt\n",
      "5722.pt\n",
      "5723.pt\n",
      "5724.pt\n",
      "5725.pt\n",
      "5726.pt\n",
      "5727.pt\n",
      "5728.pt\n",
      "5729.pt\n",
      "5730.pt\n",
      "5731.pt\n",
      "5732.pt\n",
      "5733.pt\n",
      "5734.pt\n",
      "5735.pt\n",
      "5736.pt\n",
      "5737.pt\n",
      "5738.pt\n",
      "5739.pt\n",
      "5740.pt\n",
      "5741.pt\n",
      "5742.pt\n",
      "5743.pt\n",
      "5744.pt\n",
      "5745.pt\n",
      "5746.pt\n",
      "5747.pt\n",
      "5748.pt\n",
      "5749.pt\n",
      "5750.pt\n",
      "5751.pt\n",
      "5752.pt\n",
      "5753.pt\n",
      "5754.pt\n",
      "5755.pt\n",
      "5756.pt\n",
      "5757.pt\n",
      "5758.pt\n",
      "5759.pt\n",
      "5760.pt\n",
      "5761.pt\n",
      "5762.pt\n",
      "5763.pt\n",
      "5764.pt\n",
      "5765.pt\n",
      "5766.pt\n",
      "5767.pt\n",
      "5768.pt\n",
      "5769.pt\n",
      "5770.pt\n",
      "5771.pt\n",
      "5772.pt\n",
      "5773.pt\n",
      "5774.pt\n",
      "5775.pt\n",
      "5776.pt\n",
      "5777.pt\n",
      "5778.pt\n",
      "5779.pt\n",
      "5780.pt\n",
      "5781.pt\n",
      "5782.pt\n",
      "5783.pt\n",
      "5784.pt\n",
      "5785.pt\n",
      "5786.pt\n",
      "5787.pt\n",
      "5788.pt\n",
      "5789.pt\n",
      "5790.pt\n",
      "5791.pt\n",
      "5792.pt\n",
      "5793.pt\n",
      "5794.pt\n",
      "5795.pt\n",
      "5796.pt\n",
      "5797.pt\n",
      "5798.pt\n",
      "5799.pt\n",
      "5800.pt\n",
      "5801.pt\n",
      "5802.pt\n",
      "5803.pt\n",
      "5804.pt\n",
      "5805.pt\n",
      "5806.pt\n",
      "5807.pt\n",
      "5808.pt\n",
      "5809.pt\n",
      "5810.pt\n",
      "5811.pt\n",
      "5812.pt\n",
      "5813.pt\n",
      "5814.pt\n",
      "5815.pt\n",
      "5816.pt\n",
      "5817.pt\n",
      "5818.pt\n",
      "5819.pt\n",
      "5820.pt\n",
      "5821.pt\n",
      "5822.pt\n",
      "5823.pt\n",
      "5824.pt\n",
      "5825.pt\n",
      "5826.pt\n",
      "5827.pt\n",
      "5828.pt\n",
      "5829.pt\n",
      "5830.pt\n",
      "5831.pt\n",
      "5832.pt\n",
      "5833.pt\n",
      "5834.pt\n",
      "5835.pt\n",
      "5836.pt\n",
      "5837.pt\n",
      "5838.pt\n",
      "5839.pt\n",
      "5840.pt\n",
      "5841.pt\n",
      "5842.pt\n",
      "5843.pt\n",
      "5844.pt\n",
      "5845.pt\n",
      "5846.pt\n",
      "5847.pt\n",
      "5848.pt\n",
      "5849.pt\n",
      "5850.pt\n",
      "5851.pt\n",
      "5852.pt\n",
      "5853.pt\n",
      "5854.pt\n",
      "5855.pt\n",
      "5856.pt\n",
      "5857.pt\n",
      "5858.pt\n",
      "5859.pt\n",
      "5860.pt\n",
      "5861.pt\n",
      "5862.pt\n",
      "5863.pt\n",
      "5864.pt\n",
      "5865.pt\n",
      "5866.pt\n",
      "5867.pt\n",
      "5868.pt\n",
      "5869.pt\n",
      "5870.pt\n",
      "5871.pt\n",
      "5872.pt\n",
      "5873.pt\n",
      "5874.pt\n",
      "5875.pt\n",
      "5876.pt\n",
      "5877.pt\n",
      "5878.pt\n",
      "5879.pt\n",
      "5880.pt\n",
      "5881.pt\n",
      "5882.pt\n",
      "5883.pt\n",
      "5884.pt\n",
      "5885.pt\n",
      "5886.pt\n",
      "5887.pt\n",
      "5888.pt\n",
      "5889.pt\n",
      "5890.pt\n",
      "5891.pt\n",
      "5892.pt\n",
      "5893.pt\n",
      "5894.pt\n",
      "5895.pt\n",
      "5896.pt\n",
      "5897.pt\n",
      "5898.pt\n",
      "5899.pt\n",
      "5900.pt\n",
      "5901.pt\n",
      "5902.pt\n",
      "5903.pt\n",
      "5904.pt\n",
      "5905.pt\n",
      "5906.pt\n",
      "5907.pt\n",
      "5908.pt\n",
      "5909.pt\n",
      "5910.pt\n",
      "5911.pt\n",
      "5912.pt\n",
      "5913.pt\n",
      "5914.pt\n",
      "5915.pt\n",
      "5916.pt\n",
      "5917.pt\n",
      "5918.pt\n",
      "5919.pt\n",
      "5920.pt\n",
      "5921.pt\n",
      "5922.pt\n",
      "5923.pt\n",
      "5924.pt\n",
      "5925.pt\n",
      "5926.pt\n",
      "5927.pt\n",
      "5928.pt\n",
      "5929.pt\n",
      "5930.pt\n",
      "5931.pt\n",
      "5932.pt\n",
      "5933.pt\n",
      "5934.pt\n",
      "5935.pt\n",
      "5936.pt\n",
      "5937.pt\n",
      "5938.pt\n",
      "5939.pt\n",
      "5940.pt\n",
      "5941.pt\n",
      "5942.pt\n",
      "5943.pt\n",
      "5944.pt\n",
      "5945.pt\n",
      "5946.pt\n",
      "5947.pt\n",
      "5948.pt\n",
      "5949.pt\n",
      "5950.pt\n",
      "5951.pt\n",
      "5952.pt\n",
      "5953.pt\n",
      "5954.pt\n",
      "5955.pt\n",
      "5956.pt\n",
      "5957.pt\n",
      "5958.pt\n",
      "5959.pt\n",
      "5960.pt\n",
      "5961.pt\n",
      "5962.pt\n",
      "5963.pt\n",
      "5964.pt\n",
      "5965.pt\n",
      "5966.pt\n",
      "5967.pt\n",
      "5968.pt\n",
      "5969.pt\n",
      "5970.pt\n",
      "5971.pt\n",
      "5972.pt\n",
      "5973.pt\n",
      "5974.pt\n",
      "5975.pt\n",
      "5976.pt\n",
      "5977.pt\n",
      "5978.pt\n",
      "5979.pt\n",
      "5980.pt\n",
      "5981.pt\n",
      "5982.pt\n",
      "5983.pt\n",
      "5984.pt\n",
      "5985.pt\n",
      "5986.pt\n",
      "5987.pt\n",
      "5988.pt\n",
      "5989.pt\n",
      "5990.pt\n",
      "5991.pt\n",
      "5992.pt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m outputs \u001b[39m=\u001b[39m model(X_test)\n\u001b[0;32m     80\u001b[0m predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mround(outputs)\n\u001b[1;32m---> 81\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, predicted\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy())\n\u001b[0;32m     82\u001b[0m \u001b[39m# print('Accuracy:', accuracy)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_accuracy:\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(1, -1).numpy())  # Adjusted this line\n",
    "        print(filename)\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data  = np.array(data)\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to tensors\n",
    "data = torch.tensor(data).float()    # Using PyTorch's float() method\n",
    "labels = torch.tensor(labels).float() # Using PyTorch's float() method\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a simple feed-forward neural network\n",
    "# Define a simple feed-forward neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(40, 20),  # Adjusted input size\n",
    "    nn.ReLU6(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU6(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU6(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU6(),\n",
    "    nn.Linear(10, 1),\n",
    "    nn.Dropout(0.5),   \n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.02, weight_decay=1e-6)\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(200):  # 127 epochs\n",
    "    model.train() \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs.squeeze(), y_train)  \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval() \n",
    "    outputs = model(X_test)\n",
    "    predicted = torch.round(outputs)\n",
    "    accuracy = accuracy_score(y_test, predicted.detach().numpy())\n",
    "    # print('Accuracy:', accuracy)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save model parameters\n",
    "\n",
    "# Test the model\n",
    "outputs = model(X_test)\n",
    "\n",
    "predicted = torch.round(outputs).squeeze()\n",
    "accuracy = accuracy_score(y_test, predicted.detach().numpy())\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, predicted.detach().numpy()))\n",
    "print(best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "                                              0.0/1.2 MB ? eta -:--:--\n",
      "     -                                        0.0/1.2 MB ? eta -:--:--\n",
      "     -                                        0.0/1.2 MB ? eta -:--:--\n",
      "     -                                        0.0/1.2 MB ? eta -:--:--\n",
      "     --                                       0.1/1.2 MB 297.7 kB/s eta 0:00:04\n",
      "     -------                                  0.2/1.2 MB 981.9 kB/s eta 0:00:01\n",
      "     -------                                  0.2/1.2 MB 981.9 kB/s eta 0:00:01\n",
      "     -------                                  0.2/1.2 MB 981.9 kB/s eta 0:00:01\n",
      "     -------                                  0.2/1.2 MB 981.9 kB/s eta 0:00:01\n",
      "     ---------                                0.3/1.2 MB 655.8 kB/s eta 0:00:02\n",
      "     ---------                                0.3/1.2 MB 655.8 kB/s eta 0:00:02\n",
      "     ---------                                0.3/1.2 MB 655.8 kB/s eta 0:00:02\n",
      "     ---------                                0.3/1.2 MB 655.8 kB/s eta 0:00:02\n",
      "     ---------                                0.3/1.2 MB 465.5 kB/s eta 0:00:02\n",
      "     ----------                               0.3/1.2 MB 520.4 kB/s eta 0:00:02\n",
      "     ----------                               0.3/1.2 MB 520.4 kB/s eta 0:00:02\n",
      "     ----------                               0.3/1.2 MB 520.4 kB/s eta 0:00:02\n",
      "     ----------                               0.3/1.2 MB 520.4 kB/s eta 0:00:02\n",
      "     -----------------                        0.5/1.2 MB 630.7 kB/s eta 0:00:02\n",
      "     -----------------                        0.5/1.2 MB 630.7 kB/s eta 0:00:02\n",
      "     -----------------                        0.5/1.2 MB 630.7 kB/s eta 0:00:02\n",
      "     -----------------                        0.5/1.2 MB 630.7 kB/s eta 0:00:02\n",
      "     ------------------------                 0.7/1.2 MB 695.2 kB/s eta 0:00:01\n",
      "     ------------------------                 0.7/1.2 MB 695.2 kB/s eta 0:00:01\n",
      "     ------------------------                 0.7/1.2 MB 695.2 kB/s eta 0:00:01\n",
      "     ------------------------                 0.7/1.2 MB 695.2 kB/s eta 0:00:01\n",
      "     ------------------------                 0.7/1.2 MB 695.2 kB/s eta 0:00:01\n",
      "     ---------------------------              0.8/1.2 MB 672.0 kB/s eta 0:00:01\n",
      "     ---------------------------              0.8/1.2 MB 672.0 kB/s eta 0:00:01\n",
      "     ---------------------------              0.8/1.2 MB 672.0 kB/s eta 0:00:01\n",
      "     ---------------------------              0.8/1.2 MB 672.0 kB/s eta 0:00:01\n",
      "     -----------------------------            0.9/1.2 MB 604.9 kB/s eta 0:00:01\n",
      "     -----------------------------            0.9/1.2 MB 604.9 kB/s eta 0:00:01\n",
      "     -----------------------------            0.9/1.2 MB 604.9 kB/s eta 0:00:01\n",
      "     -----------------------------            0.9/1.2 MB 604.9 kB/s eta 0:00:01\n",
      "     ------------------------------           0.9/1.2 MB 554.5 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.1/1.2 MB 667.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 696.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# ResNet34\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tenserflow (from versions: none)\n",
      "ERROR: No matching distribution found for tenserflow\n"
     ]
    }
   ],
   "source": [
    "pip install tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 32\n",
    "image_shape = (374, 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2)                 23591810  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50 = tensorflow.keras.applications.resnet50.ResNet50(weights=None, input_shape=image_shape, classes=2)\n",
    "n_epoch = 10\n",
    "batch_size = 32\n",
    "image_shape = (374, 500, 3)\n",
    "model = Sequential()\n",
    "model.add(resnet50)\n",
    "# model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.build(input_shape=image_shape)\n",
    "model.summary()\n",
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (40,)\n",
      "Shape of labels:  (5993,)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 3s 9ms/step - loss: 14.3153 - accuracy: 0.5244 - val_loss: 5.4052 - val_accuracy: 0.5947\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 10.5618 - accuracy: 0.5584 - val_loss: 3.3638 - val_accuracy: 0.6047\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 10ms/step - loss: 7.5303 - accuracy: 0.5688 - val_loss: 1.2990 - val_accuracy: 0.6947\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 6.0551 - accuracy: 0.5847 - val_loss: 0.7335 - val_accuracy: 0.7314\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 4.5454 - accuracy: 0.5951 - val_loss: 0.6876 - val_accuracy: 0.7014\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 3.7642 - accuracy: 0.6018 - val_loss: 0.6287 - val_accuracy: 0.7139\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 3.0481 - accuracy: 0.6018 - val_loss: 0.5475 - val_accuracy: 0.7364\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.4650 - accuracy: 0.6193 - val_loss: 0.5544 - val_accuracy: 0.7106\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.1077 - accuracy: 0.6241 - val_loss: 0.5840 - val_accuracy: 0.6455\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 1.7924 - accuracy: 0.6256 - val_loss: 0.5870 - val_accuracy: 0.6405\n",
      "Test loss: 0.5870027542114258\n",
      "Test accuracy: 0.6405338048934937\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set directory\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "# Load data\n",
    "data = []\n",
    "labels = []\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        data.append(feature.view(-1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples,)\n",
    "\n",
    "# Define MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=data[0].shape[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=adam)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first reshaped item in data: (1, 40)\n",
      "Shape of labels:  (5993,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`input_shape` must be a tuple of three integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     43\u001b[0m \u001b[39m# Create the ResNet50 model\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[0;32m     46\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n",
      "Cell \u001b[1;32mIn[17], line 34\u001b[0m, in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m():\n\u001b[1;32m---> 34\u001b[0m     resnet50 \u001b[39m=\u001b[39m ResNet50(weights\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]), classes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m     model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m     36\u001b[0m     model\u001b[39m.\u001b[39madd(resnet50)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\applications\\resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m     x \u001b[39m=\u001b[39m stack1(x, \u001b[39m256\u001b[39m, \u001b[39m6\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m stack1(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[39mreturn\u001b[39;00m ResNet(\n\u001b[0;32m    522\u001b[0m     stack_fn,\n\u001b[0;32m    523\u001b[0m     \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    524\u001b[0m     \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresnet50\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     include_top,\n\u001b[0;32m    527\u001b[0m     weights,\n\u001b[0;32m    528\u001b[0m     input_tensor,\n\u001b[0;32m    529\u001b[0m     input_shape,\n\u001b[0;32m    530\u001b[0m     pooling,\n\u001b[0;32m    531\u001b[0m     classes,\n\u001b[0;32m    532\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    533\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\applications\\resnet.py:159\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m \u001b[39m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m input_shape \u001b[39m=\u001b[39m imagenet_utils\u001b[39m.\u001b[39;49mobtain_input_shape(\n\u001b[0;32m    160\u001b[0m     input_shape,\n\u001b[0;32m    161\u001b[0m     default_size\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m,\n\u001b[0;32m    162\u001b[0m     min_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    163\u001b[0m     data_format\u001b[39m=\u001b[39;49mbackend\u001b[39m.\u001b[39;49mimage_data_format(),\n\u001b[0;32m    164\u001b[0m     require_flatten\u001b[39m=\u001b[39;49minclude_top,\n\u001b[0;32m    165\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:397\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m input_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(input_shape) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`input_shape` must be a tuple of three integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     \u001b[39mif\u001b[39;00m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    402\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe input must have 3 channels; Received \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: `input_shape` must be a tuple of three integers."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "directory = r'F:\\dains'  # Replace with the directory path containing the .pt files\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5993):\n",
    "    filename = f'{i}.pt'\n",
    "    if filename in os.listdir(directory):  # Ensure the file exists in the directory\n",
    "        feature = torch.load(os.path.join(directory, filename))\n",
    "        # Assuming that each .pt file contains a 1D array of features,\n",
    "        # and that the length of this array is compatible with the input shape expected by ResNet50\n",
    "        data.append(feature.view(1, -1).numpy())\n",
    "        labels.append(1 if i <= 2310 else 0)\n",
    "\n",
    "labels = np.array(labels)\n",
    "data = np.array(data)\n",
    "\n",
    "print(\"Shape of the first reshaped item in data:\", data[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of labels: \", labels.shape)  # It should be (n_samples, n_classes)\n",
    "\n",
    "def get_model():\n",
    "    resnet50 = ResNet50(weights=None, input_shape=(1, X_train.shape[2]), classes=2)\n",
    "    model = Sequential()\n",
    "    model.add(resnet50)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    adam = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=adam)\n",
    "    return model\n",
    "\n",
    "# Create the ResNet50 model\n",
    "model = get_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
