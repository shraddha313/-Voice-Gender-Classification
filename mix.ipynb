{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np \n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch # import PyTorch\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import fnmatch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(file_path, output_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "def extract_melscale_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "    return mels_db.flatten() # Flatten the feature array\n",
    "\n",
    "def extract_melspectrogram(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    return spectrogram.flatten() # Flatten the spectrogram\n",
    "\n",
    "def extract_audio_features(file_name):\n",
    "    y, sr = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "    # Change here: Find max pitch for each frame and then take their mean as overall pitch\n",
    "    pitch = np.mean([pitch[magnitude.argmax()] for pitch, magnitude in zip(pitches, magnitudes)])\n",
    "    fft = np.abs(np.fft.fft(y))[:len(y)//2]\n",
    "\n",
    "    # Combine features\n",
    "    combined_features = np.hstack([mfccs.mean(axis=1), spectral_centroids.mean(), spectral_rolloff.mean(), zero_crossing_rate.mean(), pitch, fft.mean()])\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_name):\n",
    "    # Convert m4a file to wav            \n",
    "    audio = AudioSegment.from_file(file_name)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "    data, samplerate = sf.read(\"temp.wav\")\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=samplerate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "    \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39m# Save each type of feature\u001b[39;00m\n\u001b[0;32m     95\u001b[0m save_melscale_features(wav_files, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmelscale_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m save_melspectrogram_images(wav_files, \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mF:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmelspectrogram_images\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     97\u001b[0m save_combined_mfcc_melscale_features(wav_files, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcombined_mfcc_melscale_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m save_spectral_features(wav_files, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mspectral_features\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m, in \u001b[0;36msave_melspectrogram_images\u001b[1;34m(file_paths, output_directory)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m# Save as image\u001b[39;00m\n\u001b[0;32m     29\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[1;32m---> 30\u001b[0m librosa\u001b[39m.\u001b[39;49mdisplay\u001b[39m.\u001b[39;49mspecshow(librosa\u001b[39m.\u001b[39;49mpower_to_db(melspectrogram, ref\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mmax), y_axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmel\u001b[39;49m\u001b[39m'\u001b[39;49m, fmax\u001b[39m=\u001b[39;49m\u001b[39m8000\u001b[39;49m, x_axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m plt\u001b[39m.\u001b[39mcolorbar(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%+2.0f\u001b[39;00m\u001b[39m dB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mMel spectrogram\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\display.py:1211\u001b[0m, in \u001b[0;36mspecshow\u001b[1;34m(data, x_coords, y_coords, x_axis, y_axis, sr, hop_length, n_fft, win_length, fmin, fmax, tuning, bins_per_octave, key, Sa, mela, thaat, auto_aspect, htk, unicode, intervals, unison, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[39m# Get the x and y coordinates\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m y_coords \u001b[39m=\u001b[39m __mesh_coords(y_axis, y_coords, data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_params)\n\u001b[1;32m-> 1211\u001b[0m x_coords \u001b[39m=\u001b[39m __mesh_coords(x_axis, x_coords, data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_params)\n\u001b[0;32m   1213\u001b[0m axes \u001b[39m=\u001b[39m __check_axes(ax)\n\u001b[0;32m   1215\u001b[0m out \u001b[39m=\u001b[39m axes\u001b[39m.\u001b[39mpcolormesh(x_coords, y_coords, data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "directory = r'F:\\dataset_sri'\n",
    "\n",
    "def save_melscale_features(file_paths, output_directory):\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract melscale features\n",
    "        melscale_features = extract_melscale_features(wav_file_path)\n",
    "\n",
    "        # Save as .pt file\n",
    "        output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "        torch.save(torch.tensor(melscale_features), output_file)\n",
    "\n",
    "def save_melspectrogram_images(file_paths, output_directory):\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract melspectrogram\n",
    "        melspectrogram = extract_melspectrogram(wav_file_path)\n",
    "\n",
    "        # Save as image\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(librosa.power_to_db(melspectrogram, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel spectrogram')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.png')), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "def save_combined_mfcc_melscale_features(file_paths, output_directory, n_components=40):\n",
    "    all_features = []\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract mfccs and melscale features\n",
    "        mfccs = extract_mfcc(wav_file_path)\n",
    "        melscale_features = extract_melscale_features(wav_file_path)\n",
    "        combined_features = np.concatenate([mfccs, melscale_features])\n",
    "\n",
    "        all_features.append(combined_features)\n",
    "\n",
    "    # Use PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=n_components)\n",
    "    all_features = pca.fit_transform(np.vstack(all_features))\n",
    "\n",
    "    for i, file in enumerate(file_paths):\n",
    "        # Save as .pt file\n",
    "        output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "        torch.save(torch.tensor(all_features[i]), output_file)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def save_spectral_features(file_paths, output_directory):\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract spectral features\n",
    "        y, sr = librosa.load(wav_file_path)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "        pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "        pitch = np.mean([pitch[magnitude.argmax()] for pitch, magnitude in zip(pitches, magnitudes)])\n",
    "        fft = np.abs(np.fft.fft(y))[:len(y)//2]\n",
    "        combined_features = np.concatenate([spectral_centroids, spectral_rolloff, zero_crossing_rate, pitch, fft])\n",
    "\n",
    "        # Save as .pt file\n",
    "        output_file = os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.pt'))\n",
    "        torch.save(torch.tensor(combined_features), output_file)\n",
    "\n",
    "\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "# Create directories for each type of feature\n",
    "os.makedirs(r'F:/melscale_features', exist_ok=True)\n",
    "os.makedirs(r'F:/melspectrogram_images', exist_ok=True)\n",
    "os.makedirs(r'F:/combined_mfcc_melscale_features', exist_ok=True)\n",
    "os.makedirs(r'F:/spectral_features', exist_ok=True)\n",
    "\n",
    "# Save each type of feature\n",
    "save_melscale_features(wav_files, r'F:\\melscale_features')\n",
    "save_melspectrogram_images(wav_files, r'F:\\melspectrogram_images')\n",
    "save_combined_mfcc_melscale_features(wav_files, r'F:\\combined_mfcc_melscale_features')\n",
    "save_spectral_features(wav_files, r'F:\\spectral_features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import fnmatch\n",
    "import os\n",
    "import torch\n",
    "import fnmatch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def convert_m4a_to_wav(file_path, output_path):\n",
    "    audio = AudioSegment.from_file(file_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "def extract_melspectrogram(file_path, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    return melspectrogram\n",
    "\n",
    "def save_melspectrogram_images(file_paths, output_directory):\n",
    "    for file in file_paths:\n",
    "        # Convert m4a file to wav\n",
    "        wav_file_path = file.replace('.m4a', '.wav')\n",
    "        convert_m4a_to_wav(file, wav_file_path)\n",
    "\n",
    "        # Extract melspectrogram\n",
    "        melspectrogram = extract_melspectrogram(wav_file_path)\n",
    "\n",
    "        # Save as image\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(librosa.power_to_db(melspectrogram, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel spectrogram')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_directory, os.path.basename(file).replace('.m4a', '.png')), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "directory = r'F:\\dataset_sri'\n",
    "\n",
    "wav_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for file in fnmatch.filter(files, '*.m4a')]\n",
    "\n",
    "os.makedirs(r'F:\\melspectrogram_images', exist_ok=True)\n",
    "\n",
    "save_melspectrogram_images(wav_files, r'F:\\melspectrogram_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(np.array(img).flatten())\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "folder_path = 'F:/melspectrogram_images'  # replace with your folder path\n",
    "data = load_images(folder_path)\n",
    "\n",
    "# Assign labels: first 2311 files are female, next files are male\n",
    "labels = [1 if i < 2311 else 0 for i in range(5993)]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
